{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1cSnEIDnT7SYyUpfap5KiK6Y_LWLQdk6s",
      "authorship_tag": "ABX9TyMGoq7z+lbHzpI0+k0DvwJ/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/graphlit/graphlit-samples/blob/main/python/Notebook%20Examples/Graphlit_2024_10_25_Using_Tools_with_Conversations_for_User_Memory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Description**\n",
        "\n",
        "This example shows how to use Graphlit to call tools within a prompted conversation."
      ],
      "metadata": {
        "id": "pDz1gRPjOtn5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Requirements**\n",
        "\n",
        "Prior to running this notebook, you will need to [signup](https://docs.graphlit.dev/getting-started/signup) for Graphlit, and [create a project](https://docs.graphlit.dev/getting-started/create-project).\n",
        "\n",
        "You will need the Graphlit organization ID, preview environment ID and JWT secret from your created project.\n",
        "\n",
        "Assign these properties as Colab secrets: GRAPHLIT_ORGANIZATION_ID, GRAPHLIT_ENVIRONMENT_ID and GRAPHLIT_JWT_SECRET.\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "laG2MXUIhNnx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install Graphlit Python client SDK"
      ],
      "metadata": {
        "id": "NwRzDHWWienC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fefizrrh4xGD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eebe1529-f8bc-458d-d57e-f8a790ee4ac2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting graphlit-client\n",
            "  Downloading graphlit_client-1.0.20241023001-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting httpx (from graphlit-client)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from graphlit-client) (2.9.2)\n",
            "Requirement already satisfied: PyJWT in /usr/local/lib/python3.10/dist-packages (from graphlit-client) (2.9.0)\n",
            "Collecting websockets (from graphlit-client)\n",
            "  Downloading websockets-13.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->graphlit-client) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->graphlit-client) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->graphlit-client) (4.12.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->graphlit-client) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->graphlit-client) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx->graphlit-client)\n",
            "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->graphlit-client) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->graphlit-client) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->graphlit-client)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->graphlit-client) (1.2.2)\n",
            "Downloading graphlit_client-1.0.20241023001-py3-none-any.whl (202 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.9/202.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-13.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (164 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.1/164.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: websockets, h11, httpcore, httpx, graphlit-client\n",
            "Successfully installed graphlit-client-1.0.20241023001 h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 websockets-13.1\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade graphlit-client"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize Graphlit"
      ],
      "metadata": {
        "id": "abV1114jL-bR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from graphlit import Graphlit\n",
        "from graphlit_api import input_types, enums, exceptions\n",
        "\n",
        "os.environ['GRAPHLIT_ORGANIZATION_ID'] = userdata.get('GRAPHLIT_ORGANIZATION_ID')\n",
        "os.environ['GRAPHLIT_ENVIRONMENT_ID'] = userdata.get('GRAPHLIT_ENVIRONMENT_ID')\n",
        "os.environ['GRAPHLIT_JWT_SECRET'] = userdata.get('GRAPHLIT_JWT_SECRET')\n",
        "\n",
        "graphlit = Graphlit()"
      ],
      "metadata": {
        "id": "WoMAWD4LLP_q"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Graphlit helper functions"
      ],
      "metadata": {
        "id": "pgRX57EHMVfl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Optional\n",
        "\n",
        "async def create_anthropic_specification(model: enums.AnthropicModels):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    input = input_types.SpecificationInput(\n",
        "        name=f\"Anthropic [{str(model)}]\",\n",
        "        type=enums.SpecificationTypes.COMPLETION,\n",
        "        serviceType=enums.ModelServiceTypes.ANTHROPIC,\n",
        "        anthropic=input_types.AnthropicModelPropertiesInput(\n",
        "            model=model,\n",
        "        )\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.create_specification(input)\n",
        "\n",
        "        return response.create_specification.id if response.create_specification is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "    return None\n",
        "\n",
        "async def create_openai_specification(model: enums.OpenAIModels):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    input = input_types.SpecificationInput(\n",
        "        name=f\"Anthropic [{str(model)}]\",\n",
        "        type=enums.SpecificationTypes.COMPLETION,\n",
        "        serviceType=enums.ModelServiceTypes.OPEN_AI,\n",
        "        openAI=input_types.OpenAIModelPropertiesInput(\n",
        "            model=model,\n",
        "        )\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.create_specification(input)\n",
        "\n",
        "        return response.create_specification.id if response.create_specification is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "    return None\n",
        "\n",
        "async def create_conversation(specification_id: str, messages: Optional[List] = None):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    input = input_types.ConversationInput(\n",
        "        name=\"Conversation\",\n",
        "        messages=messages,\n",
        "        specification=input_types.EntityReferenceInput(\n",
        "            id=specification_id\n",
        "        )\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.create_conversation(input)\n",
        "\n",
        "        return response.create_conversation.id if response.create_conversation is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "async def delete_conversation(conversation_id: str):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    if conversation_id is not None:\n",
        "        _ = await graphlit.client.delete_conversation(conversation_id)\n",
        "\n",
        "async def prompt_conversation(conversation_id: str, prompt: str, tools: List[input_types.ToolDefinitionInput]):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.prompt_conversation(prompt, conversation_id, None, tools)\n",
        "\n",
        "        role = response.prompt_conversation.message.role if response.prompt_conversation is not None and response.prompt_conversation.message is not None else None\n",
        "\n",
        "        if role != enums.ConversationRoleTypes.ASSISTANT:\n",
        "            print(f'Unexpected message role [{role}].')\n",
        "            return None\n",
        "\n",
        "        return response.prompt_conversation.message.tool_calls if response.prompt_conversation is not None and response.prompt_conversation.message is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "async def continue_conversation(conversation_id: str, responses: List[input_types.ConversationToolResponseInput]):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.continue_conversation(conversation_id, responses)\n",
        "\n",
        "        return response.continue_conversation.message.message if response.continue_conversation is not None and response.continue_conversation.message is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "async def delete_all_contents():\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    _ = await graphlit.client.delete_all_contents(is_synchronous=True)\n",
        "\n",
        "async def delete_all_specifications():\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    _ = await graphlit.client.delete_all_specifications(is_synchronous=True)\n",
        "\n",
        "async def delete_all_conversations():\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    _ = await graphlit.client.delete_all_conversations(is_synchronous=True)\n"
      ],
      "metadata": {
        "id": "mtwjJsvVOVCh"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from typing import Literal\n",
        "\n",
        "def set_user_name(name: str):\n",
        "    \"\"\"\n",
        "    Set the user name for the conversation.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    name\n",
        "        The user's name\n",
        "    \"\"\"\n",
        "    # NOTE: can save user name as conversation memory\n",
        "\n",
        "    print(f'Setting user name to [{name}].')\n",
        "\n",
        "    return name\n",
        "\n",
        "def call_function(tool_call):\n",
        "    function_name = tool_call.name\n",
        "    arguments = json.loads(tool_call.arguments)\n",
        "\n",
        "    response_content = None\n",
        "\n",
        "    try:\n",
        "        # Use globals() to get the function by name and call it with dynamic arguments\n",
        "        response_content = globals()[function_name](**arguments)\n",
        "\n",
        "        print(f'Function response: {response_content}')\n",
        "    except KeyError:\n",
        "        print(f\"Function '{function_name}' not found.\")\n",
        "    except TypeError as e:\n",
        "        print(f\"Error calling function: {e}\")\n",
        "\n",
        "    return response_content"
      ],
      "metadata": {
        "id": "rakJnn0HntWf"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Execute Graphlit example"
      ],
      "metadata": {
        "id": "srzhQt4COLVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from IPython.display import display, Markdown, HTML\n",
        "\n",
        "# Remove any existing contents, conversations and specifications; only needed for notebook example\n",
        "await delete_all_contents()\n",
        "await delete_all_conversations()\n",
        "await delete_all_specifications()\n",
        "\n",
        "print('Deleted all contents, conversations and specifications.')\n",
        "\n",
        "tool_calls = None\n",
        "conversation_id = None\n",
        "\n",
        "#specification_id = await create_anthropic_specification(enums.AnthropicModels.CLAUDE_3_5_SONNET)\n",
        "specification_id = await create_openai_specification(enums.OpenAIModels.GPT4O_MINI_128K)\n",
        "\n",
        "if specification_id is not None:\n",
        "    print(f'Created specification [{specification_id}].')\n",
        "\n",
        "    messages = [\n",
        "        input_types.ConversationMessageInput(role=enums.ConversationRoleTypes.USER, message=\"Hi, what can you help me with?\"),\n",
        "        input_types.ConversationMessageInput(role=enums.ConversationRoleTypes.ASSISTANT, message=\"Welcome! First, what is your name?\")\n",
        "    ]\n",
        "\n",
        "    conversation_id = await create_conversation(specification_id, messages)\n",
        "\n",
        "    if conversation_id is not None:\n",
        "        print(f'Created conversation [{conversation_id}].')\n",
        "\n",
        "        tool_name = \"set_user_name\"\n",
        "        tool_description = \"Set the user name as a memory to be retrieved later\"\n",
        "        tool_schema = \"\"\"\n",
        "        {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"name\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"The user's name\"\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\n",
        "                \"name\"\n",
        "            ]\n",
        "        }\n",
        "        \"\"\"\n",
        "\n",
        "        tools = [input_types.ToolDefinitionInput(name=tool_name, description=tool_description, schema=tool_schema)]\n",
        "\n",
        "        prompt = \"Kirk\"\n",
        "\n",
        "        tool_calls = await prompt_conversation(conversation_id, prompt, tools)\n",
        "\n",
        "        if tool_calls is not None:\n",
        "            display(Markdown('### Tool Calls:'))\n",
        "\n",
        "            for tool_call in tool_calls:\n",
        "                if tool_call is not None and tool_call.id is not None:\n",
        "                    display(Markdown(f'### Tool [{tool_call.id}]:'))\n",
        "                    display(Markdown(f'**Name:**\\n{tool_call.name}'))\n",
        "                    display(Markdown(f'**Arguments:**\\n{tool_call.arguments}'))\n",
        "                    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "uSwSy3gXq7AN",
        "outputId": "babce0c9-11b4-42b5-a9ae-29bdfe444a28"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleted all contents, conversations and specifications.\n",
            "Created specification [4d6c2577-156e-4447-93d2-5b7dc86600ec].\n",
            "Created conversation [afc88ccc-c5c4-43a8-a612-bf018bcb1aad].\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Tool Calls:"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Tool [call_3oIjXuS7VmwvdLAob45Rm0VT]:"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Name:**\nset_user_name"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Arguments:**\n{\r\n  \"name\": \"Kirk\"\r\n}"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "if conversation_id is not None and tool_calls is not None:\n",
        "    responses = []\n",
        "\n",
        "    for tool_call in tool_calls:\n",
        "        if tool_call is not None and tool_call.id is not None:\n",
        "            response_content = call_function(tool_call)\n",
        "\n",
        "            if response_content is not None:\n",
        "                responses.append(input_types.ConversationToolResponseInput(id=tool_call.id, content=response_content))\n",
        "\n",
        "    message = await continue_conversation(conversation_id, responses)\n",
        "\n",
        "    if message is not None:\n",
        "        display(Markdown('### Conversation:'))\n",
        "        display(Markdown(f'**User:**\\n{prompt}'))\n",
        "        display(Markdown(f'**Assistant:**\\n{message}'))\n",
        "        print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "RitZHrG1TyFg",
        "outputId": "83b3a996-3299-4a48-e6d6-6ff32ba18fe0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting user name to [Kirk].\n",
            "Function response: Kirk\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Conversation:"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**User:**\nKirk"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Assistant:**\nHello, Kirk! How can I assist you today?"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}