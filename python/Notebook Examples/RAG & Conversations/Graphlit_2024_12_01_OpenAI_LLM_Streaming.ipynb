{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1cSnEIDnT7SYyUpfap5KiK6Y_LWLQdk6s",
      "authorship_tag": "ABX9TyPWsQoin+KFSJDlss3K0ena",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/graphlit/graphlit-samples/blob/main/python/Notebook%20Examples/Graphlit_2024_12_01_OpenAI_LLM_Streaming.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Description**\n",
        "\n",
        "This example shows how to implement streaming LLM completions using Graphlit for RAG retrieval."
      ],
      "metadata": {
        "id": "pDz1gRPjOtn5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Requirements**\n",
        "\n",
        "Prior to running this notebook, you will need to [signup](https://docs.graphlit.dev/getting-started/signup) for Graphlit, and [create a project](https://docs.graphlit.dev/getting-started/create-project).\n",
        "\n",
        "You will need the Graphlit organization ID, preview environment ID and JWT secret from your created project.\n",
        "\n",
        "Assign these properties as Colab secrets: GRAPHLIT_ORGANIZATION_ID, GRAPHLIT_ENVIRONMENT_ID and GRAPHLIT_JWT_SECRET.\n",
        "\n",
        "Assign this property as Colab secret: OPENAI_API_KEY.\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "laG2MXUIhNnx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install Graphlit Python client SDK"
      ],
      "metadata": {
        "id": "NwRzDHWWienC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "fefizrrh4xGD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "058a3a99-c9f5-4f5c-be40-cb2caec46887"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: graphlit-client in /usr/local/lib/python3.10/dist-packages (1.0.20241201001)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from graphlit-client) (0.27.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from graphlit-client) (2.9.2)\n",
            "Requirement already satisfied: PyJWT in /usr/local/lib/python3.10/dist-packages (from graphlit-client) (2.10.0)\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.10/dist-packages (from graphlit-client) (14.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->graphlit-client) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->graphlit-client) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->graphlit-client) (4.12.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->graphlit-client) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->graphlit-client) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->graphlit-client) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->graphlit-client) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->graphlit-client) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->graphlit-client) (0.14.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->graphlit-client) (1.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade graphlit-client"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install OpenAI Python SDK"
      ],
      "metadata": {
        "id": "BRrWq5T6do8-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmSYxDDbdmQe",
        "outputId": "4b3e4c9a-3dd9-4eaf-c793-b923b3e3532d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.55.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.7.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize Graphlit"
      ],
      "metadata": {
        "id": "abV1114jL-bR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from graphlit import Graphlit\n",
        "from graphlit_api import input_types, enums, exceptions\n",
        "\n",
        "os.environ['GRAPHLIT_ORGANIZATION_ID'] = userdata.get('GRAPHLIT_ORGANIZATION_ID')\n",
        "os.environ['GRAPHLIT_ENVIRONMENT_ID'] = userdata.get('GRAPHLIT_ENVIRONMENT_ID')\n",
        "os.environ['GRAPHLIT_JWT_SECRET'] = userdata.get('GRAPHLIT_JWT_SECRET')\n",
        "\n",
        "graphlit = Graphlit()"
      ],
      "metadata": {
        "id": "WoMAWD4LLP_q"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize OpenAI"
      ],
      "metadata": {
        "id": "4KexblYef8R_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n"
      ],
      "metadata": {
        "id": "DMzvfpu9f7Xi"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Graphlit helper functions"
      ],
      "metadata": {
        "id": "pgRX57EHMVfl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Optional\n",
        "\n",
        "async def ingest_uri(uri: str):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    try:\n",
        "        # Using synchronous mode, so the notebook waits for the content to be ingested\n",
        "        response = await graphlit.client.ingest_uri(uri=uri, is_synchronous=True)\n",
        "\n",
        "        return response.ingest_uri.id if response.ingest_uri is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "async def create_openai_specification(model: enums.OpenAIModels):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    input = input_types.SpecificationInput(\n",
        "        name=f\"OpenAI [{str(model)}]\",\n",
        "        type=enums.SpecificationTypes.COMPLETION,\n",
        "        serviceType=enums.ModelServiceTypes.OPEN_AI,\n",
        "        openAI=input_types.OpenAIModelPropertiesInput(\n",
        "            model=model,\n",
        "        )\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.create_specification(input)\n",
        "\n",
        "        return response.create_specification.id if response.create_specification is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "    return None\n",
        "\n",
        "async def create_conversation(specification_id: str):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    input = input_types.ConversationInput(\n",
        "        name=\"Conversation\",\n",
        "        specification=input_types.EntityReferenceInput(\n",
        "            id=specification_id\n",
        "        )\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.create_conversation(input)\n",
        "\n",
        "        return response.create_conversation.id if response.create_conversation is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "async def delete_conversation(conversation_id: str):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    if conversation_id is not None:\n",
        "        _ = await graphlit.client.delete_conversation(conversation_id)\n",
        "\n",
        "async def format_conversation(conversation_id: str, prompt: str):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.format_conversation(prompt, conversation_id)\n",
        "\n",
        "        return response.format_conversation.message.message if response.format_conversation is not None and response.format_conversation.message is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "async def complete_conversation(conversation_id: str, completion: str):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.complete_conversation(completion, conversation_id)\n",
        "\n",
        "        return response.complete_conversation.message.message if response.complete_conversation is not None and response.complete_conversation.message is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "async def get_conversation(conversation_id: str):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.get_conversation(conversation_id)\n",
        "\n",
        "        return response.conversation\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "async def delete_all_specifications():\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    _ = await graphlit.client.delete_all_specifications(is_synchronous=True)\n",
        "\n",
        "async def delete_all_conversations():\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    _ = await graphlit.client.delete_all_conversations(is_synchronous=True)\n",
        "\n",
        "async def delete_all_contents():\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    _ = await graphlit.client.delete_all_contents(is_synchronous=True)\n"
      ],
      "metadata": {
        "id": "mtwjJsvVOVCh"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Callable\n",
        "\n",
        "def stream_completion(prompt: str, model: str, callback: Callable[[str], None]) -> str:\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0.1,\n",
        "        top_p=0.2,\n",
        "        stream=True\n",
        "    )\n",
        "\n",
        "    completion = \"\"\n",
        "\n",
        "    for chunk in response:\n",
        "        delta = chunk.choices[0].delta.content\n",
        "\n",
        "        if delta is not None:\n",
        "            callback(delta)\n",
        "            completion += delta\n",
        "\n",
        "    return completion\n"
      ],
      "metadata": {
        "id": "c_K1mE9uda8V"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Execute Graphlit example"
      ],
      "metadata": {
        "id": "srzhQt4COLVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown, HTML\n",
        "import time\n",
        "\n",
        "# Remove any existing contents, conversations and specifications; only needed for notebook example\n",
        "await delete_all_conversations()\n",
        "await delete_all_specifications()\n",
        "await delete_all_contents()\n",
        "\n",
        "print('Deleted all contents, conversations and specifications.')\n",
        "\n",
        "content_id = await ingest_uri(uri=\"https://graphlitplatform.blob.core.windows.net/samples/Unstructured%20Data%20is%20Dark%20Data%20Podcast.mp3\")\n",
        "\n",
        "if content_id is not None:\n",
        "    print(f'Ingested content [{content_id}]:')"
      ],
      "metadata": {
        "id": "fOb6COcONZIJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6314d5d-50e8-4641-cf4c-be3972e7062a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleted all contents, conversations and specifications.\n",
            "Ingested content [993af4d7-dbb4-4d49-a3ff-546a871e33f2]:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    # Specify the RAG prompt\n",
        "    prompt = \"In 3-5 detailed paragraphs, explain unstructured data and its usefulness for knowledge capture and retrieval.\""
      ],
      "metadata": {
        "id": "-9kBDUIdbhIy"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create OpenAI GPT-4o specification."
      ],
      "metadata": {
        "id": "4snKjK2ycVKw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    model = \"gpt-4o\"\n",
        "\n",
        "    specification_id = await create_openai_specification(enums.OpenAIModels.GPT4O_128K)\n",
        "\n",
        "    if specification_id is not None:\n",
        "        print(f'Created specification [{specification_id}].')\n",
        "\n",
        "        conversation_id = await create_conversation(specification_id)\n",
        "\n",
        "        if conversation_id is not None:\n",
        "            print(f'Created conversation [{conversation_id}].')\n",
        "\n",
        "            # NOTE: returns LLM-ready formatted prompt from RAG pipeline\n",
        "            message = await format_conversation(conversation_id, prompt)\n",
        "\n",
        "            if message is not None:\n",
        "                # NOTE: uncomment to see formatted LLM prompt\n",
        "\n",
        "                #print(f'Formatted LLM prompt:')\n",
        "                #print(message)\n",
        "                print()\n",
        "\n",
        "                print(f'Streaming completion:')\n",
        "\n",
        "                completion = stream_completion(message, model, lambda delta: print(delta, end=''))\n",
        "\n",
        "                if completion is not None:\n",
        "                    # NOTE: stores completion back into conversation\n",
        "                    await complete_conversation(conversation_id, completion)\n",
        "\n",
        "            conversation = await get_conversation(conversation_id)\n",
        "\n",
        "            if conversation is not None:\n",
        "                display(Markdown(f'### Conversation [{conversation.id}]:'))\n",
        "\n",
        "                if conversation.messages is not None:\n",
        "                    for message in conversation.messages:\n",
        "                        if message is not None:\n",
        "                            display(Markdown(f'**{message.role}:**\\n{message.message}'))\n",
        "\n",
        "                print()\n",
        "\n",
        "            await delete_conversation(conversation_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 758
        },
        "id": "L5AHVoKocVmD",
        "outputId": "80d847b4-c0cf-4934-8972-3480ad778e35"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created specification [be72b1a4-e30c-45d7-aa95-1db7275a8e38].\n",
            "Created conversation [b680c022-2835-463c-a52b-9587d20db043].\n",
            "\n",
            "Streaming completion:\n",
            "Unstructured data refers to information that does not have a predefined data model or is not organized in a pre-defined manner. This type of data is typically text-heavy and can include a variety of formats such as images, videos, audio files, and documents. Unlike structured data, which is highly organized and easily searchable in databases, unstructured data is more complex and requires advanced processing techniques to extract meaningful insights. Kirk Marple, the founder of Unstruct Data, describes unstructured data as encompassing everything from imagery and audio to 3D geometry point clouds, documents, and emails. This broad set of data types highlights the diverse nature of unstructured data and the challenges associated with managing and analyzing it.\n",
            "\n",
            "The usefulness of unstructured data lies in its potential to capture rich, detailed information that structured data might miss. For instance, images and videos can provide visual context that is invaluable for certain applications, such as geospatial analysis or property inspections. By processing unstructured data, organizations can extract metadata and insights that help in understanding real-world assets and conditions. This is particularly important in fields like geospatial analysis, where data from drones, robots, and mobile devices can be used to create detailed maps and models of physical environments. The ability to analyze and interpret unstructured data allows businesses to gain a deeper understanding of their operations and make more informed decisions.\n",
            "\n",
            "Unstructured data is also crucial for knowledge capture and retrieval because it can be used to build comprehensive knowledge graphs. These graphs represent relationships between different data points, allowing for more dynamic and flexible data analysis. By creating connections between various pieces of unstructured data, organizations can uncover patterns and trends that might not be immediately apparent. This capability is essential for industries that rely on large volumes of data, such as oil and gas, where semantic search and contextualization of data can lead to significant operational efficiencies and insights.\n",
            "\n",
            "Moreover, the integration of unstructured data into knowledge systems enhances the ability to perform sentiment analysis and contextual understanding. For example, analyzing the sentiment of documents or audio transcripts can provide insights into customer opinions or employee feedback, which can be critical for improving products and services. The contextualization of unstructured data, such as linking images to specific locations or events, further enriches the knowledge base and supports more accurate and timely decision-making.\n",
            "\n",
            "In conclusion, unstructured data plays a vital role in knowledge capture and retrieval by providing a rich source of information that complements structured data. Its ability to capture complex, real-world scenarios and relationships makes it an invaluable asset for organizations looking to enhance their data-driven strategies. By leveraging advanced technologies like machine learning and knowledge graphs, businesses can unlock the full potential of unstructured data, leading to improved insights and competitive advantages."
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Conversation [b680c022-2835-463c-a52b-9587d20db043]:"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**USER:**\nIn 3-5 detailed paragraphs, explain unstructured data and its usefulness for knowledge capture and retrieval."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**ASSISTANT:**\nUnstructured data refers to information that does not have a predefined data model or is not organized in a pre-defined manner. This type of data is typically text-heavy and can include a variety of formats such as images, videos, audio files, and documents. Unlike structured data, which is highly organized and easily searchable in databases, unstructured data is more complex and requires advanced processing techniques to extract meaningful insights. Kirk Marple, the founder of Unstruct Data, describes unstructured data as encompassing everything from imagery and audio to 3D geometry point clouds, documents, and emails. This broad set of data types highlights the diverse nature of unstructured data and the challenges associated with managing and analyzing it.\n\nThe usefulness of unstructured data lies in its potential to capture rich, detailed information that structured data might miss. For instance, images and videos can provide visual context that is invaluable for certain applications, such as geospatial analysis or property inspections. By processing unstructured data, organizations can extract metadata and insights that help in understanding real-world assets and conditions. This is particularly important in fields like geospatial analysis, where data from drones, robots, and mobile devices can be used to create detailed maps and models of physical environments. The ability to analyze and interpret unstructured data allows businesses to gain a deeper understanding of their operations and make more informed decisions.\n\nUnstructured data is also crucial for knowledge capture and retrieval because it can be used to build comprehensive knowledge graphs. These graphs represent relationships between different data points, allowing for more dynamic and flexible data analysis. By creating connections between various pieces of unstructured data, organizations can uncover patterns and trends that might not be immediately apparent. This capability is essential for industries that rely on large volumes of data, such as oil and gas, where semantic search and contextualization of data can lead to significant operational efficiencies and insights.\n\nMoreover, the integration of unstructured data into knowledge systems enhances the ability to perform sentiment analysis and contextual understanding. For example, analyzing the sentiment of documents or audio transcripts can provide insights into customer opinions or employee feedback, which can be critical for improving products and services. The contextualization of unstructured data, such as linking images to specific locations or events, further enriches the knowledge base and supports more accurate and timely decision-making.\n\nIn conclusion, unstructured data plays a vital role in knowledge capture and retrieval by providing a rich source of information that complements structured data. Its ability to capture complex, real-world scenarios and relationships makes it an invaluable asset for organizations looking to enhance their data-driven strategies. By leveraging advanced technologies like machine learning and knowledge graphs, businesses can unlock the full potential of unstructured data, leading to improved insights and competitive advantages."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}