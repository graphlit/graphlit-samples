{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1cSnEIDnT7SYyUpfap5KiK6Y_LWLQdk6s",
      "authorship_tag": "ABX9TyNnQ9iNqmkbAavXkZ2nrr+Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/graphlit/graphlit-samples/blob/main/python/Notebook%20Examples/Graphlit_2024_12_24_Auto_Filter_Microsoft_Emails_in_Conversation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Description**\n",
        "\n",
        "This example shows how to ingest emails from a user's Microsoft email account, and auto-filter when prompting a conversation. This is a prototype of how you could auto-filter the knowledge base based on the user's prompt, via time range and observed entities."
      ],
      "metadata": {
        "id": "M7pOtiP1OaKd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Requirements**\n",
        "\n",
        "Prior to running this notebook, you will need to [signup](https://docs.graphlit.dev/getting-started/signup) for Graphlit, and [create a project](https://docs.graphlit.dev/getting-started/create-project).\n",
        "\n",
        "You will need the Graphlit organization ID, preview environment ID and JWT secret from your created project.\n",
        "\n",
        "Assign these properties as Colab secrets: GRAPHLIT_ORGANIZATION_ID, GRAPHLIT_ENVIRONMENT_ID and GRAPHLIT_JWT_SECRET.\n",
        "\n",
        "To access your Microsoft email, assign these properties as Colab secrets: MICROSOFT_CLIENT_ID, MICROSOFT_CLIENT_SECRET and MICROSOFT_REFRESH_TOKEN.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "laG2MXUIhNnx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install Graphlit Python client SDK"
      ],
      "metadata": {
        "id": "NwRzDHWWienC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fefizrrh4xGD"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade graphlit-client"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize Graphlit"
      ],
      "metadata": {
        "id": "abV1114jL-bR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from graphlit import Graphlit\n",
        "from graphlit_api import input_types, enums, exceptions\n",
        "\n",
        "os.environ['GRAPHLIT_ORGANIZATION_ID'] = userdata.get('GRAPHLIT_ORGANIZATION_ID')\n",
        "os.environ['GRAPHLIT_ENVIRONMENT_ID'] = userdata.get('GRAPHLIT_ENVIRONMENT_ID')\n",
        "os.environ['GRAPHLIT_JWT_SECRET'] = userdata.get('GRAPHLIT_JWT_SECRET')\n",
        "\n",
        "graphlit = Graphlit()"
      ],
      "metadata": {
        "id": "WoMAWD4LLP_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['MICROSOFT_CLIENT_ID'] = userdata.get('MICROSOFT_CLIENT_ID')\n",
        "os.environ['MICROSOFT_CLIENT_SECRET'] = userdata.get('MICROSOFT_CLIENT_SECRET')\n",
        "os.environ['MICROSOFT_REFRESH_TOKEN'] = userdata.get('MICROSOFT_REFRESH_TOKEN')"
      ],
      "metadata": {
        "id": "OH82BIMRAceL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Graphlit helper functions"
      ],
      "metadata": {
        "id": "pgRX57EHMVfl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Optional\n",
        "import json\n",
        "\n",
        "async def extract_text(text: str, model_schema: str, specification_id: Optional[str] = None, prompt: Optional[str] = None):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    default_name = \"extract_pydantic_model\"\n",
        "\n",
        "    default_prompt = \"\"\"\n",
        "    Extract data using the tools provided.\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.extract_text(\n",
        "            specification=input_types.EntityReferenceInput(id=specification_id) if specification_id is not None else None,\n",
        "            tools=[input_types.ToolDefinitionInput(name=default_name, schema=model_schema)],\n",
        "            prompt=default_prompt if prompt is None else prompt,\n",
        "            text=text\n",
        "        )\n",
        "\n",
        "        if response.extract_text is None:\n",
        "            print('Failed to extract text.')\n",
        "            return None\n",
        "\n",
        "        return response.extract_text\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "    return None\n",
        "\n",
        "async def create_google_extraction_specification(model: enums.GoogleModels):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    input = input_types.SpecificationInput(\n",
        "        name=f\"Google [{model}]\",\n",
        "        type=enums.SpecificationTypes.EXTRACTION,\n",
        "        serviceType=enums.ModelServiceTypes.GOOGLE,\n",
        "        google=input_types.GoogleModelPropertiesInput(\n",
        "            model=model,\n",
        "        )\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.create_specification(input)\n",
        "\n",
        "        return response.create_specification.id if response.create_specification is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "    return None\n",
        "\n",
        "async def create_openai_extraction_specification(model: enums.OpenAIModels):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    input = input_types.SpecificationInput(\n",
        "        name=f\"OpenAI [{model}]\",\n",
        "        type=enums.SpecificationTypes.EXTRACTION,\n",
        "        serviceType=enums.ModelServiceTypes.OPEN_AI,\n",
        "        openAI=input_types.OpenAIModelPropertiesInput(\n",
        "            model=model,\n",
        "        )\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.create_specification(input)\n",
        "\n",
        "        return response.create_specification.id if response.create_specification is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "    return None\n",
        "\n",
        "# Create entity extraction workflow using LLM specification\n",
        "async def create_extraction_workflow(specification_id: str):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    input = input_types.WorkflowInput(\n",
        "        name=\"Entity Extraction\",\n",
        "        extraction=input_types.ExtractionWorkflowStageInput(\n",
        "            jobs=[\n",
        "                input_types.ExtractionWorkflowJobInput(\n",
        "                    connector=input_types.EntityExtractionConnectorInput(\n",
        "                        type=enums.EntityExtractionServiceTypes.MODEL_TEXT,\n",
        "                        modelText=input_types.ModelTextExtractionPropertiesInput(\n",
        "                            specification=input_types.EntityReferenceInput(id=specification_id)\n",
        "                        ),\n",
        "                        extractedTypes=[enums.ObservableTypes.LABEL]\n",
        "                    )\n",
        "                )\n",
        "            ]\n",
        "        )\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.create_workflow(input)\n",
        "\n",
        "        return response.create_workflow.id if response.create_workflow is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "    return None\n",
        "\n",
        "async def create_feed(workflow_id: str):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    input = input_types.FeedInput(\n",
        "        name=\"Microsoft Email\",\n",
        "        type=enums.FeedTypes.EMAIL,\n",
        "        email=input_types.EmailFeedPropertiesInput(\n",
        "            type=enums.FeedServiceTypes.MICROSOFT_EMAIL,\n",
        "            microsoft=input_types.MicrosoftEmailFeedPropertiesInput(\n",
        "                type=enums.EmailListingTypes.PAST,\n",
        "                refreshToken=os.environ['MICROSOFT_REFRESH_TOKEN'],\n",
        "                clientId=os.environ['MICROSOFT_CLIENT_ID'],\n",
        "                clientSecret=os.environ['MICROSOFT_CLIENT_SECRET']\n",
        "            ),\n",
        "            readLimit=25 # limiting to 25 emails\n",
        "        ),\n",
        "        workflow=input_types.EntityReferenceInput(id=workflow_id) if workflow_id is not None else None,\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.create_feed(input)\n",
        "\n",
        "        return response.create_feed.id if response.create_feed is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "    return None\n",
        "\n",
        "async def is_feed_done(feed_id: str):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    response = await graphlit.client.is_feed_done(feed_id)\n",
        "\n",
        "    return response.is_feed_done.result if response.is_feed_done is not None else None\n",
        "\n",
        "async def query_contents(search_text: str):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.query_contents(\n",
        "            filter=input_types.ContentFilter(\n",
        "                search=search_text,\n",
        "                searchType=enums.SearchTypes.HYBRID\n",
        "            )\n",
        "        )\n",
        "\n",
        "        return response.contents.results if response.contents is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "async def query_labels(search_text: Optional[str] = None):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.query_labels(\n",
        "            filter=input_types.LabelFilter(\n",
        "                search=search_text\n",
        "            )\n",
        "        )\n",
        "\n",
        "        return response.labels.results if response.labels is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "async def create_openai_specification(model: enums.OpenAIModels):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    input = input_types.SpecificationInput(\n",
        "        name=f\"OpenAI [{str(model)}]\",\n",
        "        type=enums.SpecificationTypes.COMPLETION,\n",
        "        serviceType=enums.ModelServiceTypes.OPEN_AI,\n",
        "        openAI=input_types.OpenAIModelPropertiesInput(\n",
        "            model=model,\n",
        "        ),\n",
        "        retrievalStrategy=input_types.RetrievalStrategyInput(\n",
        "            type=enums.RetrievalStrategyTypes.SECTION\n",
        "        ),\n",
        "        rerankingStrategy=input_types.RerankingStrategyInput(\n",
        "            serviceType=enums.RerankingModelServiceTypes.COHERE\n",
        "        ),\n",
        "        searchType=enums.ConversationSearchTypes.NONE\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.create_specification(input)\n",
        "\n",
        "        return response.create_specification.id if response.create_specification is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "    return None\n",
        "\n",
        "async def create_conversation(specification_id: str, in_last: Optional[str], observations: Optional[List[input_types.ObservationCriteriaInput]] = None):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    input = input_types.ConversationInput(\n",
        "        name=\"Conversation\",\n",
        "        specification=input_types.EntityReferenceInput(\n",
        "            id=specification_id\n",
        "        ),\n",
        "        filter=input_types.ContentCriteriaInput(\n",
        "            inLast=in_last,\n",
        "            observations=observations\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.create_conversation(input)\n",
        "\n",
        "        return response.create_conversation.id if response.create_conversation is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "async def delete_conversation(conversation_id: str):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    if conversation_id is not None:\n",
        "        _ = await graphlit.client.delete_conversation(conversation_id)\n",
        "\n",
        "async def prompt_conversation(conversation_id: str, prompt: str):\n",
        "    if graphlit.client is None:\n",
        "        return None, None\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.prompt_conversation(prompt, conversation_id, include_details=True)\n",
        "\n",
        "        message = response.prompt_conversation.message.message if response.prompt_conversation is not None and response.prompt_conversation.message is not None else None\n",
        "        details = response.prompt_conversation.details if response.prompt_conversation is not None else None\n",
        "\n",
        "        return message, details\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None, None\n",
        "\n",
        "async def delete_all_specifications():\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    _ = await graphlit.client.delete_all_specifications(is_synchronous=True)\n",
        "\n",
        "async def delete_all_workflows():\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    _ = await graphlit.client.delete_all_workflows(is_synchronous=True)\n",
        "\n",
        "async def delete_all_contents():\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    _ = await graphlit.client.delete_all_contents(is_synchronous=True)\n",
        "\n",
        "async def delete_all_feeds():\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    _ = await graphlit.client.delete_all_feeds(is_synchronous=True)\n",
        "\n",
        "async def delete_all_conversations():\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    _ = await graphlit.client.delete_all_conversations(is_synchronous=True)\n",
        "\n",
        "async def delete_all_observables():\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    _ = await graphlit.client.delete_all_persons()\n",
        "    _ = await graphlit.client.delete_all_organizations()\n",
        "    _ = await graphlit.client.delete_all_places()\n",
        "    _ = await graphlit.client.delete_all_events()\n",
        "    _ = await graphlit.client.delete_all_products()\n",
        "    _ = await graphlit.client.delete_all_softwares()\n",
        "    _ = await graphlit.client.delete_all_repos()\n",
        "    _ = await graphlit.client.delete_all_labels()\n",
        "    _ = await graphlit.client.delete_all_categories()"
      ],
      "metadata": {
        "id": "mtwjJsvVOVCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Execute Graphlit example"
      ],
      "metadata": {
        "id": "srzhQt4COLVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown\n",
        "import time\n",
        "\n",
        "# Remove any existing specifications, feeds, contents and workflows; only needed for notebook example\n",
        "await delete_all_workflows()\n",
        "await delete_all_feeds()\n",
        "await delete_all_contents()\n",
        "await delete_all_specifications()\n",
        "await delete_all_conversations()\n",
        "await delete_all_observables()\n",
        "\n",
        "print('Deleted all specifications, feeds, contents, and workflows.')\n",
        "\n",
        "#specification_id = await create_openai_extraction_specification(enums.OpenAIModels.GPT4O_128K) # NOTE: Mini doesn't generate semantic labels well enough\n",
        "specification_id = await create_google_extraction_specification(enums.GoogleModels.GEMINI_2_0_FLASH_EXPERIMENTAL)\n",
        "\n",
        "if specification_id is not None:\n",
        "    print(f'Created specification [{specification_id}].')\n",
        "\n",
        "    workflow_id = await create_extraction_workflow(specification_id)\n",
        "\n",
        "    if workflow_id is not None:\n",
        "        print(f'Created workflow [{workflow_id}].')\n"
      ],
      "metadata": {
        "id": "fOb6COcONZIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ingest Microsoft emails"
      ],
      "metadata": {
        "id": "DMtVSOqtRL32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "        feed_id = await create_feed(workflow_id)\n",
        "\n",
        "        if feed_id is not None:\n",
        "            print(f'Created feed [{feed_id}].')\n",
        "\n",
        "            # Wait for feed to complete, since ingestion happens asychronously\n",
        "            done = False\n",
        "            time.sleep(5)\n",
        "            while not done:\n",
        "                done = await is_feed_done(feed_id)\n",
        "\n",
        "                if not done:\n",
        "                    time.sleep(10)\n",
        "\n",
        "            print(f'Completed feed [{feed_id}].')"
      ],
      "metadata": {
        "id": "idevPrm7F0Qg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Search within ingested emails"
      ],
      "metadata": {
        "id": "4QrX7Iw9RIEG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NOTE: specify the text to search for in the filtered emails\n",
        "search_text = \"Azure subscription\"\n",
        "\n",
        "# Query contents by search text\n",
        "contents = await query_contents(search_text)\n",
        "\n",
        "if contents is not None and len(contents) > 0:\n",
        "    for content in contents:\n",
        "        if content is not None:\n",
        "            display(Markdown(f'### Found Microsoft email [{content.id}] that referenced search text [{search_text}].'))\n",
        "\n",
        "            if content.original_date is not None:\n",
        "                print(\"Date: \" + content.original_date)\n",
        "\n",
        "            metadata = content.email\n",
        "\n",
        "            if metadata is not None:\n",
        "                if metadata.subject is not None:\n",
        "                    print(\"Subject: \" + metadata.subject)\n",
        "                if metadata.to is not None and len(metadata.to) > 0:\n",
        "                    print(\"To: \" + \", \".join([f'\"{item.name}\" <{item.email}>' for item in metadata.to if item is not None]))\n",
        "                if metadata.from_ is not None and len(metadata.from_) > 0:\n",
        "                    print(\"From: \" + \", \".join([f'\"{item.name}\" <{item.email}>' for item in metadata.from_ if item is not None]))\n",
        "\n",
        "            if content.observations is not None:\n",
        "                for observation in content.observations:\n",
        "                    if observation is not None and observation.observable is not None:\n",
        "                        print(f'{observation.type}: {observation.observable.name}')\n",
        "\n",
        "            # NOTE: uncomment to see email markdown\n",
        "            #display(Markdown(content.markdown))\n",
        "            print()\n",
        "        else:\n",
        "            print('No content found')\n",
        "else:\n",
        "    print(f'No contents found by search [{search_text}].')\n"
      ],
      "metadata": {
        "id": "ziNt4DIzJSBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Query for labels by name"
      ],
      "metadata": {
        "id": "rAxNKWUjRXgS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ll = await query_labels(\"billing\")\n",
        "\n",
        "if ll is not None and len(ll) > 0:\n",
        "    for l in ll:\n",
        "        if l is not None:\n",
        "            print(f'Found Label [{l.id}]: {l.name}')"
      ],
      "metadata": {
        "id": "DpYRoU1EL_FA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define your user prompt"
      ],
      "metadata": {
        "id": "-rodzJXrRZs0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#prompt = \"Can you summarize my emails from today and highlight any urgent ones?\"\n",
        "#prompt = \"can you show me emails in last 3 days where I need to follow up or that may require my response?\"\n",
        "prompt = \"can you show me emails in last 3 days which contain an invoice which may need to be paid?\"\n",
        "#prompt = \"what emails did I get today?\"\n",
        "#prompt = \"can you summarize my emails from the past week?\""
      ],
      "metadata": {
        "id": "3QBRcvuablxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pytz\n",
        "from typing import List, Optional\n",
        "from pydantic import BaseModel, Field\n",
        "from datetime import datetime\n",
        "\n",
        "local_tz = pytz.timezone('America/Los_Angeles')\n",
        "\n",
        "now = datetime.now(local_tz)\n",
        "\n",
        "# NOTE: append the current time to the prompt\n",
        "formatted_time = now.strftime(\"It is now %-I:%M%p on %B %-d, %Y\")\n",
        "\n",
        "print(formatted_time)\n",
        "\n",
        "class ContentFilter(BaseModel):\n",
        "    labels: List[str] = Field(description=\"List of email labels inferred from the provided user prompt, for filtering content. For optimal search, don't add extra spaces into label names, if possible. Don't include any labels that reference a relative date, like 'today', 'yesterday', etc.\")\n",
        "    in_last: Optional[str] = Field(description=\"Duration of time, starting from today and going into the past, for filtering content. Use ISO 8601 format, like PT1D. This will be used to calculate a datetime range, like now - 'datetime range'. Treat today as from the previous midnight to now. Treat yesterday as from the previous day's midnight to now. Treat last week as previous 7 days from now.\")\n",
        "\n",
        "in_last = None\n",
        "observations: List[input_types.ObservationCriteriaInput] = []\n",
        "\n",
        "if specification_id is not None:\n",
        "    schema = ContentFilter.model_json_schema()\n",
        "\n",
        "    if schema is not None:\n",
        "        json_schema = json.dumps(schema, indent=2)\n",
        "\n",
        "        print('Schema:\\n' + json_schema)\n",
        "        print()\n",
        "\n",
        "        extractions = await extract_text(f'{prompt} {formatted_time}', json_schema)\n",
        "\n",
        "        if extractions is not None:\n",
        "            extraction = extractions[0]\n",
        "\n",
        "            if extraction is not None:\n",
        "                json_str = extraction.value\n",
        "\n",
        "                data = json.loads(json_str)\n",
        "\n",
        "                content_filter = ContentFilter.model_validate(data)\n",
        "\n",
        "                print(f'Time range:\\n{content_filter.in_last}')\n",
        "\n",
        "                in_last = content_filter.in_last\n",
        "\n",
        "                for label in content_filter.labels:\n",
        "                    print(f'Extracted Label: {label}')\n",
        "\n",
        "                    ll = await query_labels(label)\n",
        "\n",
        "                    if ll is not None and len(ll) > 0:\n",
        "                        for l in ll:\n",
        "                            if l is not None:\n",
        "                                print(f'Found Label [{l.id}]: {l.name}')\n",
        "\n",
        "                                observations.append(input_types.ObservationCriteriaInput(observable=input_types.EntityReferenceInput(id=l.id), type=enums.ObservableTypes.LABEL))\n",
        "                    else:\n",
        "                        print(f'No labels found with name [{label}].')"
      ],
      "metadata": {
        "id": "LWQe5y5bEeID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Found {len(observations)} observations.')"
      ],
      "metadata": {
        "id": "GR-p1yi4Gt0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "completion_specification_id = await create_openai_specification(enums.OpenAIModels.GPT4O_128K_20241120)\n",
        "\n",
        "if completion_specification_id is not None:\n",
        "    print(f'Created specification [{completion_specification_id}].')\n",
        "\n",
        "    conversation_id = await create_conversation(completion_specification_id, in_last, observations)\n",
        "\n",
        "    if conversation_id is not None:\n",
        "        print(f'Created conversation [{conversation_id}].')\n",
        "\n",
        "        message, details = await prompt_conversation(conversation_id, prompt)\n",
        "\n",
        "        if message is not None:\n",
        "            display(Markdown('### Conversation:'))\n",
        "            display(Markdown(f'**User:**\\n{prompt}'))\n",
        "            display(Markdown(f'**Assistant:**'))\n",
        "            print(message)\n",
        "            print()\n",
        "\n",
        "        if details is not None:\n",
        "            display(Markdown('### Details:'))\n",
        "            display(Markdown(f'**Model**: {details.model_service} {details.model}'))\n",
        "            display(Markdown(f'**Token Limit**: {details.token_limit}'))\n",
        "            display(Markdown(f'**Completion Token Limit**: {details.completion_token_limit}'))\n",
        "\n",
        "            display(Markdown(f'**# Sources**: {details.source_count}'))\n",
        "            display(Markdown(f'**# Rendered Sources**: {details.rendered_source_count}'))\n",
        "            display(Markdown(f'**# Ranked Sources**: {details.ranked_source_count}'))\n",
        "\n",
        "            print()\n",
        "\n",
        "            if details.sources is not None:\n",
        "                display(Markdown(f'#### Sources:'))\n",
        "                print(details.sources)\n",
        "                print()\n",
        "\n",
        "            if details.specification is not None:\n",
        "                display(Markdown(f'#### Specification:'))\n",
        "                print(details.specification)\n",
        "                print()\n",
        "\n",
        "            if details.messages is not None:\n",
        "                display(Markdown(f'#### Messages:'))\n",
        "\n",
        "                for message in details.messages:\n",
        "                    if message is not None and message.message is not None:\n",
        "                        display(Markdown(f'**{message.role}:**'))\n",
        "                        print(message.message)\n",
        "\n",
        "        await delete_conversation(conversation_id)"
      ],
      "metadata": {
        "id": "3ZYIgvnHbhVj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}