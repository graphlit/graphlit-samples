{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1cSnEIDnT7SYyUpfap5KiK6Y_LWLQdk6s",
      "authorship_tag": "ABX9TyPa8tWt5hVOdyMLFi4JUvol",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/graphlit/graphlit-samples/blob/main/python/Notebook%20Examples/Graphlit_2024_09_30_Publish_Podcast_Guest_Backgrounder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Description**\n",
        "\n",
        "This example shows how to ingest podcasts from Azure blob storage, and publish a summarized background bio of the podcast guest."
      ],
      "metadata": {
        "id": "M7pOtiP1OaKd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Requirements**\n",
        "\n",
        "Prior to running this notebook, you will need to [signup](https://docs.graphlit.dev/getting-started/signup) for Graphlit, and [create a project](https://docs.graphlit.dev/getting-started/create-project).\n",
        "\n",
        "You will need the Graphlit organization ID, preview environment ID and JWT secret from your created project.\n",
        "\n",
        "Assign these properties as Colab secrets: GRAPHLIT_ORGANIZATION_ID, GRAPHLIT_ENVIRONMENT_ID and GRAPHLIT_JWT_SECRET.\n",
        "\n",
        "Place MP3 recordings of podcasts on Azure blob storage.\n",
        "\n",
        "Assign these properties as Colab secrets: AZURE_STORAGE_ACCOUNT_NAME and AZURE_STORAGE_ACCESS_KEY.\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "laG2MXUIhNnx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install Graphlit Python client SDK"
      ],
      "metadata": {
        "id": "NwRzDHWWienC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fefizrrh4xGD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28679f5f-9b7d-4b4c-b94b-f90125869d1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting graphlit-client\n",
            "  Downloading graphlit_client-1.0.20240929002-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting httpx (from graphlit-client)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from graphlit-client) (2.9.2)\n",
            "Requirement already satisfied: PyJWT in /usr/local/lib/python3.10/dist-packages (from graphlit-client) (2.9.0)\n",
            "Collecting websockets (from graphlit-client)\n",
            "  Downloading websockets-13.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->graphlit-client) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->graphlit-client) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->graphlit-client) (4.12.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->graphlit-client) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->graphlit-client) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx->graphlit-client)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->graphlit-client) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->graphlit-client) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->graphlit-client)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->graphlit-client) (1.2.2)\n",
            "Downloading graphlit_client-1.0.20240929002-py3-none-any.whl (198 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.3/198.3 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-13.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (164 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.1/164.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: websockets, h11, httpcore, httpx, graphlit-client\n",
            "Successfully installed graphlit-client-1.0.20240929002 h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 websockets-13.1\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade graphlit-client"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize Graphlit"
      ],
      "metadata": {
        "id": "abV1114jL-bR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from graphlit import Graphlit\n",
        "from graphlit_api import input_types, enums, exceptions\n",
        "\n",
        "os.environ['GRAPHLIT_ORGANIZATION_ID'] = userdata.get('GRAPHLIT_ORGANIZATION_ID')\n",
        "os.environ['GRAPHLIT_ENVIRONMENT_ID'] = userdata.get('GRAPHLIT_ENVIRONMENT_ID')\n",
        "os.environ['GRAPHLIT_JWT_SECRET'] = userdata.get('GRAPHLIT_JWT_SECRET')\n",
        "\n",
        "graphlit = Graphlit()"
      ],
      "metadata": {
        "id": "WoMAWD4LLP_q"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Graphlit helper functions"
      ],
      "metadata": {
        "id": "pgRX57EHMVfl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Optional\n",
        "\n",
        "async def create_specification(model: enums.OpenAIModels):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    input = input_types.SpecificationInput(\n",
        "        name=f\"OpenAI [{model}]\",\n",
        "        type=enums.SpecificationTypes.EXTRACTION,\n",
        "        serviceType=enums.ModelServiceTypes.OPEN_AI,\n",
        "        openAI=input_types.OpenAIModelPropertiesInput(\n",
        "            model=model\n",
        "        )\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.create_specification(input)\n",
        "\n",
        "        return response.create_specification.id if response.create_specification is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "    return None\n",
        "\n",
        "async def create_feed(account_name: str, container_name: str, storage_key: str, prefix: str, workflow_id: Optional[str] = None, read_limit: Optional[int] = None):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    input = input_types.FeedInput(\n",
        "        name=f'Azure blob storage',\n",
        "        type=enums.FeedTypes.SITE,\n",
        "        site=input_types.SiteFeedPropertiesInput(\n",
        "            type=enums.FeedServiceTypes.AZURE_BLOB,\n",
        "            isRecursive=False,\n",
        "            azureBlob=input_types.AzureBlobFeedPropertiesInput(\n",
        "                accountName=account_name,\n",
        "                containerName=container_name,\n",
        "                storageAccessKey=storage_key,\n",
        "                prefix=prefix\n",
        "            ),\n",
        "            readLimit=read_limit\n",
        "        ),\n",
        "        workflow=input_types.EntityReferenceInput(\n",
        "            id=workflow_id\n",
        "        ) if workflow_id is not None else None\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.create_feed(input)\n",
        "\n",
        "        return response.create_feed.id if response.create_feed is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "    return None\n",
        "\n",
        "async def is_feed_done(feed_id: str):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    response = await graphlit.client.is_feed_done(feed_id)\n",
        "\n",
        "    return response.is_feed_done.result if response.is_feed_done is not None else None\n",
        "\n",
        "async def get_content(content_id: str):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.get_content(content_id)\n",
        "\n",
        "        return response.content\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "async def publish_content(summary_specification_id: str, publish_specification_id: str, summary_prompt: str, publish_prompt: str):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.publish_contents(\n",
        "            name=\"Published Summary\",\n",
        "            connector=input_types.ContentPublishingConnectorInput(\n",
        "               type=enums.ContentPublishingServiceTypes.TEXT,\n",
        "               format=enums.ContentPublishingFormats.MARKDOWN,\n",
        "            ),\n",
        "            summary_prompt=summary_prompt,\n",
        "            summary_specification=input_types.EntityReferenceInput(\n",
        "                id=summary_specification_id\n",
        "            ),\n",
        "            publish_prompt=publish_prompt,\n",
        "            publish_specification=input_types.EntityReferenceInput(\n",
        "                id=publish_specification_id\n",
        "            ),\n",
        "            is_synchronous=True\n",
        "        )\n",
        "\n",
        "        return response.publish_contents if response.publish_contents is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "async def delete_all_specifications():\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    _ = await graphlit.client.delete_all_specifications(is_synchronous=True)\n",
        "\n",
        "async def delete_all_contents():\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    _ = await graphlit.client.delete_all_contents(is_synchronous=True)\n",
        "\n",
        "async def delete_all_feeds():\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    _ = await graphlit.client.delete_all_feeds(is_synchronous=True)\n"
      ],
      "metadata": {
        "id": "mtwjJsvVOVCh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Execute Graphlit example"
      ],
      "metadata": {
        "id": "srzhQt4COLVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown, HTML\n",
        "import time\n",
        "\n",
        "# Remove any existing feeds and contents; only needed for notebook example\n",
        "await delete_all_feeds()\n",
        "await delete_all_contents()\n",
        "\n",
        "print('Deleted all feeds and contents.')\n",
        "\n",
        "# NOTE: point to an Azure blob container with MP3 recordings of podcasts\n",
        "container_name = 'samples'\n",
        "prefix = 'Podcasts/'\n",
        "\n",
        "account_name = userdata.get('AZURE_STORAGE_ACCOUNT_NAME')\n",
        "storage_access_key = userdata.get('AZURE_STORAGE_ACCESS_KEY')\n",
        "\n",
        "feed_id = await create_feed(account_name, container_name, storage_access_key, prefix)\n",
        "\n",
        "if feed_id is not None:\n",
        "    print(f'Created feed [{feed_id}].')\n",
        "\n",
        "    # Wait for feed to complete, since ingestion happens asychronously\n",
        "    done = False\n",
        "    time.sleep(5)\n",
        "    while not done:\n",
        "        done = await is_feed_done(feed_id)\n",
        "\n",
        "        if not done:\n",
        "            time.sleep(2)\n",
        "\n",
        "    print(f'Completed feed [{feed_id}].')\n"
      ],
      "metadata": {
        "id": "fOb6COcONZIJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3685faf-1080-4c3d-c074-d7701895e897"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleted all feeds and contents.\n",
            "Created feed [e3bdbe9f-1926-4071-81d4-85352c391d5d].\n",
            "Completed feed [e3bdbe9f-1926-4071-81d4-85352c391d5d].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove any existing specifications; only needed for notebook example\n",
        "\n",
        "await delete_all_specifications()\n",
        "\n",
        "print('Deleted all specifications.')\n",
        "\n",
        "# Configure details about podcast guest\n",
        "guest_name = 'Kirk Marple'\n",
        "guest_first_name = 'Kirk'\n",
        "company_name = 'Graphlit'\n",
        "guest_pronoun = 'his'\n",
        "\n",
        "# Configure the summary prompt to extract key details about the podcast guest you're writing about\n",
        "summary_prompt = f\"\"\"You are being provided the transcript of a podcast, where {guest_name} was a guest.\n",
        "Focus on any details that {guest_first_name} talks about, especially {guest_pronoun} professional background, and {guest_pronoun} vision for starting the company named {company_name}.\n",
        "This information will be used to compile a detailed backgrounder about {guest_first_name} and {company_name}.\n",
        "Respond with 25 verbose bullet points covering all relevant details. Be specific about any named entities like persons, companies or places.\n",
        "\"\"\"\n",
        "\n",
        "# Configure the publish prompt to compile the final backgrounder report from the details captured from the podcasts\n",
        "publish_prompt = f\"\"\"\n",
        "You are responding to a request to write a backgrounder about {guest_name} and {company_name}.\n",
        "Write a detailed backgrounder report, describing {guest_first_name} and {company_name} in the third-person.\n",
        "Make sure to cover {guest_first_name}'s early career background, previous companies that were started, and the vision for starting {company_name}.\n",
        "\"\"\"\n",
        "\n",
        "# Select the model to use for summarization; using GPT-4o Mini because of speed\n",
        "summary_model = enums.OpenAIModels.GPT4O_MINI_128K\n",
        "# Select the model to use for publishing; using o1-preview because of the more detailed responses and thought put into them\n",
        "publish_model = enums.OpenAIModels.O1_PREVIEW_128K\n",
        "\n",
        "summary_specification_id = await create_specification(summary_model)\n",
        "\n",
        "if summary_specification_id is not None:\n",
        "    print(f'Created summary specification [{summary_specification_id}].')\n",
        "\n",
        "    publish_specification_id = await create_specification(publish_model)\n",
        "\n",
        "    if publish_specification_id is not None:\n",
        "        print(f'Created publish specification [{publish_specification_id}].')\n",
        "\n",
        "        published_content = await publish_content(summary_specification_id, publish_specification_id, summary_prompt, publish_prompt)\n",
        "\n",
        "        if published_content is not None:\n",
        "            display(Markdown(f'### Published summary'))\n",
        "            display(Markdown(published_content.markdown))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UihbaaU79WYH",
        "outputId": "0d515a7e-b41d-49dd-a91a-3e9d8d4267be"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleted all specifications.\n",
            "Created summary specification [84b2d07e-a787-4673-bf6e-733956b7d457].\n",
            "Created publish specification [8ebafb6e-e699-4b29-bf92-4684cefbbdd8].\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Published summary"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Backgrounder on Kirk Marple and Graphlit\n\nKirk Marple is a seasoned technology leader with over 25 years of experience in software development and data management. His career spans across various domains, including multimedia systems, unstructured data management, and knowledge graph technologies. As the founder and CEO of Graphlit, Kirk has been at the forefront of innovation in handling unstructured data, aiming to make it more accessible and actionable for businesses across industries.\n\n## Early Career Background\n\nKirk began his professional journey after earning a degree in computer science from the University of Pennsylvania and a master's degree from the University of British Columbia, where he focused on image processing and real-time video technologies. In 1994, he joined Microsoft, where he worked for six years, including a significant tenure in Microsoft Research.\n\nAt Microsoft, Kirk was involved in pioneering projects that laid the groundwork for future technological advancements. He contributed to the development of Blackbird, a multimedia platform for MSN, and worked on 3D virtual worlds, which were precursors to today's metaverse concepts. His work encompassed multimedia technologies, 3D graphics, and the early iterations of Windows Media Player. This period provided Kirk with deep insights into multimedia data, file formats, and the potential of technology to transform how people interact with digital content.\n\n## Previous Companies Founded\n\nAfter his impactful stint at Microsoft, Kirk channeled his expertise into entrepreneurial ventures. He founded Radiant Grid, a video transcoding and media management company. Radiant Grid specialized in providing advanced transcoding solutions for broadcast and media companies, focusing on both web video and traditional broadcast video. Under his leadership, the company developed software that was adopted by major broadcasters such as ESPN, NBC, Fox, and every PBS station across the United States. Radiant Grid's technology played a crucial role in processing and managing large volumes of video content, aiding in the seamless delivery of media across various platforms.\n\nKirk successfully bootstrapped Radiant Grid, running it for over a decade. His hands-on approach and deep technical knowledge allowed the company to innovate rapidly and respond to the evolving needs of the media industry. In recognition of its value and impact, Radiant Grid was eventually acquired, marking a significant milestone in Kirk's entrepreneurial journey.\n\nFollowing the sale of Radiant Grid, Kirk took on executive roles at several technology companies, including positions as Chief Technology Officer (CTO) and Vice President (VP). He also worked at General Motors (GM), where he delved into the automotive industry's data challenges. At GM, Kirk developed data pipelines for autonomous vehicles, specifically for Cruise Automation. His work involved processing vast amounts of data from lidar and video systems, reinforcing the parallels between media data management and the data requirements of autonomous technologies.\n\n## Vision for Starting Graphlit\n\nKirk's experiences across media, broadcasting, and the automotive industry illuminated a significant gap in the technology landscape: the lack of robust tools and platforms for managing unstructured data. He observed that while structured data had advanced platforms like Fivetran and Snowflake, there was no equivalent for handling the diverse and complex nature of unstructured data, which constitutes a substantial portion of all data generated globally.\n\nRecognizing this unmet need, Kirk founded Graphlit approximately three years ago. His vision for Graphlit was to build an unstructured data platform that could ingest, process, and make sense of various data types—including documents, images, audio, video, and 3D geometry. He aimed to create a solution that would not only store unstructured data but also enrich it through metadata extraction, machine learning, and knowledge graphs.\n\nGraphlit focuses on making unstructured data explorable and actionable. By leveraging knowledge graphs, the platform connects disparate data points, revealing relationships and insights that would otherwise remain hidden. Kirk integrated advanced technologies such as Retrieval-Augmented Generation (RAG) to enhance the platform's capabilities, enabling more accurate and context-aware information retrieval.\n\nHis vision extends to providing developers and businesses with tools that simplify the integration of unstructured data into applications, particularly those utilizing large language models (LLMs) and artificial intelligence (AI). Graphlit's platform abstracts the complexity of data management, allowing users to focus on building innovative solutions without worrying about the underlying infrastructure.\n\nKirk's dedication to solving the unstructured data challenge is driven by his belief that unlocking the value hidden within this data can transform industries. By making unstructured data more accessible, Graphlit empowers organizations to derive meaningful insights, automate processes, and make informed decisions based on a comprehensive understanding of their data assets.\n\n# Conclusion\n\nKirk Marple's journey is a testament to his commitment to innovation and his ability to identify and address critical gaps in the technology sector. From his early days at Microsoft to his entrepreneurial successes with Radiant Grid and now Graphlit, he has consistently pushed the boundaries of what's possible in software and data management. His vision for Graphlit is poised to revolutionize how organizations handle unstructured data, making it an indispensable asset in the era of big data and AI-driven applications."
          },
          "metadata": {}
        }
      ]
    }
  ]
}