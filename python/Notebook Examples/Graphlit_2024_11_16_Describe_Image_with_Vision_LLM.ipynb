{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1cSnEIDnT7SYyUpfap5KiK6Y_LWLQdk6s",
      "authorship_tag": "ABX9TyPEGnP47+AsxIn3PGVKPqUE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/graphlit/graphlit-samples/blob/main/python/Notebook%20Examples/Graphlit_2024_11_16_Describe_Image_with_Vision_LLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Description**\n",
        "\n",
        "This example shows how to use Graphlit to describe a provided image using a vision LLM."
      ],
      "metadata": {
        "id": "pDz1gRPjOtn5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Requirements**\n",
        "\n",
        "Prior to running this notebook, you will need to [signup](https://docs.graphlit.dev/getting-started/signup) for Graphlit, and [create a project](https://docs.graphlit.dev/getting-started/create-project).\n",
        "\n",
        "You will need the Graphlit organization ID, preview environment ID and JWT secret from your created project.\n",
        "\n",
        "Assign these properties as Colab secrets: GRAPHLIT_ORGANIZATION_ID, GRAPHLIT_ENVIRONMENT_ID and GRAPHLIT_JWT_SECRET.\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "laG2MXUIhNnx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install Graphlit Python client SDK"
      ],
      "metadata": {
        "id": "NwRzDHWWienC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "fefizrrh4xGD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79c3362d-ba63-47e7-9665-17df93717cf5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: graphlit-client in /usr/local/lib/python3.10/dist-packages (1.0.20241116001)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from graphlit-client) (0.27.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from graphlit-client) (2.9.2)\n",
            "Requirement already satisfied: PyJWT in /usr/local/lib/python3.10/dist-packages (from graphlit-client) (2.9.0)\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.10/dist-packages (from graphlit-client) (14.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->graphlit-client) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->graphlit-client) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->graphlit-client) (4.12.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->graphlit-client) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->graphlit-client) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->graphlit-client) (1.0.6)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->graphlit-client) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->graphlit-client) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->graphlit-client) (0.14.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->graphlit-client) (1.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade graphlit-client"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize Graphlit"
      ],
      "metadata": {
        "id": "abV1114jL-bR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from graphlit import Graphlit\n",
        "from graphlit_api import input_types, enums, exceptions\n",
        "\n",
        "os.environ['GRAPHLIT_ORGANIZATION_ID'] = userdata.get('GRAPHLIT_ORGANIZATION_ID')\n",
        "os.environ['GRAPHLIT_ENVIRONMENT_ID'] = userdata.get('GRAPHLIT_ENVIRONMENT_ID')\n",
        "os.environ['GRAPHLIT_JWT_SECRET'] = userdata.get('GRAPHLIT_JWT_SECRET')\n",
        "\n",
        "graphlit = Graphlit()"
      ],
      "metadata": {
        "id": "WoMAWD4LLP_q"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Graphlit helper functions"
      ],
      "metadata": {
        "id": "pgRX57EHMVfl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Optional\n",
        "\n",
        "async def create_openai_specification(model: enums.OpenAIModels):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    input = input_types.SpecificationInput(\n",
        "        name=f\"OpenAI [{str(model)}]\",\n",
        "        type=enums.SpecificationTypes.EXTRACTION,\n",
        "        serviceType=enums.ModelServiceTypes.OPEN_AI,\n",
        "        openAI=input_types.OpenAIModelPropertiesInput(\n",
        "            model=model,\n",
        "        )\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.create_specification(input)\n",
        "\n",
        "        return response.create_specification.id if response.create_specification is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "async def describe_encoded_image(prompt: str, mimeType: str, data: str, specification_id: str):\n",
        "    if graphlit.client is None:\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.describe_encoded_image(prompt=prompt, mime_type=mimeType, data=data, specification=input_types.EntityReferenceInput(id=specification_id))\n",
        "\n",
        "        message = response.describe_encoded_image.message if response.describe_encoded_image is not None else None\n",
        "\n",
        "        return message\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "async def describe_image(prompt: str, uri: str, specification_id: str):\n",
        "    if graphlit.client is None:\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.describe_image(prompt=prompt, uri=uri, specification=input_types.EntityReferenceInput(id=specification_id))\n",
        "\n",
        "        message = response.describe_image.message if response.describe_image is not None else None\n",
        "\n",
        "        return message\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "async def delete_all_specifications():\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    _ = await graphlit.client.delete_all_specifications(is_synchronous=True)\n"
      ],
      "metadata": {
        "id": "mtwjJsvVOVCh"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "\n",
        "def image_to_base64(uri: str) -> Optional[str]:\n",
        "    \"\"\"\n",
        "    Fetch an image from a URI and return its base64 representation.\n",
        "\n",
        "    Args:\n",
        "        uri (str): The URI of the image.\n",
        "\n",
        "    Returns:\n",
        "        str: The base64-encoded string of the image.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Fetch the image content from the URI\n",
        "        response = requests.get(uri)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        # Open the image using PIL\n",
        "        image = Image.open(BytesIO(response.content))\n",
        "\n",
        "        # Convert the image to bytes\n",
        "        buffer = BytesIO()\n",
        "        image.save(buffer, format=image.format)\n",
        "        image_bytes = buffer.getvalue()\n",
        "\n",
        "        # Encode the bytes to a base64 string\n",
        "        base64_string = base64.b64encode(image_bytes).decode('utf-8')\n",
        "\n",
        "        return base64_string\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading image from URI: {e}\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "OHPi08bCfoTA"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Execute Graphlit example"
      ],
      "metadata": {
        "id": "srzhQt4COLVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown, HTML\n",
        "import time\n",
        "\n",
        "# Remove any existing specifications; only needed for notebook example\n",
        "await delete_all_specifications()\n",
        "\n",
        "print('Deleted all specifications.')\n",
        "\n",
        "uri = \"https://graphlitplatform.blob.core.windows.net/test/images/medical_chart.jpeg\""
      ],
      "metadata": {
        "id": "fOb6COcONZIJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86750de5-e290-4a8b-e6e7-74b97bc5431e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleted all specifications.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create specification, and start multi-turn summarization conversation."
      ],
      "metadata": {
        "id": "kqG9WHXhbld-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "specification_id = await create_openai_specification(enums.OpenAIModels.GPT4O_128K)\n",
        "\n",
        "if specification_id is not None:\n",
        "    print(f'Created specification [{specification_id}].')\n",
        "\n",
        "    prompt = \"Thoroughly describe this image.\"\n",
        "\n",
        "    message = await describe_image(prompt, uri, specification_id)\n",
        "\n",
        "    if message is not None:\n",
        "        display(Markdown(f'**URI Description:**\\n{message}'))\n",
        "        print()\n",
        "\n",
        "    data = image_to_base64(uri)\n",
        "    mime_type = 'image/jpeg'\n",
        "\n",
        "    prompt = \"Extract all the text from this image into Markdown format.\"\n",
        "\n",
        "    if data is not None:\n",
        "        message = await describe_encoded_image(prompt, mime_type, data, specification_id)\n",
        "\n",
        "        if message is not None:\n",
        "            display(Markdown(f'**Base64 Description:**\\n{message}'))\n",
        "            print()\n"
      ],
      "metadata": {
        "id": "uSwSy3gXq7AN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 775
        },
        "outputId": "fa9c979c-1ab5-4252-9ece-9fdd8ca19b09"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created specification [cb3a1576-de18-48a3-8170-01ee2de0771c].\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**URI Description:**\nThe image is a graph titled \"Statistical Analysis of SE-HPLC (% Main Peak) Purity Data for Drug Product Stored at <<StorageRecommended>>°C.\" It displays the purity data of a drug product over time, measured in months, using SE-HPLC (Size-Exclusion High-Performance Liquid Chromatography).\n\n### Key Elements:\n\n- **Y-Axis:** Represents the percentage of the main peak by SE-HPLC, ranging from 98.5% to 100.0%.\n- **X-Axis:** Represents time in months, from 0 to 48 months.\n- **Data Points:** \n  - Black circles represent raw data.\n  - Red hash marks indicate the worst-case lot (049D108163).\n- **Lines:**\n  - A solid red horizontal line at 98.5% marks the specification limit.\n  - A green dashed line represents the 1-sided 95% confidence bound on the worst-case lot.\n  - A blue dashed line shows the predicted mean.\n  - A vertical dotted line indicates the current shelf life.\n\n### Observations:\n\n- Most data points are above the specification limit of 98.5%.\n- The predicted mean line (blue) shows a slight downward trend over time.\n- The worst-case lot data points (red) are generally lower than the other data points but still mostly above the specification limit.\n- The confidence bound (green dashed line) also trends downward but remains above the specification limit.\n\nThis graph is used to analyze the stability and purity of the drug product over time, ensuring it remains within acceptable limits."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Base64 Description:**\n```markdown\nFigure 1. Statistical Analysis of SE-HPLC (% Main Peak) Purity Data for Drug Product Stored at\n<<StorageRecommended>>°C\n\n% Main Peak by SE-HPLC\n\nSpecification=98.5%\n\nO O O Raw Data\n# # # Worst Case Lot 049D108163\n-- -- -- 1-sided 95% Confidence Bound on Worst Case Lot\n.. __ .. Current Shelf Life\n------- Predicted Mean\n\nTime (months)\n0 6 12 18 24 30 36 42 48\n```\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}