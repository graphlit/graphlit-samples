{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/graphlit/graphlit-samples/blob/main/python/Notebook%20Examples/Graphlit_2024_12_23_Analyze_Google_Drive_Feed_Ingestion_Costs_%26_Usage.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDz1gRPjOtn5"
      },
      "source": [
        "**Description**\n",
        "\n",
        "This example shows how to analyze the credit usage and individual usage logs from a Graphlit preparation workflow applied to a Google Drive feed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laG2MXUIhNnx"
      },
      "source": [
        "**Requirements**\n",
        "\n",
        "Prior to running this notebook, you will need to [signup](https://docs.graphlit.dev/getting-started/signup) for Graphlit, and [create a project](https://docs.graphlit.dev/getting-started/create-project).\n",
        "\n",
        "You will need the Graphlit organization ID, preview environment ID and JWT secret from your created project.\n",
        "\n",
        "Assign these properties as Colab secrets: GRAPHLIT_ORGANIZATION_ID, GRAPHLIT_ENVIRONMENT_ID and GRAPHLIT_JWT_SECRET.\n",
        "\n",
        "To access your Google Drive account, assign these properties as Colab secrets: GOOGLE_DRIVE_CLIENT_ID, GOOGLE_DRIVE_CLIENT_SECRET and GOOGLE_DRIVE_REFRESH_TOKEN.\n",
        "\n",
        "You can optionally assign GOOGLE_DRIVE_FOLDER_ID to the folder to be ingested.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwRzDHWWienC"
      },
      "source": [
        "Install Graphlit Python client SDK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fefizrrh4xGD"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade graphlit-client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfT9rOE8B5aA"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade isodate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fu8U7VzxrVeT"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade tiktoken"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abV1114jL-bR"
      },
      "source": [
        "Initialize Graphlit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WoMAWD4LLP_q"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from graphlit import Graphlit\n",
        "from graphlit_api import input_types, enums, exceptions\n",
        "\n",
        "os.environ['GRAPHLIT_ORGANIZATION_ID'] = userdata.get('GRAPHLIT_ORGANIZATION_ID')\n",
        "os.environ['GRAPHLIT_ENVIRONMENT_ID'] = userdata.get('GRAPHLIT_ENVIRONMENT_ID')\n",
        "os.environ['GRAPHLIT_JWT_SECRET'] = userdata.get('GRAPHLIT_JWT_SECRET')\n",
        "\n",
        "graphlit = Graphlit()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize Google Drive credentials"
      ],
      "metadata": {
        "id": "ftJ74m9KsHbh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['GOOGLE_DRIVE_CLIENT_ID'] = userdata.get('GOOGLE_DRIVE_CLIENT_ID')\n",
        "os.environ['GOOGLE_DRIVE_CLIENT_SECRET'] = userdata.get('GOOGLE_DRIVE_CLIENT_SECRET')\n",
        "os.environ['GOOGLE_DRIVE_REFRESH_TOKEN'] = userdata.get('GOOGLE_DRIVE_REFRESH_TOKEN')\n",
        "\n",
        "os.environ['GOOGLE_DRIVE_FOLDER_ID'] = userdata.get('GOOGLE_DRIVE_FOLDER_ID')"
      ],
      "metadata": {
        "id": "0U_kTrkSsBRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgRX57EHMVfl"
      },
      "source": [
        "Define Graphlit helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtwjJsvVOVCh"
      },
      "outputs": [],
      "source": [
        "from typing import List, Optional\n",
        "from datetime import datetime, timedelta\n",
        "import isodate\n",
        "\n",
        "# NOTE: folder id is '1105Gru1PaaD4u9DmPaRAGg_4MLQ3o9CQ' from this Google Drive URI\n",
        "# https://drive.google.com/drive/folders/1105Gab1PaaD4u9DmPaRAGg_4MLQ3o9CQ\n",
        "\n",
        "# NOTE: file id is '1TEzotGuRfCkQV6Ff1g-LBZK5h9CeCLG5' from this Google Drive URI\n",
        "# https://drive.google.com/file/d/1TEzotGuRfCkAB6Ff1g-LBZK5h9CeCLG5\n",
        "\n",
        "async def create_feed(correlation_id: str):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    input = input_types.FeedInput(\n",
        "        name=\"Google Drive\",\n",
        "        type=enums.FeedTypes.SITE,\n",
        "        site=input_types.SiteFeedPropertiesInput(\n",
        "            type=enums.FeedServiceTypes.GOOGLE_DRIVE,\n",
        "            googleDrive=input_types.GoogleDriveFeedPropertiesInput(\n",
        "                clientId=os.environ['GOOGLE_DRIVE_CLIENT_ID'],\n",
        "                clientSecret=os.environ['GOOGLE_DRIVE_CLIENT_SECRET'],\n",
        "                refreshToken=os.environ['GOOGLE_DRIVE_REFRESH_TOKEN'],\n",
        "                # NOTE: you can filter on specific folder, or multiple files\n",
        "                # if neither is assigned, it will recursively ingest from the root of the Google Drive account\n",
        "                folderId=os.environ['GOOGLE_DRIVE_FOLDER_ID'],\n",
        "                #files=[\"{file-id}\",\"{file-id}\"]\n",
        "            ),\n",
        "            readLimit=10 # limiting to 10 files\n",
        "        )\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.create_feed(input, correlation_id=correlation_id)\n",
        "\n",
        "        return response.create_feed.id if response.create_feed is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "    return None\n",
        "\n",
        "async def is_feed_done(feed_id: str):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    response = await graphlit.client.is_feed_done(feed_id)\n",
        "\n",
        "    return response.is_feed_done.result if response.is_feed_done is not None else None\n",
        "\n",
        "async def query_contents(feed_id: str):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.query_contents(\n",
        "            filter=input_types.ContentFilter(\n",
        "                feeds=[\n",
        "                    input_types.EntityReferenceFilter(\n",
        "                        id=feed_id\n",
        "                    )\n",
        "                ]\n",
        "            )\n",
        "        )\n",
        "\n",
        "        return response.contents.results if response.contents is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "async def lookup_usage(correlation_id: str):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.lookup_usage(correlation_id)\n",
        "\n",
        "        return response.lookup_usage if response.lookup_usage is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "async def lookup_credits(correlation_id: str):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.lookup_credits(correlation_id)\n",
        "\n",
        "        return response.lookup_credits if response.lookup_credits is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "async def delete_all_feeds():\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    _ = await graphlit.client.delete_all_feeds(is_synchronous=True)\n",
        "\n",
        "def dump_usage_record(record):\n",
        "    print(f\"{record.date}: {record.name}\")\n",
        "\n",
        "    duration = isodate.parse_duration(record.duration)\n",
        "\n",
        "    if record.workflow:\n",
        "        print(f\"- Workflow [{record.workflow}] took {duration}, used credits [{record.credits:.8f}]\")\n",
        "    else:\n",
        "        print(f\"- Operation took {duration}, used credits [{record.credits:.8f}]\")\n",
        "\n",
        "    if record.entity_id:\n",
        "        if record.entity_type:\n",
        "            if record.entity_type == enums.EntityTypes.CONTENT and record.content_type:\n",
        "                print(f\"- {record.entity_type} [{record.entity_id}]: Content type [{record.content_type}], file type [{record.file_type}]\")\n",
        "            else:\n",
        "                print(f\"- {record.entity_type} [{record.entity_id}]\")\n",
        "        else:\n",
        "            print(f\"- Entity [{record.entity_id}]\")\n",
        "\n",
        "    if record.model_service:\n",
        "        print(f\"- Model service [{record.model_service}], model name [{record.model_name}]\")\n",
        "\n",
        "    if record.processor_name:\n",
        "        if record.processor_name in [\"Deepgram Audio Transcription\", \"Assembly.AI Audio Transcription\"]:\n",
        "            length = timedelta(milliseconds=record.count or 0)\n",
        "\n",
        "            if record.model_name:\n",
        "                print(f\"- Processor name [{record.processor_name}], model name [{record.model_name}], length [{length}]\")\n",
        "            else:\n",
        "                print(f\"- Processor name [{record.processor_name}], length [{length}]\")\n",
        "        else:\n",
        "            if record.count:\n",
        "                if record.model_name:\n",
        "                    print(f\"- Processor name [{record.processor_name}], model name [{record.model_name}], units [{record.count}]\")\n",
        "                else:\n",
        "                    print(f\"- Processor name [{record.processor_name}], units [{record.count}]\")\n",
        "            else:\n",
        "                if record.model_name:\n",
        "                    print(f\"- Processor name [{record.processor_name}], model name [{record.model_name}]\")\n",
        "                else:\n",
        "                    print(f\"- Processor name [{record.processor_name}]\")\n",
        "\n",
        "    if record.uri:\n",
        "        print(f\"- URI [{record.uri}]\")\n",
        "\n",
        "    if record.name == \"Prompt completion\":\n",
        "        if record.prompt:\n",
        "            print(f\"- Prompt [{record.prompt_tokens} tokens (includes RAG context tokens)]:\")\n",
        "            print(record.prompt)\n",
        "\n",
        "        if record.completion:\n",
        "            print(f\"- Completion [{record.completion_tokens} tokens (includes JSON guardrails tokens)], throughput: {record.throughput:.3f} tokens/sec:\")\n",
        "            print(record.completion)\n",
        "\n",
        "    elif record.name == \"Text embedding\":\n",
        "        if record.prompt_tokens is not None:\n",
        "            print(f\"- Text embedding [{record.prompt_tokens} tokens], throughput: {record.throughput:.3f} tokens/sec\")\n",
        "\n",
        "    elif record.name == \"Document preparation\":\n",
        "        if record.prompt_tokens is not None and record.completion_tokens is not None:\n",
        "            print(f\"- Document preparation [{record.prompt_tokens} input tokens, {record.completion_tokens} output tokens], throughput: {record.throughput:.3f} tokens/sec\")\n",
        "\n",
        "    elif record.name == \"Data extraction\":\n",
        "        if record.prompt_tokens is not None and record.completion_tokens is not None:\n",
        "            print(f\"- Data extraction [{record.prompt_tokens} input tokens, {record.completion_tokens} output tokens], throughput: {record.throughput:.3f} tokens/sec\")\n",
        "\n",
        "    elif record.name == \"GraphQL\":\n",
        "        if record.request:\n",
        "            print(f\"- Request:\")\n",
        "            print(record.request)\n",
        "\n",
        "        if record.variables:\n",
        "            print(f\"- Variables:\")\n",
        "            print(record.variables)\n",
        "\n",
        "        if record.response:\n",
        "            print(f\"- Response:\")\n",
        "            print(record.response)\n",
        "\n",
        "    if record.name.startswith(\"Upload\"):\n",
        "        print(f\"- File upload [{record.count} bytes], throughput: {record.throughput:.3f} bytes/sec\")\n",
        "\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OIcEuioarRvQ"
      },
      "outputs": [],
      "source": [
        "import tiktoken\n",
        "\n",
        "model = \"gpt-4o\"\n",
        "encoding = tiktoken.encoding_for_model(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_UZ6wwvty7L"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import requests\n",
        "\n",
        "def parse_token_count(uri):\n",
        "    try:\n",
        "        response = requests.get(uri)\n",
        "        response.raise_for_status()  # Raise an error for HTTP issues\n",
        "\n",
        "        data = response.json()\n",
        "\n",
        "        tok_value = data.get(\"tok\")\n",
        "\n",
        "        return tok_value\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching the JSON file: {e}\")\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"Error decoding JSON: {e}\")\n",
        "\n",
        "    return None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srzhQt4COLVI"
      },
      "source": [
        "Execute Graphlit example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fOb6COcONZIJ"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, Markdown, HTML\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "# Remove any existing feeds; only needed for notebook example\n",
        "await delete_all_feeds()\n",
        "\n",
        "print('Deleted all feeds.')\n",
        "\n",
        "# NOTE: create a unique cost correlation ID\n",
        "correlation_id = datetime.now().isoformat()\n",
        "\n",
        "feed_id = await create_feed(correlation_id=correlation_id)\n",
        "\n",
        "if feed_id is not None:\n",
        "    print(f'Created feed [{feed_id}].')\n",
        "\n",
        "    # Wait for feed to complete, since ingestion happens asychronously\n",
        "    done = False\n",
        "    time.sleep(5)\n",
        "    while not done:\n",
        "        done = await is_feed_done(feed_id)\n",
        "\n",
        "        if not done:\n",
        "            time.sleep(10)\n",
        "\n",
        "    print(f'Completed feed [{feed_id}].')\n",
        "\n",
        "    # Query contents by feed\n",
        "    contents = await query_contents(feed_id)\n",
        "\n",
        "    if contents is not None:\n",
        "        print(f'Found {len(contents)} contents in feed [{feed_id}].')\n",
        "\n",
        "        total_token_count = 0\n",
        "\n",
        "        for content in contents:\n",
        "            if content is not None:\n",
        "\n",
        "                print(f'Ingested content [{content.id}], state [{content.state}]:')\n",
        "\n",
        "                if content.text_uri is not None:\n",
        "                    print(f'Text Mezzanine: {content.text_uri}')\n",
        "\n",
        "                    token_count = parse_token_count(content.text_uri)\n",
        "\n",
        "                    if token_count is not None:\n",
        "                        total_token_count += token_count\n",
        "\n",
        "        print(f'Token count: {total_token_count}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wnmfn5hMBCKK"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, HTML, JSON\n",
        "\n",
        "time.sleep(10) # give it some time for billing events to catch up\n",
        "\n",
        "credits = await lookup_credits(correlation_id)\n",
        "\n",
        "if credits is not None:\n",
        "    display(Markdown(f\"### Credits used: {credits.credits:.6f}\"))\n",
        "    print(f\"- storage [{credits.storage_ratio:.2f}%], compute [{credits.compute_ratio:.2f}%]\")\n",
        "    print(f\"- embedding [{credits.embedding_ratio:.2f}%], completion [{credits.completion_ratio:.2f}%]\")\n",
        "    print(f\"- ingestion [{credits.ingestion_ratio:.2f}%], indexing [{credits.indexing_ratio:.2f}%], preparation [{credits.preparation_ratio:.2f}%], extraction [{credits.extraction_ratio:.2f}%], enrichment [{credits.enrichment_ratio:.2f}%], publishing [{credits.publishing_ratio:.2f}%]\")\n",
        "    print(f\"- search [{credits.search_ratio:.2f}%], conversation [{credits.conversation_ratio:.2f}%]\")\n",
        "    print()\n",
        "\n",
        "usage = await lookup_usage(correlation_id)\n",
        "\n",
        "if usage is not None:\n",
        "    display(Markdown(f\"### Usage records:\"))\n",
        "\n",
        "    for record in usage:\n",
        "        dump_usage_record(record)\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sanitized output example\n",
        "\n",
        "Credits used: 0.129584\n",
        "- storage [8.18%], compute [65.92%]\n",
        "- embedding [25.90%], completion [0.00%]\n",
        "- ingestion [0.00%], indexing [0.00%], preparation [0.00%], extraction [0.00%], enrichment [0.00%], publishing [0.00%]\n",
        "- search [0.00%], conversation [0.00%]\n",
        "\n",
        "Usage records:\n",
        "2024-12-24T03:54:16.096Z: Serverless compute\n",
        "- Workflow [Entity Event] took 0:00:04.957193, used credits [0.00892501]\n",
        "- CONTENT [a1ffdcb9-6acf-4996-a38b-4b67d4e76c66]\n",
        "\n",
        "2024-12-24T03:54:15.983Z: Image embedding\n",
        "- Workflow [Preparation] took 0:00:00.436756, used credits [0.00240000]\n",
        "- CONTENT [a1ffdcb9-6acf-4996-a38b-4b67d4e76c66]: Content type [FILE], file type [IMAGE]\n",
        "- Model service [Jina], model name [CLIP_Image]\n",
        "\n",
        "2024-12-24T03:54:15.868Z: Serverless compute\n",
        "- Workflow [Entity Event] took 0:00:04.956168, used credits [0.00892317]\n",
        "- CONTENT [92880d3e-50d2-4511-9b18-aee8575e36b1]\n",
        "\n",
        "2024-12-24T03:54:15.785Z: Image embedding\n",
        "- Workflow [Preparation] took 0:00:00.644526, used credits [0.00800000]\n",
        "- CONTENT [92880d3e-50d2-4511-9b18-aee8575e36b1]: Content type [FILE], file type [IMAGE]\n",
        "- Model service [Jina], model name [CLIP_Image]\n",
        "\n",
        "2024-12-24T03:54:15.778Z: Serverless compute\n",
        "- Workflow [Entity Event] took 0:00:05.489983, used credits [0.00988426]\n",
        "- CONTENT [dd3b34b4-057f-4707-b7ba-4dd5e45b69eb]\n",
        "\n",
        "2024-12-24T03:54:15.747Z: Serverless compute\n",
        "- Workflow [Entity Event] took 0:00:05.789132, used credits [0.01042285]\n",
        "- CONTENT [fe36412f-05db-4572-8bb7-50ecac0d7d6c]\n",
        "\n",
        "2024-12-24T03:54:15.746Z: Serverless compute\n",
        "- Workflow [Entity Event] took 0:00:05.002557, used credits [0.00900669]\n",
        "- CONTENT [085c2cfb-8190-412e-b63a-ceb642657978]\n",
        "\n",
        "2024-12-24T03:54:15.746Z: Serverless compute\n",
        "- Workflow [Entity Event] took 0:00:05.144207, used credits [0.00926172]\n",
        "- CONTENT [6298bd37-9b79-4f93-87cc-3fafbd52de18]\n",
        "\n",
        "2024-12-24T03:54:15.746Z: Serverless compute\n",
        "- Workflow [Entity Event] took 0:00:05.304285, used credits [0.00954992]\n",
        "- CONTENT [a6fc9d9c-52c2-4744-ab98-47b478996ae1]\n",
        "\n",
        "2024-12-24T03:54:15.651Z: Image embedding\n",
        "- Workflow [Preparation] took 0:00:00.608577, used credits [0.00800000]\n",
        "- CONTENT [085c2cfb-8190-412e-b63a-ceb642657978]: Content type [FILE], file type [IMAGE]\n",
        "- Model service [Jina], model name [CLIP_Image]\n",
        "\n",
        "2024-12-24T03:54:15.648Z: Image embedding\n",
        "- Workflow [Preparation] took 0:00:00.768369, used credits [0.00600000]\n",
        "- CONTENT [dd3b34b4-057f-4707-b7ba-4dd5e45b69eb]: Content type [FILE], file type [IMAGE]\n",
        "- Model service [Jina], model name [CLIP_Image]\n",
        "\n",
        "2024-12-24T03:54:15.641Z: Image embedding\n",
        "- Workflow [Preparation] took 0:00:00.686420, used credits [0.00240000]\n",
        "- CONTENT [6298bd37-9b79-4f93-87cc-3fafbd52de18]: Content type [FILE], file type [IMAGE]\n",
        "- Model service [Jina], model name [CLIP_Image]\n",
        "\n",
        "2024-12-24T03:54:15.639Z: Image embedding\n",
        "- Workflow [Preparation] took 0:00:00.897627, used credits [0.00600000]\n",
        "- CONTENT [fe36412f-05db-4572-8bb7-50ecac0d7d6c]: Content type [FILE], file type [IMAGE]\n",
        "- Model service [Jina], model name [CLIP_Image]\n",
        "\n",
        "2024-12-24T03:54:15.636Z: Image embedding\n",
        "- Workflow [Preparation] took 0:00:00.716262, used credits [0.00240000]\n",
        "- CONTENT [a6fc9d9c-52c2-4744-ab98-47b478996ae1]: Content type [FILE], file type [IMAGE]\n",
        "- Model service [Jina], model name [CLIP_Image]\n",
        "\n",
        "2024-12-24T03:54:15.576Z: Serverless compute\n",
        "- Workflow [Entity Event] took 0:00:05.443816, used credits [0.00980114]\n",
        "- CONTENT [f35edd1d-d954-4c9c-beb7-fd236cc02a06]\n",
        "\n",
        "2024-12-24T03:54:15.508Z: Image embedding\n",
        "- Workflow [Preparation] took 0:00:00.812914, used credits [0.00600000]\n",
        "- CONTENT [f35edd1d-d954-4c9c-beb7-fd236cc02a06]: Content type [FILE], file type [IMAGE]\n",
        "- Model service [Jina], model name [CLIP_Image]\n",
        "\n",
        "2024-12-24T03:54:14.845Z: Upload Image\n",
        "- Workflow [Preparation] took 0:00:00.047656, used credits [0.00029575]\n",
        "- CONTENT [a1ffdcb9-6acf-4996-a38b-4b67d4e76c66]: Content type [FILE], file type [IMAGE]\n",
        "- File upload [89296 bytes], throughput: 1873754.097 bytes/sec\n",
        "\n",
        "2024-12-24T03:54:14.322Z: Upload Image\n",
        "- Workflow [Preparation] took 0:00:00.210142, used credits [0.00042451]\n",
        "- CONTENT [92880d3e-50d2-4511-9b18-aee8575e36b1]: Content type [FILE], file type [IMAGE]\n",
        "- File upload [128173 bytes], throughput: 609935.187 bytes/sec\n",
        "\n",
        "2024-12-24T03:54:13.874Z: Upload Image\n",
        "- Workflow [Preparation] took 0:00:00.042310, used credits [0.00032739]\n",
        "- CONTENT [085c2cfb-8190-412e-b63a-ceb642657978]: Content type [FILE], file type [IMAGE]\n",
        "- File upload [98851 bytes], throughput: 2336345.223 bytes/sec\n",
        "\n",
        "2024-12-24T03:54:13.761Z: Upload Image\n",
        "- Workflow [Preparation] took 0:00:00.055706, used credits [0.00024539]\n",
        "- CONTENT [6298bd37-9b79-4f93-87cc-3fafbd52de18]: Content type [FILE], file type [IMAGE]\n",
        "- File upload [74090 bytes], throughput: 1330020.698 bytes/sec\n",
        "\n",
        "2024-12-24T03:54:13.731Z: Upload Image\n",
        "- Workflow [Preparation] took 0:00:00.035058, used credits [0.00024539]\n",
        "- CONTENT [a6fc9d9c-52c2-4744-ab98-47b478996ae1]: Content type [FILE], file type [IMAGE]\n",
        "- File upload [74090 bytes], throughput: 2113367.068 bytes/sec\n",
        "\n",
        "2024-12-24T03:54:13.577Z: Upload Image\n",
        "- Workflow [Preparation] took 0:00:00.128996, used credits [0.00025456]\n",
        "- CONTENT [dd3b34b4-057f-4707-b7ba-4dd5e45b69eb]: Content type [FILE], file type [IMAGE]\n",
        "- File upload [76861 bytes], throughput: 595842.491 bytes/sec\n",
        "\n",
        "2024-12-24T03:54:13.542Z: Upload Image\n",
        "- Workflow [Preparation] took 0:00:00.042718, used credits [0.00024324]\n",
        "- CONTENT [fe36412f-05db-4572-8bb7-50ecac0d7d6c]: Content type [FILE], file type [IMAGE]\n",
        "- File upload [73441 bytes], throughput: 1719213.068 bytes/sec\n",
        "\n",
        "2024-12-24T03:54:13.540Z: Upload Image\n",
        "- Workflow [Preparation] took 0:00:00.088569, used credits [0.00021841]\n",
        "- CONTENT [f35edd1d-d954-4c9c-beb7-fd236cc02a06]: Content type [FILE], file type [IMAGE]\n",
        "- File upload [65946 bytes], throughput: 744569.507 bytes/sec\n",
        "\n",
        "2024-12-24T03:54:12.504Z: Upload Master\n",
        "- Workflow [Ingestion] took 0:00:00.240087, used credits [0.00127167]\n",
        "- CONTENT [a1ffdcb9-6acf-4996-a38b-4b67d4e76c66]: Content type [FILE], file type [IMAGE]\n",
        "- URI [https://www.googleapis.com/drive/v3/files/redacted]\n",
        "- File upload [383957 bytes], throughput: 1599243.107 bytes/sec\n",
        "\n",
        "2024-12-24T03:54:11.888Z: Upload Master\n",
        "- Workflow [Ingestion] took 0:00:00.046908, used credits [0.00036383]\n",
        "- CONTENT [92880d3e-50d2-4511-9b18-aee8575e36b1]: Content type [FILE], file type [IMAGE]\n",
        "- URI [https://www.googleapis.com/drive/v3/files/redacted]\n",
        "- File upload [109853 bytes], throughput: 2341867.004 bytes/sec\n",
        "\n",
        "2024-12-24T03:54:11.887Z: Upload Master\n",
        "- Workflow [Ingestion] took 0:00:00.047257, used credits [0.00017238]\n",
        "- CONTENT [6298bd37-9b79-4f93-87cc-3fafbd52de18]: Content type [FILE], file type [IMAGE]\n",
        "- URI [https://www.googleapis.com/drive/v3/files/redacted]\n",
        "- File upload [52046 bytes], throughput: 1101339.484 bytes/sec\n",
        "\n",
        "2024-12-24T03:54:11.809Z: Upload Master\n",
        "- Workflow [Ingestion] took 0:00:00.086177, used credits [0.00212647]\n",
        "- CONTENT [085c2cfb-8190-412e-b63a-ceb642657978]: Content type [FILE], file type [IMAGE]\n",
        "- URI [https://www.googleapis.com/drive/v3/files/redacted]\n",
        "- File upload [642051 bytes], throughput: 7450384.036 bytes/sec\n",
        "\n",
        "2024-12-24T03:54:11.774Z: Upload Master\n",
        "- Workflow [Ingestion] took 0:00:00.071127, used credits [0.00080229]\n",
        "- CONTENT [a6fc9d9c-52c2-4744-ab98-47b478996ae1]: Content type [FILE], file type [IMAGE]\n",
        "- URI [https://www.googleapis.com/drive/v3/files/redacted]\n",
        "- File upload [242236 bytes], throughput: 3405687.581 bytes/sec\n",
        "\n",
        "2024-12-24T03:54:11.534Z: Upload Master\n",
        "- Workflow [Ingestion] took 0:00:00.123872, used credits [0.00048866]\n",
        "- CONTENT [fe36412f-05db-4572-8bb7-50ecac0d7d6c]: Content type [FILE], file type [IMAGE]\n",
        "- URI [https://www.googleapis.com/drive/v3/files/redacted]\n",
        "- File upload [147542 bytes], throughput: 1191086.268 bytes/sec\n",
        "\n",
        "2024-12-24T03:54:11.457Z: Upload Master\n",
        "- Workflow [Ingestion] took 0:00:00.184800, used credits [0.00176999]\n",
        "- CONTENT [dd3b34b4-057f-4707-b7ba-4dd5e45b69eb]: Content type [FILE], file type [IMAGE]\n",
        "- URI [https://www.googleapis.com/drive/v3/files/redacted]\n",
        "- File upload [534418 bytes], throughput: 2891866.035 bytes/sec\n",
        "\n",
        "2024-12-24T03:54:11.343Z: Upload Master\n",
        "- Workflow [Ingestion] took 0:00:00.094902, used credits [0.00050401]\n",
        "- CONTENT [f35edd1d-d954-4c9c-beb7-fd236cc02a06]: Content type [FILE], file type [IMAGE]\n",
        "- URI [https://www.googleapis.com/drive/v3/files/redacted]\n",
        "- File upload [152176 bytes], throughput: 1603513.534 bytes/sec\n",
        "\n",
        "2024-12-24T03:54:09.818Z: Serverless compute\n",
        "- Workflow [Feed] took 0:00:03.171730, used credits [0.00285522]\n",
        "\n",
        "2024-12-24T03:53:56.459Z: GraphQL\n",
        "- Operation took 0:00:00.234135, used credits [0.00000000]\n",
        "- Request:\n",
        "mutation CreateFeed($feed: FeedInput!, $correlationId: String) { createFeed(feed: $feed, correlationId: $correlationId) { id name state type } }\n",
        "- Variables:\n",
        "{\"feed\":\"{ name: \\\"Google Drive\\\", type: SITE, site: { type: GOOGLE_DRIVE, googleDrive: { folderId: \\\"redacted\\\", refreshToken: \\\"redacted\\\", clientId: \\\"redacted\\\", clientSecret: \\\"redacted\\\" }, readLimit: 10 } }\",\"correlationId\":\"\\\"2024-12-24T03:53:56.197879\\\"\"}\n",
        "- Response:\n",
        "{\"data\":{\"createFeed\":{\"id\":\"90be0893-2384-49f6-8088-8d8fea97a81f\",\"name\":\"Google Drive\",\"state\":\"ENABLED\",\"type\":\"SITE\"}}}\n",
        "\n"
      ],
      "metadata": {
        "id": "RbULQqeQzl1e"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1cSnEIDnT7SYyUpfap5KiK6Y_LWLQdk6s",
      "authorship_tag": "ABX9TyO0Rem8iBKW4DoKPeDvPEVI",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}