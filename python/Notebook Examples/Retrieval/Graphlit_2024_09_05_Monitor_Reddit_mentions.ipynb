{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1cSnEIDnT7SYyUpfap5KiK6Y_LWLQdk6s",
      "authorship_tag": "ABX9TyMMlT9qGEjNDSR2FhTrsxCt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/graphlit/graphlit-samples/blob/main/python/Notebook%20Examples/Graphlit_2024_09_05_Monitor_Reddit_mentions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Description**\n",
        "\n",
        "This example shows how to ingest a subReddit and monitor for company mentions."
      ],
      "metadata": {
        "id": "pDz1gRPjOtn5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Requirements**\n",
        "\n",
        "Prior to running this notebook, you will need to [signup](https://docs.graphlit.dev/getting-started/signup) for Graphlit, and [create a project](https://docs.graphlit.dev/getting-started/create-project).\n",
        "\n",
        "You will need the Graphlit organization ID, preview environment ID and JWT secret from your created project.\n",
        "\n",
        "Assign these properties as Colab secrets: GRAPHLIT_ORGANIZATION_ID, GRAPHLIT_ENVIRONMENT_ID and GRAPHLIT_JWT_SECRET.\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "laG2MXUIhNnx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install Graphlit Python client SDK"
      ],
      "metadata": {
        "id": "NwRzDHWWienC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fefizrrh4xGD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0816b336-29e1-4954-b1f9-b3f2dfd6645e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting graphlit-client\n",
            "  Downloading graphlit_client-1.0.20240903001-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting httpx (from graphlit-client)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from graphlit-client) (2.8.2)\n",
            "Requirement already satisfied: PyJWT in /usr/local/lib/python3.10/dist-packages (from graphlit-client) (2.9.0)\n",
            "Collecting websockets (from graphlit-client)\n",
            "  Downloading websockets-13.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->graphlit-client) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->graphlit-client) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->graphlit-client) (4.12.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->graphlit-client) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->graphlit-client) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx->graphlit-client)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->graphlit-client) (3.8)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->graphlit-client) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->graphlit-client)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->graphlit-client) (1.2.2)\n",
            "Downloading graphlit_client-1.0.20240903001-py3-none-any.whl (197 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m197.7/197.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-13.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (157 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.3/157.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: websockets, h11, httpcore, httpx, graphlit-client\n",
            "Successfully installed graphlit-client-1.0.20240903001 h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 websockets-13.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade graphlit-client"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize Graphlit"
      ],
      "metadata": {
        "id": "abV1114jL-bR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from graphlit import Graphlit\n",
        "from graphlit_api import input_types, enums, exceptions\n",
        "\n",
        "os.environ['GRAPHLIT_ORGANIZATION_ID'] = userdata.get('GRAPHLIT_ORGANIZATION_ID')\n",
        "os.environ['GRAPHLIT_ENVIRONMENT_ID'] = userdata.get('GRAPHLIT_ENVIRONMENT_ID')\n",
        "os.environ['GRAPHLIT_JWT_SECRET'] = userdata.get('GRAPHLIT_JWT_SECRET')\n",
        "\n",
        "graphlit = Graphlit()"
      ],
      "metadata": {
        "id": "WoMAWD4LLP_q"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Graphlit helper functions"
      ],
      "metadata": {
        "id": "pgRX57EHMVfl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Optional\n",
        "\n",
        "# Create entity extraction workflow, using Azure AI Text Analytics to identify organizations\n",
        "async def create_workflow():\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    input = input_types.WorkflowInput(\n",
        "        name=\"Extraction\",\n",
        "        extraction=input_types.ExtractionWorkflowStageInput(\n",
        "            jobs=[\n",
        "                input_types.ExtractionWorkflowJobInput(\n",
        "                    connector=input_types.EntityExtractionConnectorInput(\n",
        "                        type=enums.EntityExtractionServiceTypes.AZURE_COGNITIVE_SERVICES_TEXT,\n",
        "                        extractedTypes=[enums.ObservableTypes.ORGANIZATION]\n",
        "                    )\n",
        "                )\n",
        "            ]\n",
        "        )\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.create_workflow(input)\n",
        "\n",
        "        return response.create_workflow.id if response.create_workflow is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "    return None\n",
        "\n",
        "async def create_feed(name: str, workflow_id: str):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    input = input_types.FeedInput(\n",
        "        name=name,\n",
        "        type=enums.FeedTypes.REDDIT,\n",
        "        reddit=input_types.RedditFeedPropertiesInput(\n",
        "            subredditName=name,\n",
        "            readLimit=50 # limiting to 50 Reddit posts\n",
        "        ),\n",
        "        workflow=input_types.EntityReferenceInput(\n",
        "            id=workflow_id\n",
        "        )\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.create_feed(input)\n",
        "\n",
        "        return response.create_feed.id if response.create_feed is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "    return None\n",
        "\n",
        "async def is_feed_done(feed_id: str):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    response = await graphlit.client.is_feed_done(feed_id)\n",
        "\n",
        "    return response.is_feed_done.result if response.is_feed_done is not None else None\n",
        "\n",
        "async def query_organizations(name: str):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.query_organizations(\n",
        "            filter=input_types.OrganizationFilter(\n",
        "                name=name\n",
        "            )\n",
        "        )\n",
        "\n",
        "        return response.organizations.results if response.organizations is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "# Locate contents where organization was observed (by Azure AI Text Analytics)\n",
        "async def query_contents(organization_id: str):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.query_contents(\n",
        "            filter=input_types.ContentFilter(\n",
        "                observations=[\n",
        "                    input_types.ObservationReferenceFilter(\n",
        "                        type=enums.ObservableTypes.ORGANIZATION,\n",
        "                        observable=input_types.EntityReferenceFilter(\n",
        "                            id=organization_id\n",
        "                        )\n",
        "                    )\n",
        "                ]\n",
        "            )\n",
        "        )\n",
        "\n",
        "        return response.contents.results if response.contents is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "async def delete_all_workflows():\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    _ = await graphlit.client.delete_all_workflows(is_synchronous=True)\n",
        "\n",
        "async def delete_all_feeds():\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    _ = await graphlit.client.delete_all_feeds(is_synchronous=True)\n"
      ],
      "metadata": {
        "id": "mtwjJsvVOVCh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Execute Graphlit example"
      ],
      "metadata": {
        "id": "srzhQt4COLVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown\n",
        "import time\n",
        "\n",
        "# NOTE: Fill in the Reddit subreddit name\n",
        "subreddit_name = \"Anthropic\"\n",
        "\n",
        "# NOTE: Fill in the organization name you're looking for\n",
        "organization_name = \"Google\"\n",
        "\n",
        "# Remove any existing feeds and workflows; only needed for notebook example\n",
        "await delete_all_feeds()\n",
        "await delete_all_workflows()\n",
        "\n",
        "print('Deleted all feeds and workflows.')\n",
        "\n",
        "workflow_id = await create_workflow()\n",
        "\n",
        "if workflow_id is not None:\n",
        "    print(f'Created workflow [{workflow_id}].')\n",
        "\n",
        "    feed_id = await create_feed(name=subreddit_name, workflow_id=workflow_id)\n",
        "\n",
        "    if feed_id is not None:\n",
        "        print(f'Created feed [{feed_id}].')\n",
        "\n",
        "        # Wait for feed to complete, since ingestion happens asychronously\n",
        "        done = False\n",
        "        time.sleep(5)\n",
        "        while not done:\n",
        "            done = await is_feed_done(feed_id)\n",
        "\n",
        "            if not done:\n",
        "                time.sleep(2)\n",
        "\n",
        "        print(f'Completed feed [{feed_id}].')\n",
        "\n",
        "        organizations = await query_organizations(organization_name)\n",
        "\n",
        "        if organizations is not None and organizations.count != 0:\n",
        "            for organization in organizations:\n",
        "                if organization is not None:\n",
        "                    print(f'Found organization [{organization.id}] named [{organization.name}].')\n",
        "\n",
        "                    # Query contents by organization\n",
        "                    contents = await query_contents(organization.id)\n",
        "\n",
        "                    if contents is not None:\n",
        "                        for content in contents:\n",
        "                            if content is not None:\n",
        "                                display(Markdown(f'### Found Reddit post [{content.id}] that mentioned [{organization_name}]'))\n",
        "                                display(Markdown(content.markdown))\n",
        "                                print()\n",
        "        else:\n",
        "            print(f'No organizations named [{organization_name}] found.')"
      ],
      "metadata": {
        "id": "fOb6COcONZIJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bbc89771-7755-46da-dd56-db36ec7ea4bd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleted all feeds and workflows.\n",
            "Created workflow [1038c205-457a-4e87-83f5-51edb44df053].\n",
            "Created feed [f1c586bb-2ff4-4af3-aaaf-4c4d3ec2d8e9].\n",
            "Completed feed [f1c586bb-2ff4-4af3-aaaf-4c4d3ec2d8e9].\n",
            "Found organization [947e908f-78e4-4801-a870-28d0687b594c] named [Google].\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Found Reddit post [93e46d7b-62d5-4431-a718-2e41c1874e58] that mentioned [Google]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Posted by u/mitt_brukernavn123 on Reddit at 8/11/2024 11:54:40 AM UTC: Would Anthropic win the race?\nHello! \n\nI'd love to hear your thoughts about this; \n\nThere are many companies creating models. Why would Anthropic win over others? Personally I'd put money on it solely on Dario Amodel. He seems like a lovely person and I'd assume people would want to work with him (attracting the best talent, which is a strong indicator of success). \n\nThe question I have is on his thought about the race to the top (incentivizing safe models through public opinion and eventually regulation) vs to the bottom (untethered AI). \n\nMy thought is that putting limitations on the model will not win if the untethered AI performs better (although with the side effect of being able to help bad actors). Locally optimizing business owners wouldn't care (generalization) if the chosen model is \"evil\" if it gives him marginally better profits? And regulation is irrelevant (businesses take a calculated risk in any decision; how would it show on the bottom line?)\n\nI support Dario's thinking but I can't see the clear and innate link to incentivizing business owners to buy Anthropic vs using Llama for instance. \n\nHave a great day, and sorry for any ignorance (just started exploring this and really like Anthropic)\n\nu/BrutallyStupid commented at 8/11/2024 12:22:24 PM UTC:\nI personally feel the models will be commoditised and heavily regulated and there will not be a single winner as such. And systems using the models will pick and choose the appropriate model (or combination of) for the task.\n\nu/timberwolf007 commented at 8/11/2024 12:24:32 PM UTC:\nIt greatly depends on a couple of things. How educated people  generally are about the subject and how many people care about societal safety.  Most people are ignorant ( not stupid) of what A.I. is and what it’s capable of. And most people don’t care if the immediate outcome seems advantageous without considering how it could be used against them in the long term.\n\nu/Gunner3210 commented at 8/11/2024 7:37:36 PM UTC:\nThe biggest risk is probably open source models making the race itself irrelevant.\n\nHonestly, the race is already over. GPT-4o and 3.5 Sonnet are already much more capable than they need to be to power products and features that we can imagine right now.\n\neg: We have 100K+ context windows + perfect retrieval across the entire window. That's like 900 pages worth of text. \n\nAs an LLM product innovator at the very forefront, I honestly don't know what to do with that, let alone more. The team I lead has built RAG, Knowledge graphs, metaprompting and agents, and we've applied these to products with a large enterprise userbase. \n\nWe're rate-limited by product development, and customer adoption. Not reasoning abilities of models.\n\nThe power of products in connecting people to tech is formidable. Google and Meta have the upper hand here by a very large margin. Even smaller players like Slack for example, could roll something out tomorrow that truly delivers an autopilot experience, taking over menial work you don't want to do. Or work output generation tools like Figma or GitHub + Vscode etc automatically resolving Github issues. The list goes on and on.\n\nI really doubt there is much of a future to organizations that solely train more capable models.\n\nYes, Anthropic has been able to move much faster than Meta, Google or even OpenAI. But they were small and nimble.\n\nFrom experience, I can tell you that their talent acq is disorganized at best. Not saying this from a perspective of someone who got rejected. But rather as someone who jumped through the hoops, got perfect scores on their assessments and then got completely ghosted after.\n\nSo velocity wise, not sure if Anthropic will keep the lead for much longer. Strategically, it's likely that there is no more money in model training left. Products are where it's at, and neither OpenAI nor Anthropic are building any products that their own models cannot simply write develop in minutes with minor guidance from a single engineer.\n\nu/Conscious-Map6957 commented at 8/11/2024 5:14:40 PM UTC:\nNot with their non-existent customer support and payment issues. Not the mention all the random, non-explained banning I've heard from other users. Currently their application layer is very user-friendly and much better than ChatGPT's (talking about the artifacts and general UX), but that's not much of an advantage to depend on.\n\nDespite some talent moving over to Anthropic, I don't see them making any leaps over OpenAI, Meta or Google. Ultimately I believe an open-source model with some polished UI and cute features will gain the most widespread adoption.\n\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Found Reddit post [75cf940d-cce5-4409-bf88-7034e848670b] that mentioned [Google]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Posted by u/AmirHotch on Reddit at 7/31/2024 12:37:20 PM UTC: Buyers aware-you might be charged monthly but cannot access your account.\nI signed up a Claude account with google account, and subscribe the Claude Pro Plan which was charged monthly. Unfortunately, my Google account was disabled after the subscription. Due to this, I cannot log in to my Claude account, unable to use the Pro Plan benefits I'm paying for,and cannot cancel the subscription through normal means. My credit card is still being charged monthly for a service I cannot access.  \nI have sent messages via every method I know. I delivery email to [support@anthropic.com](mailto:support@anthropic.com), but the mailbox responded automatically. I navigate to the help center and click the message icon, sent my issues to them, but no one responded me. I asked my account service, they said I had to contact the mechants.  \nI still be charged, but can't cancel, can't utilize, can't contact Anthropic. I don't know what should I do now.  \nCould anyone help me? I really need assistance, thank you.\n\nUpdate: The team contacted me after I requested follow-up on discord, it has been 2 weeks since I submitted my messages. And my Google account finally restored. The issue has been solved. My gratitude to all of your sincere help and warmness.\n\nu/dukhevych commented at 7/31/2024 12:48:00 PM UTC:\nFunny thing - i got a response from anthropic when i wrote to them as a subscribed pro user. Before that all my messages were ignored. Probably someone could contact them mentioning your account. Share with me in inbox your email, I can try.\n\nu/CapnWarhol commented at 7/31/2024 1:05:04 PM UTC:\nCredit card block and chargeback\n\nu/shadows_lord commented at 7/31/2024 1:49:52 PM UTC:\nAnthropic really needs to get its shit together with all these bans. My work email got banned immediately after trying to get on the company's Team account. We moved to OpenAI Teams just because of this!\n\nu/DaKuRa09 commented at 7/31/2024 1:45:36 PM UTC:\nMaybe try to reporting them via discord? The admin there are very active\n\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Found Reddit post [3b2fb1ab-de3b-41cf-87b9-d761b134f570] that mentioned [Google]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Posted by u/Outside-Web-4118 on Reddit at 7/28/2024 7:44:00 PM UTC: Trying to test anthropic, but I can't free trial to start paying\nA friend told me that if I'm tired of trying Open Ai, I can go and support Anthropic, but a problem arose when I wanted to register.\n\nI registered normally, with my personal Google account, but when I went to verify my number, I got a message that I had already done it. This seemed strange to me, because I had never tried Anthropic. So I used another account so I could try it with another number that I have, but the same thing happened, then I asked my friend to help me, but the same thing happened again, and he used 3 different devices to register.  \n  \nI really want to support Anthropic, but not without trying it before giving them my money, I've been like this since mid-week, do you know if it's a mistake or there are no free trials anymore? If there isn't any more, why leave that sign up there?\n\nu/cathline commented at 7/29/2024 9:34:56 PM UTC:\nMine said that my phone number was not qualified to sign up for the free credits.   \n\nMy carrier is google fi so maybe that's it, but it's not a temporary number.\n\nu/Excellent-Try-9490 commented at 8/8/2024 11:16:16 AM UTC:\nI had a lot of similar sign in issues with Open AI as well. I got tired of it and started using Poe.com which uses Claude by default. I use Poe primarily now and don’t use Open AI at all except for just comparing answers sometime. I find Claude Sonnet’s answers to be way more realistic, recent, detailed and relevant than OpenAI. So - they both have issues so we just have to deal with it. I finally got an OpenAI support person to contact me after several weeks. Maybe I just got lucky\n\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}