{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1cSnEIDnT7SYyUpfap5KiK6Y_LWLQdk6s",
      "authorship_tag": "ABX9TyO4QemeFJskmh8B6aAKlYf+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/graphlit/graphlit-samples/blob/main/python/Notebook%20Examples/Graphlit_2024_10_01_Compare_Multimodal_Image_Descriptions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Description**\n",
        "\n",
        "This example shows how to ingest a series of images, and compare the quality of different multimodal models for image descriptions."
      ],
      "metadata": {
        "id": "pDz1gRPjOtn5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Requirements**\n",
        "\n",
        "Prior to running this notebook, you will need to [signup](https://docs.graphlit.dev/getting-started/signup) for Graphlit, and [create a project](https://docs.graphlit.dev/getting-started/create-project).\n",
        "\n",
        "You will need the Graphlit organization ID, preview environment ID and JWT secret from your created project.\n",
        "\n",
        "Assign these properties as Colab secrets: GRAPHLIT_ORGANIZATION_ID, GRAPHLIT_ENVIRONMENT_ID and GRAPHLIT_JWT_SECRET.\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "laG2MXUIhNnx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install Graphlit Python client SDK"
      ],
      "metadata": {
        "id": "NwRzDHWWienC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fefizrrh4xGD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cda08eb7-1aa3-4ab8-99ee-2fa9e46c566e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: graphlit-client in /usr/local/lib/python3.10/dist-packages (1.0.20240930002)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from graphlit-client) (0.27.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from graphlit-client) (2.9.2)\n",
            "Requirement already satisfied: PyJWT in /usr/local/lib/python3.10/dist-packages (from graphlit-client) (2.9.0)\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.10/dist-packages (from graphlit-client) (13.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->graphlit-client) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->graphlit-client) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->graphlit-client) (4.12.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->graphlit-client) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->graphlit-client) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->graphlit-client) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->graphlit-client) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->graphlit-client) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->graphlit-client) (0.14.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->graphlit-client) (1.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade graphlit-client"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize Graphlit"
      ],
      "metadata": {
        "id": "abV1114jL-bR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from graphlit import Graphlit\n",
        "from graphlit_api import input_types, enums, exceptions\n",
        "\n",
        "os.environ['GRAPHLIT_ORGANIZATION_ID'] = userdata.get('GRAPHLIT_ORGANIZATION_ID')\n",
        "os.environ['GRAPHLIT_ENVIRONMENT_ID'] = userdata.get('GRAPHLIT_ENVIRONMENT_ID')\n",
        "os.environ['GRAPHLIT_JWT_SECRET'] = userdata.get('GRAPHLIT_JWT_SECRET')\n",
        "\n",
        "graphlit = Graphlit()"
      ],
      "metadata": {
        "id": "WoMAWD4LLP_q"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Graphlit helper functions"
      ],
      "metadata": {
        "id": "pgRX57EHMVfl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Optional\n",
        "\n",
        "async def create_openai_specification(model: enums.OpenAIModels, prompt: str, temperature: Optional[float] = None):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    input = input_types.SpecificationInput(\n",
        "        name=f\"OpenAI [{model}]\",\n",
        "        type=enums.SpecificationTypes.EXTRACTION,\n",
        "        serviceType=enums.ModelServiceTypes.OPEN_AI,\n",
        "        customInstructions=prompt,\n",
        "        openAI=input_types.OpenAIModelPropertiesInput(\n",
        "            temperature=temperature,\n",
        "            model=model\n",
        "        )\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.create_specification(input)\n",
        "\n",
        "        return response.create_specification.id if response.create_specification is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "    return None\n",
        "\n",
        "async def create_anthropic_specification(model: enums.AnthropicModels, prompt: str, temperature: Optional[float] = None):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    input = input_types.SpecificationInput(\n",
        "        name=f\"Anthropic [{model}]\",\n",
        "        type=enums.SpecificationTypes.EXTRACTION,\n",
        "        serviceType=enums.ModelServiceTypes.ANTHROPIC,\n",
        "        customInstructions=prompt,\n",
        "        anthropic=input_types.AnthropicModelPropertiesInput(\n",
        "            temperature=temperature,\n",
        "            model=model\n",
        "        )\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.create_specification(input)\n",
        "\n",
        "        return response.create_specification.id if response.create_specification is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "    return None\n",
        "\n",
        "async def create_mistral_specification(model: enums.MistralModels, prompt: str, temperature: Optional[float] = None):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    input = input_types.SpecificationInput(\n",
        "        name=f\"Mistral [{model}]\",\n",
        "        type=enums.SpecificationTypes.EXTRACTION,\n",
        "        serviceType=enums.ModelServiceTypes.MISTRAL,\n",
        "        customInstructions=prompt,\n",
        "        mistral=input_types.MistralModelPropertiesInput(\n",
        "            temperature=temperature,\n",
        "            model=model\n",
        "        )\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.create_specification(input)\n",
        "\n",
        "        return response.create_specification.id if response.create_specification is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "    return None\n",
        "\n",
        "async def create_google_specification(model: enums.GoogleModels, prompt: str, temperature: Optional[float] = None):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    input = input_types.SpecificationInput(\n",
        "        name=f\"Google [{model}]\",\n",
        "        type=enums.SpecificationTypes.EXTRACTION,\n",
        "        serviceType=enums.ModelServiceTypes.GOOGLE,\n",
        "        customInstructions=prompt,\n",
        "        google=input_types.GoogleModelPropertiesInput(\n",
        "            temperature=temperature,\n",
        "            model=model\n",
        "        )\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.create_specification(input)\n",
        "\n",
        "        return response.create_specification.id if response.create_specification is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "    return None\n",
        "\n",
        "async def create_workflow(specification_id: str):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    input = input_types.WorkflowInput(\n",
        "        name=\"Image Extraction\",\n",
        "        extraction=input_types.ExtractionWorkflowStageInput(\n",
        "            jobs=[\n",
        "                input_types.ExtractionWorkflowJobInput(\n",
        "                    connector=input_types.EntityExtractionConnectorInput(\n",
        "                        type=enums.EntityExtractionServiceTypes.MODEL_IMAGE,\n",
        "                        modelImage=input_types.ModelImageExtractionPropertiesInput(\n",
        "                            specification=input_types.EntityReferenceInput(id=specification_id)\n",
        "                        )\n",
        "                    )\n",
        "                )\n",
        "            ]\n",
        "        )\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.create_workflow(input)\n",
        "\n",
        "        return response.create_workflow.id if response.create_workflow is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "    return None\n",
        "\n",
        "async def ingest_uri(uri: str, workflow_id: str):\n",
        "    if graphlit.client is None:\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        # Using synchronous mode, so the notebook waits for the content to be ingested\n",
        "        response = await graphlit.client.ingest_uri(uri=uri, workflow=input_types.EntityReferenceInput(id=workflow_id), is_synchronous=True)\n",
        "\n",
        "        return response.ingest_uri.id if response.ingest_uri is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "async def get_content(content_id: str):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.get_content(content_id)\n",
        "\n",
        "        return response.content\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "async def delete_content(content_id: str):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    try:\n",
        "        _ = await graphlit.client.delete_content(content_id)\n",
        "\n",
        "        return\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return\n",
        "\n",
        "async def delete_all_specifications():\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    _ = await graphlit.client.delete_all_specifications(is_synchronous=True)\n",
        "\n",
        "async def delete_all_workflows():\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    _ = await graphlit.client.delete_all_workflows(is_synchronous=True)\n",
        "\n",
        "async def delete_all_contents():\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    _ = await graphlit.client.delete_all_contents(is_synchronous=True)\n"
      ],
      "metadata": {
        "id": "mtwjJsvVOVCh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Execute Graphlit example"
      ],
      "metadata": {
        "id": "srzhQt4COLVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown\n",
        "\n",
        "# Remove any existing specifications, workflows and contents; only needed for notebook example\n",
        "await delete_all_specifications()\n",
        "await delete_all_workflows()\n",
        "await delete_all_contents()\n",
        "\n",
        "print('Deleted all specifications, workflows and contents.')\n",
        "\n",
        "# Specify image to be analyzed\n",
        "uri = \"https://graphlitplatform.blob.core.windows.net/test/images/medical_chart.jpeg\"\n",
        "\n",
        "# Specify the extraction prompt to be applied to the image\n",
        "prompt = \"Summarize this image.\"\n",
        "#prompt = \"Please give concise summary to be added in document. No explanation.\"\n",
        "\n",
        "# Specify the model temperature\n",
        "temperature = 0.3\n",
        "\n",
        "specification_id = await create_anthropic_specification(enums.AnthropicModels.CLAUDE_3_5_SONNET, prompt, temperature)\n",
        "\n",
        "if specification_id is not None:\n",
        "    print(f'Created specification [{specification_id}].')\n",
        "\n",
        "    workflow_id = await create_workflow(specification_id)\n",
        "\n",
        "    if workflow_id is not None:\n",
        "        print(f'Created workflow [{workflow_id}].')\n",
        "\n",
        "        content_id = await ingest_uri(uri, workflow_id)\n",
        "\n",
        "        if content_id is not None:\n",
        "            print(f'Ingested content [{content_id}].')\n",
        "\n",
        "            content = await get_content(content_id)\n",
        "\n",
        "            if content is not None and content.image is not None:\n",
        "                display(Markdown(f'### Described image [{content.file_name}] with Anthropic Claude 3.5 Sonnet'))\n",
        "\n",
        "                if content.image.description is not None:\n",
        "                    display(Markdown(content.image.description))\n",
        "                else:\n",
        "                    print('- No description generated')\n",
        "\n",
        "            await delete_content(content_id)\n",
        "\n",
        "specification_id = await create_openai_specification(enums.OpenAIModels.GPT4O_128K, prompt, temperature)\n",
        "\n",
        "if specification_id is not None:\n",
        "    print(f'Created specification [{specification_id}].')\n",
        "\n",
        "    workflow_id = await create_workflow(specification_id)\n",
        "\n",
        "    if workflow_id is not None:\n",
        "        print(f'Created workflow [{workflow_id}].')\n",
        "\n",
        "        content_id = await ingest_uri(uri, workflow_id)\n",
        "\n",
        "        if content_id is not None:\n",
        "            print(f'Ingested content [{content_id}].')\n",
        "\n",
        "            content = await get_content(content_id)\n",
        "\n",
        "            if content is not None and content.image is not None:\n",
        "                display(Markdown(f'### Described image [{content.file_name}] with OpenAI GPT-4o'))\n",
        "\n",
        "                if content.image.description is not None:\n",
        "                    display(Markdown(content.image.description))\n",
        "                else:\n",
        "                    print('- No description generated')\n",
        "\n",
        "            await delete_content(content_id)\n",
        "\n",
        "specification_id = await create_openai_specification(enums.OpenAIModels.GPT4O_MINI_128K, prompt, temperature)\n",
        "\n",
        "if specification_id is not None:\n",
        "    print(f'Created specification [{specification_id}].')\n",
        "\n",
        "    workflow_id = await create_workflow(specification_id)\n",
        "\n",
        "    if workflow_id is not None:\n",
        "        print(f'Created workflow [{workflow_id}].')\n",
        "\n",
        "        content_id = await ingest_uri(uri, workflow_id)\n",
        "\n",
        "        if content_id is not None:\n",
        "            print(f'Ingested content [{content_id}].')\n",
        "\n",
        "            content = await get_content(content_id)\n",
        "\n",
        "            if content is not None and content.image is not None:\n",
        "                display(Markdown(f'### Described image [{content.file_name}] with OpenAI GPT-4o Mini'))\n",
        "\n",
        "                if content.image.description is not None:\n",
        "                    display(Markdown(content.image.description))\n",
        "                else:\n",
        "                    print('- No description generated')\n",
        "\n",
        "            await delete_content(content_id)\n",
        "\n",
        "specification_id = await create_mistral_specification(enums.MistralModels.PIXTRAL_12B_2409, prompt, temperature)\n",
        "\n",
        "if specification_id is not None:\n",
        "    print(f'Created specification [{specification_id}].')\n",
        "\n",
        "    workflow_id = await create_workflow(specification_id)\n",
        "\n",
        "    if workflow_id is not None:\n",
        "        print(f'Created workflow [{workflow_id}].')\n",
        "\n",
        "        content_id = await ingest_uri(uri, workflow_id)\n",
        "\n",
        "        if content_id is not None:\n",
        "            print(f'Ingested content [{content_id}].')\n",
        "\n",
        "            content = await get_content(content_id)\n",
        "\n",
        "            if content is not None and content.image is not None:\n",
        "                display(Markdown(f'### Described image [{content.file_name}] with Mistral Pixtral'))\n",
        "\n",
        "                if content.image.description is not None:\n",
        "                    display(Markdown(content.image.description))\n",
        "                else:\n",
        "                    print('- No description generated')\n",
        "\n",
        "            await delete_content(content_id)\n",
        "\n",
        "specification_id = await create_google_specification(enums.GoogleModels.GEMINI_1_5_FLASH_002, prompt, temperature)\n",
        "\n",
        "if specification_id is not None:\n",
        "    print(f'Created specification [{specification_id}].')\n",
        "\n",
        "    workflow_id = await create_workflow(specification_id)\n",
        "\n",
        "    if workflow_id is not None:\n",
        "        print(f'Created workflow [{workflow_id}].')\n",
        "\n",
        "        content_id = await ingest_uri(uri, workflow_id)\n",
        "\n",
        "        if content_id is not None:\n",
        "            print(f'Ingested content [{content_id}].')\n",
        "\n",
        "            content = await get_content(content_id)\n",
        "\n",
        "            if content is not None and content.image is not None:\n",
        "                display(Markdown(f'### Described image [{content.file_name}] with Google Gemini 1.5 Flash'))\n",
        "\n",
        "                if content.image.description is not None:\n",
        "                    display(Markdown(content.image.description))\n",
        "                else:\n",
        "                    print('- No description generated')\n",
        "\n",
        "            await delete_content(content_id)\n",
        "\n",
        "specification_id = await create_google_specification(enums.GoogleModels.GEMINI_1_5_PRO_002, prompt, temperature)\n",
        "\n",
        "if specification_id is not None:\n",
        "    print(f'Created specification [{specification_id}].')\n",
        "\n",
        "    workflow_id = await create_workflow(specification_id)\n",
        "\n",
        "    if workflow_id is not None:\n",
        "        print(f'Created workflow [{workflow_id}].')\n",
        "\n",
        "        content_id = await ingest_uri(uri, workflow_id)\n",
        "\n",
        "        if content_id is not None:\n",
        "            print(f'Ingested content [{content_id}].')\n",
        "\n",
        "            content = await get_content(content_id)\n",
        "\n",
        "            if content is not None and content.image is not None:\n",
        "                display(Markdown(f'### Described image [{content.file_name}] with Google Gemini 1.5 Pro'))\n",
        "\n",
        "                if content.image.description is not None:\n",
        "                    display(Markdown(content.image.description))\n",
        "                else:\n",
        "                    print('- No description generated')\n",
        "\n",
        "            await delete_content(content_id)\n"
      ],
      "metadata": {
        "id": "fOb6COcONZIJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ad028b06-d357-4951-994b-51cf94fa251d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleted all specifications, workflows and contents.\n",
            "Created specification [2e90fe8e-4d11-4614-a56b-1398326efba0].\n",
            "Created workflow [7a09fbb7-98bd-45fb-b065-d5d09d851614].\n",
            "Ingested content [476c4ac7-5b9f-44b2-acac-0fbda9d81cc4].\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Described image [medical_chart.jpeg] with Anthropic Claude 3.5 Sonnet"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "This image shows a statistical analysis graph of SE-HPLC (% Main Peak) purity data for a drug product stored at a recommended temperature. The graph plots the purity percentage on the y-axis against time in months on the x-axis, up to 48 months.\n\nThe graph includes raw data points, represented by circles, which mostly cluster between 99.4% and 99.8% purity. There are three trend lines: a blue line representing the predicted mean, a green dashed line showing the 1-sided 95% confidence bound for the worst-case lot, and a red line indicating the worst-case lot 049D108163.\n\nA horizontal red line at 98.5% marks the specification limit. The graph also indicates the current shelf life with a vertical dashed line around 36 months. Overall, the data suggests that the drug product maintains high purity levels well above the specification throughout the observed time period."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created specification [968ed675-132b-42a3-8ee2-6b61e4f868a2].\n",
            "Created workflow [606c4231-9dd7-4050-8bb2-00f19e16b781].\n",
            "Ingested content [dd72d8ae-7563-4bfd-a5e0-820fb864d525].\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Described image [medical_chart.jpeg] with OpenAI GPT-4o"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The image is a graph titled 'Statistical Analysis of SE-HPLC (% Main Peak) Purity Data for Drug Product Stored at <<StorageRecommended>>Â°C'. The x-axis represents time in months, and the y-axis represents the % Main Peak by SE-HPLC. The graph includes data points for raw data, worst case lot, 1-sided 95% confidence bound on worst case lot, current shelf life, and predicted mean. The data points show a general trend over time, with a statistical specification line at 98.5%."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created specification [97361979-908f-4695-a046-23b0b9d6dd09].\n",
            "Created workflow [386e963d-e490-4966-9db0-4f93c06a4bf5].\n",
            "Ingested content [a8c4d6d7-86e5-4f61-86a3-f9b3963b9126].\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Described image [medical_chart.jpeg] with OpenAI GPT-4o Mini"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The image presents a statistical analysis of the purity data for a drug product stored at a specified temperature. It includes a scatter plot showing the percentage of the main peak (% Main Peak by SE-HPLC) over time (in months). The data points represent raw data, with a highlighted worst-case lot and confidence intervals. A predicted mean line is also included, indicating the expected purity trend over time."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created specification [10dbaae7-33e2-4067-811f-c6b4723839ae].\n",
            "Created workflow [47dc6385-9699-4023-8b63-b10b5608f317].\n",
            "Ingested content [87026db6-7d6c-46cc-9666-4d24cdaf84d7].\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Described image [medical_chart.jpeg] with Mistral Pixtral"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "The image is a statistical analysis chart showing the % Main Peak by SE-HPLC for a drug product stored at recommended temperatures over time.\n\nThe x-axis represents time in months, ranging from 0 to 48 months.\n\nThe y-axis represents the % Main Peak by SE-HPLC, ranging from 98.5% to 100%.\n\nRaw data points are plotted as open circles, with a specific worst-case lot highlighted in red.\n\nA blue dashed line represents the predicted mean, and a green dashed line represents the 1-sided 95% confidence bound on the worst-case lot.\n\nThe specification limit is indicated at 98.5%, with the current shelf life marked at 36 months.\n\nThe data points generally cluster around the 99.4% to 99.7% range, showing a slight downward trend over time."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created specification [692a767e-fd3c-4120-8688-bfe421aa8f13].\n",
            "Created workflow [01e54bff-1aff-4ddc-bc99-005bc3d6d604].\n",
            "Ingested content [4d428554-9d7f-4106-8d5c-3bb9044fc277].\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Described image [medical_chart.jpeg] with Google Gemini 1.5 Flash"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Figure 1 shows a statistical analysis of SE-HPLC (% Main Peak) purity data for a drug product stored at the recommended temperature.  The graph displays raw data, the worst-case lot data, a 95% confidence bound, the current shelf life, and the predicted mean purity over time (in months)."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created specification [c67cba31-defd-4d17-bb8d-ffabaef915d7].\n",
            "Created workflow [6201a6b0-b020-4837-912d-f8af73b38348].\n",
            "Ingested content [720c8837-d656-4fee-b214-e421148e0436].\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Described image [medical_chart.jpeg] with Google Gemini 1.5 Pro"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "This figure presents a statistical analysis of SE-HPLC purity data, specifically the percentage of the main peak, for a drug product stored at a recommended temperature. The x-axis represents time in months, ranging from 0 to 48, while the y-axis represents the percentage of the main peak by SE-HPLC, ranging from approximately 98.5 to 100. The data points are represented by open circles, with the worst-case lot highlighted by hash symbols.  A specification limit is indicated at 98.5%. The graph also includes a predicted mean line, a current shelf life line, and a 1-sided 95% confidence bound on the worst-case lot."
          },
          "metadata": {}
        }
      ]
    }
  ]
}