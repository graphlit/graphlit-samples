{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1cSnEIDnT7SYyUpfap5KiK6Y_LWLQdk6s",
      "authorship_tag": "ABX9TyNktQoe5PgJtfvGkCeGwKFX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/graphlit/graphlit-samples/blob/main/python/Notebook%20Examples/Graphlit_2024_12_28_Assign_Labels_During_Ingestion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Description**\n",
        "\n",
        "This example shows how to assign labels to ingested content, when ingesting by URI and ingesting by feed."
      ],
      "metadata": {
        "id": "M7pOtiP1OaKd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Requirements**\n",
        "\n",
        "Prior to running this notebook, you will need to [signup](https://docs.graphlit.dev/getting-started/signup) for Graphlit, and [create a project](https://docs.graphlit.dev/getting-started/create-project).\n",
        "\n",
        "You will need the Graphlit organization ID, preview environment ID and JWT secret from your created project.\n",
        "\n",
        "Assign these properties as Colab secrets: GRAPHLIT_ORGANIZATION_ID, GRAPHLIT_ENVIRONMENT_ID and GRAPHLIT_JWT_SECRET.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "laG2MXUIhNnx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install Graphlit Python client SDK"
      ],
      "metadata": {
        "id": "NwRzDHWWienC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "fefizrrh4xGD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd278a9a-8c59-4479-bc16-095cc6951222"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: graphlit-client in /usr/local/lib/python3.10/dist-packages (1.0.20241228003)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from graphlit-client) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from graphlit-client) (2.10.3)\n",
            "Requirement already satisfied: PyJWT in /usr/local/lib/python3.10/dist-packages (from graphlit-client) (2.10.1)\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.10/dist-packages (from graphlit-client) (14.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->graphlit-client) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->graphlit-client) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->graphlit-client) (4.12.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->graphlit-client) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->graphlit-client) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->graphlit-client) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->graphlit-client) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->graphlit-client) (0.14.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->graphlit-client) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->graphlit-client) (1.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade graphlit-client"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize Graphlit"
      ],
      "metadata": {
        "id": "abV1114jL-bR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from graphlit import Graphlit\n",
        "from graphlit_api import input_types, enums, exceptions\n",
        "\n",
        "os.environ['GRAPHLIT_ORGANIZATION_ID'] = userdata.get('GRAPHLIT_ORGANIZATION_ID')\n",
        "os.environ['GRAPHLIT_ENVIRONMENT_ID'] = userdata.get('GRAPHLIT_ENVIRONMENT_ID')\n",
        "os.environ['GRAPHLIT_JWT_SECRET'] = userdata.get('GRAPHLIT_JWT_SECRET')\n",
        "\n",
        "graphlit = Graphlit()"
      ],
      "metadata": {
        "id": "WoMAWD4LLP_q"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Graphlit helper functions"
      ],
      "metadata": {
        "id": "pgRX57EHMVfl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Optional\n",
        "import json\n",
        "\n",
        "async def create_web_feed(uri: str, workflow_id: str):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    input = input_types.FeedInput(\n",
        "        name=\"Web\",\n",
        "        type=enums.FeedTypes.WEB,\n",
        "        web=input_types.WebFeedPropertiesInput(\n",
        "            uri=uri,\n",
        "            readLimit=5 # limiting to 5 web pages\n",
        "        ),\n",
        "        workflow=input_types.EntityReferenceInput(id=workflow_id) if workflow_id is not None else None,\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.create_feed(input)\n",
        "\n",
        "        return response.create_feed.id if response.create_feed is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "    return None\n",
        "\n",
        "async def is_feed_done(feed_id: str):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    response = await graphlit.client.is_feed_done(feed_id)\n",
        "\n",
        "    return response.is_feed_done.result if response.is_feed_done is not None else None\n",
        "\n",
        "async def create_ingestion_workflow(label_id: str):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    input = input_types.WorkflowInput(\n",
        "        name=\"Ingestion\",\n",
        "        ingestion=input_types.IngestionWorkflowStageInput(\n",
        "            observations=[input_types.ObservationReferenceInput(\n",
        "                type=enums.ObservableTypes.LABEL,\n",
        "                observable=input_types.NamedEntityReferenceInput(id=label_id)\n",
        "            )]\n",
        "        )\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.create_workflow(input)\n",
        "\n",
        "        return response.create_workflow.id if response.create_workflow is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "async def ingest_uri(uri: str, label_id: str):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    try:\n",
        "        # Using synchronous mode, so the notebook waits for the content to be ingested\n",
        "        response = await graphlit.client.ingest_uri(uri=uri,\n",
        "                                                    observations=[input_types.ObservationReferenceInput(\n",
        "                                                        type=enums.ObservableTypes.LABEL,\n",
        "                                                        observable=input_types.NamedEntityReferenceInput(id=label_id)\n",
        "                                                    )], is_synchronous=True)\n",
        "\n",
        "        return response.ingest_uri.id if response.ingest_uri is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "async def query_contents(label_id: str):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.query_contents(\n",
        "            filter=input_types.ContentFilter(\n",
        "                observations=[\n",
        "                    input_types.ObservationReferenceFilter(\n",
        "                        type=enums.ObservableTypes.LABEL,\n",
        "                        observable=input_types.EntityReferenceFilter(id=label_id)\n",
        "                    )\n",
        "                ]\n",
        "            )\n",
        "        )\n",
        "\n",
        "        return response.contents.results if response.contents is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "async def create_label(name: str):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.create_label(\n",
        "            label=input_types.LabelInput(\n",
        "                name=name\n",
        "            )\n",
        "        )\n",
        "\n",
        "        return response.create_label.id if response.create_label is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "async def query_labels(search_text: Optional[str] = None):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.query_labels(\n",
        "            filter=input_types.LabelFilter(\n",
        "                search=search_text\n",
        "            )\n",
        "        )\n",
        "\n",
        "        return response.labels.results if response.labels is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "async def delete_all_workflows():\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    _ = await graphlit.client.delete_all_workflows(is_synchronous=True)\n",
        "\n",
        "async def delete_all_contents():\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    _ = await graphlit.client.delete_all_contents(is_synchronous=True)\n",
        "\n",
        "async def delete_all_feeds():\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    _ = await graphlit.client.delete_all_feeds(is_synchronous=True)\n",
        "\n",
        "async def delete_all_observables():\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    _ = await graphlit.client.delete_all_persons()\n",
        "    _ = await graphlit.client.delete_all_organizations()\n",
        "    _ = await graphlit.client.delete_all_places()\n",
        "    _ = await graphlit.client.delete_all_events()\n",
        "    _ = await graphlit.client.delete_all_products()\n",
        "    _ = await graphlit.client.delete_all_softwares()\n",
        "    _ = await graphlit.client.delete_all_repos()\n",
        "    _ = await graphlit.client.delete_all_labels()\n",
        "    _ = await graphlit.client.delete_all_categories()"
      ],
      "metadata": {
        "id": "mtwjJsvVOVCh"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Execute Graphlit example"
      ],
      "metadata": {
        "id": "srzhQt4COLVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown\n",
        "import time\n",
        "\n",
        "# Remove any existing feeds, contents and workflows; only needed for notebook example\n",
        "await delete_all_workflows()\n",
        "await delete_all_feeds()\n",
        "await delete_all_contents()\n",
        "await delete_all_observables()\n",
        "\n",
        "print('Deleted all feeds, contents, and workflows.')\n",
        "\n",
        "other_label_id = await create_label(name=\"Other\")\n",
        "\n",
        "if other_label_id is not None:\n",
        "    print(f'Created other label [{other_label_id}].')\n",
        "\n",
        "label_id = await create_label(name=\"Graphlit\")\n",
        "\n",
        "if label_id is not None:\n",
        "    print(f'Created label [{label_id}].')\n",
        "\n",
        "    uri = \"https://www.graphlit.com\"\n",
        "\n",
        "    content_id = await ingest_uri(uri, label_id)\n",
        "\n",
        "    if content_id is not None:\n",
        "        print(f'Ingested URI [{uri}].')\n",
        "\n",
        "    workflow_id = await create_ingestion_workflow(label_id)\n",
        "\n",
        "    if workflow_id is not None:\n",
        "        print(f'Created workflow [{workflow_id}].')\n"
      ],
      "metadata": {
        "id": "fOb6COcONZIJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5316107f-7e27-46b7-d9f3-a3fc472eb2db"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleted all feeds, contents, and workflows.\n",
            "Created other label [ef3f4327-bdd8-4cf7-b2e8-f142b6579475].\n",
            "Created label [56a5ded9-028d-4a53-9fde-f992931c05c3].\n",
            "Ingested URI [https://www.graphlit.com].\n",
            "Created workflow [ecc89ef5-e0cc-4716-bef9-05d4b9b8a6a0].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ingest web feed"
      ],
      "metadata": {
        "id": "DMtVSOqtRL32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "        uri = \"https://changelog.graphlit.dev\"\n",
        "\n",
        "        feed_id = await create_web_feed(uri, workflow_id)\n",
        "\n",
        "        if feed_id is not None:\n",
        "            print(f'Created feed [{feed_id}].')\n",
        "\n",
        "            # Wait for feed to complete, since ingestion happens asychronously\n",
        "            done = False\n",
        "            time.sleep(5)\n",
        "            while not done:\n",
        "                done = await is_feed_done(feed_id)\n",
        "\n",
        "                if not done:\n",
        "                    time.sleep(10)\n",
        "\n",
        "            print(f'Completed feed [{feed_id}].')"
      ],
      "metadata": {
        "id": "idevPrm7F0Qg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7799dae5-b073-4703-c73c-2a4006bfd48b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created feed [62906623-1ab4-4038-b30e-16e1d43bf81c].\n",
            "Completed feed [62906623-1ab4-4038-b30e-16e1d43bf81c].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Search within ingested pages"
      ],
      "metadata": {
        "id": "4QrX7Iw9RIEG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    # Query contents by label; should get content from both graphlit.com and changelog.graphlit.dev\n",
        "    contents = await query_contents(label_id)\n",
        "\n",
        "    if contents is not None and len(contents) > 0:\n",
        "        print(f'Found {len(contents)} contents by label [{label_id}].')\n",
        "\n",
        "        for content in contents:\n",
        "            if content is not None:\n",
        "                display(Markdown(f'### Found {content.type} content [{content.id}]: URI [{content.uri}]'))\n",
        "\n",
        "                if content.observations is not None:\n",
        "                    for observation in content.observations:\n",
        "                        if observation is not None and observation.observable is not None:\n",
        "                            print(f'{observation.type} [{observation.id}]: {observation.observable.name} [{observation.observable.id}]')\n",
        "\n",
        "                print()\n",
        "            else:\n",
        "                print('No content found')\n",
        "    else:\n",
        "        print(f'No contents found.')\n"
      ],
      "metadata": {
        "id": "ziNt4DIzJSBp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568
        },
        "outputId": "d19b37d4-c28e-44a0-e7ed-02cc0e2910d6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 6 contents by label [56a5ded9-028d-4a53-9fde-f992931c05c3].\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Found PAGE content [c6e6afc9-6dea-442c-a346-6fdbc7fb0400]: URI [https://changelog.graphlit.dev/august-2023/august-3-new-data-model-for-observations-new-category-entity]"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LABEL [6dd1dc59-b455-4d7b-b72f-94f977b785fe]: Graphlit [56a5ded9-028d-4a53-9fde-f992931c05c3]\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Found PAGE content [d3c40a0e-e21e-424c-98c3-64512090471d]: URI [https://changelog.graphlit.dev/april-2024/april-7-support-for-discord-feeds-cohere-reranking-section-aware-chunking-and-retrieval]"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LABEL [140309b5-89db-458d-9c94-a900394a494d]: Graphlit [56a5ded9-028d-4a53-9fde-f992931c05c3]\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Found PAGE content [8443663e-d7ec-486e-8b98-f02f4863c7de]: URI [https://changelog.graphlit.dev/august-2023/august-17-prepare-for-usage-based-billing-append-sas-tokens-to-uris]"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LABEL [c8ae67a8-9a96-4d34-a233-d5b350062eae]: Graphlit [56a5ded9-028d-4a53-9fde-f992931c05c3]\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Found PAGE content [e6eaf3cd-6dfe-428e-9686-e822a1181a14]: URI [https://changelog.graphlit.dev/]"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LABEL [899bb896-a9bb-4e27-80e7-d7a13dbd4aaa]: Graphlit [56a5ded9-028d-4a53-9fde-f992931c05c3]\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Found PAGE content [1ee0f338-8a9c-4394-b7cb-aa54bb7278be]: URI [https://changelog.graphlit.dev/april-2024/april-23-support-for-python-and-typescript-sdks-latest-openai-cohere-and-groq-models-bug-fixes]"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LABEL [6ea0c1c3-d3f1-48b5-85c1-be4bf4b5f776]: Graphlit [56a5ded9-028d-4a53-9fde-f992931c05c3]\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Found PAGE content [7fc2b7d8-bc8c-476f-a8db-a4a7772e4fa0]: URI [https://www.graphlit.com/]"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LABEL [3a3bc832-1577-4cb0-bb23-f3e90af059c9]: Graphlit [56a5ded9-028d-4a53-9fde-f992931c05c3]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Query contents by label; should get nothing since it's using the other label\n",
        "if other_label_id is not None:\n",
        "    contents = await query_contents(other_label_id)\n",
        "\n",
        "    if contents is not None and len(contents) > 0:\n",
        "        print(f'Found {len(contents)} contents by label [{other_label_id}].')\n",
        "\n",
        "        for content in contents:\n",
        "            if content is not None:\n",
        "                display(Markdown(f'### Found {content.type} content [{content.id}]: URI [{content.uri}]'))\n",
        "\n",
        "                if content.observations is not None:\n",
        "                    for observation in content.observations:\n",
        "                        if observation is not None and observation.observable is not None:\n",
        "                            print(f'{observation.type} [{observation.id}]: {observation.observable.name} [{observation.observable.id}]')\n",
        "\n",
        "                print()\n",
        "            else:\n",
        "                print('No content found')\n",
        "    else:\n",
        "        print(f'No contents found.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Si8xAM47tT7h",
        "outputId": "9127a78f-b225-4f53-aaa5-6ca783eafa43"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No contents found.\n"
          ]
        }
      ]
    }
  ]
}