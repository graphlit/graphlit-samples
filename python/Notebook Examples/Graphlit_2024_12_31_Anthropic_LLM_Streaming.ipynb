{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1cSnEIDnT7SYyUpfap5KiK6Y_LWLQdk6s",
      "authorship_tag": "ABX9TyMmwyaxhzLSubS+C/pJzptr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/graphlit/graphlit-samples/blob/main/python/Notebook%20Examples/Graphlit_2024_12_31_Anthropic_LLM_Streaming.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Description**\n",
        "\n",
        "This example shows how to implement streaming Anthropic LLM completions using Graphlit for RAG retrieval."
      ],
      "metadata": {
        "id": "pDz1gRPjOtn5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Requirements**\n",
        "\n",
        "Prior to running this notebook, you will need to [signup](https://docs.graphlit.dev/getting-started/signup) for Graphlit, and [create a project](https://docs.graphlit.dev/getting-started/create-project).\n",
        "\n",
        "You will need the Graphlit organization ID, preview environment ID and JWT secret from your created project.\n",
        "\n",
        "Assign these properties as Colab secrets: GRAPHLIT_ORGANIZATION_ID, GRAPHLIT_ENVIRONMENT_ID and GRAPHLIT_JWT_SECRET.\n",
        "\n",
        "Assign this property as Colab secret: ANTHROPIC_API_KEY.\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "laG2MXUIhNnx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install Graphlit Python client SDK"
      ],
      "metadata": {
        "id": "NwRzDHWWienC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "fefizrrh4xGD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d606edaa-30d4-42f7-b4d2-3d785b93ac73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: graphlit-client in /usr/local/lib/python3.10/dist-packages (1.0.20241229004)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from graphlit-client) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from graphlit-client) (2.10.3)\n",
            "Requirement already satisfied: PyJWT in /usr/local/lib/python3.10/dist-packages (from graphlit-client) (2.10.1)\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.10/dist-packages (from graphlit-client) (14.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->graphlit-client) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->graphlit-client) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->graphlit-client) (4.12.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->graphlit-client) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->graphlit-client) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->graphlit-client) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->graphlit-client) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->graphlit-client) (0.14.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->graphlit-client) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->graphlit-client) (1.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade graphlit-client"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install Anthropic Python SDK"
      ],
      "metadata": {
        "id": "BRrWq5T6do8-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade anthropic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmSYxDDbdmQe",
        "outputId": "41d2fcb1-ea64-4a50-91e3-eeccbf669894"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: anthropic in /usr/local/lib/python3.10/dist-packages (0.42.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (2.10.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from anthropic) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.10/dist-packages (from anthropic) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->anthropic) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->anthropic) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->anthropic) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->anthropic) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->anthropic) (2.27.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize Graphlit"
      ],
      "metadata": {
        "id": "abV1114jL-bR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from graphlit import Graphlit\n",
        "from graphlit_api import input_types, enums, exceptions\n",
        "\n",
        "os.environ['GRAPHLIT_ORGANIZATION_ID'] = userdata.get('GRAPHLIT_ORGANIZATION_ID')\n",
        "os.environ['GRAPHLIT_ENVIRONMENT_ID'] = userdata.get('GRAPHLIT_ENVIRONMENT_ID')\n",
        "os.environ['GRAPHLIT_JWT_SECRET'] = userdata.get('GRAPHLIT_JWT_SECRET')\n",
        "\n",
        "graphlit = Graphlit()"
      ],
      "metadata": {
        "id": "WoMAWD4LLP_q"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize Anthropic"
      ],
      "metadata": {
        "id": "4KexblYef8R_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from anthropic import Anthropic\n",
        "\n",
        "os.environ['ANTHROPIC_API_KEY'] = userdata.get('ANTHROPIC_API_KEY')\n",
        "\n",
        "client = Anthropic(api_key=os.environ.get(\"ANTHROPIC_API_KEY\"))\n"
      ],
      "metadata": {
        "id": "DMzvfpu9f7Xi"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Graphlit helper functions"
      ],
      "metadata": {
        "id": "pgRX57EHMVfl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Optional\n",
        "\n",
        "async def ingest_uri(uri: str):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    try:\n",
        "        # Using synchronous mode, so the notebook waits for the content to be ingested\n",
        "        response = await graphlit.client.ingest_uri(uri=uri, is_synchronous=True)\n",
        "\n",
        "        return response.ingest_uri.id if response.ingest_uri is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "async def create_anthropic_specification(model: enums.AnthropicModels):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    input = input_types.SpecificationInput(\n",
        "        name=f\"Anthropic [{str(model)}]\",\n",
        "        type=enums.SpecificationTypes.COMPLETION,\n",
        "        serviceType=enums.ModelServiceTypes.ANTHROPIC,\n",
        "        anthropic=input_types.AnthropicModelPropertiesInput(\n",
        "            model=model,\n",
        "        )\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.create_specification(input)\n",
        "\n",
        "        return response.create_specification.id if response.create_specification is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "    return None\n",
        "\n",
        "async def create_conversation(specification_id: str):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    input = input_types.ConversationInput(\n",
        "        name=\"Conversation\",\n",
        "        specification=input_types.EntityReferenceInput(\n",
        "            id=specification_id\n",
        "        )\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.create_conversation(input)\n",
        "\n",
        "        return response.create_conversation.id if response.create_conversation is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "async def delete_conversation(conversation_id: str):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    if conversation_id is not None:\n",
        "        _ = await graphlit.client.delete_conversation(conversation_id)\n",
        "\n",
        "async def format_conversation(conversation_id: str, prompt: str):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.format_conversation(prompt, conversation_id)\n",
        "\n",
        "        return response.format_conversation.message.message if response.format_conversation is not None and response.format_conversation.message is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "async def complete_conversation(conversation_id: str, completion: str):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.complete_conversation(completion, conversation_id)\n",
        "\n",
        "        return response.complete_conversation.message.message if response.complete_conversation is not None and response.complete_conversation.message is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "async def get_conversation(conversation_id: str):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.get_conversation(conversation_id)\n",
        "\n",
        "        return response.conversation\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "async def delete_all_specifications():\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    _ = await graphlit.client.delete_all_specifications(is_synchronous=True)\n",
        "\n",
        "async def delete_all_conversations():\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    _ = await graphlit.client.delete_all_conversations(is_synchronous=True)\n",
        "\n",
        "async def delete_all_contents():\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    _ = await graphlit.client.delete_all_contents(is_synchronous=True)\n"
      ],
      "metadata": {
        "id": "mtwjJsvVOVCh"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Callable\n",
        "\n",
        "def stream_completion(prompt: str, model: str, callback: Callable[[str], None]) -> str:\n",
        "    stream = client.messages.create(\n",
        "        model=model,\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": prompt,\n",
        "            }\n",
        "        ],\n",
        "        max_tokens=4096,\n",
        "        stream=True\n",
        "    )\n",
        "\n",
        "    completion = \"\"\n",
        "\n",
        "    for event in stream:\n",
        "        if event is not None and event.type == \"content_block_delta\":\n",
        "            callback(event.delta.text)\n",
        "\n",
        "            completion += event.delta.text\n",
        "\n",
        "    return completion\n"
      ],
      "metadata": {
        "id": "c_K1mE9uda8V"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Execute Graphlit example"
      ],
      "metadata": {
        "id": "srzhQt4COLVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown, HTML\n",
        "import time\n",
        "\n",
        "# Remove any existing contents, conversations and specifications; only needed for notebook example\n",
        "await delete_all_conversations()\n",
        "await delete_all_specifications()\n",
        "await delete_all_contents()\n",
        "\n",
        "print('Deleted all contents, conversations and specifications.')\n",
        "\n",
        "content_id = await ingest_uri(uri=\"https://graphlitplatform.blob.core.windows.net/samples/Unstructured%20Data%20is%20Dark%20Data%20Podcast.mp3\")\n",
        "\n",
        "if content_id is not None:\n",
        "    print(f'Ingested content [{content_id}]:')"
      ],
      "metadata": {
        "id": "fOb6COcONZIJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30ddb609-f474-4fce-abd1-fe98e12ec1f1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleted all contents, conversations and specifications.\n",
            "Ingested content [2d0777a5-9984-4f2e-b974-a9eae7b65942]:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    # Specify the RAG prompt\n",
        "    prompt = \"In 3-5 detailed paragraphs, explain unstructured data and its usefulness for knowledge capture and retrieval.\""
      ],
      "metadata": {
        "id": "-9kBDUIdbhIy"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Anthropic Claude Sonnet 3.5 specification."
      ],
      "metadata": {
        "id": "4snKjK2ycVKw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    model = \"claude-3-5-sonnet-20241022\"\n",
        "\n",
        "    specification_id = await create_anthropic_specification(enums.AnthropicModels.CLAUDE_3_5_SONNET_20241022)\n",
        "\n",
        "    if specification_id is not None:\n",
        "        print(f'Created specification [{specification_id}].')\n",
        "\n",
        "        conversation_id = await create_conversation(specification_id)\n",
        "\n",
        "        if conversation_id is not None:\n",
        "            print(f'Created conversation [{conversation_id}].')\n",
        "\n",
        "            # NOTE: returns LLM-ready formatted prompt from RAG pipeline\n",
        "            message = await format_conversation(conversation_id, prompt)\n",
        "\n",
        "            if message is not None:\n",
        "                # NOTE: uncomment to see formatted LLM prompt\n",
        "\n",
        "                #print(f'Formatted LLM prompt:')\n",
        "                #print(message)\n",
        "                #print()\n",
        "\n",
        "                print(f'Streaming completion:')\n",
        "\n",
        "                completion = stream_completion(message, model, lambda delta: print(delta, end=''))\n",
        "\n",
        "                if completion is not None:\n",
        "                    # NOTE: stores completion back into conversation\n",
        "                    await complete_conversation(conversation_id, completion)\n",
        "\n",
        "            conversation = await get_conversation(conversation_id)\n",
        "\n",
        "            if conversation is not None:\n",
        "                display(Markdown(f'### Conversation [{conversation.id}]:'))\n",
        "\n",
        "                if conversation.messages is not None:\n",
        "                    for message in conversation.messages:\n",
        "                        if message is not None:\n",
        "                            display(Markdown(f'**{message.role}:**\\n{message.message}'))\n",
        "\n",
        "                print()\n",
        "\n",
        "            await delete_conversation(conversation_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596
        },
        "id": "L5AHVoKocVmD",
        "outputId": "1e4ea7ed-0117-4248-d3ae-062a29392d2c"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created specification [7fed5400-da89-4087-acc0-aa6e17db5431].\n",
            "Created conversation [6e216851-edc4-4b5a-913c-4ec37f33584f].\n",
            "Streaming completion:\n",
            "Unstructured data encompasses a broad range of content types including images, audio, 3D geometry, point clouds, documents and emails - essentially any file-based data that isn't neatly organized in traditional database tables. While these files actually do have defined structures and formats, the term \"unstructured\" refers more to how the meaningful content within them requires additional processing and analysis to extract useful information and insights.\n",
            "\n",
            "The value of unstructured data can be understood through the concept of layered metadata extraction. First-order metadata includes basic file attributes like timestamps and headers. Second-order metadata comes from analyzing the actual content, such as performing object detection on images or transcribing audio. Third-order metadata involves making higher-level inferences and connections, like linking detected objects to real-world assets in other systems or identifying relationships between different pieces of content. This layered approach allows increasingly sophisticated knowledge capture from raw data.\n",
            "\n",
            "A major challenge with unstructured data is that it often becomes \"dark data\" over time - valuable information that gets archived but becomes difficult to access or analyze effectively. Modern knowledge graph approaches help address this by creating dynamic connections between different pieces of content and their extracted insights. Rather than just searching file names or doing basic text searches, this enables semantic searching across relationships and patterns in the data. For example, drone imagery can be automatically analyzed to detect buildings and infrastructure, then linked to relevant maintenance documents and inspection records to provide rich contextual information.\n",
            "\n",
            "The end goal is to transform raw unstructured content into discoverable, analyzable knowledge that provides real business value. This could mean identifying trends over time, automatically alerting on important observations, or enabling powerful semantic search across previously disconnected information. The key is having systems that can not only extract insights from individual pieces of content, but also create meaningful connections between different data sources to build a comprehensive knowledge network that grows more valuable over time through continuous enrichment and analysis."
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Conversation [6e216851-edc4-4b5a-913c-4ec37f33584f]:"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**USER:**\nIn 3-5 detailed paragraphs, explain unstructured data and its usefulness for knowledge capture and retrieval."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**ASSISTANT:**\nUnstructured data encompasses a broad range of content types including images, audio, 3D geometry, point clouds, documents and emails - essentially any file-based data that isn't neatly organized in traditional database tables. While these files actually do have defined structures and formats, the term \"unstructured\" refers more to how the meaningful content within them requires additional processing and analysis to extract useful information and insights.\n\nThe value of unstructured data can be understood through the concept of layered metadata extraction. First-order metadata includes basic file attributes like timestamps and headers. Second-order metadata comes from analyzing the actual content, such as performing object detection on images or transcribing audio. Third-order metadata involves making higher-level inferences and connections, like linking detected objects to real-world assets in other systems or identifying relationships between different pieces of content. This layered approach allows increasingly sophisticated knowledge capture from raw data.\n\nA major challenge with unstructured data is that it often becomes \"dark data\" over time - valuable information that gets archived but becomes difficult to access or analyze effectively. Modern knowledge graph approaches help address this by creating dynamic connections between different pieces of content and their extracted insights. Rather than just searching file names or doing basic text searches, this enables semantic searching across relationships and patterns in the data. For example, drone imagery can be automatically analyzed to detect buildings and infrastructure, then linked to relevant maintenance documents and inspection records to provide rich contextual information.\n\nThe end goal is to transform raw unstructured content into discoverable, analyzable knowledge that provides real business value. This could mean identifying trends over time, automatically alerting on important observations, or enabling powerful semantic search across previously disconnected information. The key is having systems that can not only extract insights from individual pieces of content, but also create meaningful connections between different data sources to build a comprehensive knowledge network that grows more valuable over time through continuous enrichment and analysis."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}