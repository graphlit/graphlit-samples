{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1cSnEIDnT7SYyUpfap5KiK6Y_LWLQdk6s",
      "authorship_tag": "ABX9TyMSSW7Zd7mUZxYEn4yTN1n4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/graphlit/graphlit-samples/blob/main/python/Notebook%20Examples/Graphlit_2024_09_28_Explore_and_Search_Conversations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Description**\n",
        "\n",
        "This example shows how Graphlit supports semantic search over conversations, not just contents. It also shows how to locate similar conversations to a given conversation."
      ],
      "metadata": {
        "id": "pDz1gRPjOtn5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Requirements**\n",
        "\n",
        "Prior to running this notebook, you will need to [signup](https://docs.graphlit.dev/getting-started/signup) for Graphlit, and [create a project](https://docs.graphlit.dev/getting-started/create-project).\n",
        "\n",
        "You will need the Graphlit organization ID, preview environment ID and JWT secret from your created project.\n",
        "\n",
        "Assign these properties as Colab secrets: GRAPHLIT_ORGANIZATION_ID, GRAPHLIT_ENVIRONMENT_ID and GRAPHLIT_JWT_SECRET.\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "laG2MXUIhNnx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install Graphlit Python client SDK"
      ],
      "metadata": {
        "id": "NwRzDHWWienC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "fefizrrh4xGD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7aa2db40-601d-404e-e680-34faab4da7d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: graphlit-client in /usr/local/lib/python3.10/dist-packages (1.0.20240927001)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from graphlit-client) (0.27.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from graphlit-client) (2.9.2)\n",
            "Requirement already satisfied: PyJWT in /usr/local/lib/python3.10/dist-packages (from graphlit-client) (2.9.0)\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.10/dist-packages (from graphlit-client) (13.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->graphlit-client) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->graphlit-client) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->graphlit-client) (4.12.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->graphlit-client) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->graphlit-client) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->graphlit-client) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->graphlit-client) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->graphlit-client) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->graphlit-client) (0.14.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->graphlit-client) (1.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade graphlit-client"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize Graphlit"
      ],
      "metadata": {
        "id": "abV1114jL-bR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from graphlit import Graphlit\n",
        "from graphlit_api import input_types, enums, exceptions\n",
        "\n",
        "os.environ['GRAPHLIT_ORGANIZATION_ID'] = userdata.get('GRAPHLIT_ORGANIZATION_ID')\n",
        "os.environ['GRAPHLIT_ENVIRONMENT_ID'] = userdata.get('GRAPHLIT_ENVIRONMENT_ID')\n",
        "os.environ['GRAPHLIT_JWT_SECRET'] = userdata.get('GRAPHLIT_JWT_SECRET')\n",
        "\n",
        "graphlit = Graphlit()"
      ],
      "metadata": {
        "id": "WoMAWD4LLP_q"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Graphlit helper functions"
      ],
      "metadata": {
        "id": "pgRX57EHMVfl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Optional\n",
        "\n",
        "async def ingest_uri(uri: str):\n",
        "    if graphlit.client is None:\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        # Using synchronous mode, so the notebook waits for the content to be ingested\n",
        "        response = await graphlit.client.ingest_uri(uri=uri, is_synchronous=True)\n",
        "\n",
        "        return response.ingest_uri.id if response.ingest_uri is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "async def create_anthropic_specification(model: enums.AnthropicModels):\n",
        "    if graphlit.client is None:\n",
        "        return None\n",
        "\n",
        "    input = input_types.SpecificationInput(\n",
        "        name=f\"Anthropic [{str(model)}]\",\n",
        "        type=enums.SpecificationTypes.COMPLETION,\n",
        "        serviceType=enums.ModelServiceTypes.ANTHROPIC,\n",
        "        anthropic=input_types.AnthropicModelPropertiesInput(\n",
        "            model=model,\n",
        "        )\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.create_specification(input)\n",
        "\n",
        "        return response.create_specification.id if response.create_specification is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "    return None\n",
        "\n",
        "async def create_conversation(specification_id: str):\n",
        "    if graphlit.client is None:\n",
        "        return None\n",
        "\n",
        "    input = input_types.ConversationInput(\n",
        "        name=\"Conversation\",\n",
        "        specification=input_types.EntityReferenceInput(\n",
        "            id=specification_id\n",
        "        )\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.create_conversation(input)\n",
        "\n",
        "        return response.create_conversation.id if response.create_conversation is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "async def delete_conversation(conversation_id: str):\n",
        "    if graphlit.client is None:\n",
        "        return None\n",
        "\n",
        "    if conversation_id is not None:\n",
        "        _ = await graphlit.client.delete_conversation(conversation_id)\n",
        "\n",
        "async def prompt_conversation(conversation_id: str, prompt: str):\n",
        "    if graphlit.client is None:\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.prompt_conversation(prompt, conversation_id)\n",
        "\n",
        "        return response.prompt_conversation.message.message if response.prompt_conversation is not None and response.prompt_conversation.message is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "async def query_conversations(search: str):\n",
        "    if graphlit.client is None:\n",
        "        return None;\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.query_conversations(input_types.ConversationFilter(\n",
        "            search=search,\n",
        "            searchType=enums.SearchTypes.HYBRID\n",
        "        ))\n",
        "\n",
        "        return response.conversations.results if response.conversations is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "async def query_similar_conversations(conversation_id: str):\n",
        "    if graphlit.client is None:\n",
        "        return None;\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.query_conversations(input_types.ConversationFilter(\n",
        "            searchType=enums.SearchTypes.VECTOR,\n",
        "            conversations=[\n",
        "                input_types.EntityReferenceFilter(\n",
        "                    id=conversation_id\n",
        "                )\n",
        "            ] if conversation_id is not None else None\n",
        "        ))\n",
        "\n",
        "        return response.conversations.results if response.conversations is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "async def delete_all_specifications():\n",
        "    if graphlit.client is None:\n",
        "        return None\n",
        "\n",
        "    _ = await graphlit.client.delete_all_specifications(is_synchronous=True)\n",
        "\n",
        "async def delete_all_conversations():\n",
        "    if graphlit.client is None:\n",
        "        return None\n",
        "\n",
        "    _ = await graphlit.client.delete_all_conversations(is_synchronous=True)\n",
        "\n",
        "async def delete_all_contents():\n",
        "    if graphlit.client is None:\n",
        "        return None\n",
        "\n",
        "    _ = await graphlit.client.delete_all_contents(is_synchronous=True)\n"
      ],
      "metadata": {
        "id": "mtwjJsvVOVCh"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Execute Graphlit example"
      ],
      "metadata": {
        "id": "srzhQt4COLVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown, HTML\n",
        "import time\n",
        "\n",
        "# Remove any existing contents, conversations and specifications; only needed for notebook example\n",
        "await delete_all_conversations()\n",
        "await delete_all_specifications()\n",
        "await delete_all_contents()\n",
        "\n",
        "print('Deleted all contents, conversations and specifications.')\n",
        "\n",
        "content_id = await ingest_uri(uri=\"https://graphlitplatform.blob.core.windows.net/samples/Unstructured%20Data%20is%20Dark%20Data%20Podcast.mp3\")\n",
        "\n",
        "if content_id is not None:\n",
        "    print(f'Ingested content [{content_id}]:')"
      ],
      "metadata": {
        "id": "fOb6COcONZIJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "909e5e07-6fde-4457-de52-8840d640ab15"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleted all contents, conversations and specifications.\n",
            "Ingested content [c58d39c9-3fc0-4ba0-9685-86e1820cfcfc]:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create conversation using Anthropic Sonnet 3.5 specification."
      ],
      "metadata": {
        "id": "kqG9WHXhbld-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    specification_id = await create_anthropic_specification(enums.AnthropicModels.CLAUDE_3_5_SONNET)\n",
        "\n",
        "    if specification_id is not None:\n",
        "        print(f'Created specification [{specification_id}].')\n",
        "\n",
        "        conversation_id = await create_conversation(specification_id)\n",
        "\n",
        "        if conversation_id is not None:\n",
        "            print(f'Created conversation [{conversation_id}].')\n",
        "\n",
        "            prompt = \"In 3-5 detailed paragraphs, explain unstructured data and its usefulness for knowledge capture and retrieval.\"\n",
        "\n",
        "            message = await prompt_conversation(conversation_id, prompt)\n",
        "\n",
        "            if message is not None:\n",
        "                display(Markdown('### Conversation:'))\n",
        "                display(Markdown(f'**User:**\\n{prompt}'))\n",
        "                display(Markdown(f'**Assistant:**\\n{message}'))\n",
        "                print()\n",
        "\n",
        "            prompt = \"Can you go into more details about knowledge graphs?\"\n",
        "\n",
        "            message = await prompt_conversation(conversation_id, prompt)\n",
        "\n",
        "            if message is not None:\n",
        "                display(Markdown('### Conversation:'))\n",
        "                display(Markdown(f'**User:**\\n{prompt}'))\n",
        "                display(Markdown(f'**Assistant:**\\n{message}'))\n",
        "                print()\n",
        "\n",
        "            prompt = \"OK, but be more specific.\"\n",
        "\n",
        "            message = await prompt_conversation(conversation_id, prompt)\n",
        "\n",
        "            if message is not None:\n",
        "                display(Markdown('### Conversation:'))\n",
        "                display(Markdown(f'**User:**\\n{prompt}'))\n",
        "                display(Markdown(f'**Assistant:**\\n{message}'))\n",
        "                print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uSwSy3gXq7AN",
        "outputId": "d2de3f87-9207-4889-b370-f42ab1e16136"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created specification [7a67108a-37da-453f-92f0-ed47c4ab11c6].\n",
            "Created conversation [ee21a8be-1f41-48a0-b103-a57558b98cbc].\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Conversation:"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**User:**\nIn 3-5 detailed paragraphs, explain unstructured data and its usefulness for knowledge capture and retrieval."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Assistant:**\nUnstructured data refers to a broad set of file-based information that doesn't fit neatly into traditional structured databases. This includes images, audio, video, 3D geometry, point clouds, documents, and emails. While these files do have internal structures, they are considered 'unstructured' because their content is not easily parsed or queried like structured data. Unstructured data often contains rich, contextual information about real-world assets, people, places, and things, making it a valuable but challenging source of knowledge.\n\nTo extract value from unstructured data, it's processed through multiple layers of analysis. First-order metadata comes directly from file headers or embedded information. Second-order metadata is derived through techniques like object detection in images or term extraction from documents. Third-order metadata involves making inferences and connections, such as linking detected objects to entries in other databases. This layered approach allows for increasingly sophisticated knowledge capture, moving from basic file attributes to complex relationships and insights.\n\nThe power of unstructured data lies in its ability to be contextualized and connected through knowledge graphs. By extracting observations and creating relationships between different pieces of information, organizations can discover trends, perform semantic searches, and gain insights that were previously hidden. This approach allows for pivoting on any entity or relationship, enabling dynamic exploration of data across time and space. The result is a rich, interconnected web of knowledge that can drive more informed decision-making and uncover valuable patterns in historical and current data."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Conversation:"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**User:**\nCan you go into more details about knowledge graphs?"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Assistant:**\nKnowledge graphs are a powerful way to represent and connect data dynamically. Unlike traditional databases with rigid schemas, knowledge graphs allow for flexible relationships between entities through edges that can be created on-the-fly. This enables pivoting on any entity or relationship to discover new insights and connections.\n\nThe structure of a knowledge graph consists of nodes (entities) connected by edges (relationships). Entities can represent people, places, things, or concepts. The ability to invent new edges between entities allows for continuous enrichment of the graph as new connections are discovered or inferred.\n\nKnowledge graphs excel at contextualizing and connecting unstructured data. By extracting entities and relationships from various sources like documents, images, and audio, a rich web of interconnected information can be built. This allows for semantic searches and discovery of non-obvious patterns across large datasets.\n\nOne key advantage of knowledge graphs is their ability to provide multiple layers of metadata. First-order metadata comes directly from file headers, second-order from content analysis, and third-order from inferences and connections to external data sources. This layered approach enables increasingly sophisticated knowledge capture and insights.\n\nKnowledge graphs can continuously expand through web spidering techniques, following links to discover new related information. However, it's important to implement logic to avoid infinite loops and determine when to stop expanding based on diminishing returns of new, unique data."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Conversation:"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**User:**\nOK, but be more specific."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Assistant:**\nUnstructured data encompasses a wide range of file-based information including images, audio, video, 3D geometry, point clouds, documents, and emails. While these files have internal structures, they are considered 'unstructured' because their content is not easily parsed or queried like traditional structured databases.\n\nTo extract value from unstructured data, it's processed through multiple layers of analysis. First-order metadata comes directly from file headers or embedded information. Second-order metadata is derived through techniques like object detection in images or term extraction from documents. Third-order metadata involves making inferences and connections to external data sources.\n\nThe power of unstructured data lies in its ability to be contextualized and connected through knowledge graphs. By extracting observations and creating relationships between different pieces of information, organizations can discover trends, perform semantic searches, and gain insights that were previously hidden in their data.\n\nKnowledge graphs excel at representing and connecting data dynamically. Unlike traditional databases with rigid schemas, knowledge graphs allow for flexible relationships between entities through edges that can be created on-the-fly. This enables pivoting on any entity or relationship to discover new insights and connections.\n\nOne key advantage of knowledge graphs is their ability to provide multiple layers of metadata and contextualization. This layered approach enables increasingly sophisticated knowledge capture, moving from basic file attributes to complex relationships and insights across large datasets."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create another conversation, using same specification."
      ],
      "metadata": {
        "id": "Vl3bogq6egRb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "        conversation_id = await create_conversation(specification_id)\n",
        "\n",
        "        if conversation_id is not None:\n",
        "            print(f'Created conversation [{conversation_id}].')\n",
        "\n",
        "            prompt = \"Extract the names of any people mentioned in this podcast.\"\n",
        "\n",
        "            message = await prompt_conversation(conversation_id, prompt)\n",
        "\n",
        "            if message is not None:\n",
        "                display(Markdown('### Conversation:'))\n",
        "                display(Markdown(f'**User:**\\n{prompt}'))\n",
        "                display(Markdown(f'**Assistant:**\\n{message}'))\n",
        "                print()\n",
        "\n",
        "            prompt = \"Can you go into more details about their background or where they work?\"\n",
        "\n",
        "            message = await prompt_conversation(conversation_id, prompt)\n",
        "\n",
        "            if message is not None:\n",
        "                display(Markdown('### Conversation:'))\n",
        "                display(Markdown(f'**User:**\\n{prompt}'))\n",
        "                display(Markdown(f'**Assistant:**\\n{message}'))\n",
        "                print()\n",
        "\n",
        "            prompt = \"OK, describe the topics each of these people may be most interested in.\"\n",
        "\n",
        "            message = await prompt_conversation(conversation_id, prompt)\n",
        "\n",
        "            if message is not None:\n",
        "                display(Markdown('### Conversation:'))\n",
        "                display(Markdown(f'**User:**\\n{prompt}'))\n",
        "                display(Markdown(f'**Assistant:**\\n{message}'))\n",
        "                print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "cw1Qreajefc8",
        "outputId": "dce78e04-e8e1-428a-f3f0-1b9edaef0d88"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created conversation [b20f72d8-4a9a-49fa-b8e2-299e510e63b9].\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Conversation:"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**User:**\nExtract the names of any people mentioned in this podcast."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Assistant:**\nKirk Marple, founder and CEO of Unstruct Data\n\nDaniel, host of the Mapscaping podcast\n\nLizzie, a new supporter of the podcast on Patreon"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Conversation:"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**User:**\nCan you go into more details about their background or where they work?"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Assistant:**\nKirk Marple is the founder and CEO of Unstruct Data, a company that launched about a month prior to the podcast recording. He has a background as a long-time software developer, with experience in the media software space and dabbling in geospatial data throughout his career.\n\nDaniel is the host of the Mapscaping podcast, which focuses on the geospatial community. He conducts interviews with guests and manages the podcast's content and distribution.\n\nLizzie is mentioned as a new supporter of the Mapscaping podcast on Patreon, but no further details about her background or work are provided in the given context."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Conversation:"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**User:**\nOK, describe the topics each of these people may be most interested in."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Assistant:**\nKirk Marple: Unstructured data analysis, knowledge graphs, geospatial data integration, data enrichment techniques, and enterprise software solutions for managing and extracting insights from diverse data types like images, audio, and documents.\n\nDaniel: Geospatial technologies, mapping applications, podcast production and distribution, and interviewing experts in the geospatial field to share insights with the Mapscaping podcast audience.\n\nLizzie: As a Patreon supporter, Lizzie likely has an interest in geospatial topics, mapping technologies, and staying informed about developments in the geospatial community through podcast content."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create one more conversation, unrelated to the others."
      ],
      "metadata": {
        "id": "H5qOm_tp_jyY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "        conversation_id = await create_conversation(specification_id)\n",
        "\n",
        "        if conversation_id is not None:\n",
        "            print(f'Created conversation [{conversation_id}].')\n",
        "\n",
        "            prompt = \"Tell me fun facts about Seattle\"\n",
        "\n",
        "            message = await prompt_conversation(conversation_id, prompt)\n",
        "\n",
        "            if message is not None:\n",
        "                display(Markdown('### Conversation:'))\n",
        "                display(Markdown(f'**User:**\\n{prompt}'))\n",
        "                display(Markdown(f'**Assistant:**\\n{message}'))\n",
        "                print()\n",
        "\n",
        "            prompt = \"Name some of the major waterways\"\n",
        "\n",
        "            message = await prompt_conversation(conversation_id, prompt)\n",
        "\n",
        "            if message is not None:\n",
        "                display(Markdown('### Conversation:'))\n",
        "                display(Markdown(f'**User:**\\n{prompt}'))\n",
        "                display(Markdown(f'**Assistant:**\\n{message}'))\n",
        "                print()\n",
        "\n",
        "            prompt = \"What are its major sports teams?\"\n",
        "\n",
        "            message = await prompt_conversation(conversation_id, prompt)\n",
        "\n",
        "            if message is not None:\n",
        "                display(Markdown('### Conversation:'))\n",
        "                display(Markdown(f'**User:**\\n{prompt}'))\n",
        "                display(Markdown(f'**Assistant:**\\n{message}'))\n",
        "                print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 814
        },
        "id": "xvBIDowF_jF6",
        "outputId": "f7aa8f91-fdd3-48e7-ac1c-6655643c8395"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created conversation [d88456fa-acae-4a47-b925-bb02ef586a2c].\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Conversation:"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**User:**\nTell me fun facts about Seattle"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Assistant:**\nSeattle is home to the first Starbucks coffee shop, opened in 1971 at Pike Place Market. The city is known for its thriving coffee culture and has more coffee shops per capita than any other U.S. city.\n\nThe Space Needle, Seattle's iconic landmark, was built for the 1962 World's Fair. It stands 605 feet tall and offers panoramic views of the city, Puget Sound, and surrounding mountains.\n\nSeattle's famous Pike Place Market is one of the oldest continuously operated public farmers' markets in the United States, having opened in 1907. It's known for its flying fish tradition, where fishmongers toss fish to each other as part of the show.\n\nThe city experiences an average of 152 rainy days per year, contributing to its nickname 'The Emerald City' due to the lush green vegetation that thrives in the mild, moist climate.\n\nSeattle is the birthplace of grunge music, with iconic bands like Nirvana, Pearl Jam, and Soundgarden originating from the city's music scene in the 1990s."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Conversation:"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**User:**\nName some of the major waterways"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Assistant:**\nSeattle is surrounded by several major waterways, including Puget Sound, which is an inlet of the Pacific Ocean. This expansive body of water is crucial for the city's maritime activities and scenic beauty.\n\nLake Washington, a large freshwater lake, borders Seattle to the east. It's connected to Puget Sound via the Lake Washington Ship Canal, which includes the Hiram M. Chittenden Locks, also known as the Ballard Locks.\n\nThe Duwamish River flows through Seattle and empties into Elliott Bay, part of Puget Sound. This industrialized waterway has played a significant role in the city's economic development.\n\nLake Union, located within the city limits, is another notable waterway. It's popular for recreational activities and is home to many houseboats, giving Seattle a unique floating neighborhood.\n\nThe Green River, which becomes the Duwamish River as it enters Seattle, is an important waterway for the region's ecology and has historical significance for local Native American tribes."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Conversation:"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**User:**\nWhat are its major sports teams?"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Assistant:**\nSeattle Seahawks: NFL team known for their passionate '12th Man' fanbase and Super Bowl XLVIII victory in 2014.\n\nSeattle Mariners: MLB team featuring iconic players like Ken Griffey Jr. and Ichiro Suzuki in their history.\n\nSeattle Kraken: NHL expansion team that began play in 2021, quickly gaining popularity in the hockey-loving city.\n\nSeattle Sounders FC: MLS team with a strong following, multiple MLS Cup wins, and consistently high attendance.\n\nSeattle Storm: WNBA team boasting multiple championships and star players like Sue Bird and Breanna Stewart.\n\nOL Reign: NWSL team (formerly Seattle Reign FC) featuring top international talent in women's soccer."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "search = 'Mapscaping podcast'\n",
        "\n",
        "conversations = await query_conversations(search)\n",
        "\n",
        "if conversations is not None and len(conversations) > 0:\n",
        "    for conversation in conversations:\n",
        "        if conversation is not None:\n",
        "            display(Markdown(f'### Found conversation [{conversation.id}], relevance [{conversation.relevance}]:'))\n",
        "\n",
        "            if conversation.messages is not None:\n",
        "                for message in conversation.messages:\n",
        "                    if message is not None:\n",
        "                        display(Markdown(f'**{message.role}:**\\n{message.message}'))\n",
        "\n",
        "            print()\n",
        "else:\n",
        "    print(f'No conversations found for search [{search}].')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "jvBBr7u7e6H0",
        "outputId": "7143d08e-b52a-4202-a075-357999806401"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Found conversation [b20f72d8-4a9a-49fa-b8e2-299e510e63b9], relevance [0.03333333507180214]:"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**USER:**\nExtract the names of any people mentioned in this podcast."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**ASSISTANT:**\nKirk Marple, founder and CEO of Unstruct Data\n\nDaniel, host of the Mapscaping podcast\n\nLizzie, a new supporter of the podcast on Patreon"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**USER:**\nCan you go into more details about their background or where they work?"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**ASSISTANT:**\nKirk Marple is the founder and CEO of Unstruct Data, a company that launched about a month prior to the podcast recording. He has a background as a long-time software developer, with experience in the media software space and dabbling in geospatial data throughout his career.\n\nDaniel is the host of the Mapscaping podcast, which focuses on the geospatial community. He conducts interviews with guests and manages the podcast's content and distribution.\n\nLizzie is mentioned as a new supporter of the Mapscaping podcast on Patreon, but no further details about her background or work are provided in the given context."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**USER:**\nOK, describe the topics each of these people may be most interested in."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**ASSISTANT:**\nKirk Marple: Unstructured data analysis, knowledge graphs, geospatial data integration, data enrichment techniques, and enterprise software solutions for managing and extracting insights from diverse data types like images, audio, and documents.\n\nDaniel: Geospatial technologies, mapping applications, podcast production and distribution, and interviewing experts in the geospatial field to share insights with the Mapscaping podcast audience.\n\nLizzie: As a Patreon supporter, Lizzie likely has an interest in geospatial topics, mapping technologies, and staying informed about developments in the geospatial community through podcast content."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "search = 'Knowledge graphs'\n",
        "\n",
        "conversations = await query_conversations(search)\n",
        "\n",
        "if conversations is not None and len(conversations) > 0:\n",
        "    for conversation in conversations:\n",
        "        if conversation is not None:\n",
        "            display(Markdown(f'### Found conversation [{conversation.id}], relevance [{conversation.relevance}]:'))\n",
        "\n",
        "            if conversation.messages is not None:\n",
        "                for message in conversation.messages:\n",
        "                    if message is not None:\n",
        "                        display(Markdown(f'**{message.role}:**\\n{message.message}'))\n",
        "\n",
        "            print()\n",
        "else:\n",
        "    print(f'No conversations found for search [{search}].')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VKZa68ycgauf",
        "outputId": "7fbfde97-8133-4db5-a8cf-7086cb565096"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Found conversation [ee21a8be-1f41-48a0-b103-a57558b98cbc], relevance [0.03333333507180214]:"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**USER:**\nIn 3-5 detailed paragraphs, explain unstructured data and its usefulness for knowledge capture and retrieval."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**ASSISTANT:**\nUnstructured data refers to a broad set of file-based information that doesn't fit neatly into traditional structured databases. This includes images, audio, video, 3D geometry, point clouds, documents, and emails. While these files do have internal structures, they are considered 'unstructured' because their content is not easily parsed or queried like structured data. Unstructured data often contains rich, contextual information about real-world assets, people, places, and things, making it a valuable but challenging source of knowledge.\n\nTo extract value from unstructured data, it's processed through multiple layers of analysis. First-order metadata comes directly from file headers or embedded information. Second-order metadata is derived through techniques like object detection in images or term extraction from documents. Third-order metadata involves making inferences and connections, such as linking detected objects to entries in other databases. This layered approach allows for increasingly sophisticated knowledge capture, moving from basic file attributes to complex relationships and insights.\n\nThe power of unstructured data lies in its ability to be contextualized and connected through knowledge graphs. By extracting observations and creating relationships between different pieces of information, organizations can discover trends, perform semantic searches, and gain insights that were previously hidden. This approach allows for pivoting on any entity or relationship, enabling dynamic exploration of data across time and space. The result is a rich, interconnected web of knowledge that can drive more informed decision-making and uncover valuable patterns in historical and current data."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**USER:**\nCan you go into more details about knowledge graphs?"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**ASSISTANT:**\nKnowledge graphs are a powerful way to represent and connect data dynamically. Unlike traditional databases with rigid schemas, knowledge graphs allow for flexible relationships between entities through edges that can be created on-the-fly. This enables pivoting on any entity or relationship to discover new insights and connections.\n\nThe structure of a knowledge graph consists of nodes (entities) connected by edges (relationships). Entities can represent people, places, things, or concepts. The ability to invent new edges between entities allows for continuous enrichment of the graph as new connections are discovered or inferred.\n\nKnowledge graphs excel at contextualizing and connecting unstructured data. By extracting entities and relationships from various sources like documents, images, and audio, a rich web of interconnected information can be built. This allows for semantic searches and discovery of non-obvious patterns across large datasets.\n\nOne key advantage of knowledge graphs is their ability to provide multiple layers of metadata. First-order metadata comes directly from file headers, second-order from content analysis, and third-order from inferences and connections to external data sources. This layered approach enables increasingly sophisticated knowledge capture and insights.\n\nKnowledge graphs can continuously expand through web spidering techniques, following links to discover new related information. However, it's important to implement logic to avoid infinite loops and determine when to stop expanding based on diminishing returns of new, unique data."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**USER:**\nOK, but be more specific."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**ASSISTANT:**\nUnstructured data encompasses a wide range of file-based information including images, audio, video, 3D geometry, point clouds, documents, and emails. While these files have internal structures, they are considered 'unstructured' because their content is not easily parsed or queried like traditional structured databases.\n\nTo extract value from unstructured data, it's processed through multiple layers of analysis. First-order metadata comes directly from file headers or embedded information. Second-order metadata is derived through techniques like object detection in images or term extraction from documents. Third-order metadata involves making inferences and connections to external data sources.\n\nThe power of unstructured data lies in its ability to be contextualized and connected through knowledge graphs. By extracting observations and creating relationships between different pieces of information, organizations can discover trends, perform semantic searches, and gain insights that were previously hidden in their data.\n\nKnowledge graphs excel at representing and connecting data dynamically. Unlike traditional databases with rigid schemas, knowledge graphs allow for flexible relationships between entities through edges that can be created on-the-fly. This enables pivoting on any entity or relationship to discover new insights and connections.\n\nOne key advantage of knowledge graphs is their ability to provide multiple layers of metadata and contextualization. This layered approach enables increasingly sophisticated knowledge capture, moving from basic file attributes to complex relationships and insights across large datasets."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Found conversation [b20f72d8-4a9a-49fa-b8e2-299e510e63b9], relevance [0.0317460335791111]:"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**USER:**\nExtract the names of any people mentioned in this podcast."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**ASSISTANT:**\nKirk Marple, founder and CEO of Unstruct Data\n\nDaniel, host of the Mapscaping podcast\n\nLizzie, a new supporter of the podcast on Patreon"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**USER:**\nCan you go into more details about their background or where they work?"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**ASSISTANT:**\nKirk Marple is the founder and CEO of Unstruct Data, a company that launched about a month prior to the podcast recording. He has a background as a long-time software developer, with experience in the media software space and dabbling in geospatial data throughout his career.\n\nDaniel is the host of the Mapscaping podcast, which focuses on the geospatial community. He conducts interviews with guests and manages the podcast's content and distribution.\n\nLizzie is mentioned as a new supporter of the Mapscaping podcast on Patreon, but no further details about her background or work are provided in the given context."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**USER:**\nOK, describe the topics each of these people may be most interested in."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**ASSISTANT:**\nKirk Marple: Unstructured data analysis, knowledge graphs, geospatial data integration, data enrichment techniques, and enterprise software solutions for managing and extracting insights from diverse data types like images, audio, and documents.\n\nDaniel: Geospatial technologies, mapping applications, podcast production and distribution, and interviewing experts in the geospatial field to share insights with the Mapscaping podcast audience.\n\nLizzie: As a Patreon supporter, Lizzie likely has an interest in geospatial topics, mapping technologies, and staying informed about developments in the geospatial community through podcast content."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Search for similar conversation. Note that the conversations return their relevance on 0-1 scale, based on vector embedding similarity.  You can develop a cutoff threshold for similarity, or just take the most similar conversation, depending on your use case."
      ],
      "metadata": {
        "id": "WUo92BW4jB7w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_id = conversations[0].id if conversations is not None and len(conversations) > 0 else None\n",
        "\n",
        "if conversation_id is not None:\n",
        "    similar_conversations = await query_similar_conversations(conversation_id)\n",
        "\n",
        "    if similar_conversations is not None and len(similar_conversations) > 0:\n",
        "        for conversation in similar_conversations:\n",
        "            if conversation is not None and conversation.id != conversation_id: # ignore same conversation\n",
        "                display(Markdown(f'### Found similar conversation [{conversation.id}] to [{conversation_id}], relevance [{conversation.relevance}]:'))\n",
        "\n",
        "                if conversation.messages is not None:\n",
        "                    for message in conversation.messages:\n",
        "                        if message is not None:\n",
        "                            display(Markdown(f'**{message.role}:**\\n{message.message}'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "id": "LRqN0S7Ci0BO",
        "outputId": "d84b3061-ce35-4dbd-9380-c4e70d07bcec"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Found similar conversation [b20f72d8-4a9a-49fa-b8e2-299e510e63b9] to [ee21a8be-1f41-48a0-b103-a57558b98cbc], relevance [0.8349484]:"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**USER:**\nExtract the names of any people mentioned in this podcast."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**ASSISTANT:**\nKirk Marple, founder and CEO of Unstruct Data\n\nDaniel, host of the Mapscaping podcast\n\nLizzie, a new supporter of the podcast on Patreon"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**USER:**\nCan you go into more details about their background or where they work?"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**ASSISTANT:**\nKirk Marple is the founder and CEO of Unstruct Data, a company that launched about a month prior to the podcast recording. He has a background as a long-time software developer, with experience in the media software space and dabbling in geospatial data throughout his career.\n\nDaniel is the host of the Mapscaping podcast, which focuses on the geospatial community. He conducts interviews with guests and manages the podcast's content and distribution.\n\nLizzie is mentioned as a new supporter of the Mapscaping podcast on Patreon, but no further details about her background or work are provided in the given context."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**USER:**\nOK, describe the topics each of these people may be most interested in."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**ASSISTANT:**\nKirk Marple: Unstructured data analysis, knowledge graphs, geospatial data integration, data enrichment techniques, and enterprise software solutions for managing and extracting insights from diverse data types like images, audio, and documents.\n\nDaniel: Geospatial technologies, mapping applications, podcast production and distribution, and interviewing experts in the geospatial field to share insights with the Mapscaping podcast audience.\n\nLizzie: As a Patreon supporter, Lizzie likely has an interest in geospatial topics, mapping technologies, and staying informed about developments in the geospatial community through podcast content."
          },
          "metadata": {}
        }
      ]
    }
  ]
}