{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1cSnEIDnT7SYyUpfap5KiK6Y_LWLQdk6s",
      "authorship_tag": "ABX9TyNKmvLXxWm53d1anuFLmnqf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/graphlit/graphlit-samples/blob/main/python/Notebook%20Examples/Graphlit_2024_09_30_Publish_Podcast_Guest_Backgrounder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Description**\n",
        "\n",
        "This example shows how to ingest podcasts from Azure blob storage, and publish a summarized background bio of the podcast guest."
      ],
      "metadata": {
        "id": "M7pOtiP1OaKd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Requirements**\n",
        "\n",
        "Prior to running this notebook, you will need to [signup](https://docs.graphlit.dev/getting-started/signup) for Graphlit, and [create a project](https://docs.graphlit.dev/getting-started/create-project).\n",
        "\n",
        "You will need the Graphlit organization ID, preview environment ID and JWT secret from your created project.\n",
        "\n",
        "Assign these properties as Colab secrets: GRAPHLIT_ORGANIZATION_ID, GRAPHLIT_ENVIRONMENT_ID and GRAPHLIT_JWT_SECRET.\n",
        "\n",
        "Place MP3 recordings of podcasts on Azure blob storage.\n",
        "\n",
        "Assign these properties as Colab secrets: AZURE_STORAGE_ACCOUNT_NAME and AZURE_STORAGE_ACCESS_KEY.\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "laG2MXUIhNnx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install Graphlit Python client SDK"
      ],
      "metadata": {
        "id": "NwRzDHWWienC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fefizrrh4xGD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b96dad2c-9b44-4273-c814-4d4378d6eee2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting graphlit-client\n",
            "  Downloading graphlit_client-1.0.20241228002-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from graphlit-client) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from graphlit-client) (2.10.3)\n",
            "Requirement already satisfied: PyJWT in /usr/local/lib/python3.10/dist-packages (from graphlit-client) (2.10.1)\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.10/dist-packages (from graphlit-client) (14.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->graphlit-client) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->graphlit-client) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->graphlit-client) (4.12.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->graphlit-client) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->graphlit-client) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->graphlit-client) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->graphlit-client) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->graphlit-client) (0.14.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->graphlit-client) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->graphlit-client) (1.2.2)\n",
            "Downloading graphlit_client-1.0.20241228002-py3-none-any.whl (236 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.6/236.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: graphlit-client\n",
            "Successfully installed graphlit-client-1.0.20241228002\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade graphlit-client"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize Graphlit"
      ],
      "metadata": {
        "id": "abV1114jL-bR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from graphlit import Graphlit\n",
        "from graphlit_api import input_types, enums, exceptions\n",
        "\n",
        "os.environ['GRAPHLIT_ORGANIZATION_ID'] = userdata.get('GRAPHLIT_ORGANIZATION_ID')\n",
        "os.environ['GRAPHLIT_ENVIRONMENT_ID'] = userdata.get('GRAPHLIT_ENVIRONMENT_ID')\n",
        "os.environ['GRAPHLIT_JWT_SECRET'] = userdata.get('GRAPHLIT_JWT_SECRET')\n",
        "\n",
        "graphlit = Graphlit()"
      ],
      "metadata": {
        "id": "WoMAWD4LLP_q"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Graphlit helper functions"
      ],
      "metadata": {
        "id": "pgRX57EHMVfl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Optional\n",
        "\n",
        "async def create_specification(model: enums.OpenAIModels):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    input = input_types.SpecificationInput(\n",
        "        name=f\"OpenAI [{model}]\",\n",
        "        type=enums.SpecificationTypes.EXTRACTION,\n",
        "        serviceType=enums.ModelServiceTypes.OPEN_AI,\n",
        "        openAI=input_types.OpenAIModelPropertiesInput(\n",
        "            model=model\n",
        "        )\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.create_specification(input)\n",
        "\n",
        "        return response.create_specification.id if response.create_specification is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "    return None\n",
        "\n",
        "async def create_feed(account_name: str, container_name: str, storage_key: str, prefix: str, workflow_id: Optional[str] = None, read_limit: Optional[int] = None):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    input = input_types.FeedInput(\n",
        "        name=f'Azure blob storage',\n",
        "        type=enums.FeedTypes.SITE,\n",
        "        site=input_types.SiteFeedPropertiesInput(\n",
        "            type=enums.FeedServiceTypes.AZURE_BLOB,\n",
        "            isRecursive=False,\n",
        "            azureBlob=input_types.AzureBlobFeedPropertiesInput(\n",
        "                accountName=account_name,\n",
        "                containerName=container_name,\n",
        "                storageAccessKey=storage_key,\n",
        "                prefix=prefix\n",
        "            ),\n",
        "            readLimit=read_limit\n",
        "        ),\n",
        "        workflow=input_types.EntityReferenceInput(\n",
        "            id=workflow_id\n",
        "        ) if workflow_id is not None else None\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.create_feed(input)\n",
        "\n",
        "        return response.create_feed.id if response.create_feed is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "    return None\n",
        "\n",
        "async def is_feed_done(feed_id: str):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    response = await graphlit.client.is_feed_done(feed_id)\n",
        "\n",
        "    return response.is_feed_done.result if response.is_feed_done is not None else None\n",
        "\n",
        "async def get_content(content_id: str):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.get_content(content_id)\n",
        "\n",
        "        return response.content\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "async def publish_content(summary_specification_id: str, publish_specification_id: str, summary_prompt: str, publish_prompt: str):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.publish_contents(\n",
        "            name=\"Published Summary\",\n",
        "            connector=input_types.ContentPublishingConnectorInput(\n",
        "               type=enums.ContentPublishingServiceTypes.TEXT,\n",
        "               format=enums.ContentPublishingFormats.MARKDOWN,\n",
        "            ),\n",
        "            summary_prompt=summary_prompt,\n",
        "            summary_specification=input_types.EntityReferenceInput(\n",
        "                id=summary_specification_id\n",
        "            ),\n",
        "            publish_prompt=publish_prompt,\n",
        "            publish_specification=input_types.EntityReferenceInput(\n",
        "                id=publish_specification_id\n",
        "            ),\n",
        "            is_synchronous=True\n",
        "        )\n",
        "\n",
        "        return response.publish_contents.content if response.publish_contents is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "async def delete_all_specifications():\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    _ = await graphlit.client.delete_all_specifications(is_synchronous=True)\n",
        "\n",
        "async def delete_all_contents():\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    _ = await graphlit.client.delete_all_contents(is_synchronous=True)\n",
        "\n",
        "async def delete_all_feeds():\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    _ = await graphlit.client.delete_all_feeds(is_synchronous=True)\n"
      ],
      "metadata": {
        "id": "mtwjJsvVOVCh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Execute Graphlit example"
      ],
      "metadata": {
        "id": "srzhQt4COLVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown, HTML\n",
        "import time\n",
        "\n",
        "# Remove any existing feeds and contents; only needed for notebook example\n",
        "await delete_all_feeds()\n",
        "await delete_all_contents()\n",
        "\n",
        "print('Deleted all feeds and contents.')\n",
        "\n",
        "# NOTE: point to an Azure blob container with MP3 recordings of podcasts\n",
        "container_name = 'samples'\n",
        "prefix = 'Podcasts/'\n",
        "\n",
        "account_name = userdata.get('AZURE_STORAGE_ACCOUNT_NAME')\n",
        "storage_access_key = userdata.get('AZURE_STORAGE_ACCESS_KEY')\n",
        "\n",
        "feed_id = await create_feed(account_name, container_name, storage_access_key, prefix)\n",
        "\n",
        "if feed_id is not None:\n",
        "    print(f'Created feed [{feed_id}].')\n",
        "\n",
        "    # Wait for feed to complete, since ingestion happens asychronously\n",
        "    done = False\n",
        "    time.sleep(5)\n",
        "    while not done:\n",
        "        done = await is_feed_done(feed_id)\n",
        "\n",
        "        if not done:\n",
        "            time.sleep(2)\n",
        "\n",
        "    print(f'Completed feed [{feed_id}].')\n"
      ],
      "metadata": {
        "id": "fOb6COcONZIJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd42420d-f14f-4f47-ca78-8abf270301b0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleted all feeds and contents.\n",
            "Created feed [35d2267e-ed38-452a-b61d-16c3d15539ce].\n",
            "Completed feed [35d2267e-ed38-452a-b61d-16c3d15539ce].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove any existing specifications; only needed for notebook example\n",
        "\n",
        "await delete_all_specifications()\n",
        "\n",
        "print('Deleted all specifications.')\n",
        "\n",
        "# Configure details about podcast guest\n",
        "guest_name = 'Kirk Marple'\n",
        "guest_first_name = 'Kirk'\n",
        "company_name = 'Graphlit'\n",
        "guest_pronoun = 'his'\n",
        "\n",
        "# Configure the summary prompt to extract key details about the podcast guest you're writing about\n",
        "summary_prompt = f\"\"\"You are being provided the transcript of a podcast, where {guest_name} was a guest.\n",
        "Focus on any details that {guest_first_name} talks about, especially {guest_pronoun} professional background, and {guest_pronoun} vision for starting the company named {company_name}.\n",
        "This information will be used to compile a detailed backgrounder about {guest_first_name} and {company_name}.\n",
        "Respond with 25 verbose bullet points covering all relevant details. Be specific about any named entities like persons, companies or places.\n",
        "\"\"\"\n",
        "\n",
        "# Configure the publish prompt to compile the final backgrounder report from the details captured from the podcasts\n",
        "publish_prompt = f\"\"\"\n",
        "You are responding to a request to write a backgrounder about {guest_name} and {company_name}.\n",
        "Write a detailed backgrounder report, describing {guest_first_name} and {company_name} in the third-person.\n",
        "Make sure to cover {guest_first_name}'s early career background, previous companies that were started, and the vision for starting {company_name}.\n",
        "\"\"\"\n",
        "\n",
        "# Select the model to use for summarization; using GPT-4o Mini because of speed\n",
        "summary_model = enums.OpenAIModels.GPT4O_MINI_128K\n",
        "# Select the model to use for publishing; using o1-preview because of the more detailed responses and thought put into them\n",
        "publish_model = enums.OpenAIModels.O1_PREVIEW_128K\n",
        "\n",
        "summary_specification_id = await create_specification(summary_model)\n",
        "\n",
        "if summary_specification_id is not None:\n",
        "    print(f'Created summary specification [{summary_specification_id}].')\n",
        "\n",
        "    publish_specification_id = await create_specification(publish_model)\n",
        "\n",
        "    if publish_specification_id is not None:\n",
        "        print(f'Created publish specification [{publish_specification_id}].')\n",
        "\n",
        "        published_content = await publish_content(summary_specification_id, publish_specification_id, summary_prompt, publish_prompt)\n",
        "\n",
        "        if published_content is not None:\n",
        "            display(Markdown(f'### Published summary'))\n",
        "            display(Markdown(published_content.markdown))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UihbaaU79WYH",
        "outputId": "0711a0fd-8472-452b-dbea-4f0c8950820e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleted all specifications.\n",
            "Created summary specification [940fec79-3fec-4682-a9d0-c9899406f6d7].\n",
            "Created publish specification [9682b8bf-4272-44d7-a68b-e5b7eb95e1bc].\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Published summary"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Backgrounder: Kirk Marple and Graphlit\n\nKirk Marple is a seasoned technology leader and entrepreneur with over 25 years of experience in software development, media management, and data analytics. His career spans significant contributions to pioneering technologies and the founding of innovative companies aimed at solving complex data challenges.\n\n## Early Career at Microsoft\n\nAfter completing his master's degree in computer science at the University of British Columbia, Kirk began his professional journey at Microsoft in the mid-1990s.[^1] During his six-year tenure, he worked on multimedia projects within Microsoft Research, contributing to early advancements in 3D virtual worlds—a precursor to what is now known as the metaverse.[^2] His work at Microsoft laid the foundation for his expertise in image processing, real-time video, and multimedia technologies.\n\n## Founding Radiant Grid and Media Innovations\n\nFollowing his time at Microsoft, Kirk identified an opportunity in the burgeoning field of digital media. He founded Radiant Grid, a video transcoding and media management company that specialized in the broadcast industry.[^3] Under his leadership, Radiant Grid developed software solutions that were adopted by major broadcasters and studios, including ESPN, PBS, and NBC.[^4] The company's technology played a crucial role in the early days of web and broadcast video, facilitating the transition to digital formats and cloud services.\n\nRadiant Grid's success was marked by its widespread adoption across every PBS station in the United States and its use in high-profile events like the Olympics.[^5] Kirk successfully bootstrapped the company over a decade before it was acquired, demonstrating his ability to lead and grow a tech enterprise from the ground up.\n\n## Transition to Data Analytics at General Motors\n\nAfter the sale of Radiant Grid, Kirk sought new challenges and joined General Motors (GM), where he worked on data pipelines for Cruise, GM's autonomous vehicle division.[^6] At GM, he applied his media management expertise to automotive data, specifically handling LIDAR and video data for data science applications.[^7] His work involved building architectures and prototypes using cutting-edge technologies like Kafka and Cassandra, which were instrumental in processing the massive amounts of data generated by autonomous vehicles.\n\n## Identifying the Need for Unstructured Data Solutions\n\nThroughout his career, Kirk recognized a recurring gap in the market: the lack of effective tools for managing unstructured data across various industries.[^8] Unstructured data—which includes images, videos, audio files, 3D models, and documents—constitutes a significant portion of data generated by enterprises but often remains underutilized due to the challenges in organizing and analyzing it.\n\nKirk observed that traditional data management solutions were insufficient for handling unstructured data, which requires different approaches for metadata enrichment, searchability, and integration with machine learning models.[^9] This insight became the catalyst for his next entrepreneurial venture.\n\n## Founding Graphlit: Vision and Mission\n\nIn response to the unmet needs he identified, Kirk founded Graphlit (initially known as Unstruk Data) in 2020.[^10] Graphlit is an unstructured data platform designed to help organizations transform their unstructured data into actionable intelligence.[^11] The platform focuses on:\n\n- **Automated Data Preparation**: Enriching metadata through machine learning and artificial intelligence to make data more accessible and meaningful.[^12]\n- **Integrated Compute and Graph-Based Search**: Utilizing knowledge graphs to dynamically organize and correlate data, enabling advanced search capabilities across various data types.[^13]\n- **Unstructured Data Warehouse**: Providing a scalable, serverless architecture that allows organizations to store, manage, and analyze large volumes of unstructured data efficiently.[^14]\n\nKirk's vision for Graphlit is to bridge the gap between raw unstructured data and valuable insights. By employing techniques such as metadata enrichment and knowledge graphs, Graphlit enables enterprises to uncover relationships within their data that were previously hidden or too complex to analyze.[^15]\n\n## Impact and Future Endeavors\n\nUnder Kirk's leadership, Graphlit is positioning itself as a key player in the evolving landscape of data management. The company's solutions cater to a wide range of industries, including media and entertainment, manufacturing, oil and gas, and autonomous vehicles.[^16] By addressing the challenges of unstructured data, Graphlit empowers organizations to make data-driven decisions, improve operational efficiencies, and unlock new opportunities for innovation.\n\nKirk continues to lead Graphlit with a focus on customer-centric solutions, leveraging his extensive experience in software development and data analytics to drive the company's mission forward.[^17] His commitment to building a design-led company that prioritizes user experience and technical excellence remains central to Graphlit's ongoing success.\n\n[^1]: \"Data Leadership for Everyone\" podcast - \"Unstructured Data, Metadata, and Graph Search, Oh My! with Kirk Marple\"\n[^2]: \"The Analytic Mind\" podcast - \"The Importance of Utilizing Unstructured Data with Kirk Marple\"\n[^3]: \"The Founder Pack Podcast With Brendon Rod\" - \"A Conversation With Kirk Marple, CEO & Founder @ Unstruk Data\"\n[^4]: \"IT Career Energizer\" podcast - \"Look For The Opportunities To Grow and Don’t Doubt Yourself with Kirk Marple\"\n[^5]: \"Earley AI Podcast\" - \"It’s All About the Data - Kirk Marple\"\n[^6]: \"Data Engineering Podcast\" - \"Bring Order To The Chaos Of Your Unstructured Data Assets With Unstruk\"\n[^7]: \"The Modern .NET Show\" - \"Unstructured Data With Kirk Marple\"\n[^8]: \"Data Science Conversations\" podcast - \"Enhancing GenAI with Knowledge Graphs: A Deep Dive with Kirk Marple\"\n[^9]: \"Tech Entrepreneur on a Mission\" podcast - \"On making data actionable - Kirk Marple\"\n[^10]: \"The TWIML AI Podcast\" - \"GraphRAG: Knowledge Graphs for AI Applications with Kirk Marple\"\n[^11]: \"How AI is Built\" podcast - \"Knowledge Graphs for Better RAG, Virtual Entities, Hybrid Data Models\"\n[^12]: \"Code Story\" podcast - \"Kirk Marple, Unstruk Data\"\n[^13]: \"The Thoughtful Entrepreneur\" podcast - \"Data Management with Unstructured Data\"\n[^14]: \"Silicon Alley\" podcast - \"Building a Remote First Company & Unlocking Unstructured Data in Your Business\"\n[^15]: \"Discoposse Podcast\" - \"Kirk Marple of Unstruk Data on the Unstructured Data Challenge and Lessons of a Technical Founder\"\n[^16]: \"Mapscaping Podcast\" - \"Unstructured Data is Dark Data\"\n[^17]: \"Syntio Podcast\" - \"Data Platform - Unstructured Data\""
          },
          "metadata": {}
        }
      ]
    }
  ]
}