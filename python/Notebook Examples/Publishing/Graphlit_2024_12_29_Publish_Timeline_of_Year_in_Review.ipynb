{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1cSnEIDnT7SYyUpfap5KiK6Y_LWLQdk6s",
      "authorship_tag": "ABX9TyPF/Ek/Tlgsp1BCnH0TdScE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/graphlit/graphlit-samples/blob/main/python/Notebook%20Examples/Graphlit_2024_12_29_Publish_Timeline_of_Year_in_Review.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Description**\n",
        "\n",
        "This example shows how to ingest Graphlit changelog, use OpenAI O1 to write a comprehensive year-in-review, visualized as a Graphviz DOT timeline diagram."
      ],
      "metadata": {
        "id": "pDz1gRPjOtn5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Requirements**\n",
        "\n",
        "Prior to running this notebook, you will need to [signup](https://docs.graphlit.dev/getting-started/signup) for Graphlit, and [create a project](https://docs.graphlit.dev/getting-started/create-project).\n",
        "\n",
        "You will need the Graphlit organization ID, preview environment ID and JWT secret from your created project.\n",
        "\n",
        "Assign these properties as Colab secrets: GRAPHLIT_ORGANIZATION_ID, GRAPHLIT_ENVIRONMENT_ID and GRAPHLIT_JWT_SECRET.\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "laG2MXUIhNnx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install Graphlit Python client SDK"
      ],
      "metadata": {
        "id": "NwRzDHWWienC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fefizrrh4xGD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9572f278-6532-4902-e793-b6c5219a4883"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: graphlit-client in /usr/local/lib/python3.10/dist-packages (1.0.20241229004)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from graphlit-client) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from graphlit-client) (2.10.3)\n",
            "Requirement already satisfied: PyJWT in /usr/local/lib/python3.10/dist-packages (from graphlit-client) (2.10.1)\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.10/dist-packages (from graphlit-client) (14.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->graphlit-client) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->graphlit-client) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->graphlit-client) (4.12.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->graphlit-client) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->graphlit-client) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->graphlit-client) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->graphlit-client) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->graphlit-client) (0.14.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->graphlit-client) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->graphlit-client) (1.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade graphlit-client"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade isodate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqZf2TOgnXsD",
        "outputId": "67e6480e-e308-4ec2-d60f-bd749d00ce93"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: isodate in /usr/local/lib/python3.10/dist-packages (0.7.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade graphviz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bI49fRzzRU-9",
        "outputId": "62a0a4f4-75d5-455c-e5b6-15e2a8ae12a0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (0.20.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from graphlit import Graphlit\n",
        "from graphlit_api import input_types, enums, exceptions\n",
        "\n",
        "os.environ['GRAPHLIT_ORGANIZATION_ID'] = userdata.get('GRAPHLIT_ORGANIZATION_ID')\n",
        "os.environ['GRAPHLIT_ENVIRONMENT_ID'] = userdata.get('GRAPHLIT_ENVIRONMENT_ID')\n",
        "os.environ['GRAPHLIT_JWT_SECRET'] = userdata.get('GRAPHLIT_JWT_SECRET')\n",
        "\n",
        "graphlit = Graphlit()"
      ],
      "metadata": {
        "id": "WoMAWD4LLP_q"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Graphlit helper functions"
      ],
      "metadata": {
        "id": "pgRX57EHMVfl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Optional\n",
        "\n",
        "async def create_specification(model: enums.OpenAIModels):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    input = input_types.SpecificationInput(\n",
        "        name=f\"OpenAI [{model}]\",\n",
        "        type=enums.SpecificationTypes.COMPLETION,\n",
        "        serviceType=enums.ModelServiceTypes.OPEN_AI,\n",
        "        openAI=input_types.OpenAIModelPropertiesInput(\n",
        "            model=model,\n",
        "        )\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.create_specification(input)\n",
        "\n",
        "        return response.create_specification.id if response.create_specification is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "    return None\n",
        "\n",
        "async def create_web_feed(uri: str, correlation_id: Optional[str], limit: Optional[int] = None):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    input = input_types.FeedInput(\n",
        "        name=uri,\n",
        "        type=enums.FeedTypes.WEB,\n",
        "        web=input_types.WebFeedPropertiesInput(\n",
        "            uri=uri,\n",
        "            readLimit=limit if limit is not None else 100\n",
        "        )\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.create_feed(input, correlation_id=correlation_id)\n",
        "\n",
        "        return response.create_feed.id if response.create_feed is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "    return None\n",
        "\n",
        "async def is_feed_done(feed_id: str):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    response = await graphlit.client.is_feed_done(feed_id)\n",
        "\n",
        "    return response.is_feed_done.result if response.is_feed_done is not None else None\n",
        "\n",
        "\n",
        "async def lookup_usage(correlation_id: str):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.lookup_usage(correlation_id)\n",
        "\n",
        "        return response.lookup_usage if response.lookup_usage is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "async def lookup_credits(correlation_id: str):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.lookup_credits(correlation_id)\n",
        "\n",
        "        return response.lookup_credits if response.lookup_credits is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "\n",
        "def dump_usage_record(record):\n",
        "    print(f\"{record.date}: {record.name}\")\n",
        "\n",
        "    duration = isodate.parse_duration(record.duration)\n",
        "\n",
        "    if record.workflow:\n",
        "        print(f\"- Workflow [{record.workflow}] took {duration}, used credits [{record.credits:.8f}]\")\n",
        "    else:\n",
        "        print(f\"- Operation took {duration}, used credits [{record.credits:.8f}]\")\n",
        "\n",
        "    if record.entity_id:\n",
        "        if record.entity_type:\n",
        "            if record.entity_type == enums.EntityTypes.CONTENT and record.content_type:\n",
        "                print(f\"- {record.entity_type} [{record.entity_id}]: Content type [{record.content_type}], file type [{record.file_type}]\")\n",
        "            else:\n",
        "                print(f\"- {record.entity_type} [{record.entity_id}]\")\n",
        "        else:\n",
        "            print(f\"- Entity [{record.entity_id}]\")\n",
        "\n",
        "    if record.model_service:\n",
        "        print(f\"- Model service [{record.model_service}], model name [{record.model_name}]\")\n",
        "\n",
        "    if record.processor_name:\n",
        "        if record.processor_name in [\"Deepgram Audio Transcription\", \"Assembly.AI Audio Transcription\"]:\n",
        "            length = timedelta(milliseconds=record.count or 0)\n",
        "\n",
        "            if record.model_name:\n",
        "                print(f\"- Processor name [{record.processor_name}], model name [{record.model_name}], length [{length}]\")\n",
        "            else:\n",
        "                print(f\"- Processor name [{record.processor_name}], length [{length}]\")\n",
        "        else:\n",
        "            if record.count:\n",
        "                if record.model_name:\n",
        "                    print(f\"- Processor name [{record.processor_name}], model name [{record.model_name}], units [{record.count}]\")\n",
        "                else:\n",
        "                    print(f\"- Processor name [{record.processor_name}], units [{record.count}]\")\n",
        "            else:\n",
        "                if record.model_name:\n",
        "                    print(f\"- Processor name [{record.processor_name}], model name [{record.model_name}]\")\n",
        "                else:\n",
        "                    print(f\"- Processor name [{record.processor_name}]\")\n",
        "\n",
        "    if record.uri:\n",
        "        print(f\"- URI [{record.uri}]\")\n",
        "\n",
        "    if record.name == \"Prompt completion\":\n",
        "        if record.prompt:\n",
        "            print(f\"- Prompt [{record.prompt_tokens} tokens (includes RAG context tokens)]:\")\n",
        "            print(record.prompt)\n",
        "\n",
        "        if record.completion:\n",
        "            print(f\"- Completion [{record.completion_tokens} tokens (includes JSON guardrails tokens)], throughput: {record.throughput:.3f} tokens/sec:\")\n",
        "            print(record.completion)\n",
        "\n",
        "    elif record.name == \"Text embedding\":\n",
        "        if record.prompt_tokens is not None:\n",
        "            print(f\"- Text embedding [{record.prompt_tokens} tokens], throughput: {record.throughput:.3f} tokens/sec\")\n",
        "\n",
        "    elif record.name == \"Document preparation\":\n",
        "        if record.prompt_tokens is not None and record.completion_tokens is not None:\n",
        "            print(f\"- Document preparation [{record.prompt_tokens} input tokens, {record.completion_tokens} output tokens], throughput: {record.throughput:.3f} tokens/sec\")\n",
        "\n",
        "    elif record.name == \"Data extraction\":\n",
        "        if record.prompt_tokens is not None and record.completion_tokens is not None:\n",
        "            print(f\"- Data extraction [{record.prompt_tokens} input tokens, {record.completion_tokens} output tokens], throughput: {record.throughput:.3f} tokens/sec\")\n",
        "\n",
        "    elif record.name == \"GraphQL\":\n",
        "        if record.request:\n",
        "            print(f\"- Request:\")\n",
        "            print(record.request)\n",
        "\n",
        "        if record.variables:\n",
        "            print(f\"- Variables:\")\n",
        "            print(record.variables)\n",
        "\n",
        "        if record.response:\n",
        "            print(f\"- Response:\")\n",
        "            print(record.response)\n",
        "\n",
        "    if record.name.startswith(\"Upload\"):\n",
        "        print(f\"- File upload [{record.count} bytes], throughput: {record.throughput:.3f} bytes/sec\")\n",
        "\n",
        "    print()\n",
        "\n",
        "async def get_content(content_id: str):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    response = await graphlit.client.get_content(content_id)\n",
        "\n",
        "    return response.content\n",
        "\n",
        "async def query_contents(feed_id: str):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.query_contents(\n",
        "            filter=input_types.ContentFilter(\n",
        "                feeds=[\n",
        "                    input_types.EntityReferenceFilter(\n",
        "                        id=feed_id\n",
        "                    )\n",
        "                ]\n",
        "            )\n",
        "        )\n",
        "\n",
        "        return response.contents.results if response.contents is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "async def publish_contents(feed_id: str, summary_specification_id: str, publish_specification_id: str, summary_prompt: str, publish_prompt: str, correlation_id: str):\n",
        "    if graphlit.client is None:\n",
        "        return None, None\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.publish_contents(\n",
        "            name=\"Published Summary\",\n",
        "            connector=input_types.ContentPublishingConnectorInput(\n",
        "               type=enums.ContentPublishingServiceTypes.TEXT,\n",
        "               format=enums.ContentPublishingFormats.MARKDOWN\n",
        "            ),\n",
        "            summary_prompt=summary_prompt,\n",
        "            summary_specification=input_types.EntityReferenceInput(\n",
        "                id=summary_specification_id\n",
        "            ),\n",
        "            publish_prompt = publish_prompt,\n",
        "            publish_specification=input_types.EntityReferenceInput(\n",
        "                id=publish_specification_id\n",
        "            ),\n",
        "            filter=input_types.ContentFilter(\n",
        "                feeds=[input_types.EntityReferenceFilter(id=feed_id)]\n",
        "            ),\n",
        "            include_details=True,\n",
        "            is_synchronous=True,\n",
        "            correlation_id=correlation_id\n",
        "        )\n",
        "\n",
        "        return response.publish_contents.content.id if response.publish_contents is not None and response.publish_contents.content is not None else None, response.publish_contents.details if response.publish_contents is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None, None\n",
        "\n",
        "async def delete_all_specifications():\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    _ = await graphlit.client.delete_all_specifications(is_synchronous=True)\n",
        "\n",
        "async def delete_all_feeds():\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    _ = await graphlit.client.delete_all_feeds(is_synchronous=True)\n",
        "\n",
        "async def delete_all_contents():\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    _ = await graphlit.client.delete_all_contents(is_synchronous=True)"
      ],
      "metadata": {
        "id": "mtwjJsvVOVCh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import isodate\n",
        "from IPython.display import display, Markdown, HTML\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Remove any existing feeds, contents and specifications; only needed for notebook example\n",
        "await delete_all_feeds()\n",
        "await delete_all_specifications()\n",
        "await delete_all_contents()\n",
        "\n",
        "print('Deleted all feeds, contents and specifications.')\n",
        "\n",
        "# NOTE: create a unique cost correlation ID\n",
        "ingestion_correlation_id = datetime.now().isoformat()\n",
        "publish_correlation_id = datetime.now().isoformat()\n",
        "\n",
        "uri = \"https://changelog.graphlit.dev\"\n",
        "limit = 100 # maximum number of web pages to ingest\n",
        "\n",
        "feed_id = await create_web_feed(uri, ingestion_correlation_id, limit)\n",
        "\n",
        "if feed_id is not None:\n",
        "    print(f'Created feed [{feed_id}]: {uri}')\n",
        "\n",
        "    # Wait for feed to complete, since ingestion happens asychronously\n",
        "    done = False\n",
        "    time.sleep(5)\n",
        "    while not done:\n",
        "        done = await is_feed_done(feed_id)\n",
        "\n",
        "        if not done:\n",
        "            time.sleep(10)\n",
        "\n",
        "    print(f'Completed feed [{feed_id}].')\n",
        "\n",
        "    # Query contents by feed\n",
        "    contents = await query_contents(feed_id)\n",
        "\n",
        "    if contents is not None:\n",
        "        print(f'Found {len(contents)} contents in feed [{feed_id}].')\n",
        "        print()\n",
        "\n",
        "        for content in contents:\n",
        "            if content is not None:\n",
        "\n",
        "                display(Markdown(f'# Ingested content [{content.id}]'))\n",
        "\n",
        "                print(f'Text Mezzanine: {content.text_uri}')\n",
        "\n",
        "                print(content.markdown)"
      ],
      "metadata": {
        "id": "fOb6COcONZIJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "825cc371-812b-4e8e-c7ec-600fdad2231a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleted all feeds, contents and specifications.\n",
            "Created feed [67102186-088a-46b0-a03d-e94e916ad3ed]: https://changelog.graphlit.dev\n",
            "Completed feed [67102186-088a-46b0-a03d-e94e916ad3ed].\n",
            "Found 48 contents in feed [67102186-088a-46b0-a03d-e94e916ad3ed].\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Ingested content [02c635c4-808d-495e-9744-bb501a2066e8]"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Mezzanine: https://graphlit202412121b7b448d.blob.core.windows.net/files/02c635c4-808d-495e-9744-bb501a2066e8/Mezzanine/page.json?sv=2025-01-05&se=2024-12-30T09%3A59%3A34Z&sr=c&sp=rl&sig=owRWJoJ3af3UPDIm9IYAnrH5uSy6%2BBWimVfnmZsHaVo%3D\n",
            "üéí\tSeptember 2024\n",
            "\n",
            "# September 30: Support for Azure AI Inference models, Mistral Pixtral and latest Google Gemini models\n",
            "### New Features\n",
            "\n",
            "- üí° Graphlit now supports the Azure AI Model Inference API (aka Models as a Service) model service which offers serverless hosting to many models such as Meta Llama 3.2, Cohere Command-R, and many more. For Azure AI, all models are 'custom', and you will need to provide the serverless endpoint, API key and number of tokens accepted in context window, after provisioning the model of your choice.\n",
            "- We have added support for the multimodal Mistral Pixtral model, under the model enum PIXTRAL_12B_2409.\n",
            "- We have added versioned model enums for Google Gemini, so you can access GEMINI_1_5_FLASH_001, GEMINI_1_5_FLASH_002, GEMINI_1_5_PRO_001 and GEMINI_1_5_PRO_002.\n",
            "\n",
            "PreviousOctober 3: Support tool calling, ingestBatch mutation, Gemini Flash 1.5 8b, bug fixes\n",
            "NextSeptember 26: Support for Google AI and Cerebras models, and latest Groq models\n",
            "Last updated2 months ago \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Ingested content [6a1f0635-0338-4b77-85c2-a476edc6cde9]"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Mezzanine: https://graphlit202412121b7b448d.blob.core.windows.net/files/6a1f0635-0338-4b77-85c2-a476edc6cde9/Mezzanine/page.json?sv=2025-01-05&se=2024-12-30T09%3A59%3A34Z&sr=c&sp=rl&sig=owRWJoJ3af3UPDIm9IYAnrH5uSy6%2BBWimVfnmZsHaVo%3D\n",
            "üéí\tSeptember 2024\n",
            "\n",
            "# September 3: Support for web search feeds, model deprecations\n",
            "### New Features\n",
            "\n",
            "- üí° Graphlit now supports web search feeds, using the Tavily and Exa.AI web search APIs. You can choose the SEARCH feed type, and assign your search text property, and we will ingest the referenced web pages from the search results. Optionally, you can select the search service via the serviceType property under search feed properties. By default, Graphlit will use the Tavily API.\n",
            "- ‚ö° We have deprecated these OpenAI models, according to the future support OpenAI is providing to these legacy models: GPT35_TURBO, GPT35_TURBO_0613, GPT35_TURBO_16K, GPT35_TURBO_16K_0125, GPT35_TURBO_16K_0613, GPT35_TURBO_16K_1106, GPT4, GPT4_0613, GPT4_32K, GPT4_32K_0613, GPT4_TURBO_VISION_128K, and GPT4_TURBO_VISION_128K_1106. We suggest using GPT-4o or GPT-4o Mini instead.\n",
            "\n",
            "### Bugs Fixed\n",
            "\n",
            "- GPLA-2523: Can't ingest from same feed URI multiple times and wait on isFeedDone\n",
            "\n",
            "PreviousSeptember 26: Support for Google AI and Cerebras models, and latest Groq models\n",
            "NextSeptember 1: Support for FHIR enrichment, latest Cohere models, bug fixes\n",
            "Last updated3 months ago \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Ingested content [efb60fde-e52e-4726-893f-d58347a0deeb]"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Mezzanine: https://graphlit202412121b7b448d.blob.core.windows.net/files/efb60fde-e52e-4726-893f-d58347a0deeb/Mezzanine/page.json?sv=2025-01-05&se=2024-12-30T09%3A59%3A34Z&sr=c&sp=rl&sig=owRWJoJ3af3UPDIm9IYAnrH5uSy6%2BBWimVfnmZsHaVo%3D\n",
            "üéÉ\tOctober 2024\n",
            "\n",
            "# October 22: Support for latest Anthropic Sonnet 3.5 model, Cohere image embeddings\n",
            "### New Features\n",
            "\n",
            "- Graphlit now supports the latest Anthropic Sonnet 3.5 model (released 10/22/2024). We have added date-versions model enums for the Anthropic models: CLAUDE_3_5_SONNET_20240620, CLAUDE_3_5_SONNET_20241022, CLAUDE_3_HAIKU_20240307, CLAUDE_3_OPUS_20240229, CLAUDE_3_SONNET_20240229. The existing model enums will target the latest released models, as specified by Anthropic.\n",
            "- Graphlit now supports image embeddings using the Cohere Embed 3.0 models.\n",
            "\n",
            "PreviousOctober 31: Support for simulated tool calling, bug fixes\n",
            "NextOctober 21: Support OpenAI, Cohere, Jina, Mistral, Voyage and Google AI embedding models\n",
            "Last updated2 months ago \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Ingested content [4adced81-1014-450d-9e42-e81ec370a757]"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Mezzanine: https://graphlit202412121b7b448d.blob.core.windows.net/files/4adced81-1014-450d-9e42-e81ec370a757/Mezzanine/page.json?sv=2025-01-05&se=2024-12-30T09%3A59%3A34Z&sr=c&sp=rl&sig=owRWJoJ3af3UPDIm9IYAnrH5uSy6%2BBWimVfnmZsHaVo%3D\n",
            "üéÉ\tOctober 2023\n",
            "\n",
            "# October 30: Optimized conversation responses; added observable aliases; bug fixes\n",
            "### New Features\n",
            "\n",
            "- üí° Graphlit now supports 'aliases' of observable names, as the alternateNames property. When an observed entity, such as Organization, is enriched, we store the original name and the enriched name as an alias. For example, \"OpenAI\" may be enriched to \"OpenAI, Inc.\", and we store \"OpenAI\" as an alias, and update the name to \"OpenAI, Inc.\".\n",
            "- üí° Added workflows filter to ContentCriteriaInput type, for filtering content by workflow(s) when creating conversation.\n",
            "- Optimized formatting of content sources into prompt context, for more accurate conversation responses.\n",
            "- Optimized formatting of extracted text from Slack messages, for better knowledge retrieval.\n",
            "- Updated text tokenizer for more accurate token counting.\n",
            "- Upgraded Azure Text Analytics to latest preview API version.\n",
            "- Authors found in RSS feeds are now stored as observations of Person entities.\n",
            "- Added rate limiting for Reddit feeds.\n",
            "- Added rate limiting for Wikipedia enrichment.\n",
            "- Added support for reading Reddit post comments when reading Reddit feed.\n",
            "- ‚ö° EmbedFacets has been renamed to EnableFacets in the conversation strategy.\n",
            "- ‚ö° Removed extra content level in IngestionWorkflowStage type. Now, the if property is of type IngestionContentFilter.\n",
            "\n",
            "### Bugs Fixed\n",
            "\n",
            "- GPLA-1556: Better handling of very long user prompts.\n",
            "- GPLA-1627: Optimized token budget for more accurate prompt completion.\n",
            "- GPLA-1585: More accurate entity matching in Wikipedia entity enrichment.\n",
            "\n",
            "PreviousDecember 10: Support for OpenAI GPT-4 Turbo, Llama 2 and Mistral models; query by example, bug fixes\n",
            "NextOctober 15: Support for Anthropic Claude models, Slack feeds and entity enrichment\n",
            "Last updated1 year ago \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Ingested content [d764f4d3-1282-441c-8e4a-08ce664b0b47]"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Mezzanine: https://graphlit202412121b7b448d.blob.core.windows.net/files/d764f4d3-1282-441c-8e4a-08ce664b0b47/Mezzanine/page.json?sv=2025-01-05&se=2024-12-30T09%3A59%3A34Z&sr=c&sp=rl&sig=owRWJoJ3af3UPDIm9IYAnrH5uSy6%2BBWimVfnmZsHaVo%3D\n",
            "ü¶É\tNovember 2024\n",
            "\n",
            "# November 16: Support for image description, multi-turn text summarization\n",
            "### New Features\n",
            "\n",
            "- üí° Graphlit now supports multi-turn summarization of text with the reviseText mutation. You can provide an LLM prompt and text string, along with an optional specification. This can be used for summarizing any raw text and having a multi-turn conversation with the LLM to revise the output from the LLM. (Colab Notebook Example)\n",
            "- üí° Graphlit now supports image descriptions using vision LLMs, without needing to ingest the image first. With the new describeImage mutation, which takes a URI, and describeEncodedImage mutation, which takes a Base-64 encoded image and MIME type, you can use any vision LLM to prompt an image description. These mutations accept an optional specification, where you can select your vision LLM. If not provided, OpenAI GPT-4o will be used. (Colab Notebook Example)\n",
            "\n",
            "PreviousNovember 24: Support for direct LLM prompt, multi-turn image analysis, bug fixes\n",
            "NextNovember 10: Support for web search, multi-turn content summarization, Deepgram language detection\n",
            "Last updated1 month ago \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Ingested content [3092dd49-a054-4d32-94b2-cb67133a305d]"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Mezzanine: https://graphlit202412121b7b448d.blob.core.windows.net/files/3092dd49-a054-4d32-94b2-cb67133a305d/Mezzanine/page.json?sv=2025-01-05&se=2024-12-30T09%3A59%3A34Z&sr=c&sp=rl&sig=owRWJoJ3af3UPDIm9IYAnrH5uSy6%2BBWimVfnmZsHaVo%3D\n",
            "ü¶É\tNovember 2024\n",
            "\n",
            "# November 24: Support for direct LLM prompt, multi-turn image analysis, bug fixes\n",
            "### New Features\n",
            "\n",
            "- üí° Graphlit now supports multi-turn analysis of images with the reviseImage and reviseEncodedImage mutations. You can provide an LLM prompt and either a URI or Base-64 encoded image and MIME type, along with an optional LLM specification. This can be used for analyzing any image and having a multi-turn conversation with the LLM to revise the output from the LLM. (Colab Notebook Example)\n",
            "- üí° Graphlit now supports directly prompting an LLM with the prompt mutation, bypassing any RAG content retrieval, while providing an optional list of previous conversation messages. This also accepts an optional LLM specification. (Colab Notebook Example)\n",
            "- We have added support for the new Mistral Pixtral Large model, with PIXTRAL_LARGE model enum, which can be used with LLM completion or entity extraction LLM specifications.\n",
            "- We have added support for the OpenAI 2024-11-20 version of GPT-4o, with GPT4O_128K_20241120 model enum.\n",
            "- ‚ö° We have added Microsoft Entra ID (fka Azure Active Directory) clientId and clientSecret properties to the SharePointFeedPropertiesInput type, which are now required when creating a SharePoint feed using user authentication with refreshToken property. (Colab Notebook Example)\n",
            "\n",
            "### Bugs Fixed\n",
            "\n",
            "- GPLA-3438: Not filtering on desktop presentation when scraping web pages\n",
            "- GPLA-3340: Failed to parse invalid JSON from extracted PDF page\n",
            "- GPLA-3427: Not formatting extracted tables properly from Sonnet 3.5\n",
            "\n",
            "PreviousDecember 1: Support for retrieval-only RAG pipeline, bug fixes\n",
            "NextNovember 16: Support for image description, multi-turn text summarization\n",
            "Last updated1 month ago \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Ingested content [b96def70-f8ed-4c72-9757-a1648306835a]"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Mezzanine: https://graphlit202412121b7b448d.blob.core.windows.net/files/b96def70-f8ed-4c72-9757-a1648306835a/Mezzanine/page.json?sv=2025-01-05&se=2024-12-30T09%3A59%3A34Z&sr=c&sp=rl&sig=owRWJoJ3af3UPDIm9IYAnrH5uSy6%2BBWimVfnmZsHaVo%3D\n",
            "üéí\tSeptember 2024\n",
            "\n",
            "# September 1: Support for FHIR enrichment, latest Cohere models, bug fixes\n",
            "### New Features\n",
            "\n",
            "- üí° Graphlit now supports entity enrichment from Fast Healthcare Interoperability Resources (FHIR) servers. You can provide the endpoint for a FHIR server, and Graphlit will enrich medical-related entities from the data found in the FHIR server.\n",
            "- Added support for latest Cohere models (COMMAND_R_202408, COMMAND_R_PLUS_202408) and added datestamped model enums for the previous versions (COMMAND_R_202403, COMMAND_R_PLUS_202404). The latest model enums (COMMAND_R and COMMAND_R_PLUS) currently point to the models (COMMAND_R_202403 and COMMAND_R_PLUS_202404) as specified by the Cohere API.\n",
            "- Added support for the latest Azure AI Document Intelligence v4.0 preview API (2024-07-31), now used by default.\n",
            "- ‚ö° We have changed the name of the LinkReferenceType to LinkReference to follow the existing data model standard.\n",
            "\n",
            "### Bugs Fixed\n",
            "\n",
            "- GPLA-3120: LLM is adding source tags to end of completed messages\n",
            "- GPLA-3133: Failed to load sitemap on child page of website.\n",
            "\n",
            "PreviousSeptember 3: Support for web search feeds, model deprecations\n",
            "NextAugust 20: Support for medical entities, Anthropic prompt caching, bug fixes\n",
            "Last updated3 months ago \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Ingested content [f3c48cd9-fc5b-4306-9135-aed548177631]"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Mezzanine: https://graphlit202412121b7b448d.blob.core.windows.net/files/f3c48cd9-fc5b-4306-9135-aed548177631/Mezzanine/page.json?sv=2025-01-05&se=2024-12-30T09%3A59%3A34Z&sr=c&sp=rl&sig=owRWJoJ3af3UPDIm9IYAnrH5uSy6%2BBWimVfnmZsHaVo%3D\n",
            "üõ†Ô∏è\tSeptember 2023\n",
            "\n",
            "# September 4: Workflow configuration; support for Notion feeds; document OCR\n",
            "### New Features\n",
            "\n",
            "- üî• Added Workflow entity to data model for configuring stages of content workflow; can be assigned to Feed or with ingestPage, ingestFile, or ingestText mutations to control how content is ingested, prepared, extracted and enriched into the knowledge graph.\n",
            "- üí° Added support for Notion feeds: now can create feed to ingest files from Notion pages or databases (i.e. wikis).\n",
            "- üí° Added support for API-created Observation entities, which allow for custom observations of observable entities (i.e. Person, Label) on Content.\n",
            "- üí° Added support for Azure AI Document Intelligence as an optional method for preparing PDF files, using OCR and advanced layout analysis.\n",
            "- üí° Added summarization strategies, where content can be summarized into paragraphs, bullet points or headline.\n",
            "- Added ability to assign default Workflow and Specification to project.\n",
            "- Added more well-known link types, during link crawling, such as Discord, Airtable and TypeForm.\n",
            "- ‚ÑπÔ∏è Free/Hobby plan now has 5GB storage quota; any content ingested past that limit will be auto-deleted.\n",
            "- ‚ö° Actions have been moved into Workflow entity.\n",
            "- ‚ö° Link enrichment for Feeds has been moved into the Workflow enrichment stage, now called link crawling. ExcludeContentDomain property has been reversed and is now called IncludeContentDomain.\n",
            "\n",
            "### Bugs Fixed\n",
            "\n",
            "- GPLA-1204: Failed to ingest content with backslash in name.\n",
            "- GPLA-1276: Failed to ingest RSS posts which contained enclosure URI, but no post URI.\n",
            "\n",
            "PreviousSeptember 20: Paid subscription plans; support for custom observed entities & Azure OpenAI GPT-4\n",
            "NextAugust 17: Prepare for usage-based billing; append SAS tokens to URIs\n",
            "Last updated1 year ago \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Ingested content [f0a42b0a-353b-4f08-9a5d-40ce9196a46b]"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Mezzanine: https://graphlit202412121b7b448d.blob.core.windows.net/files/f0a42b0a-353b-4f08-9a5d-40ce9196a46b/Mezzanine/page.json?sv=2025-01-05&se=2024-12-30T09%3A59%3A34Z&sr=c&sp=rl&sig=owRWJoJ3af3UPDIm9IYAnrH5uSy6%2BBWimVfnmZsHaVo%3D\n",
            "üéÉ\tOctober 2024\n",
            "\n",
            "# October 31: Support for simulated tool calling, bug fixes\n",
            "### New Features\n",
            "\n",
            "- Graphlit now supports simulated tool calling for LLMs which don't natively support it, such as OpenAI o1-preview and o1-mini. Tool schema will be formatted into the LLM prompt context, and tool responses are parsed out of the JSON formatted response.\n",
            "- ‚ö° Given customer feedback, we have lowered the vector and hybrid thresholds used by the semantic search. Previously, some content at a low relevance was being excluded from the semantic search results. Now, more low-relevance content will be included in the results, used by the RAG pipeline. Reranking can be used to sort the search results for relevance.\n",
            "\n",
            "### Bugs Fixed\n",
            "\n",
            "- GPLA-3357: Not extracting all images from PDF, and should filter out single-color images.\n",
            "\n",
            "PreviousNovember 4: Support for Anthropic Claude 3.5 Haiku, bug fixes\n",
            "NextOctober 22: Support for latest Anthropic Sonnet 3.5 model, Cohere image embeddings\n",
            "Last updated1 month ago \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Ingested content [4fa1f011-eca1-4585-9a4b-d31369c468cb]"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Mezzanine: https://graphlit202412121b7b448d.blob.core.windows.net/files/4fa1f011-eca1-4585-9a4b-d31369c468cb/Mezzanine/page.json?sv=2025-01-05&se=2024-12-30T09%3A59%3A34Z&sr=c&sp=rl&sig=owRWJoJ3af3UPDIm9IYAnrH5uSy6%2BBWimVfnmZsHaVo%3D\n",
            "üéÉ\tOctober 2024\n",
            "\n",
            "# October 7: Support for Anthropic and Gemini tool calling\n",
            "### New Features\n",
            "\n",
            "- üí° Graphlit now supports tool calling with Anthropic and Google Gemini models.\n",
            "- ‚ö° We have removed the uri property for tools from ToolDefinitionInput, such that inline webhook tools are no longer supported. Now you can define any external tools to be called, and those can support sync or async data access to fulfill the tool call.\n",
            "\n",
            "PreviousOctober 9: Support for GitHub repository feeds, bug fixes\n",
            "NextOctober 3: Support tool calling, ingestBatch mutation, Gemini Flash 1.5 8b, bug fixes\n",
            "Last updated2 months ago \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Ingested content [865f424b-fa74-4640-b593-a9840336a452]"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Mezzanine: https://graphlit202412121b7b448d.blob.core.windows.net/files/865f424b-fa74-4640-b593-a9840336a452/Mezzanine/page.json?sv=2025-01-05&se=2024-12-30T09%3A59%3A34Z&sr=c&sp=rl&sig=owRWJoJ3af3UPDIm9IYAnrH5uSy6%2BBWimVfnmZsHaVo%3D\n",
            "üéí\tSeptember 2024\n",
            "\n",
            "# September 26: Support for Google AI and Cerebras models, and latest Groq models\n",
            "### New Features\n",
            "\n",
            "- üí° Graphlit now supports the Cerebras model service which offers the LLAMA_3_1_70B and LLAMA_3_1_8B models.\n",
            "- üí° Graphlit now supports the Google AI model service which offers the GEMINI_1_5_PRO and GEMINI_1_5_FLASH models.\n",
            "- We have added support for the latest Groq Llama 3.2 preview models, including LLAMA_3_2_1B_PREVIEW, LLAMA_3_2_3B_PREVIEW, LLAMA_3_2_11B_TEXT_PREVIEW, and LLAMA_3_2_90B_TEXT_PREVIEW. We have also added support for the Llama 3.2 multimodal model LLAMA_3_2_11B_VISION_PREVIEW.\n",
            "- We have added a new specification parameter to the promptConversation mutation. Now you can specify your initial specification for a new conversation, or update an existing conversation, without requiring additional API calls.\n",
            "- ‚ö° We have changed the retrieval behavior of the promptConversation mutation. Now, if no relevant content was found via vector-based semantic search (given the user prompt), we will fallback to any relevant content from the message in the conversation. If there was no content from the conversation to fallback to, we will fallback to the last ingested content in the project. This solves an issue where a first prompt like 'Summarize this' would find no relevant content. Now it will fallback to retrieve the last ingested content.\n",
            "- ‚ö° We have renamed the Groq model enum from LLAVA_1_5_7B to LLAVA_1_5_7B_PREVIEW.\n",
            "\n",
            "### Bugs Fixed\n",
            "\n",
            "- GPLA-3083: Not sending custom instructions/guidance with extraction prompt\n",
            "- GPLA-3146: Filtering Persons by email not working\n",
            "- GPLA-3171: Not failing on deprecated OpenAI model\n",
            "- GPLA-3158: Summarization not using revision strategy\n",
            "\n",
            "PreviousSeptember 30: Support for Azure AI Inference models, Mistral Pixtral and latest Google Gemini models\n",
            "NextSeptember 3: Support for web search feeds, model deprecations\n",
            "Last updated3 months ago \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Ingested content [75f8d5dd-c5e0-4c08-b334-dc5e80ea8025]"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Mezzanine: https://graphlit202412121b7b448d.blob.core.windows.net/files/75f8d5dd-c5e0-4c08-b334-dc5e80ea8025/Mezzanine/page.json?sv=2025-01-05&se=2024-12-30T09%3A59%3A34Z&sr=c&sp=rl&sig=owRWJoJ3af3UPDIm9IYAnrH5uSy6%2BBWimVfnmZsHaVo%3D\n",
            "üõ†Ô∏è\tSeptember 2023\n",
            "\n",
            "# September 24: Support for YouTube feeds; added documentation; bug fixes\n",
            "### New Features\n",
            "\n",
            "- üî• Graphlit now supports YouTube feeds, where you can ingest a set of YouTube videos, or an entire YouTube playlist or channel. Note, we currently support only the ingestion of audio from YouTube videos, which gets transcribed and added to your conversational knowledge graph.\n",
            "\n",
            "### New Documentation\n",
            "\n",
            "- Added documentation for observable entities mutations and queries (Label, Category, Person, Organization, Place, Event, Product, Repo, Software).\n",
            "- Added documentation for using custom Azure OpenAI and OpenAI models with Specifications\n",
            "\n",
            "### Bugs Fixed\n",
            "\n",
            "- GPLA-1459: LLM prompt formatting was exceeding the token budget with long user prompts.\n",
            "- GPLA-1445: Failed to ingest PDF from URL where filename in Content-Disposition header contained a backslash.\n",
            "\n",
            "PreviousOctober 15: Support for Anthropic Claude models, Slack feeds and entity enrichment\n",
            "NextSeptember 20: Paid subscription plans; support for custom observed entities & Azure OpenAI GPT-4\n",
            "Last updated7 months ago \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Ingested content [5345f273-4dcb-4f44-a1a3-4226ff5eaed8]"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Mezzanine: https://graphlit202412121b7b448d.blob.core.windows.net/files/5345f273-4dcb-4f44-a1a3-4226ff5eaed8/Mezzanine/page.json?sv=2025-01-05&se=2024-12-30T09%3A59%3A34Z&sr=c&sp=rl&sig=owRWJoJ3af3UPDIm9IYAnrH5uSy6%2BBWimVfnmZsHaVo%3D\n",
            "üõ†Ô∏è\tSeptember 2023\n",
            "\n",
            "# September 20: Paid subscription plans; support for custom observed entities & Azure OpenAI GPT-4\n",
            "### New Features\n",
            "\n",
            "- üî• Graphlit now supports paid Hobby, Starter and Growth tiers for projects, in addition to the existing Free tier. Starting at $49/mo, plus $0.10/credit for usage, we now support higher quota based on your subscribed tier. By providing a payment method for your organization in the Developer Portal, you can upgrade each project individually to the tier that fits your application's needs.\n",
            "- üí° Added GraphQL mutations for the creation, update and deletion of observed entities (i.e. Person, Organization, Place, Product, Event, Label, Category).\n",
            "- üí° Added new observed entity types to knowledge graph: Repo (i.e. Git repo), Software.\n",
            "- üí° Added searchType and numberSimilar fields to Specification object for configuring semantic search in conversations. In situations where the user prompt is limited in length, HYBRID search type can provide better semantic search results for the prompt context.\n",
            "- üí° Added support for the Azure OpenAI GPT-4 model.\n",
            "- Added support for project quota field. Project quotas are based on the subscribed pricing tier. Quota limits are now applied as content is ingested, and as feeds and conversations are created.\n",
            "- Added contentLimit to conversation strategy object to limit the number of semantic search content results which are formatted into prompt context.\n",
            "- Better relevance ranking on semantic search results when formatting prompt context in conversations.\n",
            "- ‚ÑπÔ∏è Free tier has updated quota: 1GB storage, 100 contents, 3 feeds and 10 conversations.\n",
            "- ‚ö° Now using the Deepgram Nova-2 audio transcription model, which is 18% more accurate, and 5-40x faster.\n",
            "\n",
            "### Bugs Fixed\n",
            "\n",
            "- GPLA-1373: Failed to extract multiple text pages from DOCX without page breaks. Now we support token-aware page chunking.\n",
            "- GPLA-1377: Failed during semantic search with no content results, when prompting conversation.\n",
            "- GPLA-1415: Failed when user prompt couldn't generate text embeddings.\n",
            "\n",
            "PreviousSeptember 24: Support for YouTube feeds; added documentation; bug fixes\n",
            "NextSeptember 4: Workflow configuration; support for Notion feeds; document OCR\n",
            "Last updated11 months ago \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Ingested content [e112772f-cc4a-4323-8c80-8c1d8c123dd2]"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Mezzanine: https://graphlit202412121b7b448d.blob.core.windows.net/files/e112772f-cc4a-4323-8c80-8c1d8c123dd2/Mezzanine/page.json?sv=2025-01-05&se=2024-12-30T09%3A59%3A34Z&sr=c&sp=rl&sig=owRWJoJ3af3UPDIm9IYAnrH5uSy6%2BBWimVfnmZsHaVo%3D\n",
            "üéÉ\tOctober 2024\n",
            "\n",
            "# October 9: Support for GitHub repository feeds, bug fixes\n",
            "### New Features\n",
            "\n",
            "- üí° Graphlit now supports GitHub feeds, by providing the repository owner and name similar to GitHub Issues feeds, and will ingest code files from any GitHub repository.\n",
            "\n",
            "### Bugs Fixed\n",
            "\n",
            "- GPLA-3262: Missing row separator in table markdown formatting\n",
            "\n",
            "PreviousOctober 21: Support OpenAI, Cohere, Jina, Mistral, Voyage and Google AI embedding models\n",
            "NextOctober 7: Support for Anthropic and Gemini tool calling\n",
            "Last updated2 months ago \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Ingested content [1cd2c534-2f49-4677-ab4a-68a4365f4fdd]"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Mezzanine: https://graphlit202412121b7b448d.blob.core.windows.net/files/1cd2c534-2f49-4677-ab4a-68a4365f4fdd/Mezzanine/page.json?sv=2025-01-05&se=2024-12-30T09%3A59%3A34Z&sr=c&sp=rl&sig=owRWJoJ3af3UPDIm9IYAnrH5uSy6%2BBWimVfnmZsHaVo%3D\n",
            "üéÉ\tOctober 2023\n",
            "\n",
            "# October 15: Support for Anthropic Claude models, Slack feeds and entity enrichment\n",
            "### New Features\n",
            "\n",
            "- üî• Graphlit now supports Anthropic Claude and Anthropic Claude Instant large language models.\n",
            "- üî• Graphlit now supports Slack feeds, and will ingest Slack messages and linked file attachments from a Slack channel. Note, this requires the creation of a Slack bot which has been added to the appropriate Slack channel.\n",
            "- üí° Added support for entity enrichment to workflow object, which offers Diffbot, Wikipedia and Crunchbase enrichment of observed entities, such as Person, Organization and Place.\n",
            "- üí° Added support for text extraction from images. When using Azure Image Analytics for entity extraction, Graphlit will extract and store any identified text which then becomes searchable.\n",
            "- Added embedFacets property to conversation strategy in specification object.\n",
            "- Added embedCitations property to conversation strategy in specification object. This makes content citations optional with the completed conversation message.\n",
            "- Added GraphQL mutations for multi-delete of entities, such as deleteCollections, deleteLabels, or deleteConversations.\n",
            "- Added GraphQL deleteAllConversations mutation to delete all conversations.\n",
            "- Added support for automatically adding ingested content to one or more collections, via ingestion stage of workflow object.\n",
            "- Added specification property to preparation workflow stage, which will be used to select the LLM for text summarization.\n",
            "- Expanded the properties for observed entities, such as Person, Organization or Product. Now supports a wider range of properties for entity enrichment.\n",
            "\n",
            "### Bugs Fixed\n",
            "\n",
            "- GPLA-1520: Unlimited conversation quota not assigned when upgrading project tier\n",
            "- GPLA-1285: Entity enrichment not firing event, which can be sent to actions\n",
            "- GPLA-1361: Web page left in ingested state, when URL not accessible.\n",
            "\n",
            "PreviousOctober 30: Optimized conversation responses; added observable aliases; bug fixes\n",
            "NextSeptember 24: Support for YouTube feeds; added documentation; bug fixes\n",
            "Last updated1 year ago \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Ingested content [0341d367-6775-4e57-9a3d-7904d813f243]"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Mezzanine: https://graphlit202412121b7b448d.blob.core.windows.net/files/0341d367-6775-4e57-9a3d-7904d813f243/Mezzanine/page.json?sv=2025-01-05&se=2024-12-30T09%3A59%3A34Z&sr=c&sp=rl&sig=owRWJoJ3af3UPDIm9IYAnrH5uSy6%2BBWimVfnmZsHaVo%3D\n",
            "ü¶É\tNovember 2024\n",
            "\n",
            "# November 10: Support for web search, multi-turn content summarization, Deepgram language detection\n",
            "### New Features\n",
            "\n",
            "- üí° Graphlit now supports web search with the searchWeb mutation. You can select the search service, either Tavily or Exa.AI, and provide the search query and number of search results to be returned. This is different than the web search feed, in that searchWeb returns the relevant text from the web page and the web page URL from each search hit, but does not ingest each of the web pages. This new mutation is optimized to be used from within an LLM tool.\n",
            "- üí° Graphlit now supports multi-turn summarization of content with the reviseContent mutation. You can provide an LLM prompt and a content reference, along with an optional specification. This can be used for summarizing any content (documents, web pages, audio transcripts, etc.), and having a multi-turn conversation with the LLM to revise the output from the LLM. Internally, this creates a conversation locked to a single piece of content. This works especially well with the OpenAI o1-preview and o1-mini models, because they provide a longer LLM output from each turn.\n",
            "- Graphlit now supports the configuration of the Deepgram transcription language, and whether detectLanguage is enabled in DeepgramAudioPreparationPropertiesInput. Language detection is now enabled by default, and can be disabled by setting detectLanguage to false.\n",
            "- ‚ö° We have added a requireTool option to promptConversation mutation, so you can control whether the LLM must call one of the provided tool, or if tool calling is optional.\n",
            "- ‚ö° For accounts created after Nov 8, 2024, we have lowered the credits quota on the Free tier from 1000 credits to 100 credits, and now offer unlimited feeds on the Hobby Tier.\n",
            "- ‚ö° The Graphlit Data API will now return HTTP 402 (Payment Required) when you have exceeded the credits quota on the free tier. You must upgrade to the Hobby Tier (or higher) to continue using the API, once the credits quota has been reached.\n",
            "\n",
            "PreviousNovember 16: Support for image description, multi-turn text summarization\n",
            "NextNovember 4: Support for Anthropic Claude 3.5 Haiku, bug fixes\n",
            "Last updated1 month ago \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Ingested content [c693346f-b33a-4931-88f4-5c7142c749b9]"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Mezzanine: https://graphlit202412121b7b448d.blob.core.windows.net/files/c693346f-b33a-4931-88f4-5c7142c749b9/Mezzanine/page.json?sv=2025-01-05&se=2024-12-30T09%3A59%3A34Z&sr=c&sp=rl&sig=owRWJoJ3af3UPDIm9IYAnrH5uSy6%2BBWimVfnmZsHaVo%3D\n",
            "üéÉ\tOctober 2024\n",
            "\n",
            "# October 3: Support tool calling, ingestBatch mutation, Gemini Flash 1.5 8b, bug fixes\n",
            "### New Features\n",
            "\n",
            "- üí° Graphlit now supports the ingestBatch mutation, which accepts an array of URIs to files or web pages, and will asynchronously ingest these into content objects.\n",
            "- üí° Graphlit now supports the continueConversation mutation, which accepts an array of called tool responses. Also, promptConversation now accepts an array of tool definitions. When tools are called by the LLM, the assistant message returned from promptConversation will have a list of toolCalls which need to responded to from your calling code. These responses are to be provided back to the LLM via the continueConversation mutation.\n",
            "- üí° Graphlit now supports tool calling with OpenAI, Mistral, Deepseek, Groq, and Cerebras model services. Anthropic, Google Gemini and Cohere support will come later.\n",
            "- Added support for prefilled user and assistant messages with createConversation mutation. Now you can send an array of messages when creating a new conversation, which will bootstrap the conversation with the LLM. These must be provided in user/assistant pairs.\n",
            "- Added support for Google Gemini Flash 1.5 8b model.\n",
            "- ‚ö° We have deprecated the tools property in the Specification object. These will be removed at a later date. Tools are now to be sent directly to the extractContents and promptConversation mutations.\n",
            "\n",
            "### Bugs Fixed\n",
            "\n",
            "- GPLA-3207: Models shouldn't be required on update specification call\n",
            "- GPLA-3220: Don't send system prompt with OpenAI o1 models\n",
            "\n",
            "PreviousOctober 7: Support for Anthropic and Gemini tool calling\n",
            "NextSeptember 30: Support for Azure AI Inference models, Mistral Pixtral and latest Google Gemini models\n",
            "Last updated2 months ago \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Ingested content [d2f41682-fb8b-4599-8c64-91891e13c336]"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Mezzanine: https://graphlit202412121b7b448d.blob.core.windows.net/files/d2f41682-fb8b-4599-8c64-91891e13c336/Mezzanine/page.json?sv=2025-01-05&se=2024-12-30T09%3A59%3A34Z&sr=c&sp=rl&sig=owRWJoJ3af3UPDIm9IYAnrH5uSy6%2BBWimVfnmZsHaVo%3D\n",
            "üçÄ\tMarch 2024\n",
            "\n",
            "# March 10: Support for Claude 3, Mistral and Groq models, usage/credits telemetry, bug fixes\n",
            "### New Features\n",
            "\n",
            "- üí° Graphlit now supports a Command-Line Interface (CLI) for directly accessing the Graphlit Data API without writing code. See the documentation here.\n",
            "- üí° Graphlit now supports the Groq Platform, and models such as Mixtral 8x7b.\n",
            "- üí° Graphlit now supports Claude 3 Opus and Sonnet models.\n",
            "- üí° Graphlit now supports Mistral La Plateforme, and models such as Mistral Small, Medium, and Large and Mixtral 8x7b.\n",
            "- üí° Graphlit now supports the latest v4 of Azure Document Intelligence, including their new models such as Credit Card, Marriage Certificate, and Mortgage documents.\n",
            "- Added support for detailed usage and credits telemetry via API, with the usage, credits, lookupUsage and lookupCredits queries.\n",
            "- Added support for correlated telemetry, where an optional correlationId can be provided with GraphQL queries and mutations, so credits and usage can be tracked across requests.\n",
            "- Added support for project webhook, which will be called when credits have been consumed by the project.\n",
            "- Added support for image extraction during DOCX, XLSX, and PPTX document preparation.\n",
            "- Added text and markdown properties to Content object, which provide formatted output of extracted text from any content.\n",
            "- Added more accurate extraction of tables into mezzanine JSON format, across all content types.\n",
            "- Added throughput property to Conversation messages, which returns the tokens/second throughput of LLM.\n",
            "- ‚ö° Deprecated mezzanineUri property in Content object, which has been replaced by textUri and audioUri.\n",
            "\n",
            "### Bugs Fixed\n",
            "\n",
            "- GPLA-2281: Not extracting table from PPTX file.\n",
            "- GPLA-2282: Not extracting Markdown tables.\n",
            "- GPLA-2247: Not extracting relative HTML links properly.\n",
            "- GPLA-2241: Failed to post Alert to Slack with Markdown format.\n",
            "\n",
            "PreviousMarch 13: Support for Claude 3 Haiku model, direct ingestion of Base64 encoded files\n",
            "NextFebruary 21: Support for OneDrive and Google Drive feeds, extract images from PDFs, bug fixes\n",
            "Last updated8 months ago \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Ingested content [fc169406-76bc-479f-93f2-0c1b1ba4277e]"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Mezzanine: https://graphlit202412121b7b448d.blob.core.windows.net/files/fc169406-76bc-479f-93f2-0c1b1ba4277e/Mezzanine/page.json?sv=2025-01-05&se=2024-12-30T09%3A59%3A34Z&sr=c&sp=rl&sig=owRWJoJ3af3UPDIm9IYAnrH5uSy6%2BBWimVfnmZsHaVo%3D\n",
            "üéì\tJune 2024\n",
            "\n",
            "# June 9: Support for Deepseek models, JSON-LD webpage parsing, performance improvements and bug fixes\n",
            "### New Features\n",
            "\n",
            "- üí° Graphlit now supports Deepseek LLMs for prompt completion. We offer the deepseek-chat and deepseek-coder models.\n",
            "- üí° Graphlit now supports parsing embedded JSON-LD from web pages. If a web page contains 'script' tags with JSON-LD, we will automatically parse and inject into the knowledge graph.\n",
            "- ‚ö° We have changed the default model for entity extraction and image completions to be OpenAI GPT-4o. This provides faster performance and better quality output.\n",
            "- ‚ö° We have changed the behavior of knowledge graph generation, from a prompted conversation, to be opt-in. In order to receive the graph's nodes and edges with the response, you will now need to set generateGraph to True in the specification's graphStrategy object. This provides improved performance when the graph is not needed for visualization.\n",
            "- Added thing property for observable entities, which returns the JSON-LD metadata associated with the entity.\n",
            "- Added regex-based filtering for URI paths during feed ingestion, link crawling, and workflow filtering. You can assign regex patterns in allowedPaths and excludedPaths.\n",
            "- Added observableLimit to configure the limit of how many observed entities will be added to the GraphRAG context, defaults to 1000.\n",
            "- Added prompt to suggestConversation mutation, which allows customization of the followup question generation.\n",
            "- Updated suggestConversation to incorporate the past conversation message history, in addition to the filtered set of content sources.\n",
            "- üî• We have improved performance in knowledge graph retrieval and generation, via better parallelization and batching.\n",
            "\n",
            "### Bugs Fixed\n",
            "\n",
            "- GPLA-2748: Optimize the retrieval performance of observed entities during GraphRAG\n",
            "- GPLA-2732: Invalid user-provided URI causing parsing exception\n",
            "- GPLA-2666: Shouldn't require tenant ID for Microsoft email or Teams\n",
            "- GPLA-2772: Not returning labels or categories from graph in API\n",
            "- GPLA-2762: Failed to extract spreadsheet images\n",
            "- GPLA-2687: Email to/from not getting added as observations on emails\n",
            "- GPLA-2738: API is returning 'audio' metadata from podcast HTML document\n",
            "\n",
            "PreviousJune 21: Support for the Claude 3.5 Sonnet model, knowledge graph semantic search, and bug fixes\n",
            "NextMay 15: Support for GraphRAG, OpenAI GPT-4o model, performance improvements and bug fixes\n",
            "Last updated6 months ago \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Ingested content [2489940d-1c11-4cab-82d2-26e5a1bc0dff]"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Mezzanine: https://graphlit202412121b7b448d.blob.core.windows.net/files/2489940d-1c11-4cab-82d2-26e5a1bc0dff/Mezzanine/page.json?sv=2025-01-05&se=2024-12-30T09%3A59%3A34Z&sr=c&sp=rl&sig=owRWJoJ3af3UPDIm9IYAnrH5uSy6%2BBWimVfnmZsHaVo%3D\n",
            "ü¶É\tNovember 2024\n",
            "\n",
            "# November 4: Support for Anthropic Claude 3.5 Haiku, bug fixes\n",
            "### New Features\n",
            "\n",
            "- Graphlit now supports the latest Anthropic Haiku 3.5 model, with the model enum CLAUDE_3_5_HAIKU_20241022.\n",
            "- ‚ö° Once a project has hit the free tier quota, we will now automatically disable all feeds. Once the project has been upgraded to a paid tier, you can use the enableFeed mutation to re-enable your existing feeds to continue ingestion.\n",
            "- ‚ö° We have added the disableFallback flag to the RetrievalStrategyInput type, so you can disable the default behavior of falling back to the previous conversation's contents, or worst-case, falling back to the most recently uploaded content. By setting disableFallback to true, conversations will only attempt to retrieve contents based on the provided filter and/or augmentedFilter properties.\n",
            "\n",
            "### Bugs Fixed\n",
            "\n",
            "- GPLA-3367: Not extracting text from HTML button element\n",
            "\n",
            "PreviousNovember 10: Support for web search, multi-turn content summarization, Deepgram language detection\n",
            "NextOctober 31: Support for simulated tool calling, bug fixes\n",
            "Last updated1 month ago \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Ingested content [2dd30528-0956-4c46-9a9c-8ce6ecc9931e]"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Mezzanine: https://graphlit202412121b7b448d.blob.core.windows.net/files/2dd30528-0956-4c46-9a9c-8ce6ecc9931e/Mezzanine/page.json?sv=2025-01-05&se=2024-12-30T09%3A59%3A34Z&sr=c&sp=rl&sig=owRWJoJ3af3UPDIm9IYAnrH5uSy6%2BBWimVfnmZsHaVo%3D\n",
            "üéÉ\tOctober 2024\n",
            "\n",
            "# October 21: Support OpenAI, Cohere, Jina, Mistral, Voyage and Google AI embedding models\n",
            "### New Features\n",
            "\n",
            "- üí° Graphlit now supports the configuration of image and text embedding models, at the Project level. You can create an embedding specification for a text or image embedding model, and then assign that to the Project, and all further embedding requests will use that embedding model. See this Colab notebook for an example of how to configure the project.\n",
            "- üí° Graphlit now supports the OpenAI Embedding-3-Small and Embedding-3-Large, Cohere Embed 3.0, Jina Embed 3.0, Mistral Embed, and Voyage 2.0 and 3.0 text embedding models. Graphlit also now supports Jina CLIP image embeddings, which are used by default for image search.\n",
            "- Graphlit now supports the chunkTokenLimit property in Specifications, which specifies the number of tokens for each embedded text chunk. If this is not configured, Graphlit uses 600 tokens for each embedded text chunk.\n",
            "- Graphlit now supports the Voyage reranking model.\n",
            "- Graphlit now supports the ingestTextBatch mutation, which accepts an array of text and name pairs, and will asynchronously ingest these into content objects.\n",
            "- ‚ö° We have moved the chunkTokenLimit property from the Workflow storage embeddings strategy to the Specification object. The Workflow storage property has now been deprecated.\n",
            "- ‚ö° We have deprecated the openAIImage property from Workflow entity extraction properties. Use the modelImage property instead.\n",
            "\n",
            "Once a text embedding model has been updated at the project level, any content, conversations or observed entities will no longer be semantically searchable.\n",
            "Text embeddings are not compatible across models, so you will need to delete and reingest any content, or recreate conversations or knowledge graph entities, with the new embedding model to become searchable.\n",
            "PreviousOctober 22: Support for latest Anthropic Sonnet 3.5 model, Cohere image embeddings\n",
            "NextOctober 9: Support for GitHub repository feeds, bug fixes\n",
            "Last updated2 months ago \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Ingested content [1bc9cf17-e156-441d-a307-def6a31d693e]"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Mezzanine: https://graphlit202412121b7b448d.blob.core.windows.net/files/1bc9cf17-e156-441d-a307-def6a31d693e/Mezzanine/page.json?sv=2025-01-05&se=2024-12-30T09%3A59%3A34Z&sr=c&sp=rl&sig=owRWJoJ3af3UPDIm9IYAnrH5uSy6%2BBWimVfnmZsHaVo%3D\n",
            "üíê\tMay 2024\n",
            "\n",
            "# May 5: Support for Jina and Pongo rerankers, Microsoft Teams feed, new YouTube downloader, bug fixes\n",
            "### New Features\n",
            "\n",
            "- üí° Graphlit now supports the Jina reranker and Pongo semantic filtering (reranking), in the Specification object. Now you can choose between COHERE, PONGO and JINA for your reranking serviceType.\n",
            "- üí° Graphlit now supports Microsoft Teams feeds for reading messages from Teams channels.\n",
            "- Given changes in YouTube video player HTML, we have rewritten the YouTube downloader to support the new page format.\n",
            "- Added better handling of HTTP errors when validating URIs. Previously some websites were returning HTTP 403 (Forbidden) errors when validating their URI, or downloading content. Now Graphlit is able to scrape these sites, which previously returned errors.\n",
            "- Added support for updating content metadata in updateContent mutation. Now the video, audio, document, etc. metadata can be updated after the content workflow has finished.\n",
            "- Added query_contents_graph (and queryContentsGraph) functions to SDKs, which can be used to return nodes and edges from knowledge graph for visualization.\n",
            "- ‚ö° Citation indices have been changed to be one-based from zero-based. For example, you will now see \"This is a citation. [1]\" as the first citation in the list.\n",
            "- ‚ö° Added isSynchronous flag to deleteAll and multiple delete mutations. By default, bulk delete operations are now asynchronous (and completed after the mutation returns), unless the isSynchronous flag is set to true.\n",
            "- ‚ö° Added missing count mutations, such as countAlerts, countFeeds, etc.\n",
            "- ‚ö° Renamed query_content_facets to query_contents_facets in Python SDK\n",
            "- ‚ö° Renamed queryContentFacets to queryContentsFacets in Node.js SDK\n",
            "\n",
            "### Bugs Fixed\n",
            "\n",
            "- GPLA-2544: Page relevance not filled-in in all situations\n",
            "- GPLA-2546: Not extracting links from PDF with Azure AI Doc Intelligence\n",
            "- GPLA-2557: Sporadically returning HTTP 500 from GraphQL API\n",
            "- GPLA-2573: Failed to re-ingest content which was deleted immediately after initial ingestion\n",
            "- GPLA-2575: Not validating for empty (non-null) parameters in mutations\n",
            "- GPLA-2578: Need to handle invalid JSON from LLMs; improper escaping or formatting\n",
            "- GPLA-2585: Failed to ingest encoded file with colon (:) in name\n",
            "\n",
            "PreviousMay 15: Support for GraphRAG, OpenAI GPT-4o model, performance improvements and bug fixes\n",
            "NextApril 23: Support for Python and TypeScript SDKs, latest OpenAI, Cohere & Groq models, bug fixes\n",
            "Last updated7 months ago \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Ingested content [b682b0ca-255c-4b02-b016-cb56f05edb64]"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Mezzanine: https://graphlit202412121b7b448d.blob.core.windows.net/files/b682b0ca-255c-4b02-b016-cb56f05edb64/Mezzanine/page.json?sv=2025-01-05&se=2024-12-30T09%3A59%3A34Z&sr=c&sp=rl&sig=owRWJoJ3af3UPDIm9IYAnrH5uSy6%2BBWimVfnmZsHaVo%3D\n",
            "üçÄ\tMarch 2024\n",
            "\n",
            "# March 13: Support for Claude 3 Haiku model, direct ingestion of Base64 encoded files\n",
            "### New Features\n",
            "\n",
            "- üí° Graphlit now supports the Claude 3 Haiku model.\n",
            "- Added support for direct ingestion of Base64 encoded files with the ingestEncodedFile mutation. You can pass a Base64 encoded string and MIME type of the file, and it will be ingested into the Graphlit Platform.\n",
            "- Added modelService and model properties to ConversationMessage type, which return the model service and model which was used for the LLM completion.\n",
            "\n",
            "PreviousMarch 23: Support for Linear, GitHub Issues and Jira issue feeds, ingest files via Web feed sitemap\n",
            "NextMarch 10: Support for Claude 3, Mistral and Groq models, usage/credits telemetry, bug fixes\n",
            "Last updated8 months ago \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Ingested content [8a9c0eb5-3658-4cca-bf2c-d68cdbea3f15]"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Mezzanine: https://graphlit202412121b7b448d.blob.core.windows.net/files/8a9c0eb5-3658-4cca-bf2c-d68cdbea3f15/Mezzanine/page.json?sv=2025-01-05&se=2024-12-30T09%3A59%3A34Z&sr=c&sp=rl&sig=owRWJoJ3af3UPDIm9IYAnrH5uSy6%2BBWimVfnmZsHaVo%3D\n",
            "üíê\tMay 2024\n",
            "\n",
            "# May 15: Support for GraphRAG, OpenAI GPT-4o model, performance improvements and bug fixes\n",
            "### New Features\n",
            "\n",
            "- üí° Graphlit now supports GraphRAG, where the extracted entities in the knowledge graph can be added as additional context to your RAG con,versation. Also, with GraphRAG, entities can be extracted from the user prompt, and used as additional content filters - or can be used to query related content sources, which are combined with the vector search results. This can be configured by specifying your graphStrategy in the Specification object.\n",
            "- üí° Graphlit now supports LLM revisions within RAG conversations, where the LLM can be prompted to revise its initial completion response. From our testing, this has been shown to provide 35% more output tokens with higher quality responses. This can be configured by specifying your revisionStrategy, and you can use our built-in revision prompt, or provide a custom one, and specify how many revisions you want the LLM to make.\n",
            "- üí° Graphlit now supports the new OpenAI GPT-4o model for RAG conversations.\n",
            "- ‚ö° We have changed the default model for Conversations to be OpenAI GPT-4o, from Azure OpenAI GPT-3.5 16k. This provides faster performance and better quality output.\n",
            "- Added graph to promptConversation response, so you can visualize or leverage the nodes and edges of the knowledge graph, resulting from the content retrieval. For example, if a Person and Organization were observed in the cited content sources used by the RAG pipeline, you will get back those entities and their relationship (such as Person 'works-for' Organization).\n",
            "- Expanded the enriched data from WIkipedia to include the long description of an entity.\n",
            "- Added getSharePointLibraries, getSharePointFolders, and getOneDriveFolders queries to the API, which can be used to enumerate the storage services. This makes locating the SharePoint libraryId easier, for example.\n",
            "- Added getTeams and getTeamsChannels queries to the API for enumerating Microsoft Teams workspaces.\n",
            "- Added extractedCount to the entity extraction connector to limit the number of extracted entities, per entity type. I.e. if extracted count is 10, it will extract at most ten each of Persons, Organizations, etc.\n",
            "- üî• We have improved performance in several areas: creation of observations after entity extraction, access to cloud storage, rendering the RAG context.\n",
            "- üî• We have optimized the LLM entity extraction process to identify more properties, as well as entity-to-entity relationships.\n",
            "\n",
            "### Bugs Fixed\n",
            "\n",
            "- GPLA-2652: Not extracting text from HTML in RSS post\n",
            "- GPLA-2627: Limit filter only returning half the results\n",
            "- GPLA-2613: Not properly extracting structured text from JSON/XML formats\n",
            "\n",
            "PreviousJune 9: Support for Deepseek models, JSON-LD webpage parsing, performance improvements and bug fixes\n",
            "NextMay 5: Support for Jina and Pongo rerankers, Microsoft Teams feed, new YouTube downloader, bug fixes\n",
            "Last updated6 months ago \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Ingested content [3d78b65e-a42d-44e9-8a9a-07faf938ee0d]"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Mezzanine: https://graphlit202412121b7b448d.blob.core.windows.net/files/3d78b65e-a42d-44e9-8a9a-07faf938ee0d/Mezzanine/page.json?sv=2025-01-05&se=2024-12-30T09%3A59%3A34Z&sr=c&sp=rl&sig=owRWJoJ3af3UPDIm9IYAnrH5uSy6%2BBWimVfnmZsHaVo%3D\n",
            "üçÄ\tMarch 2024\n",
            "\n",
            "# March 23: Support for Linear, GitHub Issues and Jira issue feeds, ingest files via Web feed sitemap\n",
            "### New Features\n",
            "\n",
            "- üí° Graphlit now supports Linear, GitHub Issues and Atlassian Jira feeds. Graphlit will ingest issues (aka tasks, stories) from these issue-tracking services as individual content items, which will be made searchable and conversational.\n",
            "- üí° Added support for ISSUEcontent type, which includes metadata such as title, authors, commenters, status, type, project and team.\n",
            "- üí° Added support for default feed read limit. Now, if you don't specify the readLimit property on feeds, it will default to reading 100 content items. You can override this default by assigning a custom read limit, which has no upper bounds. However, one-shot feeds much complete within 15 minutes, or they will be stopped automatically.\n",
            "- Added support for ingesting files referenced in a Web sitemap. Previously any files (i.e. PDF, MP3) referenced in a sitemap.xml would be ignored. Now you can optionally enable includeFiles in the WebFeedPropertiesInput object to have Graphlit ingest non-HTML pages as part of the Web feed.\n",
            "\n",
            "### Bugs Fixed\n",
            "\n",
            "- GPLA-2374: Failed to ingest MP4 with large XMP metadata.\n",
            "\n",
            "PreviousApril 7: Support for Discord feeds, Cohere reranking, section-aware chunking and retrieval\n",
            "NextMarch 13: Support for Claude 3 Haiku model, direct ingestion of Base64 encoded files\n",
            "Last updated8 months ago \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Ingested content [41e9b6e8-c479-4416-8ec3-7168709d2861]"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Mezzanine: https://graphlit202412121b7b448d.blob.core.windows.net/files/41e9b6e8-c479-4416-8ec3-7168709d2861/Mezzanine/page.json?sv=2025-01-05&se=2024-12-30T09%3A59%3A34Z&sr=c&sp=rl&sig=owRWJoJ3af3UPDIm9IYAnrH5uSy6%2BBWimVfnmZsHaVo%3D\n",
            "‚òÄÔ∏è\tJuly 2024\n",
            "\n",
            "# July 4: Support for webhook Alerts, keywords summarization, Deepseek 128k context window, bug fixes\n",
            "### New Features\n",
            "\n",
            "- üí° Graphlit now supports webhook Alerts. In addition to Slack notifications, you can now receive an HTTP POST webhook with the results of the published text (or text and audio URI) from a prompted alert.\n",
            "- Updated the Deepseek chat and coder models to support a 128k token context window.\n",
            "- Added customSummary property to Content object, which returns the custom summary generated via preparation workflow.\n",
            "- Added keywords summarization type, which is now stored in keywords property in Content object.\n",
            "- Added slackChannels query, which returns the list of Slack channels from the workspace authenticated by the Slack bot token.\n",
            "- ‚ö° We have changed the response from the credits query to return a single ProjectCredits object, rather than the list of correlated objects previously returned. The credits response now covers all credit usage over the time period specified.\n",
            "\n",
            "### Bugs Fixed\n",
            "\n",
            "- GPLA-2874: Processing entities is taking longer than 30min for 300+ page PDF\n",
            "- GPLA-2875: Messages in queue expiring too early\n",
            "- GPLA-2881: Feed read count increasing, after hitting read limit\n",
            "- GPLA-2884: Need to handle Anthropic 'overloaded' API response\n",
            "- GPLA-2906: JIRA issue identifier not assigned to issue metadata\n",
            "\n",
            "PreviousJuly 19: Support for OpenAI GPT-4o Mini, BYO-key for Azure AI, similarity by summary, bug fixes\n",
            "NextJune 21: Support for the Claude 3.5 Sonnet model, knowledge graph semantic search, and bug fixes\n",
            "Last updated5 months ago \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Ingested content [4b9dad6a-8d6f-4daa-b1d9-6c5277939931]"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Mezzanine: https://graphlit202412121b7b448d.blob.core.windows.net/files/4b9dad6a-8d6f-4daa-b1d9-6c5277939931/Mezzanine/page.json?sv=2025-01-05&se=2024-12-30T09%3A59%3A34Z&sr=c&sp=rl&sig=owRWJoJ3af3UPDIm9IYAnrH5uSy6%2BBWimVfnmZsHaVo%3D\n",
            "‚òÄÔ∏è\tJuly 2024\n",
            "\n",
            "# July 28: Support for indexing workflow stage, Azure AI language detection, bug fixes\n",
            "### New Features\n",
            "\n",
            "- Added indexing workflow stage. This provides for configuration of indexing services, which may infer metadata from the content.\n",
            "- Added AZURE_AI_LANGUAGE content indexing service, which supports inferring the language of extracted text or transcript.\n",
            "- Added support for language content metadata. This returns a list of languages in ISO 639-1 format, which may have been inferred from the extracted text or transcript.\n",
            "- Added support for MODEL_IMAGE extraction service. This provides integration with vision models beyond those provided by OpenAI. You can assign a custom specification and bring-your-own API key for image extraction models.\n",
            "- ‚ö° We have deprecated the OPENAI_IMAGE service type, and developers should now use the LLM image service instead.\n",
            "- ‚ö° We have removed the language field from AudioMetadata type, which has been replaced by the new LanguageMetadata type.\n",
            "\n",
            "### Bugs Fixed\n",
            "\n",
            "- GPLA-2987: Extracting text with Azure Doc Intelligence does not extract hyperlinks\n",
            "\n",
            "PreviousAugust 8: Support for LLM-based document extraction, .NET SDK, bug fixes\n",
            "NextJuly 25: Support for Mistral Large 2 & Nemo, Groq Llama 3.1 models, bug fixes\n",
            "Last updated5 months ago \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Ingested content [0ed6b24e-fec6-4008-8bb9-beda6073cbe6]"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Mezzanine: https://graphlit202412121b7b448d.blob.core.windows.net/files/0ed6b24e-fec6-4008-8bb9-beda6073cbe6/Mezzanine/page.json?sv=2025-01-05&se=2024-12-30T09%3A59%3A34Z&sr=c&sp=rl&sig=owRWJoJ3af3UPDIm9IYAnrH5uSy6%2BBWimVfnmZsHaVo%3D\n",
            "‚òÄÔ∏è\tJuly 2024\n",
            "\n",
            "# July 25: Support for Mistral Large 2 & Nemo, Groq Llama 3.1 models, bug fixes\n",
            "### New Features\n",
            "\n",
            "- üí° Graphlit now supports the Mistral Large 2 and Mistral Nemo models. The existing MISTRAL_LARGE model enum now will use Mistral Large 2.\n",
            "- üí° Graphlit now supports the Llama 3.1 8b, 70b and 405b models on Groq. (Note, these are rate-limited according to Groq's platform constraints.)\n",
            "- Added support for revision strategy on data extraction specifications. Now you can prompt the LLM to revise its previous data extraction response, similar to the existing completion revision strategy.\n",
            "- Added version property for AzureDocumentPreparationProperties type for assigning the API version used by Azure AI Document Intelligence. By default, Graphlit will continue to use the v4.0 (Preview) API version, but you can override this to assign version to V2023_10_31 to use the v3.1 (GA) API version instead. For some documents, the General Availability (GA) version of the API can provide better results.\n",
            "\n",
            "### Bugs Fixed\n",
            "\n",
            "- GPLA-2988: Not extracting hyperlinks from Office documents.\n",
            "\n",
            "PreviousJuly 28: Support for indexing workflow stage, Azure AI language detection, bug fixes\n",
            "NextJuly 19: Support for OpenAI GPT-4o Mini, BYO-key for Azure AI, similarity by summary, bug fixes\n",
            "Last updated5 months ago \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Ingested content [257dc6c9-65d0-416d-9b1c-d412aeb42bd4]"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Mezzanine: https://graphlit202412121b7b448d.blob.core.windows.net/files/257dc6c9-65d0-416d-9b1c-d412aeb42bd4/Mezzanine/page.json?sv=2025-01-05&se=2024-12-30T09%3A59%3A34Z&sr=c&sp=rl&sig=owRWJoJ3af3UPDIm9IYAnrH5uSy6%2BBWimVfnmZsHaVo%3D\n",
            "üéì\tJune 2024\n",
            "\n",
            "# June 21: Support for the Claude 3.5 Sonnet model, knowledge graph semantic search, and bug fixes\n",
            "### New Features\n",
            "\n",
            "- üí° Graphlit now supports the Anthropic Claude 3.5 Sonnet model, which can be assigned with the CLAUDE_3_5_SONNET model enum.\n",
            "- üí° Graphlit now supports semantic search of observable entities in the knowledge graph, such as Person, Organization and Place. These entity types will now have vector embeddings created from their enriched metadata, and support searching by similar text, and searching by similar entities.\n",
            "- ‚ö° We have changed the Google Drive and Google Email feed properties to require the Google OAuth client ID and client secret, along with the existing refresh token, for proper authentication against Google APIs.\n",
            "- ‚ö° We have added a credits quota on the Free Tier. Once 1000 credits have been used on the Free Tier, no more content can be ingested, and an upgrade to a paid tier is required. Customers will receive an email when the credits, storage or contents quota has been reached.\n",
            "\n",
            "### Bugs Fixed\n",
            "\n",
            "- GPLA-2837: Failed to ingest LinkedIn page as Web feed\n",
            "- GPLA-2831: Zero-byte file was left in Indexed state\n",
            "- GPLA-2834: Not reading any files from Azure blob feed with space in prefix\n",
            "- GPLA-2828: Better handling for files with unknown (or missing) file extensions\n",
            "\n",
            "PreviousJuly 4: Support for webhook Alerts, keywords summarization, Deepseek 128k context window, bug fixes\n",
            "NextJune 9: Support for Deepseek models, JSON-LD webpage parsing, performance improvements and bug fixes\n",
            "Last updated6 months ago \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Ingested content [7c8442ac-7d94-4a40-9a3b-fdda07048992]"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Mezzanine: https://graphlit202412121b7b448d.blob.core.windows.net/files/7c8442ac-7d94-4a40-9a3b-fdda07048992/Mezzanine/page.json?sv=2025-01-05&se=2024-12-30T09%3A59%3A34Z&sr=c&sp=rl&sig=owRWJoJ3af3UPDIm9IYAnrH5uSy6%2BBWimVfnmZsHaVo%3D\n",
            "üéÜ\tJanuary 2024\n",
            "\n",
            "# January 22: Support for Google and Microsoft email feeds, reingest content in-place, bug fixes\n",
            "### New Features\n",
            "\n",
            "- üí° Graphlit now supports Google and Microsoft email feeds. Email feeds can be created to ingest past emails, or poll for new emails. Emails create an EMAIL content type. Attachment files can optionally be extracted from emails, and will be linked to their parent email content. If assigning a workflow to the feed, the workflow will be applied both to the email content and the extracted attachment files.\n",
            "- üí° Graphlit now supports reingesting content in-place. The ingestText, ingestPage and ingestFile mutations now take an optional id parameter for an existing content object. If this id is provided, the existing content will be updated from the provided text or URI source, and will restart the assigned workflow.\n",
            "- Added restartAllContents mutation to restart workflow on all partially-ingested contents in project.\n",
            "- Added text field to ConversationCitation type, which returns the relevant text from the content source with the citation.\n",
            "\n",
            "### Bugs Fixed\n",
            "\n",
            "- GPLA-1313: Not extracting links from HTML\n",
            "- GPLA-2030: No text extracted from shapes in PPTX files\n",
            "\n",
            "PreviousFebruary 2: Support for Semantic Alerts, OpenAI 0125 models, performance enhancements, bug fixes\n",
            "NextJanuary 18: Support for content publishing, LLM tools, CLIP image embeddings, bug fixes\n",
            "Last updated8 months ago \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Ingested content [f2817947-a5aa-41d7-a297-b6f16a2d42e1]"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Mezzanine: https://graphlit202412121b7b448d.blob.core.windows.net/files/f2817947-a5aa-41d7-a297-b6f16a2d42e1/Mezzanine/page.json?sv=2025-01-05&se=2024-12-30T09%3A59%3A34Z&sr=c&sp=rl&sig=owRWJoJ3af3UPDIm9IYAnrH5uSy6%2BBWimVfnmZsHaVo%3D\n",
            "üéÑ\tDecember 2023\n",
            "\n",
            "# December 10: Support for OpenAI GPT-4 Turbo, Llama 2 and Mistral models; query by example, bug fixes\n",
            "### New Features\n",
            "\n",
            "- üí° Graphlit now supports the OpenAI GPT-4 Turbo 128k model, both in Azure OpenAI and native OpenAI services. Added new model enum GPT4_TURBO_VISION_128K.\n",
            "- üí° Graphlit now supports Llama 2 7b, 13b, 70b models and Mistral 7b model, via Replicate. Developers can use their own Replicate API key, or be charged as credits for Graphlit usage.\n",
            "- üí° Graphlit now supports the Anthropic Claude 2.1 model. Added new model enum CLAUDE_2_1.\n",
            "- üí° Graphlit now supports the OpenAI GPT-4 Vision model for image descriptions and text extraction. Added new model enum GPT4_TURBO_VISION_128K. See usage example in \"Multimodal RAG\" blog post.\n",
            "- Added query by example to contents query. Developers can specify one or more example contents, and query will use vector embeddings to return similar contents.\n",
            "- Added query by example to conversations query. Developers can specify one or more example conversations, and query will use vector embeddings to return similar conversations.\n",
            "- Added vector search support for conversations queries. Developers can provide search text which will use vector embeddings to return similar conversations.\n",
            "- Added promptSpecifications mutation for directly prompting multiple models. This can be used to evaluate prompts against multiple models or compare different specification parameters in parallel.\n",
            "- Added promptStrategy field to Specification, which supports multiple strategy types for preprocessing the prompt before being sent to the LLM model. For example, REWRITE prompt strategy will ask LLM to rewrite the incoming user prompt based on the previous conversation messages.\n",
            "- Added suggestConversation mutation, which returns a list of suggested followup questions based on the specified conversation and related contents. This can be used to auto-suggest questions for chatbot users.\n",
            "- Added new summarization types: CHAPTERS, QUESTIONS and POSTS. See usage examples in the \"LLMs for Podcasters\" blog post.\n",
            "- Added versioned model enums such as GPT4_0613 and GPT35_TURBO_16K_1106. Without version specified, such as GPT35_TURBO_16K, Graphlit will use the latest production model version, as defined by the LLM vendor.\n",
            "- Added lookupContents query to get multiple contents by id in one query.\n",
            "- ‚ö° In Content type, headline field was renamed to headlines and now returns an array of strings.\n",
            "- ‚ö° Entity names are now limited to 1024 characters. Names will be truncated if they exceed the maximum length.\n",
            "- ‚ö° In SummarizationTypes enum, BULLET_POINTS was renamed to BULLETS.\n",
            "- ‚ö° In ProjectStorage type, originalTotalSize was renamed to totalSize, and totalRenditionSize field was added. totalSize is the sum of the ingested source file sizes, and totalRenditionSize is the sum of the source file sizes and any derived rendition sizes.\n",
            "- ‚ö° In ConversationStrategy type, strategyType was renamed to type for consistency with rest of data model.\n",
            "- ‚ö° In Specification type, optimizeSearchConversation was removed, and now is handled by OPTIMIZE_SEARCH prompt strategy.\n",
            "\n",
            "### Bugs Fixed\n",
            "\n",
            "- GPLA-1725: Should ignore RSS.xml from web feed sitemap\n",
            "- GPLA-1726: GPT-3.5 Turbo 16k LLM is adding \"Citation #\" to response\n",
            "- GPLA-1698: Workflow not applied to link-crawled content\n",
            "- GPLA-1692: Mismatched project storage total size, when some content has errored\n",
            "- GPLA-1237: Add relevance threshold for semantic search\n",
            "\n",
            "PreviousJanuary 18: Support for content publishing, LLM tools, CLIP image embeddings, bug fixes\n",
            "NextOctober 30: Optimized conversation responses; added observable aliases; bug fixes\n",
            "Last updated11 months ago \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Ingested content [a263132e-7225-40d3-a75d-39b3ef1edbd1]"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Mezzanine: https://graphlit202412121b7b448d.blob.core.windows.net/files/a263132e-7225-40d3-a75d-39b3ef1edbd1/Mezzanine/page.json?sv=2025-01-05&se=2024-12-30T09%3A59%3A34Z&sr=c&sp=rl&sig=owRWJoJ3af3UPDIm9IYAnrH5uSy6%2BBWimVfnmZsHaVo%3D\n",
            "üéÇ\tAugust 2024\n",
            "\n",
            "# August 8: Support for LLM-based document extraction, .NET SDK, bug fixes\n",
            "### New Features\n",
            "\n",
            "- üí° Graphlit now supports LLM-based document preparation, using vision-capable models such as OpenAI GPT-4o and Anthropic Sonnet 3.5. This is available via the MODEL_DOCUMENT preparation service type, and you can assign a customspecification object and bring your own LLM keys.\n",
            "- üí° Graphlit now provides an open source .NET SDK, supporting .NET 6 and .NET 8 (and above). SDK package can be found on Nuget.org. Code samples can be found on GitHub.\n",
            "- Added identifier property to Content object for mapping content to external database identifiers. This is supported for content filtering as well.\n",
            "- Added support for Claude 3 vision models for image-based entity extraction, using the MODEL_IMAGE entity extraction service.\n",
            "- Added context augmentation to conversations, via the augmentedFilter property on the Conversation object. Any content which matches this augmented filter will be injected into the LLM prompt content, without needing to be related by vector similarity to the user prompt. This is useful for specifying domain knowledge which should always be referenced by the RAG pipeline.\n",
            "- Added support for the latest snapshot of OpenAI GPT-4o, with the model enum GPT4O_128K_20240806.\n",
            "- Added reranking of related entities, when preparing the LLM prompt context for GraphRAG. If reranking is enabled, the metadata from the related entities will be reranked with the same reranker assigned to the conversation specification.\n",
            "- ‚ö° We have changed the type of the duration field in the AudioMetadata and VideoMetadata types to be TimeSpan rather than string, as to be more consistent with the rest of the API data model.\n",
            "\n",
            "### Bugs Fixed\n",
            "\n",
            "- GPLA-2884: Support retry on HTTP 529 (Overloaded) error from Anthropic API.\n",
            "\n",
            "PreviousAugust 11: Support for Azure AI Document Intelligence by default, language-aware summaries\n",
            "NextJuly 28: Support for indexing workflow stage, Azure AI language detection, bug fixes\n",
            "Last updated4 months ago \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Ingested content [d40abe32-e564-4a6c-bd34-cea90b98c172]"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Mezzanine: https://graphlit202412121b7b448d.blob.core.windows.net/files/d40abe32-e564-4a6c-bd34-cea90b98c172/Mezzanine/page.json?sv=2025-01-05&se=2024-12-30T09%3A59%3A34Z&sr=c&sp=rl&sig=owRWJoJ3af3UPDIm9IYAnrH5uSy6%2BBWimVfnmZsHaVo%3D\n",
            "üéá\tJuly 2023\n",
            "\n",
            "# July 15: Support for SharePoint feeds, new Conversation features\n",
            "### New Features\n",
            "\n",
            "- üí° Added support for SharePoint feeds: now can create feed to ingest files from SharePoint document library (and optionally, folder within document library)\n",
            "- üí° Added support for PII detection during entity extraction from text documents and audio transcripts: now we will create labels such as PII: Social Security Number automatically when PII is detected\n",
            "- üí° Added support for developer's own OpenAI API keys and Azure OpenAI deployments in Specifications\n",
            "- ‚ÑπÔ∏è Changed semantics of deleteFeed to delete the contents ingested by the feed; since contents are linked to feeds, now feeds can be disabled, while keeping the lineage to the feed, and if feeds are deleted, they will delete the linked contents, so we never lose the feed-to-content lineage\n",
            "- Added GraphQL query for SharePoint consent URI, for registered Graphlit Platform Azure AD application\n",
            "- Better handling of web sitemap indexes: now if a sitemap.xml contains a sitemapindex element, we will load all linked sitemaps for evaluating web pages to ingest from Web feed\n",
            "- Added new GraphQL mutations for openConversation, closeConversation and undoConversation\n",
            "- Added timestamps to Conversation messages\n",
            "- Added new GraphQL mutations for openCollection and closeCollection\n",
            "- Added more configuration for content search: now can specify searchType (KEYWORD, VECTOR, HYBRID) and queryType (SIMPLE, FULL - aka Lucene syntax)\n",
            "- Better parsing of iTunes podcast metadata\n",
            "- ‚ö° Renamed listingLimit field on feeds to readLimit\n",
            "- ‚ö° Renamed topK to numberSimilar for content vector search type\n",
            "- ‚ö° Changed GraphQL feed properties: split out azure into azureBlob and azureFile properties\n",
            "- ‚ö° Changed GraphQL specification properties: split out openAI into openAI and azureOpenAI properties\n",
            "- ‚ö° Removed count fields on query results, and replaced with explicit count{Entity} queries, which support search and filtering.\n",
            "\n",
            "### Bugs Fixed\n",
            "\n",
            "- GPLA-1043: Reddit readLimit not taking effect: now the specified limit of Reddit posts will be leveraged for Reddit feeds\n",
            "- GPLA-1064: Performance on entity extraction and observation creation for large PDFs was under expectations: now able to build knowledge graph from large PDFs much faster (4x speed improvement)\n",
            "- GPLA-1053: If rendition generation errored during content workflow, the content was not properly marked as errored\n",
            "- GPLA-1102: Large Web sitemaps were slow to load; rewrote sitemap index handling, and now can process sitemaps with 150K+ entries in seconds.\n",
            "\n",
            "PreviousAugust 3: New data model for Observations, new Category entity\n",
            "Last updated5 months ago \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Ingested content [fbde99f0-f7ca-4f5d-a318-eb7f4de07912]"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Mezzanine: https://graphlit202412121b7b448d.blob.core.windows.net/files/fbde99f0-f7ca-4f5d-a318-eb7f4de07912/Mezzanine/page.json?sv=2025-01-05&se=2024-12-30T09%3A59%3A34Z&sr=c&sp=rl&sig=owRWJoJ3af3UPDIm9IYAnrH5uSy6%2BBWimVfnmZsHaVo%3D\n",
            "üéÇ\tAugust 2024\n",
            "\n",
            "# August 20: Support for medical entities, Anthropic prompt caching, bug fixes\n",
            "### New Features\n",
            "\n",
            "- üí° Graphlit now supports the extraction of medical-related entities: MedicalStudy, MedicalCondition, MedicalGuideline, MedicalDrug, MedicalDrugClass, MedicalIndication, MedicalContraindication, MedicalTest, MedicalDevice, MedicalTherapy, and MedicalProcedure.\n",
            "- üí° Graphlit now supports medical-related entities in GraphRAG, and via API for queries and mutations.\n",
            "- Added support for Anthropic prompt caching. When using Anthropic Sonnet 3.5 or Haiku 3, Anthropic will now cache the entity extraction and LLM document preparation system prompts, which saves on token cost and increases performance.\n",
            "\n",
            "### Bugs Fixed\n",
            "\n",
            "- GPLA-3104: Should default search type to VECTOR, when performing entity similarity filter.\n",
            "- GPLA-3112: Empty PDF fails entity extraction.\n",
            "\n",
            "PreviousSeptember 1: Support for FHIR enrichment, latest Cohere models, bug fixes\n",
            "NextAugust 11: Support for Azure AI Document Intelligence by default, language-aware summaries\n",
            "Last updated4 months ago \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Ingested content [0932e05b-1816-4e99-a4ef-7bc475de60fc]"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Mezzanine: https://graphlit202412121b7b448d.blob.core.windows.net/files/0932e05b-1816-4e99-a4ef-7bc475de60fc/Mezzanine/page.json?sv=2025-01-05&se=2024-12-30T09%3A59%3A34Z&sr=c&sp=rl&sig=owRWJoJ3af3UPDIm9IYAnrH5uSy6%2BBWimVfnmZsHaVo%3D\n",
            "üåßÔ∏è\tFebruary 2024\n",
            "\n",
            "# February 2: Support for Semantic Alerts, OpenAI 0125 models, performance enhancements, bug fixes\n",
            "### New Features\n",
            "\n",
            "- üí° Graphlit now supports Semantic Alerts, which allows for LLM summarization and publishing of content, on a periodic basis. This is useful for generating daily reports from email, Slack or other time-based feeds. Alerts support the same publishing options, i.e. audio and text, as the publishContents mutation.\n",
            "- üí° Graphlit now supports the latest OpenAI 0125 model versions, for GPT-4 and GPT-3.5 Turbo. We will add support for Azure OpenAI when Microsoft releases support for these.\n",
            "- Slack feeds now support a listing type field, where you can specify if you want PAST or NEW Slack messages in the feed.\n",
            "- üî• This release provides many performance enhancements, which will speed up the content workflows for ingested content.\n",
            "\n",
            "### Bugs Fixed\n",
            "\n",
            "- GPLA-2114: Collections not being added to text embedding index documents.\n",
            "- GPLA-2063: Not handling hallucinated citations.\n",
            "- GPLA-1916: Collections not inherited from project-scope into tenant-scope.\n",
            "- GPLA-2105: Should error on add/remove of contents to/from collections if content does not exist.\n",
            "\n",
            "PreviousFebruary 21: Support for OneDrive and Google Drive feeds, extract images from PDFs, bug fixes\n",
            "NextJanuary 22: Support for Google and Microsoft email feeds, reingest content in-place, bug fixes\n",
            "Last updated10 months ago \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Ingested content [7b5b7874-c84b-4607-877c-8bec0e167127]"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Mezzanine: https://graphlit202412121b7b448d.blob.core.windows.net/files/7b5b7874-c84b-4607-877c-8bec0e167127/Mezzanine/page.json?sv=2025-01-05&se=2024-12-30T09%3A59%3A34Z&sr=c&sp=rl&sig=owRWJoJ3af3UPDIm9IYAnrH5uSy6%2BBWimVfnmZsHaVo%3D\n",
            "üéÑ\tDecember 2024\n",
            "\n",
            "# December 22: Support for Dropbox, Box, Intercom and Zendesk feeds, OpenAI o1, Gemini 2.0, bug fixes\n",
            "### New Features\n",
            "\n",
            "- üí° Graphlit now supports Dropbox feeds for ingesting files on the Dropbox cloud service. Dropbox feeds require your appKey, appSecret, redirectUriand refreshTokento be assigned. The feed also accepts an optional pathparameter to read files from a specific Dropbox folder.\n",
            "- üí° Graphlit now supports Box feeds for ingesting files on the Box cloud service. Box feeds require your clientId, clientSecret, redirectUriand refreshTokento be assigned.\n",
            "- üí° Graphlit now supports Intercom feeds for ingesting Intercom Articles and Tickets. We will ingest Intercom Articles as PAGEcontent type, and Tickets as ISSUEcontent type. Intercom feeds require the accessTokenproperty to be assigned.\n",
            "- üí° Graphlit now supports Zendesk feeds for ingesting Zendesk Articles and Tickets. We will ingest Zendesk Articles as PAGEcontent type, and Tickets as ISSUEcontent type. Zendesk feeds require the accessTokenproperty and your Zendesk subdomain to be assigned.\n",
            "- Graphlit now supports the latest OpenAI o1 model, with the model enums O1_200kand O1_200k_20241217.\n",
            "- Graphlit now supports the latest Gemini Flash 2.0 Experimental model, with the model enum GEMINI_2_0_FLASH_EXPERIMENTAL.\n",
            "- Graphlit now supports the latest Cohere R7B model, with the model enum COMMAND_R7B_202412.\n",
            "- Graphlit now supports returning the low-level details from prompting RAG conversations, by adding the includeDetailsparameter and setting to True. This includes details on the number of sources, the exact list of messages provided to the LLM, and more.\n",
            "- We have added support for filtering of observables, such as Person or Organization, by URI property.\n",
            "- We have added the ability to bypass semantic search in content retrieval with conversations. You can assign NONEfor the conversation search type, and it will ignore the user prompt when retrieving content. It will inject all contents resulting from the content filter into the RAG prompt context.\n",
            "- We have added a new createdInLastproperty to all entity filters, which allows easier filtering of entities created within a recent time period. Also, we have added a new inLastproperty to the content filter, which allows easier filtering of content authored within a recent time period. For example, find all images taken in the last 3 days, or find me all emails I received yesterday.\n",
            "- We have added support for the latest Azure AI Document Intelligence models, with enums US_PAY_STUB, US_BANK_STATEMENT, and US_BANK_CHECK.\n",
            "- We have added support for Google Drive and OneDrive feeds to ingest specific files by providing a list of file identifiers (files), in addition to the folder identifier (folderId). If files identifiers are provided, they take precedence over the folder identifier.\n",
            "- ‚ö° For projects upgraded to the Starter Tier after Dec 9, 2024, we have removed the content items limit. Now you can store an unlimited number of content items (i.e. files, web pages, Slack messages) on the Starter or Growth Tiers. If you have an existing project on the Starter Tier, please reach out and we will manually remove that content item limit on the project.\n",
            "\n",
            "### Bugs Fixed\n",
            "\n",
            "- GPLA-3529: Can't assign collection to multitenant content\n",
            "- GPLA-3579: Should decode HTML characters when parsing HTML email\n",
            "- GPLA-3576: Ingesting content in-place doesn't handle isSynchronous properly\n",
            "- GPLA-3457: IsFeedDone doesn't return True for finished feed with no contents\n",
            "- GPLA-3572: Not handling HTTP 400 error on uploading from URI\n",
            "\n",
            "PreviousDecember 27: Support for LLM fallbacks, native Google Docs formats, website unblocking, bug fixes\n",
            "NextDecember 9: Support for website mapping, web page screenshots, Groq Llama 3.3 model, bug fixes\n",
            "Last updated5 days ago \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Ingested content [3923639b-14f1-484b-86e7-7c6f6e67461d]"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Mezzanine: https://graphlit202412121b7b448d.blob.core.windows.net/files/3923639b-14f1-484b-86e7-7c6f6e67461d/Mezzanine/page.json?sv=2025-01-05&se=2024-12-30T09%3A59%3A34Z&sr=c&sp=rl&sig=owRWJoJ3af3UPDIm9IYAnrH5uSy6%2BBWimVfnmZsHaVo%3D\n",
            "üéÇ\tAugust 2023\n",
            "\n",
            "# August 3: New data model for Observations, new Category entity\n",
            "### New Features\n",
            "\n",
            "- üí° Revised data model for Observations, Occurrences and observables (i.e. Person, Organization). Now after entity extraction, content will have one Observation for each observed entity, and a list of occurrences. Occurrence now supports text, time and image occurrence types. (Text: page index, time: start/end timestamp, image: bounding box) Observations now have ObservableType and Observable fields, which specify the observed entity type and entity reference.\n",
            "- üí° Added Category entity to GraphQL data model, which supports PII categories such as Phone Number or Credit Card Number.\n",
            "- Added probability field to model properties, for the LLM's token probability. (See OpenAI documentation for more detail.)\n",
            "- Added error field to feeds. If a feed fails to read from the data source, and is marked as ERRORED state, the error field will have the error description.\n",
            "- Support reingestion of changed files from feeds. For feeds, such as SharePoint or Web, where we can recognize that a file or page was updated, we will now reingest the content in-place. Content will keep the same ID, and will restart the content workflow by re-downloading the updated content from the data source. Existing observations will be deleted, and new observations will be created from the updated content.\n",
            "- ‚ÑπÔ∏è Ingestion of content is now idempotent, meaning if you ingest content again from the same URI, we will reingest the content in-place, while keeping the same ID. (If we can recognize the content has not changed, such as by ETag, we will return the existing content object.)\n",
            "- ‚ÑπÔ∏è Changed GraphQL data type of SharePoint tenantId, libraryId and siteId to ID rather than String.\n",
            "- ‚ú® Performance optimization of entity extraction, and the creation of observations.\n",
            "\n",
            "### Bugs Fixed\n",
            "\n",
            "- GPLA-1130: Only was extracting text from first column of PDF tables.\n",
            "- GPLA-1140: Text from DOCX tables was not extracted properly.\n",
            "- GPLA-1154: Audio content ingested from RSS feed was not deleted when feed was deleted.\n",
            "\n",
            "PreviousAugust 9: Support direct text, Markdown and HTML ingestion; new Specification LLM strategy\n",
            "NextJuly 15: Support for SharePoint feeds, new Conversation features\n",
            "Last updated1 year ago \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Ingested content [67150a0e-9b17-4261-8f62-1c57686d46e1]"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Mezzanine: https://graphlit202412121b7b448d.blob.core.windows.net/files/67150a0e-9b17-4261-8f62-1c57686d46e1/Mezzanine/page.json?sv=2025-01-05&se=2024-12-30T09%3A59%3A34Z&sr=c&sp=rl&sig=owRWJoJ3af3UPDIm9IYAnrH5uSy6%2BBWimVfnmZsHaVo%3D\n",
            "üåßÔ∏è\tFebruary 2024\n",
            "\n",
            "# February 21: Support for OneDrive and Google Drive feeds, extract images from PDFs, bug fixes\n",
            "### New Features\n",
            "\n",
            "- üí° Graphlit now supports OneDrive and Google Drive feeds. Files can be ingested from OneDrive or Google Drive, including shared drives where the authenticated user has access. Both OneDrive and Google Drive support the reading of existing files, and tracking new files added to storage with recurrent feeds.\n",
            "- üí° Graphlit now supports email backup files, such as EML or MSG, which will be assigned the EMAIL file type. During email file preparation, we will automatically extract and ingest any file attachments.\n",
            "- üí° Graphlit now automatically extracts embedded images in PDF files, ingests them as content objects, and links them as children of the parent PDF.\n",
            "- üí° Graphlit now supports recursive Notion feeds. When the isRecursive flag is true in the Notion feed properties, we will crawl child pages and databases, and recursively ingest them in addition to the specified pages and databases.\n",
            "- Added support for assigning collections to content ingested with the ingestPage, ingestFile or ingestText mutations. This saves a step where the content will automatically be added to the collection(s) without requiring another mutation call.\n",
            "- Added support for the CODE file type for a wide variety of source code formats, i.e. Python .py, Javascript .js. Code files use optimized text splitting for enhanced search and retrieval.\n",
            "- Added support for customGuidance in Specification object, which can be used for injecting a guidance prompt during the RAG process. For example, you can instruct the LLM to return a default response string if no content sources are found via semantic search.\n",
            "- Added tenants field to Project object, which returns a list of all tenant IDs which have been used to create an entity in Graphlit.\n",
            "- Added email metadata, separate from document metadata. Now emails will contain indexed metadata such as to, from, or subject.\n",
            "- ‚ö° The contents field for content objects has been replaced with children and parent fields. For example, when a ZIP file is unpacked, the unpacked files will be added as children of the ZIP file, and the ZIP file will be the parent of each of the unpacked files.\n",
            "- ‚ö° Removed enableImageAnalysis field from image preparation properties in workflow object. Now is enabled by default.\n",
            "- ‚ö° Moved disableSmartCapture field to preparation workflow stage from page preparation properties. This is used to disable the use of headless Chrome browser to capture HTML from web pages. It is enabled by default, and if disabled, Graphlit will simply download the HTML from the web page rather than rendering on headless Chrome browser.\n",
            "\n",
            "### Bugs Fixed\n",
            "\n",
            "- GPLA-2099: Failed to ingest ArXiV PDF. Fixed PDF parsing error.\n",
            "- GPLA-2174: LLM response is incorrect with conversation history, but no content sources.\n",
            "- GPLA-2199: ZIP package left in Indexed state after content workflow.\n",
            "\n",
            "PreviousMarch 10: Support for Claude 3, Mistral and Groq models, usage/credits telemetry, bug fixes\n",
            "NextFebruary 2: Support for Semantic Alerts, OpenAI 0125 models, performance enhancements, bug fixes\n",
            "Last updated9 months ago \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Ingested content [1a8c6b11-f325-47e9-bb39-643f7fb92154]"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Mezzanine: https://graphlit202412121b7b448d.blob.core.windows.net/files/1a8c6b11-f325-47e9-bb39-643f7fb92154/Mezzanine/page.json?sv=2025-01-05&se=2024-12-30T09%3A59%3A34Z&sr=c&sp=rl&sig=owRWJoJ3af3UPDIm9IYAnrH5uSy6%2BBWimVfnmZsHaVo%3D\n",
            "üéÇ\tAugust 2023\n",
            "\n",
            "# August 9: Support direct text, Markdown and HTML ingestion; new Specification LLM strategy\n",
            "### New Features\n",
            "\n",
            "- üí° Added ingestText mutation which supports direct Content ingestion of plain text, Markdown and HTML. Now, if you have pre-scraped HTML or Markdown text, you can ingest it into Graphlit without reading from a URL.\n",
            "- üí° Added Specification strategy property, which allows customization of the LLM context when prompting a conversation. ConversationStrategy now provides Windowed and Summarized message histories, as well as configuration of the weight between existing conversation messages and Content text pages (or audio transcript segments) in the LLM context.\n",
            "- üí° Added auto-summarization of extracted text and audio transcripts. There is a new Content summary property where a list of summary bullet points can be found. These summaries can be optionally included in the Conversation prompt context for more accurate LLM responses.\n",
            "- ‚ÑπÔ∏è Added AzureOpenAIModels and OpenAIModels types to Specification model properties to make it easier to specify the desired LLM.\n",
            "- ‚ÑπÔ∏è Renamed ConversationMessage date property to timestamp\n",
            "- ‚ú® Refined the internal LLM prompts for providing content as part of Conversation context. This provides for much clearer and accurate results from the LLM.\n",
            "\n",
            "PreviousAugust 17: Prepare for usage-based billing; append SAS tokens to URIs\n",
            "NextAugust 3: New data model for Observations, new Category entity\n",
            "Last updated1 year ago \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Ingested content [5da3504c-5d1d-4b5c-848e-d3ddb11f3964]"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Mezzanine: https://graphlit202412121b7b448d.blob.core.windows.net/files/5da3504c-5d1d-4b5c-848e-d3ddb11f3964/Mezzanine/page.json?sv=2025-01-05&se=2024-12-30T09%3A59%3A34Z&sr=c&sp=rl&sig=owRWJoJ3af3UPDIm9IYAnrH5uSy6%2BBWimVfnmZsHaVo%3D\n",
            "üéÇ\tAugust 2024\n",
            "\n",
            "# August 11: Support for Azure AI Document Intelligence by default, language-aware summaries\n",
            "### New Features\n",
            "\n",
            "- Added support for language-aware summaries when using LLM-based document extraction. Now the summaries for tables and sections generated by the LLM will follow the language of the source text.\n",
            "- Added support for language-aware entity descriptions with using LLM-based entity extraction. Now the entity descriptions generated by the LLM will follow the language of the source text.\n",
            "- ‚ö° We have changed the default document preparation method to use Azure AI Document Intelligence, rather than our built-in document parsers. We have found that the fidelity of Azure AI is considerably better for complex PDFs, and provides better support for table extraction, so we have made this the default. Note: this does come with increased credit usage per-page, for PDF, DOCX and PPTX documents, but the quality of the extracted documents are noticeably higher for use in RAG pipelines.\n",
            "\n",
            "### Bugs Fixed\n",
            "\n",
            "- GPLA-3070: Not getting slide count assigned to metadata for PPTX files.\n",
            "\n",
            "PreviousAugust 20: Support for medical entities, Anthropic prompt caching, bug fixes\n",
            "NextAugust 8: Support for LLM-based document extraction, .NET SDK, bug fixes\n",
            "Last updated4 months ago \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Ingested content [253c57c2-3536-4a73-aa76-101372e74b0e]"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Mezzanine: https://graphlit202412121b7b448d.blob.core.windows.net/files/253c57c2-3536-4a73-aa76-101372e74b0e/Mezzanine/page.json?sv=2025-01-05&se=2024-12-30T09%3A59%3A34Z&sr=c&sp=rl&sig=owRWJoJ3af3UPDIm9IYAnrH5uSy6%2BBWimVfnmZsHaVo%3D\n",
            "üéÑ\tDecember 2024\n",
            "\n",
            "# December 9: Support for website mapping, web page screenshots, Groq Llama 3.3 model, bug fixes\n",
            "### New Features\n",
            "\n",
            "- üí° Graphlit now supports mapping a website with the mapWebmutation. You can provide a URL to a website, and the query will return a list of URLs based on the sitemap.xml (or sitemap-index.xml) file, at or underneath the provided URL.\n",
            "- üí° Graphlit now supports the generation of web page screenshots with the screenshotPagemutation. By providing the URL of a web page, and optionally, the maximum desired height of the screenshot, we will screenshot the webpage and ingest it automatically as content. You can provide an optional workflow, which will be applied to the ingested image content, for operations like generating image descriptions with a vision LLM.\n",
            "- üí° Graphlit now supports the direct summarization of text with the summarizeTextmutation. By providing the desired summarization strategy, we will summarize the text (i.e. bullet points, social media posts) and return the summarization.\n",
            "- üí° Graphlit now supports the direct extraction of text with the extractTextmutation. By providing the LLM tool definitions and an optional LLM specification, we will prompt the desired LLM (or OpenAI GPT-4o, by default) to invoke the provided tools, and return the JSON responses from the LLM tool calling.\n",
            "- Graphlit now supports the latest Groq Llama 3.3 model, with the model enum LLAMA_3_3_70B.\n",
            "- We have updated Cohere reranking to use the latest Cohere rerank-v3.5model by default.\n",
            "- ‚ö° We have added a new flattenCitationsfield to the ConversationStrategyInputtype. By assigning this field to True, when calling promptConversation,we will combine multiple citations from the same content into a single citation.\n",
            "- ‚ö° For Microsoft email, Microsoft Teams and OneDrive feeds, we have added the clientIdand clientSecretfields as required feed properties. These properties must be assigned, in addition to the refreshTokenfield for proper authentication to the Microsoft Graph API used by these feeds. (Colab Notebook Example)\n",
            "\n",
            "### Bugs Fixed\n",
            "\n",
            "- GPLA-3492: Not finding sitemap at parent web path\n",
            "- GPLA-3500: Failed to handle mismatch of Deepgram model/language\n",
            "\n",
            "PreviousDecember 22: Support for Dropbox, Box, Intercom and Zendesk feeds, OpenAI o1, Gemini 2.0, bug fixes\n",
            "NextDecember 1: Support for retrieval-only RAG pipeline, bug fixes\n",
            "Last updated19 days ago \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Ingested content [ebda0578-6209-4833-9bee-36d0050dc5ee]"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Mezzanine: https://graphlit202412121b7b448d.blob.core.windows.net/files/ebda0578-6209-4833-9bee-36d0050dc5ee/Mezzanine/page.json?sv=2025-01-05&se=2024-12-30T09%3A59%3A34Z&sr=c&sp=rl&sig=owRWJoJ3af3UPDIm9IYAnrH5uSy6%2BBWimVfnmZsHaVo%3D\n",
            "‚òÄÔ∏è\tJuly 2024\n",
            "\n",
            "# July 19: Support for OpenAI GPT-4o Mini, BYO-key for Azure AI, similarity by summary, bug fixes\n",
            "### New Features\n",
            "\n",
            "- üí° Graphlit now supports the OpenAI GPT-4o Mini model, with 16k output tokens.\n",
            "- üí° Graphlit now supports 'bring-your-own-key' for Azure AI Document Intelligence models. We have added a custom endpoint and key property, which can be assigned to use your own Azure AI resource.\n",
            "- Updated to use Jina reranker v2 (jina-reranker-v2-base-multilingual) by default.\n",
            "- Updated to assign the summary, bullets, etc properties when calling summarizeContents mutation. Now when summarizing contents, we will store the resulting summary in the content itself, in addition to returning the summarized results.\n",
            "- Added relevance property to all entity types, which will be assigned when searching for these entities. Entity results will be sorted (descending) by this search relevance score.\n",
            "- Added the ability to manually update summary, bullets, etc. properties when calling the updateContent mutation.\n",
            "- Added offset property to AtlassianJiraFeedProperties, so the timezone offset can be properly assigned for paging of the Jira feed. (Defaults to zero offset, i.e. UTC.) Jira does not store dates in UTC format, and the timestamps are based on the server timezone of the hosted Jira instance. By assigning the timezone offset with the Jira feed, we can reliably page the updated date timestamps from the Jira API.\n",
            "- ‚ö° We have changed the content similarity search behavior to find similar content by summary, rather than text of the document, when a summary has been previously generated. For long documents, this will provide a more accurate similarity, rather than comparing on the first few pages of text in a document.\n",
            "- ‚ö° We have changed the behavior of assigning offset in the entity filter objects for paging through entities. If using vector or hybrid search, this offset will be ignored (i.e. zero offset). Paging will not be supported through vector or hybrid search results. For keyword search, the offset will continue to be used, along with the limit property, to provide paging through the search results. We have made this change because we have found that index-based paging is not reliable with our vector/hybrid search approach. We are investigating ways to support this reliably with vector/hybrid search in the future.\n",
            "\n",
            "### Bugs Fixed\n",
            "\n",
            "- GPLA-2915: Add retry on OpenAI API HTTP 524 error (gateway timeout).\n",
            "- GPLA-2908: Not paging through Jira feed correctly.\n",
            "- GPLA-2917: Search by similar content is not giving expected results on long documents.\n",
            "- GPLA-2244: Keyword search not finding text in latter part of long PDF.\n",
            "\n",
            "PreviousJuly 25: Support for Mistral Large 2 & Nemo, Groq Llama 3.1 models, bug fixes\n",
            "NextJuly 4: Support for webhook Alerts, keywords summarization, Deepseek 128k context window, bug fixes\n",
            "Last updated5 months ago \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Ingested content [4eff5e88-2cf6-489f-9bfb-52b30823e07e]"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Mezzanine: https://graphlit202412121b7b448d.blob.core.windows.net/files/4eff5e88-2cf6-489f-9bfb-52b30823e07e/Mezzanine/page.json?sv=2025-01-05&se=2024-12-30T09%3A59%3A34Z&sr=c&sp=rl&sig=owRWJoJ3af3UPDIm9IYAnrH5uSy6%2BBWimVfnmZsHaVo%3D\n",
            "üéÑ\tDecember 2024\n",
            "\n",
            "# December 1: Support for retrieval-only RAG pipeline, bug fixes\n",
            "### New Features\n",
            "\n",
            "- üí° Graphlit now supports formatting of LLM-ready prompts with our RAG pipeline, via the new formatConversation and completeConversation mutations. This is valuable for supporting LLM streaming by directly calling the LLM from your application, and using Graphlit for RAG retrieval and conversation history. (Colab Notebook Example)\n",
            "- We have added support for inline hyperlinks in extracted text from documents and web pages.\n",
            "\n",
            "### Bugs Fixed\n",
            "\n",
            "- GPLA-3466: Owner ID should accept any non-whitespace string\n",
            "- GPLA-3458: Not getting Person-to-Organization edges from entity extraction\n",
            "\n",
            "PreviousDecember 9: Support for website mapping, web page screenshots, Groq Llama 3.3 model, bug fixes\n",
            "NextNovember 24: Support for direct LLM prompt, multi-turn image analysis, bug fixes\n",
            "Last updated28 days ago \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Ingested content [a937626a-37ee-4eb1-93e5-2206e9a188ec]"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Mezzanine: https://graphlit202412121b7b448d.blob.core.windows.net/files/a937626a-37ee-4eb1-93e5-2206e9a188ec/Mezzanine/page.json?sv=2025-01-05&se=2024-12-30T09%3A59%3A34Z&sr=c&sp=rl&sig=owRWJoJ3af3UPDIm9IYAnrH5uSy6%2BBWimVfnmZsHaVo%3D\n",
            "üéÜ\tJanuary 2024\n",
            "\n",
            "# January 18: Support for content publishing, LLM tools, CLIP image embeddings, bug fixes\n",
            "### New Features\n",
            "\n",
            "- üí° Graphlit now supports content publishing, where documents, audio transcripts and even image descriptions, can be summarized, and repurposed into blog posts, emails or AI-generated podcasts. With the new publishContents mutation, you can configure LLM prompts for summarization and publishing, and assign specifications to use different models and/or system prompts for each step in the process. The published content will be reingested into Graphlit, and can be searched or used for conversations, like any other form of content.\n",
            "- üí° Graphlit now supports publishing conversations as content with the new publishConversation mutation. You can generate text or audio transcripts of your conversations, to be reused in other tools.\n",
            "- üí° Graphlit now supports bulk summarization of contents with the summarizeContents mutation. You can filter a set of content, by feed, by observable or by similar text, and run a set of summarizations across each content in parallel.\n",
            "- üí° Graphlit now supports LLM entity extraction, with the new MODEL_TEXT entity extraction service type. Similar to using Azure Cognitive Service Text Analytics, you can use any OpenAI or Anthropic model for extracting entities from text. Internally the LLM returns JSON-LD entities, which we convert into Person, Organization, Place, etc. entities and assign observations to the extracted content.\n",
            "- üí° Graphlit now supports LLM tools (aka function calls) with OpenAI models. You can define the tools to be used with the LLM in the specification object. With the new extractContents mutation, you can execute a prompt against content using a specification with tools defined. The mutation will return the JSON arguments assigned by the LLM.\n",
            "- üí° Graphlit now supports callback webhooks for LLM tools. If you assign a URI in the ToolDefinition object, Graphlit will call your webhook the tool name and JSON arguments. When you respond to the webhook with JSON, we will add that response to the LLM messages, and ask the LLM to complete the original prompt.\n",
            "- üí° Graphlit now supports the selection of the Deepgram model (such as Meeting, Phonecall or Finance) with the preparation workflow. Also, you can assign your own Deepgram API key, which will be used for audio transcription using that workflow.\n",
            "- Added support for CLIP image embeddings using Roboflow, which can be used for similar image search. If you search for contents by similar contents, we will now use the content's text and/or image embeddings to find similar content.\n",
            "- Added support for dynamic web page ingestion. Graphlit now navigates to and automatically scrolls web pages using Browserless.io, so we capture the fully rendered HTML before extracting text. Also, we now support web page screenshots, if enabled with enableImageAnalysis property in preparation workflow. These screenshots can be analyzed with multimodal modals, such as GPT-4 Vision, or can be used to create image embeddings for similar image search.\n",
            "- Added table parsing when preparing documents. We now store structured (tab-delimited) text in the JSON text mezzanine which is extracted from documents in the preparation workflow.\n",
            "- Added reverse geocoding of lat/long locations found in image or other content metadata. We now store the real-world address with the content metadata, for use in conversations.\n",
            "- Added assistant messages to the conversation message history provided to the LLM. Originally we had included only user messages, but now we are formatting both user and assistant messages into the LLM prompt for conversations.\n",
            "- Added new chunking algorithm for text embeddings. We support semantic chunking at the page or transcript segment level, and now will create embeddings from smaller sized text chunks per page or segment.\n",
            "- Added content metadata to text and image embeddings. To provide better context for the text embeddings, we now include formatted content metadata, which includes fields like title, subject, author, or description. For emails, we include to, from, cc, and bcc fields.\n",
            "- Added helper mutations isContentDone and isFeedDone which can be used for polling completion of ingested content, or all content ingested by a feed.\n",
            "- Added richer image descriptions generated by the GPT-4 Vision model. Now these provide more useful detail.\n",
            "- Added validation of extracted hyperlinks. Now we test the URIs and remove any inaccessible links during content enrichment.\n",
            "- Added deleteContents, deleteFeeds, and deleteConversations mutations for multi-deletion of contents, feeds or conversations.\n",
            "- Added deleteAllContents, deleteAllFeeds, and deleteAllConversations mutations for bulk, filtered deletion of entities. You can delete all your contents, feeds, or conversations in your project, or a filtered subset of those entities.\n",
            "- ‚ÑπÔ∏è Starter tier now has a higher content limit of 100K content items.\n",
            "- ‚ö° In the OpenAIImageExtractionProperties type, the detailMode field was renamed to detailLevel.\n",
            "- ‚ö° Each SummarizationStrategy object now accepts the specification which is used by the summarization, rather than being assigned at the preparation workflow stage.\n",
            "- ‚ö° addCollectionContents and removeCollectionContents mutations have been deprecated in favor of addContentsToCollections and removeContentsFromCollection mutations.\n",
            "\n",
            "### Bugs Fixed\n",
            "\n",
            "- GPLA-1846: Parse Markdown headings into mezzanine JSON\n",
            "- GPLA-1779: Not returning SAS token with mezzanine, master URIs\n",
            "- GPLA-1348: Summarize text content, not just file content\n",
            "- GPLA-1297: Not assigning content error message on preparation workflow failure\n",
            "\n",
            "PreviousJanuary 22: Support for Google and Microsoft email feeds, reingest content in-place, bug fixes\n",
            "NextDecember 10: Support for OpenAI GPT-4 Turbo, Llama 2 and Mistral models; query by example, bug fixes\n",
            "\n",
            "---\n",
            "Last updated8 months ago \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Ingested content [a0d556d6-0bbc-4df0-9577-bb621d9c6fc2]"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Mezzanine: https://graphlit202412121b7b448d.blob.core.windows.net/files/a0d556d6-0bbc-4df0-9577-bb621d9c6fc2/Mezzanine/page.json?sv=2025-01-05&se=2024-12-30T09%3A59%3A34Z&sr=c&sp=rl&sig=owRWJoJ3af3UPDIm9IYAnrH5uSy6%2BBWimVfnmZsHaVo%3D\n",
            "üêá\tApril 2024\n",
            "\n",
            "# April 23: Support for Python and TypeScript SDKs, latest OpenAI, Cohere & Groq models, bug fixes\n",
            "### New Features\n",
            "\n",
            "- üí° Graphlit now supports a native Python SDK, using Pydantic types. The Python SDK is code-generated from the current GraphQL schema, but does not require GraphQL knowledge. You can find the latest PyPi package here. The Streamlit sample applications have been updated to use the new Python SDK.\n",
            "- üí° Graphlit now supports a native Node.js SDK, using TypeScript types. The Node.js SDK is code-generated from the current GraphQL schema, but does not require GraphQL knowledge. You can find the latest NPM package here.\n",
            "- üí° Graphlit now supports the 2024-04-09 models in the OpenAI model service. GPT4_TURBO-128K will give the latest OpenAI GPT-4 model, following this model list. We have added the GPT4_TURBO_128K_2024_04_09 enum to specify the new model.\n",
            "- üí° Graphlit now supports LLaMA3 70b, LLaMA3 8b and Gemma 7b models in the Groq model service.\n",
            "- üí° Graphlit now supports the Command R and Command-R+ models in the Cohere model service.\n",
            "- Added support for Jina reranking, using the JINA reranking model service type in the reranking retrieval strategy.\n",
            "- Updated the Cohere reranking model to use the latest v3.0 model.\n",
            "- Increased the reliability of parsing LLM responses, in cases where they don't follow the JSON schema.\n",
            "- ‚ö° Cleaned up nullability of GraphQL parameters, so parameters better reflect if they are required or optional, or allow nulls.\n",
            "- ‚ö° Added missing deleteWorkflows and deleteAllCollections mutations.\n",
            "- ‚ö° Split out reranking model service type as RetrievalModelServiceTypes enum.\n",
            "\n",
            "### Bugs Fixed\n",
            "\n",
            "- GPLA-2114: Adding content to collections not syncing search index\n",
            "- GPLA-2511: Failing to render any conversation sources with section retrieval and text content\n",
            "\n",
            "PreviousMay 5: Support for Jina and Pongo rerankers, Microsoft Teams feed, new YouTube downloader, bug fixes\n",
            "NextApril 7: Support for Discord feeds, Cohere reranking, section-aware chunking and retrieval\n",
            "Last updated8 months ago \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Ingested content [9ded6f5c-a667-442d-8848-30d7a22e79e0]"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Mezzanine: https://graphlit202412121b7b448d.blob.core.windows.net/files/9ded6f5c-a667-442d-8848-30d7a22e79e0/Mezzanine/page.json?sv=2025-01-05&se=2024-12-30T09%3A59%3A34Z&sr=c&sp=rl&sig=owRWJoJ3af3UPDIm9IYAnrH5uSy6%2BBWimVfnmZsHaVo%3D\n",
            "üéÇ\tAugust 2023\n",
            "\n",
            "# August 17: Prepare for usage-based billing; append SAS tokens to URIs\n",
            "### New Features\n",
            "\n",
            "- ‚ÑπÔ∏è Behind the scenes, Graphlit is preparing to launch usage-based billing. This release put in place the infrastructure to track billable events. Organizations now have a Stripe customer associated with them, and Graphlit projects are auto-subscribed to a Free/Hobby pricing plan. In a future release, we will provide the ability to upgrade to a paid plan in the Graphlit Developer Portal. Also, we will provide visualization of usage, on granular basis, in the Portal.\n",
            "- üí° Content URIs now have Shared Access Signature (SAS) token appended, so they are accessible after query. For example, content.transcriptUri will now be able to be downloaded or used directly in an application (until the SAS token expires).\n",
            "- üß± Added more robustness for error handling and retries, especially for LLM APIs and audio transcription APIs.\n",
            "\n",
            "PreviousSeptember 4: Workflow configuration; support for Notion feeds; document OCR\n",
            "NextAugust 9: Support direct text, Markdown and HTML ingestion; new Specification LLM strategy\n",
            "Last updated1 year ago \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Ingested content [8443a72b-f798-4325-b0ac-b821d4e7dea8]"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Mezzanine: https://graphlit202412121b7b448d.blob.core.windows.net/files/8443a72b-f798-4325-b0ac-b821d4e7dea8/Mezzanine/page.json?sv=2025-01-05&se=2024-12-30T09%3A59%3A34Z&sr=c&sp=rl&sig=owRWJoJ3af3UPDIm9IYAnrH5uSy6%2BBWimVfnmZsHaVo%3D\n",
            "üêá\tApril 2024\n",
            "\n",
            "# April 7: Support for Discord feeds, Cohere reranking, section-aware chunking and retrieval\n",
            "### New Features\n",
            "\n",
            "- üí° Graphlit now supports Discord feeds. By connecting to a Discord channel and providing a bot token, you can ingest all Discord messages and file attachments.\n",
            "- üí° Graphlit now supports Cohere reranking after content retrieval in RAG pipeline. You can optionally use the Cohere rerank model to semantically rerank the semantic search results, before providing as context to the LLM.\n",
            "- Added support for section-aware text chunking and retrieval. Now, when using section-aware document preparation, such as Azure AI Document Intelligence, Graphlit will store the extracted text according to the semantic chunks (i.e. sections). The text for each section will be individually chunked and embedded into the vector index.\n",
            "- Added support for retrievalStrategy in Specification type. Graphlit now supports CHUNK, SECTION and CONTENT retrieval strategies. Chunk retrieval will use the search hit chunk, section retrieval will expand the search hit chunk to the containing section (or page, if not using section-aware preparation). Content retrieval will expand the search hit chunk to the text of the entire document.\n",
            "- Added support for rerankingStrategy in Specification type. You can now configure the reranking of content sources, using the Cohere reranking model, by assigning serviceType to COHERE. More reranking models are planned for the future.\n",
            "- Added isSynchronous flag to content ingestion mutations, such as ingestUri, so the mutation will wait for the content to complete the ingestion workflow (or error) before returning. This is useful for utilizing the API in a Jupyter notebook or Streamlit application, in a synchronous manner without polling.\n",
            "- Added includeAttachments flag to SlackFeedProperties. When enabled, Graphlit will automatically ingest any attachments within Slack messages.\n",
            "- ‚ö° Added ingestUri mutation to replace the now deprecated ingestPage and ingestFile mutations. We had seen confusion on when to use one vs the other, and now for any URI, whether it is a web page or hosted PDF, you can pass it to ingestUri, and we will infer the correct content ingestion workflow.\n",
            "- ‚ö° Removed includeSummaries from the ConversationStrategyInput type. This will re-added in the future as part of the retrieval strategy.\n",
            "- ‚ö° Deprecated enableExpandedRetrieval in ConversationStrategyInput type. This is now handled by setting strategyType to SECTION or CONTENT in the RetrievalStrategyInput type.\n",
            "- ‚ö° Moved contentLimit from ConversationStrategyInput type to RetrievalStrategyInput type. You can optionally assign the contentLimit to retrievalStrategy which limits the number of content sources leveraged in the LLM prompt context. (Default is 100.)\n",
            "\n",
            "### Bugs Fixed\n",
            "\n",
            "- GPLA-2469: Failed to ingest PDF hosted on GitHub\n",
            "- GPLA-2390: Claude 3 Haiku not adhering to JSON schema\n",
            "- GPLA-2474: Prompt rewriting should ignore formatting instructions in prompt\n",
            "- GPLA-2462: Missing line break after table rows\n",
            "- GPLA-2417: Not extracting images from PPTX correctly\n",
            "\n",
            "PreviousApril 23: Support for Python and TypeScript SDKs, latest OpenAI, Cohere & Groq models, bug fixes\n",
            "NextMarch 23: Support for Linear, GitHub Issues and Jira issue feeds, ingest files via Web feed sitemap\n",
            "Last updated8 months ago \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Ingested content [52613eca-1a5a-40ae-91b0-3d8243a55439]"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Mezzanine: https://graphlit202412121b7b448d.blob.core.windows.net/files/52613eca-1a5a-40ae-91b0-3d8243a55439/Mezzanine/page.json?sv=2025-01-05&se=2024-12-30T09%3A59%3A34Z&sr=c&sp=rl&sig=owRWJoJ3af3UPDIm9IYAnrH5uSy6%2BBWimVfnmZsHaVo%3D\n",
            "üéÑ\tDecember 2024\n",
            "\n",
            "# December 27: Support for LLM fallbacks, native Google Docs formats, website unblocking, bug fixes\n",
            "### New Features\n",
            "\n",
            "- üí° Graphlit now supports LLM fallbacks which can help protect your application from model provider downtime. By assigning the fallbacksproperty when creating your conversation, you can provide an optional list of LLM specifications to be used (in order). These fallback specifications will only be used when we failed to prompt the conversation via the main specification. Caveat, the RAG pipeline will only use the strategies provided in the main specification for prompt rewriting, content retrieval, etc. Content is not re-retrieved upon fallback - the formatted LLM prompt will be tried against each fallback specification in succession until one succeeds. (Colab Notebook Example)\n",
            "- üí° Graphlit now supports querying of all available models, through the new modelsquery in the API. This returns the model enum, model service type enum, description, and several other useful details about the models.\n",
            "- Graphlit now supports the ingestion of native Google Docs, Google Sheets and Google Slides documents from Google Drive feeds. These formats will be auto-exported to the corresponding Microsoft Office format (DOCX, XLSX, PPTX) prior to ingesting as content.\n",
            "- Graphlit now supports unblocking of websites, such as those using Cloudflare. You can set enableUnblockedCaptureto true on the PreparationWorkflowStageto enable unblocking - through our integration with Browserless.io headless browser service. This does incur an additional cost per page, compared to normal web page ingestion.\n",
            "- We have added support for assigning observations to contents ingested via feeds. By assigning observationsto the IngestionWorkflowStagein workflow object, you can assign Labels, Organizations, etc. without needing to use entity extraction.\n",
            "- We have added support for assigning observations when ingesting content via ingestUri, ingestText, etc. mutations. By passing observationsas a parameter, similar to `collections`, you can assign Labels, Organizations, etc. without needing to use entity extraction.\n",
            "- ‚ö° We have changed the response type of the publishContentsmutation to return PublishContentstype. This new PublishContentstype wraps the published Contentobject, and includes the new Detailsproperty of PublishingDetailstype. We have added an includeDetailsparameter to publishContentsmutation, which will fill in the Details property with a list of intermediate content summaries and the published text, among other publishing metrics.\n",
            "- ‚ö° We have changed the behavior of publishContentssuch that, if no content was retrieved for publishing, the mutation returns a null content object rather than returning an error.\n",
            "\n",
            "### Bugs Fixed\n",
            "\n",
            "- GPLA-3645: Table headers merged together on web scrape\n",
            "- GPLA-3634: Failed to extract pages from PDF with empty hyperlink text\n",
            "- GPLA-3633: Not handling empty observables properly for reranking\n",
            "\n",
            "NextDecember 22: Support for Dropbox, Box, Intercom and Zendesk feeds, OpenAI o1, Gemini 2.0, bug fixes\n",
            "Last updated23 hours ago \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from graphviz import Source\n",
        "from IPython.display import display, Markdown, Image, HTML\n",
        "\n",
        "# Prompt which gets run on each web page to summarize key points\n",
        "summary_prompt = \"\"\"\n",
        "You are an AI assistant that extracts the most important information from product changelog pages.\n",
        "\n",
        "You are being provided a changelog web page for one of many releases of the Graphlit Platform in 2024.\n",
        "\n",
        "Your task is to produce a concise summary that covers:\n",
        "\n",
        "New Features ‚Äì Briefly list or describe each new capability.\n",
        "Enhancements/Improvements ‚Äì Any notable improvements or changes.\n",
        "Bug Fixes ‚Äì Summaries of what was fixed and why it matters.\n",
        "Other Key Details ‚Äì Any version numbers, feature flags, or breaking changes.\n",
        "Dates - When a feature was released, include both the month and year\n",
        "Value - What this offers to developers.\n",
        "Keep it succinct, accurate, and organized. Use short sentences or bullet points so it‚Äôs easy to incorporate into a map/reduce pipeline. Omit any superfluous text.\n",
        "\n",
        "Output:\n",
        "A concise summary in bullet points highlighting the essential updates from the changelog.\n",
        "\"\"\"\n",
        "\n",
        "# Prompt which gets run against all summaries (in map/reduce manner) to generate timeline\n",
        "publish_prompt = \"\"\"\n",
        "Based on the provided changelog summaries, generate a tree-like timeline visualization for the year 2024 in Graphviz DOT format.\n",
        "Include all major releases, features, and events mentioned. Disregard any unrelated details.\n",
        "Only include changelogs from 2024.\n",
        "\n",
        "---\n",
        "\n",
        "**Diagram Structure:**\n",
        "- **Year Node:** Represent the year (`2024`) as the root node of the tree.\n",
        "- **Quarter Subgraphs (`cluster_Q1`, `cluster_Q2`, etc.):** Group all months of each quarter together.\n",
        "- **Month Nodes:** Each quarter contains its months (e.g., January, February, and March in Q1).\n",
        "- **Feature/Event Nodes:** Connect features/events directly to their corresponding months, with edges labeled by their release or event dates.\n",
        "- Draw hierarchical connections:\n",
        "  - Year ‚Üí Quarters (e.g., `2024 ‚Üí Q1, Q2, Q3, Q4`).\n",
        "  - Quarters ‚Üí Months (e.g., `Q1 ‚Üí January, February, March`).\n",
        "  - Months ‚Üí Features/Events, with labeled edges (e.g., `\"January\" ‚Üí \"Feature A\" [label=\"Jan 15\"];`).\n",
        "\n",
        "---\n",
        "\n",
        "**DOT Style Requirements:**\n",
        "- Use `rankdir=TB` to arrange the timeline from top to bottom (Year ‚Üí Quarters ‚Üí Months ‚Üí Features/Events).\n",
        "- Use the font ‚ÄúInter‚Äù for all elements.\n",
        "- All nodes should have `shape=rect`, `style=filled`, and consistent dimensions (`width=1.2, height=1.2`).\n",
        "- Subgraph clusters organize quarters and months hierarchically.\n",
        "- Label edges with descriptive phrases such as \"Launched on [Date]\" or \"Introduced on [Date].\"\n",
        "- Do not create nested subgraphs for features/events; connect them directly to their corresponding months.\n",
        "- End every DOT statement with a semicolon. Return only plain Graphviz DOT syntax.\n",
        "\n",
        "---\n",
        "\n",
        "**Example (for styling reference only):**\n",
        "\n",
        "digraph Timeline {\n",
        "    rankdir=TB; // Top-to-bottom layout\n",
        "\n",
        "    // Global styling\n",
        "    graph [bgcolor=\"#FFFFFF\", fontname=\"Inter\"];\n",
        "    node  [shape=rect, style=filled, fontname=\"Inter\", fontcolor=\"#333333\", width=1.2, height=1.2];\n",
        "    edge  [color=\"#777777\", arrowhead=normal, arrowsize=0.6, fontsize=10];\n",
        "\n",
        "    // Root node for the year\n",
        "    \"2024\" [fillcolor=\"#FFD700\"];\n",
        "\n",
        "    // Q1 Subgraph\n",
        "    subgraph cluster_Q1 {\n",
        "        label=\"Q1\";\n",
        "        style=\"filled\";\n",
        "        color=\"#F0F0F0\";\n",
        "\n",
        "        // Month nodes in Q1\n",
        "        \"January\" [fillcolor=\"#FFECB3\"];\n",
        "        \"February\" [fillcolor=\"#FFECB3\"];\n",
        "        \"March\" [fillcolor=\"#FFECB3\"];\n",
        "    }\n",
        "\n",
        "    // Connections\n",
        "    \"2024\" -> \"Q1\";\n",
        "    \"Q1\" -> \"January\";\n",
        "    \"Q1\" -> \"February\";\n",
        "    \"Q1\" -> \"March\";\n",
        "\n",
        "    // Feature connections\n",
        "    \"January\" -> \"Content publishing, LLM tools\" [label=\"Jan 18\"];\n",
        "    \"January\" -> \"Google/Microsoft email feeds\" [label=\"Jan 22\"];\n",
        "    \"February\" -> \"Semantic Alerts, OpenAI models\" [label=\"Feb 2\"];\n",
        "    \"February\" -> \"OneDrive/Google Drive feeds\" [label=\"Feb 21\"];\n",
        "}\n",
        "\n",
        "Don't wrap your response on markdown. No ```dot ... ``` blocks.\n",
        "\"\"\"\n",
        "\n",
        "if feed_id is not None:\n",
        "    summary_specification_id = await create_specification(enums.OpenAIModels.GPT4O_MINI_128K)\n",
        "\n",
        "    if summary_specification_id is not None:\n",
        "        print(f'Created summary specification [{summary_specification_id}]:')\n",
        "\n",
        "        publish_specification_id = await create_specification(enums.OpenAIModels.O1_200K) # enums.OpenAIModels.GPT4O_128K\n",
        "\n",
        "        if publish_specification_id is not None:\n",
        "            print(f'Created publish specification [{publish_specification_id}]:')\n",
        "\n",
        "            display(Markdown(f'### Publishing Contents...'))\n",
        "\n",
        "            published_content_id, details = await publish_contents(feed_id, summary_specification_id, publish_specification_id, summary_prompt, publish_prompt, publish_correlation_id)\n",
        "\n",
        "            if published_content_id is not None:\n",
        "                print(f'Completed publishing content [{published_content_id}].')\n",
        "\n",
        "                if details is not None:\n",
        "                    if details.summaries is not None and len(details.summaries) > 0:\n",
        "                        summaries = \"\\n\".join(details.summaries)\n",
        "                        print(f'Summaries: {summaries}')\n",
        "\n",
        "                # Need to reload content to get published markdown\n",
        "                published_content = await get_content(published_content_id)\n",
        "\n",
        "                if published_content is not None:\n",
        "                    display(Markdown(f'### Published [{published_content.name}]'))\n",
        "\n",
        "                    display(Markdown('### Timeline'))\n",
        "                    print(published_content.markdown)\n",
        "\n",
        "                    if published_content.markdown is not None:\n",
        "                        src = Source(published_content.markdown)\n",
        "                        src.render('timeline_dot', format='png')\n",
        "\n",
        "                        display(Image('timeline_dot.png', width=1400))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ieBzAp6Z2Zew",
        "outputId": "34fa081d-9e3a-40c5-cffe-3f8259fb1fa5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created summary specification [d8b437e2-3df2-4ba4-b985-2195ad4b724e]:\n",
            "Created publish specification [9b058a33-cb26-4748-bf28-172441e99ab8]:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Publishing Contents..."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed publishing content [4ca481d2-d06b-4549-948c-f87a1cb98629].\n",
            "Summaries: <source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/december-2024/december-9-support-for-website-mapping-web-page-screenshots-groq-llama-3.3-model-bug-fixes</name><title>December 9: Support for website mapping, web page screenshots, Groq Llama 3.3 model, bug fixes | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Support for website mapping using mapWebmutation to return URLs from sitemap.xml.\n",
            "  - Generation of web page screenshots with screenshotPagemutation, including optional workflows for image processing.\n",
            "  - Direct summarization of text with summarizeTextmutation, allowing various summarization strategies.\n",
            "  - Direct extraction of text with extractTextmutation, utilizing LLM tools for JSON responses.\n",
            "  - Support for Groq Llama 3.3 model (LLAMA_3_3_70B).\n",
            "  - Updated Cohere reranking to use rerank-v3.5 model by default.\n",
            "  - New flattenCitations field in ConversationStrategyInput to combine multiple citations.\n",
            "  - Required clientId and clientSecret fields added for Microsoft email, Teams, and OneDrive feeds.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Improved handling of citations in conversation prompts.\n",
            "  - Enhanced authentication requirements for Microsoft Graph API feeds.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issue with not finding sitemap at parent web path (GPLA-3492).\n",
            "  - Resolved mismatch handling for Deepgram model/language (GPLA-3500).\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: December 9, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced capabilities for web mapping, content ingestion, and improved API interactions.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            "\n",
            "<source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/january-2024/january-22-support-for-google-and-microsoft-email-feeds-reingest-content-in-place-bug-fixes</name><title>January 22: Support for Google and Microsoft email feeds, reingest content in-place, bug fixes | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Support for Google and Microsoft email feeds, allowing ingestion of past and new emails, creating an EMAIL content type. Attachments can be extracted and linked to their parent emails.\n",
            "  - Support for reingesting content in-place with optional id parameter for existing content objects, updating them from provided text or URI source, and restarting assigned workflows.\n",
            "  - Added restartAllContents mutation to restart workflows on all partially-ingested contents in a project.\n",
            "  - Added text field to ConversationCitation type to return relevant text from the content source with the citation.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Improved content ingestion capabilities with new features for email and content updates.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issue with not extracting links from HTML (GPLA-1313).\n",
            "  - Resolved problem of no text being extracted from shapes in PPTX files (GPLA-2030).\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: January 22, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced content ingestion options and improved workflow management, increasing efficiency in handling email and existing content updates.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            "\n",
            "<source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/</name><title>December 27: Support for LLM fallbacks, native Google Docs formats, website unblocking, bug fixes | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Support for LLM fallbacks to protect against model provider downtime.\n",
            "  - New API query for all available models, providing model details.\n",
            "  - Ingestion of native Google Docs, Sheets, and Slides from Google Drive, auto-exported to Microsoft formats.\n",
            "  - Website unblocking support via Browserless.io integration, with additional costs per page.\n",
            "  - Ability to assign observations (Labels, Organizations) to ingested content without entity extraction.\n",
            "  - Enhanced content publishing response type with new details and metrics.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Changed response type of publishContents mutation to include publishing details.\n",
            "  - Updated behavior of publishContents to return null for no content instead of an error.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed merged table headers on web scrape (GPLA-3645).\n",
            "  - Resolved issues with extracting pages from PDFs with empty hyperlink text (GPLA-3634).\n",
            "  - Improved handling of empty observables for reranking (GPLA-3633).\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: December 2024.\n",
            "  \n",
            "- Value:\n",
            "  - Offers developers improved content ingestion, enhanced model querying, and better error handling, increasing application reliability and functionality.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            "\n",
            "<source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/april-2024/april-23-support-for-python-and-typescript-sdks-latest-openai-cohere-and-groq-models-bug-fixes</name><title>April 23: Support for Python and TypeScript SDKs, latest OpenAI, Cohere & Groq models, bug fixes | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Native Python SDK introduced, using Pydantic types; code-generated from GraphQL schema, no GraphQL knowledge required.\n",
            "  - Native Node.js SDK introduced, using TypeScript types; code-generated from GraphQL schema, no GraphQL knowledge required.\n",
            "  - Support for OpenAI's 2024-04-09 models, including GPT4_TURBO-128K.\n",
            "  - Support for Groq models: LLaMA3 70b, LLaMA3 8b, and Gemma 7b.\n",
            "  - Support for Command R and Command-R+ models in Cohere model service.\n",
            "  - Added support for Jina reranking with the JINA reranking model service type.\n",
            "  - Updated Cohere reranking model to v3.0.\n",
            "  - Improved reliability of parsing LLM responses that don't follow JSON schema.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Cleaned up nullability of GraphQL parameters for better clarity on required, optional, or nullable parameters.\n",
            "  - Added missing deleteWorkflows and deleteAllCollections mutations.\n",
            "  - Split reranking model service type into RetrievalModelServiceTypes enum.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issue where adding content to collections did not sync with the search index (GPLA-2114).\n",
            "  - Resolved rendering issues with conversation sources in section retrieval and text content (GPLA-2511).\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: April 2024.\n",
            "  \n",
            "- Value:\n",
            "  - Offers developers enhanced SDKs for Python and Node.js, improved model support, and better handling of LLM responses, increasing development efficiency and capabilities.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            "\n",
            "<source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/january-2024/january-18-support-for-content-publishing-llm-tools-clip-image-embeddings-bug-fixes</name><title>January 18: Support for content publishing, LLM tools, CLIP image embeddings, bug fixes | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Support for content publishing, allowing documents, audio transcripts, and image descriptions to be summarized and repurposed.\n",
            "  - New mutation for publishing conversations as content, generating text or audio transcripts.\n",
            "  - Bulk summarization of contents with the summarizeContents mutation.\n",
            "  - LLM entity extraction using MODEL_TEXT service type, returning JSON-LD entities.\n",
            "  - Support for LLM tools (function calls) with OpenAI models, including extractContents mutation.\n",
            "  - Callback webhooks for LLM tools, enabling interaction with external services.\n",
            "  - Selection of Deepgram models for audio transcription with custom API key.\n",
            "  - CLIP image embeddings support for similar image search.\n",
            "  - Dynamic web page ingestion with automatic scrolling and screenshot capabilities.\n",
            "  - Table parsing for structured text extraction from documents.\n",
            "  - Reverse geocoding of lat/long locations in content metadata.\n",
            "  - Inclusion of assistant messages in conversation history for LLM prompts.\n",
            "  - New chunking algorithm for semantic text embeddings.\n",
            "  - Enhanced content metadata for text and image embeddings.\n",
            "  - Helper mutations for polling content ingestion completion.\n",
            "  - Richer image descriptions generated by GPT-4 Vision model.\n",
            "  - Validation of extracted hyperlinks to remove inaccessible links.\n",
            "  - Multi-deletion mutations for contents, feeds, and conversations.\n",
            "  - Bulk deletion mutations for filtered subsets of entities.\n",
            "  - Starter tier content limit increased to 100K items.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Renamed detailMode field to detailLevel in OpenAIImageExtractionProperties.\n",
            "  - SummarizationStrategy objects now accept specifications directly.\n",
            "  - Deprecated addCollectionContents and removeCollectionContents mutations in favor of new mutations.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issues with parsing Markdown headings, returning SAS tokens, summarizing text content, and assigning error messages on workflow failures.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: January 18, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced content management capabilities, improved integration with LLM tools, and better data handling for various content types.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            "\n",
            "<source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/august-2023/august-17-prepare-for-usage-based-billing-append-sas-tokens-to-uris</name><title>August 17: Prepare for usage-based billing; append SAS tokens to URIs | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Infrastructure for usage-based billing implemented; organizations now have a Stripe customer and auto-subscribed to a Free/Hobby pricing plan.\n",
            "  - Content URIs now include Shared Access Signature (SAS) tokens for direct access after queries.\n",
            "  \n",
            "- Enhancements/Improvements:\n",
            "  - Improved error handling and retries for LLM APIs and audio transcription APIs.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: August 17, 2023.\n",
            "  \n",
            "- Value:\n",
            "  - Prepares developers for future billing options and enhances content accessibility and API reliability.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            "\n",
            "<source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/july-2024/july-19-support-for-openai-gpt-4o-mini-byo-key-for-azure-ai-similarity-by-summary-bug-fixes</name><title>July 19: Support for OpenAI GPT-4o Mini, BYO-key for Azure AI, similarity by summary, bug fixes | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Support for OpenAI GPT-4o Mini model with 16k output tokens.\n",
            "  - 'Bring-your-own-key' support for Azure AI Document Intelligence models with custom endpoint and key property.\n",
            "  - Updated to Jina reranker v2 by default.\n",
            "  - Enhanced summarizeContents mutation to store summaries in content.\n",
            "  - Added relevance property for entity types, sorting results by relevance score.\n",
            "  - Ability to manually update summary and bullet properties in updateContent mutation.\n",
            "  - Offset property added to AtlassianJiraFeedProperties for proper timezone assignment.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Content similarity search now finds similar content by summary for better accuracy.\n",
            "  - Changed entity filter object behavior for paging; zero offset for vector/hybrid search.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Added retry on OpenAI API HTTP 524 error.\n",
            "  - Fixed paging issues with Jira feed.\n",
            "  - Improved search results for similar content in long documents.\n",
            "  - Resolved keyword search issues in long PDFs.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: July 19, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers improved model support, enhanced search capabilities, and better handling of content summaries and entity relevance.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            "\n",
            "<source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/december-2024/december-1-support-for-retrieval-only-rag-pipeline-bug-fixes</name><title>December 1: Support for retrieval-only RAG pipeline, bug fixes | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Support for formatting LLM-ready prompts with RAG pipeline using formatConversation and completeConversation mutations.\n",
            "  - Inline hyperlinks can now be included in extracted text from documents and web pages.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Improved support for LLM streaming by enabling direct calls to the LLM from applications.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issue GPLA-3466: Owner ID now accepts any non-whitespace string.\n",
            "  - Fixed issue GPLA-3458: Resolved problem with missing Person-to-Organization edges from entity extraction.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: December 1, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Enhancements provide developers with better integration for LLM interactions and improved text extraction capabilities.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            "\n",
            "<source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/august-2023/august-9-support-direct-text-markdown-and-html-ingestion-new-specification-llm-strategy</name><title>August 9: Support direct text, Markdown and HTML ingestion; new Specification LLM strategy | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Added ingestText mutation for direct ingestion of plain text, Markdown, and HTML without URL reading.\n",
            "  - Introduced Specification strategy property for customizing LLM context with Windowed and Summarized message histories.\n",
            "  - Implemented auto-summarization of extracted text and audio transcripts, with summaries available for Conversation prompt context.\n",
            "  - Added AzureOpenAIModels and OpenAIModels types to Specification model properties for easier LLM specification.\n",
            "  - Renamed ConversationMessage date property to timestamp.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Refined internal LLM prompts for clearer and more accurate results.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - No specific bug fixes mentioned.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: August 2023.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced content ingestion capabilities, improved LLM context customization, and better summarization features for more accurate responses.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            "\n",
            "<source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/december-2024/december-22-support-for-dropbox-box-intercom-and-zendesk-feeds-openai-o1-gemini-2.0-bug-fixes</name><title>December 22: Support for Dropbox, Box, Intercom and Zendesk feeds, OpenAI o1, Gemini 2.0, bug fixes | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Support for Dropbox feeds for file ingestion, requiring appKey, appSecret, redirectUri, and refreshToken.\n",
            "  - Support for Box feeds for file ingestion, requiring clientId, clientSecret, redirectUri, and refreshToken.\n",
            "  - Support for Intercom feeds for ingesting Articles and Tickets, requiring accessToken.\n",
            "  - Support for Zendesk feeds for ingesting Articles and Tickets, requiring accessToken and Zendesk subdomain.\n",
            "  - Support for OpenAI o1 model with enums O1_200k and O1_200k_20241217.\n",
            "  - Support for Gemini Flash 2.0 Experimental model with enum GEMINI_2_0_FLASH_EXPERIMENTAL.\n",
            "  - Support for Cohere R7B model with enum COMMAND_R7B_202412.\n",
            "  - Ability to return low-level details from RAG conversations with includeDetails parameter.\n",
            "  - Support for filtering observables by URI property.\n",
            "  - Ability to bypass semantic search in content retrieval with conversations.\n",
            "  - New createdInLast property for entity filters and inLast property for content filters.\n",
            "  - Support for Azure AI Document Intelligence models with enums US_PAY_STUB, US_BANK_STATEMENT, and US_BANK_CHECK.\n",
            "  - Support for Google Drive and OneDrive feeds to ingest specific files by file identifiers.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Removal of content items limit for projects upgraded to the Starter Tier after December 9, 2024.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issues with multitenant content assignment, HTML character decoding in emails, synchronous content ingestion, feed completion status, and HTTP error handling during uploads.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: December 22, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced integration capabilities with popular cloud services and improved content management features.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            "\n",
            "<source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/february-2024/february-21-support-for-onedrive-and-google-drive-feeds-extract-images-from-pdfs-bug-fixes</name><title>February 21: Support for OneDrive and Google Drive feeds, extract images from PDFs, bug fixes | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Support for OneDrive and Google Drive feeds, allowing ingestion of files from shared drives.\n",
            "  - Support for email backup files (EML, MSG) with automatic extraction of attachments.\n",
            "  - Automatic extraction of embedded images from PDF files, linking them as children of the parent PDF.\n",
            "  - Support for recursive Notion feeds with the isRecursive flag for crawling child pages and databases.\n",
            "  - Collections can now be assigned to content during ingestion without additional mutation calls.\n",
            "  - Introduction of CODE file type for various source code formats with optimized text splitting.\n",
            "  - Custom guidance can be injected during the RAG process via the Specification object.\n",
            "  - Added tenants field to Project object for listing tenant IDs used in entity creation.\n",
            "  - Email metadata is now indexed separately from document metadata.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Contents field in content objects replaced with children and parent fields for better structure.\n",
            "  - Removed enableImageAnalysis field; it is now enabled by default.\n",
            "  - Moved disableSmartCapture field to preparation workflow stage, enabled by default.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed PDF parsing error for ArXiV PDFs (GPLA-2099).\n",
            "  - Corrected LLM response issues with conversation history and no content sources (GPLA-2174).\n",
            "  - Resolved issue of ZIP package remaining in Indexed state after content workflow (GPLA-2199).\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: February 21, 2024.\n",
            "\n",
            "- Value:\n",
            "  - These updates enhance file ingestion capabilities, improve metadata handling, and streamline workflows for developers.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            "\n",
            "<source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/august-2023/august-3-new-data-model-for-observations-new-category-entity</name><title>August 3: New data model for Observations, new Category entity | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Revised data model for Observations, Occurrences, and observables (e.g., Person, Organization).\n",
            "  - Each observed entity now has one Observation and a list of occurrences (supports text, time, and image types).\n",
            "  - Added Category entity to GraphQL data model for PII categories (e.g., Phone Number, Credit Card Number).\n",
            "  - Introduced probability field for LLM's token probability.\n",
            "  - Added error field to feeds for error descriptions on failed reads.\n",
            "  - Support for reingestion of changed files from feeds, maintaining the same ID.\n",
            "  - Idempotent content ingestion from the same URI, returning existing content if unchanged.\n",
            "  - Changed GraphQL data type for SharePoint identifiers to ID.\n",
            "  - Performance optimization for entity extraction and observation creation.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Improved handling of content ingestion and updates.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed extraction issues from PDF and DOCX tables.\n",
            "  - Resolved issue where audio content from RSS feeds was not deleted upon feed deletion.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: August 2023.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers improved data handling, enhanced performance, and better error management.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            "\n",
            "<source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/december-2023/december-10-support-for-openai-gpt-4-turbo-llama-2-and-mistral-models-query-by-example-bug-fixes</name><title>December 10: Support for OpenAI GPT-4 Turbo, Llama 2 and Mistral models; query by example, bug fixes | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Support for OpenAI GPT-4 Turbo 128k model in Azure OpenAI and native OpenAI services.\n",
            "  - Support for Llama 2 (7b, 13b, 70b) and Mistral 7b models via Replicate.\n",
            "  - Support for Anthropic Claude 2.1 model.\n",
            "  - Support for OpenAI GPT-4 Vision model for image descriptions and text extraction.\n",
            "  - Query by example added for contents and conversations, utilizing vector embeddings.\n",
            "  - Vector search support for conversations queries.\n",
            "  - New promptSpecifications mutation for prompting multiple models.\n",
            "  - New promptStrategy field for preprocessing prompts.\n",
            "  - SuggestConversation mutation for auto-suggesting follow-up questions.\n",
            "  - New summarization types: CHAPTERS, QUESTIONS, and POSTS.\n",
            "  - Versioned model enums introduced (e.g., GPT4_0613).\n",
            "  - LookupContents query to retrieve multiple contents by ID.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Renamed headline field to headlines, returning an array of strings.\n",
            "  - Entity names limited to 1024 characters.\n",
            "  - BULLET_POINTS renamed to BULLETS in SummarizationTypes enum.\n",
            "  - ProjectStorage type fields renamed for clarity.\n",
            "  - Removed optimizeSearchConversation from Specification type, now handled by OPTIMIZE_SEARCH prompt strategy.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Ignored RSS.xml from web feed sitemap.\n",
            "  - Resolved issue with GPT-3.5 Turbo 16k LLM adding \"Citation #\" to responses.\n",
            "  - Fixed workflow application to link-crawled content.\n",
            "  - Corrected mismatched project storage total size.\n",
            "  - Added relevance threshold for semantic search.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: December 10, 2023.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced model support, improved querying capabilities, and streamlined prompt management, facilitating more efficient and effective application development.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            "\n",
            "<source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/february-2024/february-2-support-for-semantic-alerts-openai-0125-models-performance-enhancements-bug-fixes</name><title>February 2: Support for Semantic Alerts, OpenAI 0125 models, performance enhancements, bug fixes | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Support for Semantic Alerts for LLM summarization and content publishing on a periodic basis, useful for generating daily reports from various feeds.\n",
            "  - Support for OpenAI 0125 model versions for GPT-4 and GPT-3.5 Turbo, with plans to add Azure OpenAI support when available.\n",
            "  - Slack feeds now include a listing type field to specify PAST or NEW messages.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Performance enhancements to speed up content workflows for ingested content.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issues with collections not being added to text embedding index documents.\n",
            "  - Resolved handling of hallucinated citations.\n",
            "  - Addressed inheritance of collections from project-scope to tenant-scope.\n",
            "  - Implemented error handling for adding/removing contents to/from collections if content does not exist.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: February 2, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers improved content management capabilities, enhanced performance, and better error handling in workflows.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            "\n",
            "<source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/june-2024/june-21-support-for-the-claude-3.5-sonnet-model-knowledge-graph-semantic-search-and-bug-fixes</name><title>June 21: Support for the Claude 3.5 Sonnet model, knowledge graph semantic search, and bug fixes | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Support for the Anthropic Claude 3.5 Sonnet model (model enum: CLAUDE_3_5_SONNET).\n",
            "  - Semantic search for observable entities in the knowledge graph (Person, Organization, Place) with vector embeddings for enriched metadata.\n",
            "  - Google Drive and Google Email feed properties now require Google OAuth client ID, client secret, and refresh token for authentication.\n",
            "  - Introduction of a credits quota on the Free Tier; after 1000 credits, content ingestion stops until an upgrade to a paid tier.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Improved authentication process for Google APIs.\n",
            "  - Notification system for Free Tier users when credits, storage, or content quotas are reached.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issues with ingesting LinkedIn pages, handling zero-byte files, reading files from Azure blob feeds with spaces, and better handling of files with unknown or missing extensions.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: June 21, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Enhancements provide developers with improved model support, better search capabilities, and clearer usage limits on the Free Tier, facilitating more efficient development and integration.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            "\n",
            "<source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/may-2024/may-5-support-for-jina-and-pongo-rerankers-microsoft-teams-feed-new-youtube-downloader-bug-fixes</name><title>May 5: Support for Jina and Pongo rerankers, Microsoft Teams feed, new YouTube downloader, bug fixes | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Support for Jina and Pongo rerankers in the Specification object; options for COHERE, PONGO, and JINA as reranking service types.\n",
            "  - Microsoft Teams feeds support for reading messages from Teams channels.\n",
            "  - Rewritten YouTube downloader to accommodate changes in YouTube video player HTML.\n",
            "  - Improved handling of HTTP errors for URI validation and content downloading.\n",
            "  - Support for updating content metadata in updateContent mutation post-workflow.\n",
            "  - Added query_contents_graph functions to SDKs for knowledge graph visualization.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Citation indices changed from zero-based to one-based.\n",
            "  - Added isSynchronous flag for deleteAll and multiple delete mutations; default is asynchronous.\n",
            "  - Added missing count mutations (e.g., countAlerts, countFeeds).\n",
            "  - Renamed query_content_facets to query_contents_facets in Python SDK.\n",
            "  - Renamed queryContentFacets to queryContentsFacets in Node.js SDK.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed page relevance not being filled in all situations.\n",
            "  - Resolved issues with link extraction from PDFs using Azure AI Doc Intelligence.\n",
            "  - Addressed sporadic HTTP 500 errors from GraphQL API.\n",
            "  - Fixed re-ingestion failures for content deleted immediately after initial ingestion.\n",
            "  - Validated non-null parameters in mutations.\n",
            "  - Handled invalid JSON from LLMs with proper escaping or formatting.\n",
            "  - Fixed ingestion of encoded files with colons in names.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: May 5, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced flexibility with reranking options, improved integration with Microsoft Teams, and better error handling, leading to a more robust content management experience.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            "\n",
            "<source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/march-2024/march-10-support-for-claude-3-mistral-and-groq-models-usage-credits-telemetry-bug-fixes</name><title>March 10: Support for Claude 3, Mistral and Groq models, usage/credits telemetry, bug fixes | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Command-Line Interface (CLI) for direct access to the Graphlit Data API.\n",
            "  - Support for Groq Platform and models like Mixtral 8x7b.\n",
            "  - Support for Claude 3 Opus and Sonnet models.\n",
            "  - Support for Mistral La Plateforme and models such as Mistral Small, Medium, and Large.\n",
            "  - Support for Azure Document Intelligence v4, including new models for Credit Card, Marriage Certificate, and Mortgage documents.\n",
            "  - Detailed usage and credits telemetry via API.\n",
            "  - Correlated telemetry with optional correlationId for tracking credits and usage.\n",
            "  - Project webhook for tracking consumed credits.\n",
            "  - Image extraction during DOCX, XLSX, and PPTX document preparation.\n",
            "  - Text and markdown properties added to Content object for formatted output.\n",
            "  - More accurate extraction of tables into mezzanine JSON format.\n",
            "  - Throughput property added to Conversation messages for tokens/second throughput.\n",
            "  - Deprecated mezzanineUri property replaced by textUri and audioUri.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issues with table extraction from PPTX files and Markdown tables.\n",
            "  - Improved extraction of relative HTML links.\n",
            "  - Resolved failure to post Alerts to Slack with Markdown format.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: March 2024.\n",
            "  \n",
            "- Value:\n",
            "  - Enhancements provide developers with improved API access, better document processing capabilities, and more accurate data extraction, facilitating more efficient application development.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            "\n",
            "<source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/november-2024/november-4-support-for-anthropic-claude-3.5-haiku-bug-fixes</name><title>November 4: Support for Anthropic Claude 3.5 Haiku, bug fixes | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Support for Anthropic Haiku 3.5 model (model enum: CLAUDE_3_5_HAIKU_20241022).\n",
            "  - Automatic disabling of all feeds upon reaching the free tier quota; re-enable feeds with enableFeed mutation after upgrading to a paid tier.\n",
            "  - Addition of disableFallback flag in RetrievalStrategyInput type to control fallback behavior in conversations.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Improved control over conversation content retrieval with the disableFallback flag.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issue GPLA-3367: Text extraction from HTML button elements.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: November 4, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced model support, better feed management, and improved content retrieval control.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            "\n",
            "<source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/october-2023/october-15-support-for-anthropic-claude-models-slack-feeds-and-entity-enrichment</name><title>October 15: Support for Anthropic Claude models, Slack feeds and entity enrichment | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Support for Anthropic Claude and Anthropic Claude Instant large language models.\n",
            "  - Ingestion of Slack messages and linked file attachments from a Slack channel (requires a Slack bot).\n",
            "  - Entity enrichment for observed entities (Person, Organization, Place) using Diffbot, Wikipedia, and Crunchbase.\n",
            "  - Text extraction from images using Azure Image Analytics, making identified text searchable.\n",
            "  - Added embedFacets and embedCitations properties to conversation strategy in specification object.\n",
            "  - GraphQL mutations for multi-delete of entities (deleteCollections, deleteLabels, deleteConversations).\n",
            "  - GraphQL deleteAllConversations mutation to delete all conversations.\n",
            "  - Automatic addition of ingested content to collections during the ingestion stage of the workflow.\n",
            "  - Specification property added to preparation workflow stage for selecting LLM for text summarization.\n",
            "  - Expanded properties for observed entities for enhanced entity enrichment.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed unlimited conversation quota not assigned when upgrading project tier (GPLA-1520).\n",
            "  - Resolved issue with entity enrichment not firing event (GPLA-1285).\n",
            "  - Fixed web page remaining in ingested state when URL is not accessible (GPLA-1361).\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: October 15, 2023.\n",
            "\n",
            "- Value:\n",
            "  - Enhances capabilities for developers by integrating advanced LLMs, improving data ingestion from Slack, and enriching entity data, thus facilitating better data management and analysis.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            "\n",
            "<source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/september-2023/september-20-paid-subscription-plans-support-for-custom-observed-entities-and-azure-openai-gpt-4</name><title>September 20: Paid subscription plans; support for custom observed entities & Azure OpenAI GPT-4 | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Introduction of paid Hobby, Starter, and Growth subscription tiers, starting at $49/month, with usage fees of $0.10/credit.\n",
            "  - GraphQL mutations for creating, updating, and deleting observed entities (Person, Organization, Place, Product, Event, Label, Category).\n",
            "  - New observed entity types added: Repo (Git repo), Software.\n",
            "  - Added searchType and numberSimilar fields to Specification object for enhanced semantic search.\n",
            "  - Support for Azure OpenAI GPT-4 model.\n",
            "  - Project quota field introduced, with limits based on subscription tier.\n",
            "  - ContentLimit added to conversation strategy object for semantic search results.\n",
            "  - Improved relevance ranking for semantic search results.\n",
            "  - Updated Free tier quota: 1GB storage, 100 contents, 3 feeds, and 10 conversations.\n",
            "  - Implementation of Deepgram Nova-2 audio transcription model, offering 18% more accuracy and 5-40x faster processing.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Better semantic search results with new configuration options.\n",
            "  - Enhanced audio transcription accuracy and speed.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Resolved issue with extracting multiple text pages from DOCX files.\n",
            "  - Fixed semantic search failure when no content results were available.\n",
            "  - Addressed failure in generating text embeddings from user prompts.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: September 20, 2023.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers flexible subscription options, improved search capabilities, and enhanced audio transcription, facilitating better project management and user experience.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            "\n",
            "<source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/october-2024/october-9-support-for-github-repository-feeds-bug-fixes</name><title>October 9: Support for GitHub repository feeds, bug fixes | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Support for GitHub repository feeds, allowing ingestion of code files by providing the repository owner and name.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed missing row separator in table markdown formatting (GPLA-3262).\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: October 9, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Enhances integration with GitHub, improving developers' ability to work with code repositories.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            "\n",
            "<source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/november-2024/november-24-support-for-direct-llm-prompt-multi-turn-image-analysis-bug-fixes</name><title>November 24: Support for direct LLM prompt, multi-turn image analysis, bug fixes | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Support for multi-turn analysis of images using reviseImage and reviseEncodedImage mutations, allowing LLM prompts with image URIs or Base-64 encoded images.\n",
            "  - Direct prompting of an LLM with the prompt mutation, bypassing RAG content retrieval, with optional previous conversation messages.\n",
            "  - Support for Mistral Pixtral Large model (PIXTRAL_LARGE).\n",
            "  - Support for OpenAI GPT-4o (GPT4O_128K_20241120).\n",
            "  - Added Microsoft Entra ID clientId and clientSecret properties for SharePoint feed creation with user authentication.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Improved user authentication process for SharePoint feeds.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed filtering issue on desktop presentation when scraping web pages (GPLA-3438).\n",
            "  - Resolved JSON parsing error from extracted PDF pages (GPLA-3340).\n",
            "  - Corrected table formatting from Sonnet 3.5 (GPLA-3427).\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: November 2024.\n",
            "  \n",
            "- Value:\n",
            "  - Enhancements provide developers with advanced image analysis capabilities and improved LLM interactions, streamlining workflows and increasing efficiency.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            "\n",
            "<source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/september-2024/september-1-support-for-fhir-enrichment-latest-cohere-models-bug-fixes</name><title>September 1: Support for FHIR enrichment, latest Cohere models, bug fixes | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Support for entity enrichment from FHIR servers for medical-related entities.\n",
            "  - Added support for latest Cohere models (COMMAND_R_202408, COMMAND_R_PLUS_202408) with datestamped model enums for previous versions.\n",
            "  - Support for the latest Azure AI Document Intelligence v4.0 preview API (2024-07-31) now used by default.\n",
            "  - Renamed LinkReferenceType to LinkReference to align with data model standards.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Updated naming conventions for consistency with existing standards.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issue where LLM was adding source tags to the end of completed messages (GPLA-3120).\n",
            "  - Resolved failure to load sitemap on child page of website (GPLA-3133).\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: September 1, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Enhances data enrichment capabilities for healthcare applications and improves model support for developers.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            "\n",
            "<source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/october-2023/october-30-optimized-conversation-responses-added-observable-aliases-bug-fixes</name><title>October 30: Optimized conversation responses; added observable aliases; bug fixes | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Support for 'aliases' of observable names via the alternateNames property, allowing original and enriched names to be stored together.\n",
            "  - Workflows filter added to ContentCriteriaInput type for filtering content by workflow(s) in conversations.\n",
            "  - Optimized formatting of content sources and extracted text from Slack messages for improved conversation responses and knowledge retrieval.\n",
            "  - Updated text tokenizer for better token counting.\n",
            "  - Upgraded Azure Text Analytics to the latest preview API version.\n",
            "  - Authors in RSS feeds are now stored as observations of Person entities.\n",
            "  - Rate limiting added for Reddit feeds and Wikipedia enrichment.\n",
            "  - Support for reading Reddit post comments from Reddit feeds.\n",
            "  - EmbedFacets renamed to EnableFacets in conversation strategy.\n",
            "  - Removed extra content level in IngestionWorkflowStage type; if property is now of type IngestionContentFilter.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Better handling of long user prompts.\n",
            "  - Optimized token budget for more accurate prompt completion.\n",
            "  - Improved entity matching in Wikipedia entity enrichment.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Addressed issues with long user prompts for better handling.\n",
            "  - Enhanced token budget optimization for prompt completion accuracy.\n",
            "  - Improved accuracy in entity matching during Wikipedia enrichment.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: October 2023.\n",
            "\n",
            "- Value:\n",
            "  - These updates enhance the platform's capabilities for developers, improving conversation accuracy, content filtering, and data handling efficiency.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            "\n",
            "<source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/october-2024/october-22-support-for-latest-anthropic-sonnet-3.5-model-cohere-image-embeddings</name><title>October 22: Support for latest Anthropic Sonnet 3.5 model, Cohere image embeddings | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Support for the latest Anthropic Sonnet 3.5 model (released 10/22/2024).\n",
            "  - Added date-version model enums for Anthropic models: CLAUDE_3_5_SONNET_20240620, CLAUDE_3_5_SONNET_20241022, CLAUDE_3_HAIKU_20240307, CLAUDE_3_OPUS_20240229, CLAUDE_3_SONNET_20240229.\n",
            "  - Support for image embeddings using Cohere Embed 3.0 models.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Existing model enums will now target the latest released models as specified by Anthropic.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: October 22, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers access to the latest AI models and enhanced image embedding capabilities.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            "\n",
            "<source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/april-2024/april-7-support-for-discord-feeds-cohere-reranking-section-aware-chunking-and-retrieval</name><title>April 7: Support for Discord feeds, Cohere reranking, section-aware chunking and retrieval | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Support for Discord feeds: Ingest messages and file attachments from a Discord channel using a bot token.\n",
            "  - Cohere reranking: Optionally rerank semantic search results in the RAG pipeline using the Cohere rerank model.\n",
            "  - Section-aware text chunking and retrieval: Store extracted text according to semantic chunks for improved indexing.\n",
            "  - Retrieval strategies: Support for CHUNK, SECTION, and CONTENT retrieval strategies.\n",
            "  - Reranking strategy: Configure reranking of content sources using the Cohere model.\n",
            "  - Synchronous content ingestion: Added isSynchronous flag for content ingestion mutations to wait for completion.\n",
            "  - Slack attachments: Added includeAttachments flag to automatically ingest attachments in Slack messages.\n",
            "  - IngestUri mutation: Replaces deprecated ingestPage and ingestFile mutations for simplified content ingestion.\n",
            "  \n",
            "- Enhancements/Improvements:\n",
            "  - Removed includeSummaries from ConversationStrategyInput; will be re-added later.\n",
            "  - Deprecated enableExpandedRetrieval; now managed by strategyType in RetrievalStrategyInput.\n",
            "  - Moved contentLimit to RetrievalStrategyInput for better content source management.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issues with PDF ingestion from GitHub.\n",
            "  - Resolved JSON schema adherence for Claude 3 Haiku.\n",
            "  - Prompt rewriting now ignores formatting instructions.\n",
            "  - Corrected missing line breaks after table rows.\n",
            "  - Fixed image extraction from PPTX files.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: April 2024.\n",
            "  - Version updates include new flags and strategies for improved functionality.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced content ingestion capabilities, improved retrieval strategies, and better integration with messaging platforms.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            "\n",
            "<source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/july-2024/july-4-support-for-webhook-alerts-keywords-summarization-deepseek-128k-context-window-bug-fixes</name><title>July 4: Support for webhook Alerts, keywords summarization, Deepseek 128k context window, bug fixes | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Support for webhook Alerts, allowing HTTP POST notifications with published text results.\n",
            "  - Updated Deepseek models to support a 128k token context window.\n",
            "  - Added customSummary property to Content object for custom summaries.\n",
            "  - Introduced keywords summarization type, stored in the keywords property of Content object.\n",
            "  - Added slackChannels query to list Slack channels from the authenticated workspace.\n",
            "  - Changed credits query response to return a single ProjectCredits object covering all credit usage.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Improved response structure for credits query.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Resolved issue of processing entities taking longer than 30 minutes for large PDFs.\n",
            "  - Fixed early expiration of messages in the queue.\n",
            "  - Addressed incorrect feed read count after hitting the read limit.\n",
            "  - Handled Anthropic 'overloaded' API response.\n",
            "  - Assigned JIRA issue identifier to issue metadata.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: July 4, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Enhancements improve notification capabilities, model performance, and data handling, offering developers more efficient tools for managing alerts and processing content.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            "\n",
            "<source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/june-2024/june-9-support-for-deepseek-models-json-ld-webpage-parsing-performance-improvements-and-bug-fixes</name><title>June 9: Support for Deepseek models, JSON-LD webpage parsing, performance improvements and bug fixes | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Support for Deepseek LLMs for prompt completion (deepseek-chat and deepseek-coder models).\n",
            "  - Parsing of embedded JSON-LD from web pages, automatically injecting into the knowledge graph.\n",
            "  - Default model for entity extraction and image completions changed to OpenAI GPT-4o for improved performance and quality.\n",
            "  - Knowledge graph generation behavior changed to opt-in; requires setting generateGraph to True for response inclusion.\n",
            "  - Added thing property for observable entities to return associated JSON-LD metadata.\n",
            "  - Regex-based filtering for URI paths during feed ingestion and workflow filtering.\n",
            "  - Added observableLimit to configure the number of observed entities in GraphRAG context (default 1000).\n",
            "  - Customization of follow-up question generation via prompt in suggestConversation mutation.\n",
            "  - Updated suggestConversation to include past conversation message history.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Improved performance in knowledge graph retrieval and generation through better parallelization and batching.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Optimized retrieval performance of observed entities during GraphRAG.\n",
            "  - Fixed parsing exception caused by invalid user-provided URI.\n",
            "  - Removed requirement for tenant ID for Microsoft email or Teams.\n",
            "  - Resolved issue of not returning labels or categories from graph in API.\n",
            "  - Fixed failure to extract spreadsheet images.\n",
            "  - Addressed issue of email to/from not being added as observations.\n",
            "  - Corrected API returning 'audio' metadata from podcast HTML documents.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: June 9, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced capabilities for model support, improved performance, and better handling of data through new features and bug fixes.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            "\n",
            "<source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/november-2024/november-10-support-for-web-search-multi-turn-content-summarization-deepgram-language-detection</name><title>November 10: Support for web search, multi-turn content summarization, Deepgram language detection | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Support for web search via the searchWeb mutation, allowing selection of search service (Tavily or Exa.AI) and retrieval of relevant text and URLs.\n",
            "  - Multi-turn content summarization with the reviseContent mutation, enabling conversation with LLM for content revision.\n",
            "  - Configuration of Deepgram transcription language and default language detection enabled in DeepgramAudioPreparationPropertiesInput.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Added requireTool option to promptConversation mutation for controlling tool calling.\n",
            "  - Reduced credits quota on Free tier from 1000 to 100 for accounts created after Nov 8, 2024; unlimited feeds now available on Hobby Tier.\n",
            "  - Graphlit Data API now returns HTTP 402 (Payment Required) when exceeding Free tier credits quota.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - No specific bug fixes mentioned.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: November 10, 2024.\n",
            "\n",
            "- Value:\n",
            "  - These updates enhance the platform's capabilities for developers, providing more flexible search and summarization tools, improved language detection, and clearer usage policies regarding credits.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            "\n",
            "<source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/september-2024/september-26-support-for-google-ai-and-cerebras-models-and-latest-groq-models</name><title>September 26: Support for Google AI and Cerebras models, and latest Groq models | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Support for Cerebras model service: LLAMA_3_1_70B and LLAMA_3_1_8B models.\n",
            "  - Support for Google AI model service: GEMINI_1_5_PRO and GEMINI_1_5_FLASH models.\n",
            "  - Support for latest Groq Llama 3.2 preview models: LLAMA_3_2_1B_PREVIEW, LLAMA_3_2_3B_PREVIEW, LLAMA_3_2_11B_TEXT_PREVIEW, LLAMA_3_2_90B_TEXT_PREVIEW, and multimodal model LLAMA_3_2_11B_VISION_PREVIEW.\n",
            "  - New specification parameter added to promptConversation mutation for initial or updated conversation specifications.\n",
            "  \n",
            "- Enhancements/Improvements:\n",
            "  - Changed retrieval behavior of promptConversation mutation to fallback to relevant content from the conversation or last ingested content if no relevant content is found.\n",
            "  - Renamed Groq model enum from LLAVA_1_5_7B to LLAVA_1_5_7B_PREVIEW.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issue with not sending custom instructions/guidance with extraction prompt (GPLA-3083).\n",
            "  - Resolved filtering Persons by email not working (GPLA-3146).\n",
            "  - Addressed issue of not failing on deprecated OpenAI model (GPLA-3171).\n",
            "  - Fixed summarization not using revision strategy (GPLA-3158).\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: September 26, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced model support and improved conversation handling, increasing the efficiency and effectiveness of interactions with the platform.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            "\n",
            "<source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/september-2023/september-4-workflow-configuration-support-for-notion-feeds-document-ocr</name><title>September 4: Workflow configuration; support for Notion feeds; document OCR | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Added Workflow entity for configuring content workflow stages.\n",
            "  - Support for Notion feeds to ingest files from Notion pages or databases.\n",
            "  - API-created Observation entities for custom observations on Content.\n",
            "  - Support for Azure AI Document Intelligence for PDF preparation using OCR.\n",
            "  - Summarization strategies for content into paragraphs, bullet points, or headlines.\n",
            "  - Ability to assign default Workflow and Specification to projects.\n",
            "  - Added support for more link types during link crawling (e.g., Discord, Airtable, TypeForm).\n",
            "  - Free/Hobby plan now includes a 5GB storage quota.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Actions moved into Workflow entity.\n",
            "  - Link enrichment for Feeds moved to Workflow enrichment stage, renamed to link crawling.\n",
            "  - ExcludeContentDomain property renamed to IncludeContentDomain.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issue with content ingestion failure due to backslash in name.\n",
            "  - Resolved failure to ingest RSS posts with enclosure URI but no post URI.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: September 4, 2023.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced workflow configuration, improved content ingestion from Notion, and advanced document processing capabilities.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            "\n",
            "<source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/october-2024/october-31-support-for-simulated-tool-calling-bug-fixes</name><title>October 31: Support for simulated tool calling, bug fixes | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Support for simulated tool calling for LLMs like OpenAI o1-preview and o1-mini.\n",
            "  - Tool schema formatted into LLM prompt context; tool responses parsed from JSON.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Lowered vector and hybrid thresholds for semantic search based on customer feedback, allowing more low-relevance content in results.\n",
            "  - Reranking feature for sorting search results by relevance.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issue GPLA-3357: now extracts all images from PDF and filters out single-color images.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: October 2024.\n",
            "\n",
            "- Value:\n",
            "  - Enhancements improve search result relevance and broaden content inclusion, benefiting developers using the platform.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            "\n",
            "<source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/september-2024/september-3-support-for-web-search-feeds-model-deprecations</name><title>September 3: Support for web search feeds, model deprecations | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Support for web search feeds using Tavily and Exa.AI APIs.\n",
            "  - Ability to choose SEARCH feed type and assign search text property for ingesting web pages from search results.\n",
            "  - Option to select search service via serviceType property, defaulting to Tavily API.\n",
            "  \n",
            "- Enhancements/Improvements:\n",
            "  - Deprecation of several OpenAI models due to reduced future support, including various versions of GPT-3.5 and GPT-4. Recommended alternatives are GPT-4o and GPT-4o Mini.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issue GPLA-2523: Ingestion from the same feed URI multiple times and waiting on isFeedDone.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: September 3, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced capabilities for web search integration and guidance on model usage with improved support for newer models.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            "\n",
            "<source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/august-2024/august-11-support-for-azure-ai-document-intelligence-by-default-language-aware-summaries</name><title>August 11: Support for Azure AI Document Intelligence by default, language-aware summaries | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Support for language-aware summaries in LLM-based document extraction, aligning summaries with the source text language.\n",
            "  - Support for language-aware entity descriptions in LLM-based entity extraction, matching descriptions to the source text language.\n",
            "  - Default document preparation method changed to Azure AI Document Intelligence for improved fidelity in complex PDFs and better table extraction.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Increased credit usage per page for PDF, DOCX, and PPTX documents due to the switch to Azure AI Document Intelligence, but with significantly higher quality in extracted documents for RAG pipelines.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issue GPLA-3070 where slide count was not assigned to metadata for PPTX files.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: August 11, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced document extraction capabilities with improved accuracy and language support, facilitating better integration in applications.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            "\n",
            "<source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/august-2024/august-20-support-for-medical-entities-anthropic-prompt-caching-bug-fixes</name><title>August 20: Support for medical entities, Anthropic prompt caching, bug fixes | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Support for extraction of medical-related entities: MedicalStudy, MedicalCondition, MedicalGuideline, MedicalDrug, MedicalDrugClass, MedicalIndication, MedicalContraindication, MedicalTest, MedicalDevice, MedicalTherapy, and MedicalProcedure.\n",
            "  - Medical-related entities supported in GraphRAG and via API for queries and mutations.\n",
            "  - Added support for Anthropic prompt caching, improving performance and reducing token costs when using Anthropic Sonnet 3.5 or Haiku 3.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Improved entity extraction and LLM document preparation through caching.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed default search type to VECTOR for entity similarity filter (GPLA-3104).\n",
            "  - Resolved issue where empty PDFs failed entity extraction (GPLA-3112).\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: August 20, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Enhancements provide developers with improved capabilities for handling medical data and increased efficiency in using Anthropic models.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            "\n",
            "<source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/july-2023/july-15-support-for-sharepoint-feeds-new-conversation-features</name><title>July 15: Support for SharePoint feeds, new Conversation features | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Support for SharePoint feeds to ingest files from SharePoint document libraries.\n",
            "  - PII detection during entity extraction from text documents and audio transcripts, automatically labeling detected PII.\n",
            "  - Support for custom OpenAI API keys and Azure OpenAI deployments in Specifications.\n",
            "  - GraphQL query for SharePoint consent URI for registered Azure AD applications.\n",
            "  - Improved handling of web sitemap indexes to load linked sitemaps.\n",
            "  - New GraphQL mutations for managing conversations and collections.\n",
            "  - Timestamps added to Conversation messages.\n",
            "  - Enhanced content search configuration with searchType and queryType options.\n",
            "  - Better parsing of iTunes podcast metadata.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Renamed listingLimit to readLimit and topK to numberSimilar for clarity.\n",
            "  - Split GraphQL feed properties into azureBlob and azureFile.\n",
            "  - Split GraphQL specification properties into openAI and azureOpenAI.\n",
            "  - Removed count fields on query results, replaced with explicit count queries for better search and filtering.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed Reddit readLimit issue to ensure specified limits are applied.\n",
            "  - Improved performance of entity extraction and observation creation for large PDFs (4x speed improvement).\n",
            "  - Corrected error handling for rendition generation in content workflows.\n",
            "  - Enhanced loading speed for large web sitemaps, now processing 150K+ entries quickly.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: July 15, 2023.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced capabilities for data ingestion, improved performance, and better management of content and conversations.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            "\n",
            "<source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/august-2024/august-8-support-for-llm-based-document-extraction-.net-sdk-bug-fixes</name><title>August 8: Support for LLM-based document extraction, .NET SDK, bug fixes | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Support for LLM-based document preparation using models like OpenAI GPT-4o and Anthropic Sonnet 3.5 via MODEL_DOCUMENT service.\n",
            "  - Introduction of an open source .NET SDK for .NET 6 and .NET 8, available on Nuget.org with code samples on GitHub.\n",
            "  - Added identifier property to Content object for mapping to external database identifiers, aiding in content filtering.\n",
            "  - Support for Claude 3 vision models for image-based entity extraction using MODEL_IMAGE service.\n",
            "  - Context augmentation in conversations through augmentedFilter property, allowing injection of domain knowledge into LLM prompts.\n",
            "  - Support for the latest OpenAI GPT-4o snapshot (GPT4O_128K_20240806).\n",
            "  - Reranking of related entities for LLM prompt context preparation in GraphRAG.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Changed duration field type in AudioMetadata and VideoMetadata from string to TimeSpan for consistency in API data model.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issue GPLA-2884 to support retry on HTTP 529 (Overloaded) error from Anthropic API.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: August 8, 2024.\n",
            "\n",
            "- Value:\n",
            "  - These updates enhance document extraction capabilities, improve SDK accessibility for developers, and streamline content management and entity extraction processes.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            "\n",
            "<source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/july-2024/july-25-support-for-mistral-large-2-and-nemo-groq-llama-3.1-models-bug-fixes</name><title>July 25: Support for Mistral Large 2 & Nemo, Groq Llama 3.1 models, bug fixes | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Support for Mistral Large 2 and Mistral Nemo models; existing MISTRAL_LARGE model enum updated.\n",
            "  - Support for Llama 3.1 models (8b, 70b, 405b) on Groq, with rate limits per Groq's platform.\n",
            "  - Added revision strategy for data extraction specifications, allowing LLM to revise previous responses.\n",
            "  - Version property added for AzureDocumentPreparationProperties to assign API version for Azure AI Document Intelligence; default is v4.0 (Preview), can override to V2023_10_31 for v3.1 (GA) API version.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issue with hyperlinks not being extracted from Office documents (GPLA-2988).\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: July 25, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Enhancements improve model support and data extraction capabilities, offering developers more flexibility and better results with Azure AI.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            "\n",
            "<source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/july-2024/july-28-support-for-indexing-workflow-stage-azure-ai-language-detection-bug-fixes</name><title>July 28: Support for indexing workflow stage, Azure AI language detection, bug fixes | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Added indexing workflow stage for configuring indexing services to infer metadata from content.\n",
            "  - Introduced AZURE_AI_LANGUAGE content indexing service for inferring language from extracted text or transcripts.\n",
            "  - Supported language content metadata returning a list of languages in ISO 639-1 format.\n",
            "  - Added MODEL_IMAGE extraction service for integration with custom vision models using a personal API key.\n",
            "  \n",
            "- Enhancements/Improvements:\n",
            "  - Deprecated OPENAI_IMAGE service type; developers should now use the LLM image service.\n",
            "  - Removed language field from AudioMetadata type, replaced with new LanguageMetadata type.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issue GPLA-2987 where Azure Doc Intelligence did not extract hyperlinks from text.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: July 28, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced capabilities for content indexing, language detection, and image extraction, improving overall functionality and flexibility.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            "\n",
            "<source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/march-2024/march-23-support-for-linear-github-issues-and-jira-issue-feeds-ingest-files-via-web-feed-sitemap</name><title>March 23: Support for Linear, GitHub Issues and Jira issue feeds, ingest files via Web feed sitemap | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Support for Linear, GitHub Issues, and Atlassian Jira feeds for ingesting issues as searchable content items.\n",
            "  - Introduction of ISSUE content type with metadata including title, authors, commenters, status, type, project, and team.\n",
            "  - Default feed read limit set to 100 content items, customizable with no upper bounds; one-shot feeds must complete within 15 minutes.\n",
            "  - Ingestion of files referenced in a Web sitemap is now supported, allowing non-HTML pages to be included.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Improved handling of files in Web sitemaps, enabling ingestion of various file types.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issue GPLA-2374 related to failing to ingest MP4 files with large XMP metadata.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: March 2024.\n",
            "  \n",
            "- Value:\n",
            "  - Enhances the platform's capability to integrate with popular issue-tracking services, improving content searchability and usability for developers.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            "\n",
            "<source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/may-2024/may-15-support-for-graphrag-openai-gpt-4o-model-performance-improvements-and-bug-fixes</name><title>May 15: Support for GraphRAG, OpenAI GPT-4o model, performance improvements and bug fixes | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Support for GraphRAG, allowing extracted entities in the knowledge graph to enhance RAG conversations.\n",
            "  - LLM revisions in RAG conversations, improving output by 35% with higher quality responses.\n",
            "  - Integration of the OpenAI GPT-4o model for RAG conversations.\n",
            "  - Default model for Conversations changed to OpenAI GPT-4o for improved performance.\n",
            "  - Added graph visualization in promptConversation responses to show relationships between entities.\n",
            "  - Expanded Wikipedia data to include long descriptions of entities.\n",
            "  - New API queries: getSharePointLibraries, getSharePointFolders, getOneDriveFolders for easier storage service enumeration.\n",
            "  - New API queries: getTeams and getTeamsChannels for Microsoft Teams workspace enumeration.\n",
            "  - Added extractedCount to limit the number of extracted entities per type.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Performance improvements in entity extraction, cloud storage access, and RAG context rendering.\n",
            "  - Optimized LLM entity extraction to identify more properties and relationships.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issues with text extraction from HTML in RSS posts.\n",
            "  - Resolved limit filter returning incomplete results.\n",
            "  - Corrected structured text extraction from JSON/XML formats.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: May 15, 2024.\n",
            "  - Default model updated to OpenAI GPT-4o.\n",
            "\n",
            "- Value:\n",
            "  - Enhancements provide developers with improved performance, better quality responses, and more efficient data extraction capabilities.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            "\n",
            "<source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/october-2024/october-21-support-openai-cohere-jina-mistral-voyage-and-google-ai-embedding-models</name><title>October 21: Support OpenAI, Cohere, Jina, Mistral, Voyage and Google AI embedding models | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Support for configuration of image and text embedding models at the Project level.\n",
            "  - Support for OpenAI Embedding-3-Small and Embedding-3-Large, Cohere Embed 3.0, Jina Embed 3.0, Mistral Embed, and Voyage 2.0 and 3.0 text embedding models.\n",
            "  - Support for Jina CLIP image embeddings for image search.\n",
            "  - Introduction of chunkTokenLimit property in Specifications for token count per embedded text chunk.\n",
            "  - Support for Voyage reranking model.\n",
            "  - New ingestTextBatch mutation for asynchronous ingestion of text and name pairs.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Moved chunkTokenLimit property from Workflow storage embeddings strategy to Specification object; Workflow storage property deprecated.\n",
            "  - Deprecated openAIImage property from Workflow entity extraction properties; use modelImage property instead.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Updating text embedding models at the project level will affect semantic searchability of content, conversations, or observed entities. Requires deletion and reingestion of content for new model compatibility.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: October 2024.\n",
            "  - Breaking change: Text embeddings are not compatible across models.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced flexibility in embedding model configuration and improved ingestion capabilities, while ensuring compatibility and searchability of content.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            "\n",
            "<source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/march-2024/march-13-support-for-claude-3-haiku-model-direct-ingestion-of-base64-encoded-files</name><title>March 13: Support for Claude 3 Haiku model, direct ingestion of Base64 encoded files | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Support for Claude 3 Haiku model.\n",
            "  - Direct ingestion of Base64 encoded files via the ingestEncodedFile mutation, allowing the input of a Base64 string and MIME type.\n",
            "  - Added modelService and model properties to ConversationMessage type for LLM completion details.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - None specified.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - None specified.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: March 13, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced model support and improved file ingestion capabilities, streamlining the integration process.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            "\n",
            "<source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/october-2024/october-3-support-tool-calling-ingestbatch-mutation-gemini-flash-1.5-8b-bug-fixes</name><title>October 3: Support tool calling, ingestBatch mutation, Gemini Flash 1.5 8b, bug fixes | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Support for ingestBatch mutation to asynchronously ingest an array of URIs into content objects.\n",
            "  - Introduction of continueConversation mutation for handling tool responses and promptConversation now accepts an array of tool definitions.\n",
            "  - Tool calling support added for OpenAI, Mistral, Deepseek, Groq, and Cerebras model services; support for Anthropic, Google Gemini, and Cohere coming later.\n",
            "  - Prefilled user and assistant messages supported with createConversation mutation, allowing an array of messages in user/assistant pairs.\n",
            "  - Added support for Google Gemini Flash 1.5 8b model.\n",
            "  - Deprecation of tools property in the Specification object; tools to be sent directly to extractContents and promptConversation mutations.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Improved handling of tool calling and conversation management.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issue where models were incorrectly required on update specification call (GPLA-3207).\n",
            "  - Resolved issue of sending system prompt with OpenAI o1 models (GPLA-3220).\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: October 2024.\n",
            "  - Deprecation notice for tools property in the Specification object.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced capabilities for managing conversations and tool interactions, improving integration with various model services.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            "\n",
            "<source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/september-2023/september-24-support-for-youtube-feeds-added-documentation-bug-fixes</name><title>September 24: Support for YouTube feeds; added documentation; bug fixes | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Support for YouTube feeds, allowing ingestion of YouTube videos, playlists, or channels (currently supports audio ingestion and transcription).\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Added documentation for observable entities mutations and queries (Label, Category, Person, Organization, Place, Event, Product, Repo, Software).\n",
            "  - Added documentation for using custom Azure OpenAI and OpenAI models with Specifications.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed LLM prompt formatting issue that exceeded token budget with long user prompts (GPLA-1459).\n",
            "  - Resolved issue with ingesting PDF from URL when filename in Content-Disposition header contained a backslash (GPLA-1445).\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: September 2023.\n",
            "\n",
            "- Value:\n",
            "  - Enhances developers' ability to integrate YouTube content and improves documentation for better usage of observable entities and custom models.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            "\n",
            "<source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/october-2024/october-7-support-for-anthropic-and-gemini-tool-calling</name><title>October 7: Support for Anthropic and Gemini tool calling | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Support for tool calling with Anthropic and Google Gemini models.\n",
            "  - Removal of the uri property for tools from ToolDefinitionInput, eliminating support for inline webhook tools. External tools can now be defined for sync or async data access.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Improved flexibility in defining external tools for tool calls.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - No specific bug fixes mentioned.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: October 7, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced capabilities for integrating external tools and improved data access options.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            "\n",
            "<source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/november-2024/november-16-support-for-image-description-multi-turn-text-summarization</name><title>November 16: Support for image description, multi-turn text summarization | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Multi-turn summarization of text with the reviseText mutation, allowing for LLM prompts and text revisions.\n",
            "  - Image descriptions supported via describeImage mutation (URI input) and describeEncodedImage mutation (Base-64 encoded image), utilizing vision LLMs.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Optional specifications for selecting vision LLMs; defaults to OpenAI GPT-4o if not specified.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - No specific bug fixes mentioned in this release.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: November 16, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced capabilities for text summarization and image description without prior image ingestion, improving interaction with LLMs.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            "\n",
            "<source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/september-2024/september-30-support-for-azure-ai-inference-models-mistral-pixtral-and-latest-google-gemini-models</name><title>September 30: Support for Azure AI Inference models, Mistral Pixtral and latest Google Gemini models | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Support for Azure AI Model Inference API, enabling serverless hosting for models like Meta Llama 3.2 and Cohere Command-R.\n",
            "  - Added support for the multimodal Mistral Pixtral model (PIXTRAL_12B_2409).\n",
            "  - Introduced versioned model enums for Google Gemini: GEMINI_1_5_FLASH_001, GEMINI_1_5_FLASH_002, GEMINI_1_5_PRO_001, GEMINI_1_5_PRO_002.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Enhanced model accessibility through versioned enums for Google Gemini.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - No specific bug fixes mentioned in this release.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: September 30, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers expanded model options and improved integration with Azure AI services, enhancing flexibility in model deployment.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Published [Published Summary]"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Timeline"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "digraph Timeline {\n",
            "    rankdir=TB; // Top-to-bottom layout\n",
            "    \n",
            "    // Global styling\n",
            "    graph [bgcolor=\"#FFFFFF\", fontname=\"Inter\"];\n",
            "    node  [shape=rect, style=filled, fontname=\"Inter\", fontcolor=\"#333333\", width=1.2, height=1.2];\n",
            "    edge  [color=\"#777777\", arrowhead=normal, arrowsize=0.6, fontsize=10];\n",
            "\n",
            "    // Root node for the year\n",
            "    \"2024\" [fillcolor=\"#FFD700\"];\n",
            "\n",
            "    // Q1 Subgraph\n",
            "    subgraph cluster_Q1 {\n",
            "        label=\"Q1\";\n",
            "        style=\"filled\";\n",
            "        color=\"#F0F0F0\";\n",
            "\n",
            "        \"January\"  [fillcolor=\"#FFECB3\"];\n",
            "        \"February\" [fillcolor=\"#FFECB3\"];\n",
            "        \"March\"    [fillcolor=\"#FFECB3\"];\n",
            "    }\n",
            "\n",
            "    // Q2 Subgraph\n",
            "    subgraph cluster_Q2 {\n",
            "        label=\"Q2\";\n",
            "        style=\"filled\";\n",
            "        color=\"#F0F0F0\";\n",
            "\n",
            "        \"April\" [fillcolor=\"#C8E6C9\"];\n",
            "        \"May\"   [fillcolor=\"#C8E6C9\"];\n",
            "        \"June\"  [fillcolor=\"#C8E6C9\"];\n",
            "    }\n",
            "\n",
            "    // Q3 Subgraph\n",
            "    subgraph cluster_Q3 {\n",
            "        label=\"Q3\";\n",
            "        style=\"filled\";\n",
            "        color=\"#F0F0F0\";\n",
            "\n",
            "        \"July\"    [fillcolor=\"#BBDEFB\"];\n",
            "        \"August\"  [fillcolor=\"#BBDEFB\"];\n",
            "        \"September\" [fillcolor=\"#BBDEFB\"];\n",
            "    }\n",
            "\n",
            "    // Q4 Subgraph\n",
            "    subgraph cluster_Q4 {\n",
            "        label=\"Q4\";\n",
            "        style=\"filled\";\n",
            "        color=\"#F0F0F0\";\n",
            "\n",
            "        \"October\"  [fillcolor=\"#FFE0B2\"];\n",
            "        \"November\" [fillcolor=\"#FFE0B2\"];\n",
            "        \"December\" [fillcolor=\"#FFE0B2\"];\n",
            "    }\n",
            "\n",
            "    // Connections from Year to Quarters\n",
            "    \"2024\" -> \"Q1\";\n",
            "    \"2024\" -> \"Q2\";\n",
            "    \"2024\" -> \"Q3\";\n",
            "    \"2024\" -> \"Q4\";\n",
            "\n",
            "    // Connections from Quarters to Months\n",
            "    \"Q1\" -> \"January\";\n",
            "    \"Q1\" -> \"February\";\n",
            "    \"Q1\" -> \"March\";\n",
            "\n",
            "    \"Q2\" -> \"April\";\n",
            "    \"Q2\" -> \"May\";\n",
            "    \"Q2\" -> \"June\";\n",
            "\n",
            "    \"Q3\" -> \"July\";\n",
            "    \"Q3\" -> \"August\";\n",
            "    \"Q3\" -> \"September\";\n",
            "\n",
            "    \"Q4\" -> \"October\";\n",
            "    \"Q4\" -> \"November\";\n",
            "    \"Q4\" -> \"December\";\n",
            "\n",
            "    // January 2024\n",
            "    \"January\" -> \"Content publishing, LLM tools\" [label=\"Jan 18\"];\n",
            "    \"January\" -> \"Google/Microsoft email feeds\"  [label=\"Jan 22\"];\n",
            "\n",
            "    // February 2024\n",
            "    \"February\" -> \"Semantic Alerts, OpenAI 0125 models\" [label=\"Feb 2\"];\n",
            "    \"February\" -> \"OneDrive and Google Drive feeds\"     [label=\"Feb 21\"];\n",
            "\n",
            "    // March 2024\n",
            "    \"March\" -> \"Claude 3, Mistral, Groq models\"                 [label=\"Mar 10\"];\n",
            "    \"March\" -> \"Claude 3 Haiku, base64 ingestion\"               [label=\"Mar 13\"];\n",
            "    \"March\" -> \"Linear, GitHub Issues, Jira feeds\"              [label=\"Mar 23\"];\n",
            "\n",
            "    // April 2024\n",
            "    \"April\" -> \"Discord feeds, section chunking\"       [label=\"Apr 7\"];\n",
            "    \"April\" -> \"Python/TypeScript SDKs, new models\"     [label=\"Apr 23\"];\n",
            "\n",
            "    // May 2024\n",
            "    \"May\" -> \"Jina/Pongo rerankers, MS Teams feed\" [label=\"May 5\"];\n",
            "    \"May\" -> \"GraphRAG, GPT-4o model\"             [label=\"May 15\"];\n",
            "\n",
            "    // June 2024\n",
            "    \"June\" -> \"Deepseek models, JSON-LD parsing\"       [label=\"Jun 9\"];\n",
            "    \"June\" -> \"Claude 3.5 Sonnet, knowledge graph\"      [label=\"Jun 21\"];\n",
            "\n",
            "    // July 2024\n",
            "    \"July\" -> \"Webhook Alerts, keywords summarization\"    [label=\"Jul 4\"];\n",
            "    \"July\" -> \"GPT-4o Mini, BYO-key (Azure AI)\"           [label=\"Jul 19\"];\n",
            "    \"July\" -> \"Mistral Large2 Nemo, Groq Llama3.1\"        [label=\"Jul 25\"];\n",
            "    \"July\" -> \"Indexing workflow, language detection\"      [label=\"Jul 28\"];\n",
            "\n",
            "    // August 2024\n",
            "    \"August\" -> \"LLM-based doc extraction, .NET SDK\"     [label=\"Aug 8\"];\n",
            "    \"August\" -> \"Azure AI Doc Intelligence default\"      [label=\"Aug 11\"];\n",
            "    \"August\" -> \"Medical entities, Anthropic caching\"    [label=\"Aug 20\"];\n",
            "\n",
            "    // September 2024\n",
            "    \"September\" -> \"FHIR enrichment, Cohere models\"          [label=\"Sep 1\"];\n",
            "    \"September\" -> \"Web search feeds, model deprecations\"    [label=\"Sep 3\"];\n",
            "    \"September\" -> \"Google AI, Cerebras, Groq\"               [label=\"Sep 26\"];\n",
            "    \"September\" -> \"Azure AI Inference, Mistral Pixtral\"     [label=\"Sep 30\"];\n",
            "\n",
            "    // October 2024\n",
            "    \"October\" -> \"Tool calling, ingestBatch, Gemini 1.5\"      [label=\"Oct 3\"];\n",
            "    \"October\" -> \"Anthropic, Gemini tool calling\"             [label=\"Oct 7\"];\n",
            "    \"October\" -> \"GitHub repository feeds\"                    [label=\"Oct 9\"];\n",
            "    \"October\" -> \"OpenAI/Cohere/Jina embeddings\"              [label=\"Oct 21\"];\n",
            "    \"October\" -> \"Anthropic Sonnet 3.5, Cohere image\"         [label=\"Oct 22\"];\n",
            "    \"October\" -> \"Simulated tool calling, search tweaks\"      [label=\"Oct 31\"];\n",
            "\n",
            "    // November 2024\n",
            "    \"November\" -> \"Claude 3.5 Haiku, feed mgmt\"                [label=\"Nov 4\"];\n",
            "    \"November\" -> \"Web search, multi-turn summarization\"        [label=\"Nov 10\"];\n",
            "    \"November\" -> \"Image description, multi-turn summarization\" [label=\"Nov 16\"];\n",
            "    \"November\" -> \"Direct LLM prompt, multi-turn images\"        [label=\"Nov 24\"];\n",
            "\n",
            "    // December 2024\n",
            "    \"December\" -> \"Retrieval-only RAG pipeline\"          [label=\"Dec 1\"];\n",
            "    \"December\" -> \"Website mapping, Groq Llama 3.3\"       [label=\"Dec 9\"];\n",
            "    \"December\" -> \"Dropbox/Box/Intercom, OpenAI o1\"       [label=\"Dec 22\"];\n",
            "    \"December\" -> \"LLM fallbacks, Google Docs\"            [label=\"Dec 27\"];\n",
            "}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "image/png": {
              "width": 1400
            }
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, HTML, JSON\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "time.sleep(10) # give it some time for billing events to catch up\n",
        "\n",
        "credits = await lookup_credits(ingestion_correlation_id)\n",
        "\n",
        "if credits is not None:\n",
        "    display(Markdown(f\"### Credits used: {credits.credits:.6f} for ingestion\"))\n",
        "    print(f\"- storage [{credits.storage_ratio:.2f}%], compute [{credits.compute_ratio:.2f}%]\")\n",
        "    print(f\"- embedding [{credits.embedding_ratio:.2f}%], completion [{credits.completion_ratio:.2f}%]\")\n",
        "    print(f\"- ingestion [{credits.ingestion_ratio:.2f}%], indexing [{credits.indexing_ratio:.2f}%], preparation [{credits.preparation_ratio:.2f}%], extraction [{credits.extraction_ratio:.2f}%], enrichment [{credits.enrichment_ratio:.2f}%], publishing [{credits.publishing_ratio:.2f}%]\")\n",
        "    print(f\"- search [{credits.search_ratio:.2f}%], conversation [{credits.conversation_ratio:.2f}%]\")\n",
        "    print()\n",
        "\n",
        "usage = await lookup_usage(ingestion_correlation_id)\n",
        "\n",
        "if usage is not None:\n",
        "    display(Markdown(f\"### Usage records:\"))\n",
        "\n",
        "    for record in usage:\n",
        "        dump_usage_record(record)\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "s7M_W9n7ntKA",
        "outputId": "1539c272-b95f-48c9-e88a-2c074eb6fe33"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Credits used: 5.968785 for ingestion"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- storage [0.76%], compute [64.97%]\n",
            "- embedding [3.38%], completion [0.00%]\n",
            "- ingestion [0.00%], indexing [0.00%], preparation [30.89%], extraction [0.00%], enrichment [0.00%], publishing [0.00%]\n",
            "- search [0.00%], conversation [0.00%]\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Usage records:"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-12-30T03:59:28.408Z: Serverless compute\n",
            "- Workflow [Entity Event] took 0:00:09.695636, used credits [0.01745619]\n",
            "- CONTENT [75f8d5dd-c5e0-4c08-b334-dc5e80ea8025]\n",
            "\n",
            "2024-12-30T03:59:28.309Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.309100, used credits [0.00044200]\n",
            "- CONTENT [75f8d5dd-c5e0-4c08-b334-dc5e80ea8025]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [221 tokens], throughput: 714.980 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:28.295Z: Serverless compute\n",
            "- Workflow [Entity Event] took 0:00:09.452146, used credits [0.01701780]\n",
            "- CONTENT [2489940d-1c11-4cab-82d2-26e5a1bc0dff]\n",
            "\n",
            "2024-12-30T03:59:28.214Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.212805, used credits [0.00044200]\n",
            "- CONTENT [75f8d5dd-c5e0-4c08-b334-dc5e80ea8025]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [221 tokens], throughput: 1038.510 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:28.200Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.324811, used credits [0.00049600]\n",
            "- CONTENT [2489940d-1c11-4cab-82d2-26e5a1bc0dff]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [248 tokens], throughput: 763.520 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:28.126Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.247751, used credits [0.00049600]\n",
            "- CONTENT [2489940d-1c11-4cab-82d2-26e5a1bc0dff]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [248 tokens], throughput: 1001.003 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:27.409Z: Serverless compute\n",
            "- Workflow [Entity Event] took 0:00:10.930525, used credits [0.01967950]\n",
            "- CONTENT [f3c48cd9-fc5b-4306-9135-aed548177631]\n",
            "\n",
            "2024-12-30T03:59:27.316Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.173166, used credits [0.00075600]\n",
            "- CONTENT [f3c48cd9-fc5b-4306-9135-aed548177631]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [378 tokens], throughput: 2182.872 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:27.281Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.147083, used credits [0.00075600]\n",
            "- CONTENT [f3c48cd9-fc5b-4306-9135-aed548177631]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [378 tokens], throughput: 2569.979 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:26.775Z: Serverless compute\n",
            "- Workflow [Entity Event] took 0:00:10.574753, used credits [0.01903896]\n",
            "- CONTENT [c693346f-b33a-4931-88f4-5c7142c749b9]\n",
            "\n",
            "2024-12-30T03:59:26.754Z: Upload Mezzanine\n",
            "- Workflow [Preparation] took 0:00:00.053009, used credits [0.00000952]\n",
            "- CONTENT [75f8d5dd-c5e0-4c08-b334-dc5e80ea8025]: Content type [PAGE], file type [DATA]\n",
            "- File upload [2465 bytes], throughput: 46501.713 bytes/sec\n",
            "\n",
            "2024-12-30T03:59:26.696Z: Upload Mezzanine\n",
            "- Workflow [Preparation] took 0:00:00.061290, used credits [0.00000878]\n",
            "- CONTENT [2489940d-1c11-4cab-82d2-26e5a1bc0dff]: Content type [PAGE], file type [DATA]\n",
            "- File upload [2273 bytes], throughput: 37085.743 bytes/sec\n",
            "\n",
            "2024-12-30T03:59:26.640Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.285646, used credits [0.00075200]\n",
            "- CONTENT [c693346f-b33a-4931-88f4-5c7142c749b9]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [376 tokens], throughput: 1316.315 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:26.515Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.151060, used credits [0.00075200]\n",
            "- CONTENT [c693346f-b33a-4931-88f4-5c7142c749b9]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [376 tokens], throughput: 2489.071 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:26.262Z: Serverless compute\n",
            "- Workflow [Entity Event] took 0:00:10.342315, used credits [0.01862048]\n",
            "- CONTENT [1cd2c534-2f49-4677-ab4a-68a4365f4fdd]\n",
            "\n",
            "2024-12-30T03:59:26.124Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.271742, used credits [0.00078400]\n",
            "- CONTENT [1cd2c534-2f49-4677-ab4a-68a4365f4fdd]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [392 tokens], throughput: 1442.544 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:26.097Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.278581, used credits [0.00078400]\n",
            "- CONTENT [1cd2c534-2f49-4677-ab4a-68a4365f4fdd]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [392 tokens], throughput: 1407.133 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:25.703Z: Upload Mezzanine\n",
            "- Workflow [Preparation] took 0:00:00.138897, used credits [0.00001484]\n",
            "- CONTENT [f3c48cd9-fc5b-4306-9135-aed548177631]: Content type [PAGE], file type [DATA]\n",
            "- File upload [3840 bytes], throughput: 27646.425 bytes/sec\n",
            "\n",
            "2024-12-30T03:59:24.919Z: Upload Mezzanine\n",
            "- Workflow [Preparation] took 0:00:00.069894, used credits [0.00001299]\n",
            "- CONTENT [c693346f-b33a-4931-88f4-5c7142c749b9]: Content type [PAGE], file type [DATA]\n",
            "- File upload [3363 bytes], throughput: 48115.649 bytes/sec\n",
            "\n",
            "2024-12-30T03:59:24.300Z: Upload Master\n",
            "- Workflow [Ingestion] took 0:00:00.188320, used credits [0.00075665]\n",
            "- CONTENT [2489940d-1c11-4cab-82d2-26e5a1bc0dff]: Content type [PAGE], file type [DOCUMENT]\n",
            "- URI [https://changelog.graphlit.dev/november-2024/november-4-support-for-anthropic-claude-3.5-haiku-bug-fixes]\n",
            "- File upload [195821 bytes], throughput: 1039829.482 bytes/sec\n",
            "\n",
            "2024-12-30T03:59:24.293Z: Upload Mezzanine\n",
            "- Workflow [Preparation] took 0:00:00.067325, used credits [0.00001681]\n",
            "- CONTENT [1cd2c534-2f49-4677-ab4a-68a4365f4fdd]: Content type [PAGE], file type [DATA]\n",
            "- File upload [4351 bytes], throughput: 64626.714 bytes/sec\n",
            "\n",
            "2024-12-30T03:59:24.228Z: Upload Master\n",
            "- Workflow [Ingestion] took 0:00:00.135355, used credits [0.00079421]\n",
            "- CONTENT [75f8d5dd-c5e0-4c08-b334-dc5e80ea8025]: Content type [PAGE], file type [DOCUMENT]\n",
            "- URI [https://changelog.graphlit.dev/september-2023/september-24-support-for-youtube-feeds-added-documentation-bug-fixes]\n",
            "- File upload [205540 bytes], throughput: 1518521.994 bytes/sec\n",
            "\n",
            "2024-12-30T03:59:23.566Z: Web capture\n",
            "- Workflow [Preparation] took 0:00:04.629583, used credits [0.03800000]\n",
            "- CONTENT [2489940d-1c11-4cab-82d2-26e5a1bc0dff]\n",
            "- Processor name [Browserless], units [1]\n",
            "\n",
            "2024-12-30T03:59:23.377Z: Web capture\n",
            "- Workflow [Preparation] took 0:00:04.605834, used credits [0.03800000]\n",
            "- CONTENT [75f8d5dd-c5e0-4c08-b334-dc5e80ea8025]\n",
            "- Processor name [Browserless], units [1]\n",
            "\n",
            "2024-12-30T03:59:23.074Z: Upload Master\n",
            "- Workflow [Ingestion] took 0:00:00.221909, used credits [0.00081003]\n",
            "- CONTENT [f3c48cd9-fc5b-4306-9135-aed548177631]: Content type [PAGE], file type [DOCUMENT]\n",
            "- URI [https://changelog.graphlit.dev/september-2023/september-4-workflow-configuration-support-for-notion-feeds-document-ocr]\n",
            "- File upload [209635 bytes], throughput: 944688.613 bytes/sec\n",
            "\n",
            "2024-12-30T03:59:22.716Z: Upload Master\n",
            "- Workflow [Ingestion] took 0:00:00.146236, used credits [0.00079268]\n",
            "- CONTENT [c693346f-b33a-4931-88f4-5c7142c749b9]: Content type [PAGE], file type [DOCUMENT]\n",
            "- URI [https://changelog.graphlit.dev/october-2024/october-3-support-tool-calling-ingestbatch-mutation-gemini-flash-1.5-8b-bug-fixes]\n",
            "- File upload [205146 bytes], throughput: 1402841.022 bytes/sec\n",
            "\n",
            "2024-12-30T03:59:22.234Z: Web capture\n",
            "- Workflow [Preparation] took 0:00:05.654290, used credits [0.03800000]\n",
            "- CONTENT [f3c48cd9-fc5b-4306-9135-aed548177631]\n",
            "- Processor name [Browserless], units [1]\n",
            "\n",
            "2024-12-30T03:59:21.913Z: Upload Master\n",
            "- Workflow [Ingestion] took 0:00:00.119572, used credits [0.00082284]\n",
            "- CONTENT [1cd2c534-2f49-4677-ab4a-68a4365f4fdd]: Content type [PAGE], file type [DOCUMENT]\n",
            "- URI [https://changelog.graphlit.dev/october-2023/october-15-support-for-anthropic-claude-models-slack-feeds-and-entity-enrichment]\n",
            "- File upload [212951 bytes], throughput: 1780946.678 bytes/sec\n",
            "\n",
            "2024-12-30T03:59:21.850Z: Web capture\n",
            "- Workflow [Preparation] took 0:00:05.582721, used credits [0.03800000]\n",
            "- CONTENT [c693346f-b33a-4931-88f4-5c7142c749b9]\n",
            "- Processor name [Browserless], units [1]\n",
            "\n",
            "2024-12-30T03:59:21.336Z: Web capture\n",
            "- Workflow [Preparation] took 0:00:05.364693, used credits [0.03800000]\n",
            "- CONTENT [1cd2c534-2f49-4677-ab4a-68a4365f4fdd]\n",
            "- Processor name [Browserless], units [1]\n",
            "\n",
            "2024-12-30T03:59:18.721Z: Serverless compute\n",
            "- Workflow [Entity Event] took 0:00:39.954085, used credits [0.07193400]\n",
            "- CONTENT [67150a0e-9b17-4261-8f62-1c57686d46e1]\n",
            "\n",
            "2024-12-30T03:59:18.589Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.408882, used credits [0.00146200]\n",
            "- CONTENT [67150a0e-9b17-4261-8f62-1c57686d46e1]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [731 tokens], throughput: 1787.801 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:18.524Z: Serverless compute\n",
            "- Workflow [Entity Event] took 0:00:39.699346, used credits [0.07147536]\n",
            "- CONTENT [a937626a-37ee-4eb1-93e5-2206e9a188ec]\n",
            "\n",
            "2024-12-30T03:59:18.387Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.232782, used credits [0.00130800]\n",
            "- CONTENT [67150a0e-9b17-4261-8f62-1c57686d46e1]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [654 tokens], throughput: 2809.493 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:18.340Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.316953, used credits [0.00310800]\n",
            "- CONTENT [a937626a-37ee-4eb1-93e5-2206e9a188ec]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [1554 tokens], throughput: 4902.937 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:18.166Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.165278, used credits [0.00239200]\n",
            "- CONTENT [a937626a-37ee-4eb1-93e5-2206e9a188ec]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [1196 tokens], throughput: 7236.310 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:17.333Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:02.462058, used credits [0.00130800]\n",
            "- CONTENT [67150a0e-9b17-4261-8f62-1c57686d46e1]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [654 tokens], throughput: 265.631 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:17.327Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:02.209501, used credits [0.00310800]\n",
            "- CONTENT [a937626a-37ee-4eb1-93e5-2206e9a188ec]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [1554 tokens], throughput: 703.326 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:16.214Z: Serverless compute\n",
            "- Workflow [Entity Event] took 0:00:37.444757, used credits [0.06741616]\n",
            "- CONTENT [7b5b7874-c84b-4607-877c-8bec0e167127]\n",
            "\n",
            "2024-12-30T03:59:16.085Z: Serverless compute\n",
            "- Workflow [Entity Event] took 0:00:37.270912, used credits [0.06710317]\n",
            "- CONTENT [1bc9cf17-e156-441d-a307-def6a31d693e]\n",
            "\n",
            "2024-12-30T03:59:16.078Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.439701, used credits [0.00182200]\n",
            "- CONTENT [7b5b7874-c84b-4607-877c-8bec0e167127]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [911 tokens], throughput: 2071.864 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:16.060Z: Serverless compute\n",
            "- Workflow [Entity Event] took 0:00:37.288549, used credits [0.06713493]\n",
            "- CONTENT [0932e05b-1816-4e99-a4ef-7bc475de60fc]\n",
            "\n",
            "2024-12-30T03:59:15.977Z: Serverless compute\n",
            "- Workflow [Entity Event] took 0:00:36.839402, used credits [0.06632627]\n",
            "- CONTENT [d40abe32-e564-4a6c-bd34-cea90b98c172]\n",
            "\n",
            "2024-12-30T03:59:15.935Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.232062, used credits [0.00063000]\n",
            "- CONTENT [0932e05b-1816-4e99-a4ef-7bc475de60fc]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [315 tokens], throughput: 1357.396 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:15.929Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.377588, used credits [0.00111400]\n",
            "- CONTENT [1bc9cf17-e156-441d-a307-def6a31d693e]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [557 tokens], throughput: 1475.155 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:15.899Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.197438, used credits [0.00063000]\n",
            "- CONTENT [0932e05b-1816-4e99-a4ef-7bc475de60fc]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [315 tokens], throughput: 1595.440 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:15.892Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.309057, used credits [0.00138600]\n",
            "- CONTENT [1bc9cf17-e156-441d-a307-def6a31d693e]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [693 tokens], throughput: 2242.303 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:15.852Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.223986, used credits [0.00166600]\n",
            "- CONTENT [7b5b7874-c84b-4607-877c-8bec0e167127]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [833 tokens], throughput: 3718.984 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:15.767Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.263728, used credits [0.00139200]\n",
            "- CONTENT [d40abe32-e564-4a6c-bd34-cea90b98c172]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [696 tokens], throughput: 2639.083 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:15.721Z: Serverless compute\n",
            "- Workflow [Entity Event] took 0:00:36.944317, used credits [0.06651516]\n",
            "- CONTENT [3d78b65e-a42d-44e9-8a9a-07faf938ee0d]\n",
            "\n",
            "2024-12-30T03:59:15.640Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.164065, used credits [0.00111000]\n",
            "- CONTENT [d40abe32-e564-4a6c-bd34-cea90b98c172]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [555 tokens], throughput: 3382.810 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:15.627Z: Serverless compute\n",
            "- Workflow [Entity Event] took 0:00:36.852229, used credits [0.06634937]\n",
            "- CONTENT [4eff5e88-2cf6-489f-9bfb-52b30823e07e]\n",
            "\n",
            "2024-12-30T03:59:15.618Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.291349, used credits [0.00063600]\n",
            "- CONTENT [3d78b65e-a42d-44e9-8a9a-07faf938ee0d]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [318 tokens], throughput: 1091.474 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:15.597Z: Serverless compute\n",
            "- Workflow [Entity Event] took 0:00:36.793433, used credits [0.06624351]\n",
            "- CONTENT [f0a42b0a-353b-4f08-9a5d-40ce9196a46b]\n",
            "\n",
            "2024-12-30T03:59:15.534Z: Serverless compute\n",
            "- Workflow [Entity Event] took 0:00:36.767126, used credits [0.06619615]\n",
            "- CONTENT [4adced81-1014-450d-9e42-e81ec370a757]\n",
            "\n",
            "2024-12-30T03:59:15.533Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.210191, used credits [0.00063600]\n",
            "- CONTENT [3d78b65e-a42d-44e9-8a9a-07faf938ee0d]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [318 tokens], throughput: 1512.908 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:15.522Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.184732, used credits [0.00039400]\n",
            "- CONTENT [4eff5e88-2cf6-489f-9bfb-52b30823e07e]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [197 tokens], throughput: 1066.413 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:15.498Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.158317, used credits [0.00039400]\n",
            "- CONTENT [4eff5e88-2cf6-489f-9bfb-52b30823e07e]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [197 tokens], throughput: 1244.338 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:15.481Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.361675, used credits [0.00045200]\n",
            "- CONTENT [f0a42b0a-353b-4f08-9a5d-40ce9196a46b]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [226 tokens], throughput: 624.870 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:15.450Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.368400, used credits [0.00239200]\n",
            "- CONTENT [a937626a-37ee-4eb1-93e5-2206e9a188ec]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [1196 tokens], throughput: 3246.469 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:15.434Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.332724, used credits [0.00063000]\n",
            "- CONTENT [0932e05b-1816-4e99-a4ef-7bc475de60fc]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [315 tokens], throughput: 946.732 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:15.386Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.330002, used credits [0.00074800]\n",
            "- CONTENT [4adced81-1014-450d-9e42-e81ec370a757]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [374 tokens], throughput: 1133.327 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:15.359Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.369990, used credits [0.00182200]\n",
            "- CONTENT [7b5b7874-c84b-4607-877c-8bec0e167127]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [911 tokens], throughput: 2462.231 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:15.324Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.269676, used credits [0.00074800]\n",
            "- CONTENT [4adced81-1014-450d-9e42-e81ec370a757]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [374 tokens], throughput: 1386.851 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:15.308Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.185623, used credits [0.00045200]\n",
            "- CONTENT [f0a42b0a-353b-4f08-9a5d-40ce9196a46b]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [226 tokens], throughput: 1217.521 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:15.296Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.278424, used credits [0.00111400]\n",
            "- CONTENT [1bc9cf17-e156-441d-a307-def6a31d693e]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [557 tokens], throughput: 2000.550 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:15.273Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.173553, used credits [0.00063000]\n",
            "- CONTENT [0932e05b-1816-4e99-a4ef-7bc475de60fc]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [315 tokens], throughput: 1815.005 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:15.232Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.273205, used credits [0.00139200]\n",
            "- CONTENT [d40abe32-e564-4a6c-bd34-cea90b98c172]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [696 tokens], throughput: 2547.539 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:15.225Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.282681, used credits [0.00111000]\n",
            "- CONTENT [d40abe32-e564-4a6c-bd34-cea90b98c172]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [555 tokens], throughput: 1963.345 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:15.199Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.274646, used credits [0.00146200]\n",
            "- CONTENT [67150a0e-9b17-4261-8f62-1c57686d46e1]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [731 tokens], throughput: 2661.605 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:15.193Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.166767, used credits [0.00138600]\n",
            "- CONTENT [1bc9cf17-e156-441d-a307-def6a31d693e]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [693 tokens], throughput: 4155.491 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:15.156Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.180465, used credits [0.00166600]\n",
            "- CONTENT [7b5b7874-c84b-4607-877c-8bec0e167127]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [833 tokens], throughput: 4615.853 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:15.098Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.393592, used credits [0.00063600]\n",
            "- CONTENT [3d78b65e-a42d-44e9-8a9a-07faf938ee0d]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [318 tokens], throughput: 807.943 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:15.081Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.315824, used credits [0.00039400]\n",
            "- CONTENT [4eff5e88-2cf6-489f-9bfb-52b30823e07e]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [197 tokens], throughput: 623.765 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:15.062Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.203951, used credits [0.00039400]\n",
            "- CONTENT [4eff5e88-2cf6-489f-9bfb-52b30823e07e]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [197 tokens], throughput: 965.918 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:15.020Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.330736, used credits [0.00063600]\n",
            "- CONTENT [3d78b65e-a42d-44e9-8a9a-07faf938ee0d]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [318 tokens], throughput: 961.491 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:14.845Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.251509, used credits [0.00045200]\n",
            "- CONTENT [f0a42b0a-353b-4f08-9a5d-40ce9196a46b]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [226 tokens], throughput: 898.577 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:14.795Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.218498, used credits [0.00045200]\n",
            "- CONTENT [f0a42b0a-353b-4f08-9a5d-40ce9196a46b]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [226 tokens], throughput: 1034.334 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:14.747Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.413582, used credits [0.00074800]\n",
            "- CONTENT [4adced81-1014-450d-9e42-e81ec370a757]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [374 tokens], throughput: 904.295 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:14.662Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.348892, used credits [0.00310800]\n",
            "- CONTENT [a937626a-37ee-4eb1-93e5-2206e9a188ec]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [1554 tokens], throughput: 4454.098 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:14.646Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.345717, used credits [0.00063000]\n",
            "- CONTENT [0932e05b-1816-4e99-a4ef-7bc475de60fc]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [315 tokens], throughput: 911.149 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:14.642Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.305069, used credits [0.00074800]\n",
            "- CONTENT [4adced81-1014-450d-9e42-e81ec370a757]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [374 tokens], throughput: 1225.951 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:14.627Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.317424, used credits [0.00182200]\n",
            "- CONTENT [7b5b7874-c84b-4607-877c-8bec0e167127]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [911 tokens], throughput: 2869.982 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:14.590Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.331125, used credits [0.00166600]\n",
            "- CONTENT [7b5b7874-c84b-4607-877c-8bec0e167127]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [833 tokens], throughput: 2515.663 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:14.564Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.579400, used credits [0.00139200]\n",
            "- CONTENT [d40abe32-e564-4a6c-bd34-cea90b98c172]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [696 tokens], throughput: 1201.243 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:14.526Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.261557, used credits [0.00239200]\n",
            "- CONTENT [a937626a-37ee-4eb1-93e5-2206e9a188ec]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [1196 tokens], throughput: 4572.626 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:14.455Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.135188, used credits [0.00063000]\n",
            "- CONTENT [0932e05b-1816-4e99-a4ef-7bc475de60fc]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [315 tokens], throughput: 2330.095 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:14.433Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.221833, used credits [0.00130800]\n",
            "- CONTENT [67150a0e-9b17-4261-8f62-1c57686d46e1]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [654 tokens], throughput: 2948.160 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:14.428Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.203360, used credits [0.00146200]\n",
            "- CONTENT [67150a0e-9b17-4261-8f62-1c57686d46e1]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [731 tokens], throughput: 3594.616 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:14.420Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.285441, used credits [0.00039400]\n",
            "- CONTENT [4eff5e88-2cf6-489f-9bfb-52b30823e07e]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [197 tokens], throughput: 690.160 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:14.414Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.233460, used credits [0.00138600]\n",
            "- CONTENT [1bc9cf17-e156-441d-a307-def6a31d693e]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [693 tokens], throughput: 2968.389 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:14.395Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.226004, used credits [0.00111400]\n",
            "- CONTENT [1bc9cf17-e156-441d-a307-def6a31d693e]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [557 tokens], throughput: 2464.554 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:14.334Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.207379, used credits [0.00039400]\n",
            "- CONTENT [4eff5e88-2cf6-489f-9bfb-52b30823e07e]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [197 tokens], throughput: 949.953 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:14.312Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.285584, used credits [0.00045200]\n",
            "- CONTENT [f0a42b0a-353b-4f08-9a5d-40ce9196a46b]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [226 tokens], throughput: 791.360 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:14.308Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.326417, used credits [0.00063600]\n",
            "- CONTENT [3d78b65e-a42d-44e9-8a9a-07faf938ee0d]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [318 tokens], throughput: 974.215 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:14.189Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.196095, used credits [0.00045200]\n",
            "- CONTENT [f0a42b0a-353b-4f08-9a5d-40ce9196a46b]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [226 tokens], throughput: 1152.500 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:14.185Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.209592, used credits [0.00111000]\n",
            "- CONTENT [d40abe32-e564-4a6c-bd34-cea90b98c172]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [555 tokens], throughput: 2647.999 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:14.132Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.155118, used credits [0.00063600]\n",
            "- CONTENT [3d78b65e-a42d-44e9-8a9a-07faf938ee0d]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [318 tokens], throughput: 2050.052 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:13.959Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.662608, used credits [0.00074800]\n",
            "- CONTENT [4adced81-1014-450d-9e42-e81ec370a757]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [374 tokens], throughput: 564.437 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:13.875Z: Serverless compute\n",
            "- Workflow [Entity Event] took 0:00:06.906109, used credits [0.01243387]\n",
            "- CONTENT [4b9dad6a-8d6f-4daa-b1d9-6c5277939931]\n",
            "\n",
            "2024-12-30T03:59:13.777Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.510373, used credits [0.00054200]\n",
            "- CONTENT [4b9dad6a-8d6f-4daa-b1d9-6c5277939931]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [271 tokens], throughput: 530.984 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:13.619Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.172724, used credits [0.00074800]\n",
            "- CONTENT [4adced81-1014-450d-9e42-e81ec370a757]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [374 tokens], throughput: 2165.308 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:13.578Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.329738, used credits [0.00146200]\n",
            "- CONTENT [67150a0e-9b17-4261-8f62-1c57686d46e1]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [731 tokens], throughput: 2216.913 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:13.543Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.605895, used credits [0.00138600]\n",
            "- CONTENT [1bc9cf17-e156-441d-a307-def6a31d693e]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [693 tokens], throughput: 1143.762 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:13.495Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.511175, used credits [0.00039400]\n",
            "- CONTENT [4eff5e88-2cf6-489f-9bfb-52b30823e07e]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [197 tokens], throughput: 385.387 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:13.485Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.243705, used credits [0.00063000]\n",
            "- CONTENT [0932e05b-1816-4e99-a4ef-7bc475de60fc]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [315 tokens], throughput: 1292.545 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:13.471Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.252162, used credits [0.00130800]\n",
            "- CONTENT [67150a0e-9b17-4261-8f62-1c57686d46e1]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [654 tokens], throughput: 2593.569 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:13.464Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.195932, used credits [0.00054200]\n",
            "- CONTENT [4b9dad6a-8d6f-4daa-b1d9-6c5277939931]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [271 tokens], throughput: 1383.134 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:13.418Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.495572, used credits [0.00182200]\n",
            "- CONTENT [7b5b7874-c84b-4607-877c-8bec0e167127]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [911 tokens], throughput: 1838.280 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:13.404Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.255951, used credits [0.00310800]\n",
            "- CONTENT [a937626a-37ee-4eb1-93e5-2206e9a188ec]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [1554 tokens], throughput: 6071.475 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:13.360Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.148093, used credits [0.00063000]\n",
            "- CONTENT [0932e05b-1816-4e99-a4ef-7bc475de60fc]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [315 tokens], throughput: 2127.039 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:13.353Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.246877, used credits [0.00239200]\n",
            "- CONTENT [a937626a-37ee-4eb1-93e5-2206e9a188ec]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [1196 tokens], throughput: 4844.512 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:13.225Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.160226, used credits [0.00039400]\n",
            "- CONTENT [4eff5e88-2cf6-489f-9bfb-52b30823e07e]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [197 tokens], throughput: 1229.515 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:13.197Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.346825, used credits [0.00111000]\n",
            "- CONTENT [d40abe32-e564-4a6c-bd34-cea90b98c172]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [555 tokens], throughput: 1600.229 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:13.192Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.328139, used credits [0.00111400]\n",
            "- CONTENT [1bc9cf17-e156-441d-a307-def6a31d693e]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [557 tokens], throughput: 1697.451 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:13.171Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.236405, used credits [0.00139200]\n",
            "- CONTENT [d40abe32-e564-4a6c-bd34-cea90b98c172]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [696 tokens], throughput: 2944.099 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:13.163Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.193396, used credits [0.00045200]\n",
            "- CONTENT [f0a42b0a-353b-4f08-9a5d-40ce9196a46b]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [226 tokens], throughput: 1168.589 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:13.163Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.189898, used credits [0.00045200]\n",
            "- CONTENT [f0a42b0a-353b-4f08-9a5d-40ce9196a46b]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [226 tokens], throughput: 1190.113 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:13.157Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.342620, used credits [0.00063600]\n",
            "- CONTENT [3d78b65e-a42d-44e9-8a9a-07faf938ee0d]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [318 tokens], throughput: 928.142 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:13.031Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.205882, used credits [0.00063600]\n",
            "- CONTENT [3d78b65e-a42d-44e9-8a9a-07faf938ee0d]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [318 tokens], throughput: 1544.573 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:13.030Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.184994, used credits [0.00166600]\n",
            "- CONTENT [7b5b7874-c84b-4607-877c-8bec0e167127]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [833 tokens], throughput: 4502.839 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:12.797Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.366324, used credits [0.00074800]\n",
            "- CONTENT [4adced81-1014-450d-9e42-e81ec370a757]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [374 tokens], throughput: 1020.956 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:12.793Z: Serverless compute\n",
            "- Workflow [Entity Event] took 0:00:32.854278, used credits [0.05915139]\n",
            "- CONTENT [865f424b-fa74-4640-b593-a9840336a452]\n",
            "\n",
            "2024-12-30T03:59:12.762Z: Serverless compute\n",
            "- Workflow [Entity Event] took 0:00:32.839320, used credits [0.05912446]\n",
            "- CONTENT [efb60fde-e52e-4726-893f-d58347a0deeb]\n",
            "\n",
            "2024-12-30T03:59:12.762Z: Serverless compute\n",
            "- Workflow [Entity Event] took 0:00:33.077011, used credits [0.05955240]\n",
            "- CONTENT [02c635c4-808d-495e-9744-bb501a2066e8]\n",
            "\n",
            "2024-12-30T03:59:12.757Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.334996, used credits [0.00074800]\n",
            "- CONTENT [4adced81-1014-450d-9e42-e81ec370a757]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [374 tokens], throughput: 1116.432 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:12.523Z: Serverless compute\n",
            "- Workflow [Entity Event] took 0:00:07.471986, used credits [0.01345269]\n",
            "- CONTENT [3092dd49-a054-4d32-94b2-cb67133a305d]\n",
            "\n",
            "2024-12-30T03:59:12.403Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.298127, used credits [0.00076800]\n",
            "- CONTENT [3092dd49-a054-4d32-94b2-cb67133a305d]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [384 tokens], throughput: 1288.042 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:12.373Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.465097, used credits [0.00095800]\n",
            "- CONTENT [865f424b-fa74-4640-b593-a9840336a452]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [479 tokens], throughput: 1029.894 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:12.360Z: Serverless compute\n",
            "- Workflow [Entity Event] took 0:00:32.484639, used credits [0.05848588]\n",
            "- CONTENT [5345f273-4dcb-4f44-a1a3-4226ff5eaed8]\n",
            "\n",
            "2024-12-30T03:59:12.358Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.390512, used credits [0.00117000]\n",
            "- CONTENT [865f424b-fa74-4640-b593-a9840336a452]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [585 tokens], throughput: 1498.034 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:12.353Z: Upload Mezzanine\n",
            "- Workflow [Preparation] took 0:00:00.055535, used credits [0.00001077]\n",
            "- CONTENT [4b9dad6a-8d6f-4daa-b1d9-6c5277939931]: Content type [PAGE], file type [DATA]\n",
            "- File upload [2786 bytes], throughput: 50166.200 bytes/sec\n",
            "\n",
            "2024-12-30T03:59:12.236Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.128891, used credits [0.00076800]\n",
            "- CONTENT [3092dd49-a054-4d32-94b2-cb67133a305d]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [384 tokens], throughput: 2979.259 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:12.199Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.323297, used credits [0.00044000]\n",
            "- CONTENT [efb60fde-e52e-4726-893f-d58347a0deeb]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [220 tokens], throughput: 680.489 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:12.192Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.320592, used credits [0.00044000]\n",
            "- CONTENT [efb60fde-e52e-4726-893f-d58347a0deeb]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [220 tokens], throughput: 686.230 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:12.066Z: Serverless compute\n",
            "- Workflow [Entity Event] took 0:00:32.176627, used credits [0.05793134]\n",
            "- CONTENT [b96def70-f8ed-4c72-9757-a1648306835a]\n",
            "\n",
            "2024-12-30T03:59:12.054Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.730338, used credits [0.00146200]\n",
            "- CONTENT [67150a0e-9b17-4261-8f62-1c57686d46e1]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [731 tokens], throughput: 1000.907 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:12.017Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.292170, used credits [0.00052800]\n",
            "- CONTENT [02c635c4-808d-495e-9744-bb501a2066e8]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [264 tokens], throughput: 903.584 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:11.951Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.493964, used credits [0.00052800]\n",
            "- CONTENT [02c635c4-808d-495e-9744-bb501a2066e8]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [264 tokens], throughput: 534.451 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:11.908Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.466243, used credits [0.00113600]\n",
            "- CONTENT [5345f273-4dcb-4f44-a1a3-4226ff5eaed8]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [568 tokens], throughput: 1218.249 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:11.692Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.251157, used credits [0.00059000]\n",
            "- CONTENT [b96def70-f8ed-4c72-9757-a1648306835a]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [295 tokens], throughput: 1174.564 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:11.679Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.273378, used credits [0.00059000]\n",
            "- CONTENT [b96def70-f8ed-4c72-9757-a1648306835a]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [295 tokens], throughput: 1079.092 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:11.657Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.506248, used credits [0.00093600]\n",
            "- CONTENT [5345f273-4dcb-4f44-a1a3-4226ff5eaed8]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [468 tokens], throughput: 924.448 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:11.466Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.485542, used credits [0.00130800]\n",
            "- CONTENT [67150a0e-9b17-4261-8f62-1c57686d46e1]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [654 tokens], throughput: 1346.947 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:11.084Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.650266, used credits [0.00310800]\n",
            "- CONTENT [a937626a-37ee-4eb1-93e5-2206e9a188ec]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [1554 tokens], throughput: 2389.792 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:11.046Z: Upload Mezzanine\n",
            "- Workflow [Preparation] took 0:00:00.056829, used credits [0.00001288]\n",
            "- CONTENT [3092dd49-a054-4d32-94b2-cb67133a305d]: Content type [PAGE], file type [DATA]\n",
            "- File upload [3334 bytes], throughput: 58667.333 bytes/sec\n",
            "\n",
            "2024-12-30T03:59:10.992Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.291563, used credits [0.00039400]\n",
            "- CONTENT [4eff5e88-2cf6-489f-9bfb-52b30823e07e]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [197 tokens], throughput: 675.669 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:10.927Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.223025, used credits [0.00039400]\n",
            "- CONTENT [4eff5e88-2cf6-489f-9bfb-52b30823e07e]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [197 tokens], throughput: 883.308 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:10.875Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.470276, used credits [0.00139200]\n",
            "- CONTENT [d40abe32-e564-4a6c-bd34-cea90b98c172]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [696 tokens], throughput: 1479.980 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:10.786Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.234216, used credits [0.00063600]\n",
            "- CONTENT [3d78b65e-a42d-44e9-8a9a-07faf938ee0d]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [318 tokens], throughput: 1357.720 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:10.782Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.201773, used credits [0.00063600]\n",
            "- CONTENT [3d78b65e-a42d-44e9-8a9a-07faf938ee0d]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [318 tokens], throughput: 1576.027 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:10.765Z: Upload Master\n",
            "- Workflow [Ingestion] took 0:00:00.073443, used credits [0.00077804]\n",
            "- CONTENT [4b9dad6a-8d6f-4daa-b1d9-6c5277939931]: Content type [PAGE], file type [DOCUMENT]\n",
            "- URI [https://changelog.graphlit.dev/july-2024/july-28-support-for-indexing-workflow-stage-azure-ai-language-detection-bug-fixes]\n",
            "- File upload [201356 bytes], throughput: 2741678.535 bytes/sec\n",
            "\n",
            "2024-12-30T03:59:10.710Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.323673, used credits [0.00166600]\n",
            "- CONTENT [7b5b7874-c84b-4607-877c-8bec0e167127]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [833 tokens], throughput: 2573.582 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:10.695Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.309358, used credits [0.00111000]\n",
            "- CONTENT [d40abe32-e564-4a6c-bd34-cea90b98c172]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [555 tokens], throughput: 1794.037 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:10.689Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.315989, used credits [0.00063000]\n",
            "- CONTENT [0932e05b-1816-4e99-a4ef-7bc475de60fc]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [315 tokens], throughput: 996.869 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:10.647Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.200714, used credits [0.00182200]\n",
            "- CONTENT [7b5b7874-c84b-4607-877c-8bec0e167127]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [911 tokens], throughput: 4538.785 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:10.622Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.209365, used credits [0.00239200]\n",
            "- CONTENT [a937626a-37ee-4eb1-93e5-2206e9a188ec]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [1196 tokens], throughput: 5712.501 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:10.538Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.359350, used credits [0.00111400]\n",
            "- CONTENT [1bc9cf17-e156-441d-a307-def6a31d693e]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [557 tokens], throughput: 1550.021 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:10.533Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.156253, used credits [0.00063000]\n",
            "- CONTENT [0932e05b-1816-4e99-a4ef-7bc475de60fc]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [315 tokens], throughput: 2015.959 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:10.462Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.279408, used credits [0.00045200]\n",
            "- CONTENT [f0a42b0a-353b-4f08-9a5d-40ce9196a46b]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [226 tokens], throughput: 808.854 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:10.456Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.260574, used credits [0.00138600]\n",
            "- CONTENT [1bc9cf17-e156-441d-a307-def6a31d693e]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [693 tokens], throughput: 2659.516 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:10.448Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.251353, used credits [0.00045200]\n",
            "- CONTENT [f0a42b0a-353b-4f08-9a5d-40ce9196a46b]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [226 tokens], throughput: 899.135 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:10.443Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.396678, used credits [0.00074800]\n",
            "- CONTENT [4adced81-1014-450d-9e42-e81ec370a757]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [374 tokens], throughput: 942.831 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:10.268Z: Web capture\n",
            "- Workflow [Preparation] took 0:00:03.264419, used credits [0.03800000]\n",
            "- CONTENT [4b9dad6a-8d6f-4daa-b1d9-6c5277939931]\n",
            "- Processor name [Browserless], units [1]\n",
            "\n",
            "2024-12-30T03:59:10.243Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.201919, used credits [0.00074800]\n",
            "- CONTENT [4adced81-1014-450d-9e42-e81ec370a757]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [374 tokens], throughput: 1852.232 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:09.565Z: Upload Master\n",
            "- Workflow [Ingestion] took 0:00:00.075248, used credits [0.00079518]\n",
            "- CONTENT [3092dd49-a054-4d32-94b2-cb67133a305d]: Content type [PAGE], file type [DOCUMENT]\n",
            "- URI [https://changelog.graphlit.dev/november-2024/november-24-support-for-direct-llm-prompt-multi-turn-image-analysis-bug-fixes]\n",
            "- File upload [205793 bytes], throughput: 2734877.923 bytes/sec\n",
            "\n",
            "2024-12-30T03:59:09.241Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.239099, used credits [0.00111400]\n",
            "- CONTENT [1bc9cf17-e156-441d-a307-def6a31d693e]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [557 tokens], throughput: 2329.581 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:09.234Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.567319, used credits [0.00182200]\n",
            "- CONTENT [7b5b7874-c84b-4607-877c-8bec0e167127]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [911 tokens], throughput: 1605.799 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:09.217Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.415020, used credits [0.00063000]\n",
            "- CONTENT [0932e05b-1816-4e99-a4ef-7bc475de60fc]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [315 tokens], throughput: 759.000 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:09.036Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.226375, used credits [0.00063000]\n",
            "- CONTENT [0932e05b-1816-4e99-a4ef-7bc475de60fc]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [315 tokens], throughput: 1391.495 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:08.997Z: Web capture\n",
            "- Workflow [Preparation] took 0:00:03.907775, used credits [0.03800000]\n",
            "- CONTENT [3092dd49-a054-4d32-94b2-cb67133a305d]\n",
            "- Processor name [Browserless], units [1]\n",
            "\n",
            "2024-12-30T03:59:08.960Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.301482, used credits [0.00138600]\n",
            "- CONTENT [1bc9cf17-e156-441d-a307-def6a31d693e]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [693 tokens], throughput: 2298.642 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:08.930Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.305070, used credits [0.00045200]\n",
            "- CONTENT [f0a42b0a-353b-4f08-9a5d-40ce9196a46b]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [226 tokens], throughput: 740.812 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:08.924Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.780188, used credits [0.00310800]\n",
            "- CONTENT [a937626a-37ee-4eb1-93e5-2206e9a188ec]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [1554 tokens], throughput: 1991.827 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:08.889Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.267852, used credits [0.00045200]\n",
            "- CONTENT [f0a42b0a-353b-4f08-9a5d-40ce9196a46b]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [226 tokens], throughput: 843.750 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:08.874Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.411964, used credits [0.00146200]\n",
            "- CONTENT [67150a0e-9b17-4261-8f62-1c57686d46e1]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [731 tokens], throughput: 1774.429 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:08.786Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.156380, used credits [0.00166600]\n",
            "- CONTENT [7b5b7874-c84b-4607-877c-8bec0e167127]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [833 tokens], throughput: 5326.755 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:08.775Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.358929, used credits [0.00130800]\n",
            "- CONTENT [67150a0e-9b17-4261-8f62-1c57686d46e1]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [654 tokens], throughput: 1822.089 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:08.769Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.332188, used credits [0.00039400]\n",
            "- CONTENT [4eff5e88-2cf6-489f-9bfb-52b30823e07e]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [197 tokens], throughput: 593.038 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:08.743Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.289716, used credits [0.00039400]\n",
            "- CONTENT [4eff5e88-2cf6-489f-9bfb-52b30823e07e]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [197 tokens], throughput: 679.975 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:08.713Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.272902, used credits [0.00139200]\n",
            "- CONTENT [d40abe32-e564-4a6c-bd34-cea90b98c172]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [696 tokens], throughput: 2550.370 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:08.690Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.347273, used credits [0.00063600]\n",
            "- CONTENT [3d78b65e-a42d-44e9-8a9a-07faf938ee0d]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [318 tokens], throughput: 915.706 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:08.683Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.289266, used credits [0.00111000]\n",
            "- CONTENT [d40abe32-e564-4a6c-bd34-cea90b98c172]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [555 tokens], throughput: 1918.649 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:08.615Z: Serverless compute\n",
            "- Workflow [Entity Event] took 0:00:10.785584, used credits [0.01941855]\n",
            "- CONTENT [d2f41682-fb8b-4599-8c64-91891e13c336]\n",
            "\n",
            "2024-12-30T03:59:08.510Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.154411, used credits [0.00063600]\n",
            "- CONTENT [3d78b65e-a42d-44e9-8a9a-07faf938ee0d]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [318 tokens], throughput: 2059.441 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:08.502Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.287768, used credits [0.00090800]\n",
            "- CONTENT [d2f41682-fb8b-4599-8c64-91891e13c336]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [454 tokens], throughput: 1577.661 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:08.482Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.350010, used credits [0.00074800]\n",
            "- CONTENT [4adced81-1014-450d-9e42-e81ec370a757]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [374 tokens], throughput: 1068.542 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:08.465Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.349214, used credits [0.00239200]\n",
            "- CONTENT [a937626a-37ee-4eb1-93e5-2206e9a188ec]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [1196 tokens], throughput: 3424.829 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:08.458Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.242038, used credits [0.00109800]\n",
            "- CONTENT [d2f41682-fb8b-4599-8c64-91891e13c336]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [549 tokens], throughput: 2268.236 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:08.298Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.175708, used credits [0.00074800]\n",
            "- CONTENT [4adced81-1014-450d-9e42-e81ec370a757]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [374 tokens], throughput: 2128.527 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:07.466Z: Serverless compute\n",
            "- Workflow [Entity Event] took 0:00:14.764731, used credits [0.02658267]\n",
            "- CONTENT [2dd30528-0956-4c46-9a9c-8ce6ecc9931e]\n",
            "\n",
            "2024-12-30T03:59:07.363Z: Upload Mezzanine\n",
            "- Workflow [Preparation] took 0:00:00.451141, used credits [0.00000616]\n",
            "- CONTENT [efb60fde-e52e-4726-893f-d58347a0deeb]: Content type [PAGE], file type [DATA]\n",
            "- File upload [1595 bytes], throughput: 3535.481 bytes/sec\n",
            "\n",
            "2024-12-30T03:59:07.356Z: Serverless compute\n",
            "- Workflow [Entity Event] took 0:00:14.653665, used credits [0.02638270]\n",
            "- CONTENT [fc169406-76bc-479f-93f2-0c1b1ba4277e]\n",
            "\n",
            "2024-12-30T03:59:07.335Z: Serverless compute\n",
            "- Workflow [Entity Event] took 0:00:11.798746, used credits [0.02124266]\n",
            "- CONTENT [e112772f-cc4a-4323-8c80-8c1d8c123dd2]\n",
            "\n",
            "2024-12-30T03:59:07.294Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.353328, used credits [0.00085400]\n",
            "- CONTENT [2dd30528-0956-4c46-9a9c-8ce6ecc9931e]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [427 tokens], throughput: 1208.508 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:07.222Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.323549, used credits [0.00023800]\n",
            "- CONTENT [e112772f-cc4a-4323-8c80-8c1d8c123dd2]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [119 tokens], throughput: 367.796 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:07.207Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.309693, used credits [0.00023800]\n",
            "- CONTENT [e112772f-cc4a-4323-8c80-8c1d8c123dd2]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [119 tokens], throughput: 384.251 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:07.170Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.233987, used credits [0.00125200]\n",
            "- CONTENT [fc169406-76bc-479f-93f2-0c1b1ba4277e]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [626 tokens], throughput: 2675.361 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:07.147Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.214870, used credits [0.00103400]\n",
            "- CONTENT [fc169406-76bc-479f-93f2-0c1b1ba4277e]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [517 tokens], throughput: 2406.104 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:07.143Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.202290, used credits [0.00085400]\n",
            "- CONTENT [2dd30528-0956-4c46-9a9c-8ce6ecc9931e]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [427 tokens], throughput: 2110.829 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:06.916Z: Upload Mezzanine\n",
            "- Workflow [Preparation] took 0:00:00.057667, used credits [0.00001807]\n",
            "- CONTENT [d2f41682-fb8b-4599-8c64-91891e13c336]: Content type [PAGE], file type [DATA]\n",
            "- File upload [4677 bytes], throughput: 81103.859 bytes/sec\n",
            "\n",
            "2024-12-30T03:59:06.782Z: Serverless compute\n",
            "- Workflow [Entity Event] took 0:00:11.257642, used credits [0.02026845]\n",
            "- CONTENT [4fa1f011-eca1-4585-9a4b-d31369c468cb]\n",
            "\n",
            "2024-12-30T03:59:06.689Z: Serverless compute\n",
            "- Workflow [Entity Event] took 0:00:14.795115, used credits [0.02663737]\n",
            "- CONTENT [6a1f0635-0338-4b77-85c2-a476edc6cde9]\n",
            "\n",
            "2024-12-30T03:59:06.629Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.246753, used credits [0.00027600]\n",
            "- CONTENT [4fa1f011-eca1-4585-9a4b-d31369c468cb]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [138 tokens], throughput: 559.264 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:06.627Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.248827, used credits [0.00027600]\n",
            "- CONTENT [4fa1f011-eca1-4585-9a4b-d31369c468cb]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [138 tokens], throughput: 554.602 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:06.611Z: Upload Mezzanine\n",
            "- Workflow [Preparation] took 0:00:00.120989, used credits [0.00001700]\n",
            "- CONTENT [5345f273-4dcb-4f44-a1a3-4226ff5eaed8]: Content type [PAGE], file type [DATA]\n",
            "- File upload [4400 bytes], throughput: 36366.882 bytes/sec\n",
            "\n",
            "2024-12-30T03:59:06.602Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.828297, used credits [0.00139200]\n",
            "- CONTENT [d40abe32-e564-4a6c-bd34-cea90b98c172]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [696 tokens], throughput: 840.279 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:06.593Z: Upload Mezzanine\n",
            "- Workflow [Preparation] took 0:00:00.237239, used credits [0.00001020]\n",
            "- CONTENT [b96def70-f8ed-4c72-9757-a1648306835a]: Content type [PAGE], file type [DATA]\n",
            "- File upload [2640 bytes], throughput: 11128.009 bytes/sec\n",
            "\n",
            "2024-12-30T03:59:06.495Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.938160, used credits [0.00310800]\n",
            "- CONTENT [a937626a-37ee-4eb1-93e5-2206e9a188ec]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [1554 tokens], throughput: 1656.433 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:06.489Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.924740, used credits [0.00074800]\n",
            "- CONTENT [4adced81-1014-450d-9e42-e81ec370a757]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [374 tokens], throughput: 404.438 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:06.474Z: Upload Mezzanine\n",
            "- Workflow [Preparation] took 0:00:00.164903, used credits [0.00000757]\n",
            "- CONTENT [02c635c4-808d-495e-9744-bb501a2066e8]: Content type [PAGE], file type [DATA]\n",
            "- File upload [1959 bytes], throughput: 11879.689 bytes/sec\n",
            "\n",
            "2024-12-30T03:59:06.470Z: Upload Mezzanine\n",
            "- Workflow [Preparation] took 0:00:00.218737, used credits [0.00001446]\n",
            "- CONTENT [865f424b-fa74-4640-b593-a9840336a452]: Content type [PAGE], file type [DATA]\n",
            "- File upload [3743 bytes], throughput: 17111.866 bytes/sec\n",
            "\n",
            "2024-12-30T03:59:06.358Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.786025, used credits [0.00063000]\n",
            "- CONTENT [0932e05b-1816-4e99-a4ef-7bc475de60fc]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [315 tokens], throughput: 400.751 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:06.305Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.293397, used credits [0.00068800]\n",
            "- CONTENT [6a1f0635-0338-4b77-85c2-a476edc6cde9]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [344 tokens], throughput: 1172.472 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:06.287Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.844506, used credits [0.00063600]\n",
            "- CONTENT [3d78b65e-a42d-44e9-8a9a-07faf938ee0d]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [318 tokens], throughput: 376.552 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:06.283Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.878643, used credits [0.00074800]\n",
            "- CONTENT [4adced81-1014-450d-9e42-e81ec370a757]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [374 tokens], throughput: 425.656 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:06.267Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.862691, used credits [0.00045200]\n",
            "- CONTENT [f0a42b0a-353b-4f08-9a5d-40ce9196a46b]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [226 tokens], throughput: 261.971 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:06.266Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.699713, used credits [0.00146200]\n",
            "- CONTENT [67150a0e-9b17-4261-8f62-1c57686d46e1]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [731 tokens], throughput: 1044.714 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:06.263Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.579020, used credits [0.00111000]\n",
            "- CONTENT [d40abe32-e564-4a6c-bd34-cea90b98c172]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [555 tokens], throughput: 958.517 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:06.257Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.852855, used credits [0.00239200]\n",
            "- CONTENT [a937626a-37ee-4eb1-93e5-2206e9a188ec]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [1196 tokens], throughput: 1402.349 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:06.256Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.851990, used credits [0.00166600]\n",
            "- CONTENT [7b5b7874-c84b-4607-877c-8bec0e167127]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [833 tokens], throughput: 977.711 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:06.248Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.586204, used credits [0.00063600]\n",
            "- CONTENT [3d78b65e-a42d-44e9-8a9a-07faf938ee0d]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [318 tokens], throughput: 542.473 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:06.248Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.688005, used credits [0.00182200]\n",
            "- CONTENT [7b5b7874-c84b-4607-877c-8bec0e167127]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [911 tokens], throughput: 1324.118 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:06.241Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.578858, used credits [0.00138600]\n",
            "- CONTENT [1bc9cf17-e156-441d-a307-def6a31d693e]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [693 tokens], throughput: 1197.184 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:06.230Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.826000, used credits [0.00130800]\n",
            "- CONTENT [67150a0e-9b17-4261-8f62-1c57686d46e1]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [654 tokens], throughput: 791.767 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:06.216Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.711834, used credits [0.00111400]\n",
            "- CONTENT [1bc9cf17-e156-441d-a307-def6a31d693e]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [557 tokens], throughput: 782.486 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:06.197Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.787361, used credits [0.00039400]\n",
            "- CONTENT [4eff5e88-2cf6-489f-9bfb-52b30823e07e]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [197 tokens], throughput: 250.203 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:06.196Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.748824, used credits [0.00063000]\n",
            "- CONTENT [0932e05b-1816-4e99-a4ef-7bc475de60fc]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [315 tokens], throughput: 420.660 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:06.196Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.621794, used credits [0.00045200]\n",
            "- CONTENT [f0a42b0a-353b-4f08-9a5d-40ce9196a46b]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [226 tokens], throughput: 363.464 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:06.196Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.620573, used credits [0.00039400]\n",
            "- CONTENT [4eff5e88-2cf6-489f-9bfb-52b30823e07e]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [197 tokens], throughput: 317.448 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:05.977Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.174002, used credits [0.00068800]\n",
            "- CONTENT [6a1f0635-0338-4b77-85c2-a476edc6cde9]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [344 tokens], throughput: 1976.985 tokens/sec\n",
            "\n",
            "2024-12-30T03:59:05.339Z: Upload Mezzanine\n",
            "- Workflow [Preparation] took 0:00:00.065135, used credits [0.00001413]\n",
            "- CONTENT [2dd30528-0956-4c46-9a9c-8ce6ecc9931e]: Content type [PAGE], file type [DATA]\n",
            "- File upload [3658 bytes], throughput: 56159.851 bytes/sec\n",
            "\n",
            "2024-12-30T03:59:05.129Z: Upload Mezzanine\n",
            "- Workflow [Preparation] took 0:00:00.098447, used credits [0.00000570]\n",
            "- CONTENT [e112772f-cc4a-4323-8c80-8c1d8c123dd2]: Content type [PAGE], file type [DATA]\n",
            "- File upload [1474 bytes], throughput: 14972.584 bytes/sec\n",
            "\n",
            "2024-12-30T03:59:05.066Z: Upload Mezzanine\n",
            "- Workflow [Preparation] took 0:00:00.078989, used credits [0.00001951]\n",
            "- CONTENT [fc169406-76bc-479f-93f2-0c1b1ba4277e]: Content type [PAGE], file type [DATA]\n",
            "- File upload [5048 bytes], throughput: 63907.714 bytes/sec\n",
            "\n",
            "2024-12-30T03:59:04.835Z: Upload Mezzanine\n",
            "- Workflow [Preparation] took 0:00:00.083302, used credits [0.00000562]\n",
            "- CONTENT [4fa1f011-eca1-4585-9a4b-d31369c468cb]: Content type [PAGE], file type [DATA]\n",
            "- File upload [1455 bytes], throughput: 17466.525 bytes/sec\n",
            "\n",
            "2024-12-30T03:59:04.289Z: Upload Mezzanine\n",
            "- Workflow [Preparation] took 0:00:00.057242, used credits [0.00000856]\n",
            "- CONTENT [6a1f0635-0338-4b77-85c2-a476edc6cde9]: Content type [PAGE], file type [DATA]\n",
            "- File upload [2216 bytes], throughput: 38712.766 bytes/sec\n",
            "\n",
            "2024-12-30T03:59:04.231Z: Upload Master\n",
            "- Workflow [Ingestion] took 0:00:00.158146, used credits [0.00085421]\n",
            "- CONTENT [d2f41682-fb8b-4599-8c64-91891e13c336]: Content type [PAGE], file type [DOCUMENT]\n",
            "- URI [https://changelog.graphlit.dev/march-2024/march-10-support-for-claude-3-mistral-and-groq-models-usage-credits-telemetry-bug-fixes]\n",
            "- File upload [221069 bytes], throughput: 1397874.755 bytes/sec\n",
            "\n",
            "2024-12-30T03:59:03.297Z: Web capture\n",
            "- Workflow [Preparation] took 0:00:05.424606, used credits [0.03800000]\n",
            "- CONTENT [d2f41682-fb8b-4599-8c64-91891e13c336]\n",
            "- Processor name [Browserless], units [1]\n",
            "\n",
            "2024-12-30T03:59:02.895Z: Upload Master\n",
            "- Workflow [Ingestion] took 0:00:00.113028, used credits [0.00084850]\n",
            "- CONTENT [fc169406-76bc-479f-93f2-0c1b1ba4277e]: Content type [PAGE], file type [DOCUMENT]\n",
            "- URI [https://changelog.graphlit.dev/june-2024/june-9-support-for-deepseek-models-json-ld-webpage-parsing-performance-improvements-and-bug-fixes]\n",
            "- File upload [219592 bytes], throughput: 1942803.756 bytes/sec\n",
            "\n",
            "2024-12-30T03:59:02.833Z: Upload Master\n",
            "- Workflow [Ingestion] took 0:00:00.259143, used credits [0.00071913]\n",
            "- CONTENT [e112772f-cc4a-4323-8c80-8c1d8c123dd2]: Content type [PAGE], file type [DOCUMENT]\n",
            "- URI [https://changelog.graphlit.dev/october-2024/october-9-support-for-github-repository-feeds-bug-fixes]\n",
            "- File upload [186111 bytes], throughput: 718178.489 bytes/sec\n",
            "\n",
            "2024-12-30T03:59:02.821Z: Upload Master\n",
            "- Workflow [Ingestion] took 0:00:00.087109, used credits [0.00077617]\n",
            "- CONTENT [2dd30528-0956-4c46-9a9c-8ce6ecc9931e]: Content type [PAGE], file type [DOCUMENT]\n",
            "- URI [https://changelog.graphlit.dev/october-2024/october-21-support-openai-cohere-jina-mistral-voyage-and-google-ai-embedding-models]\n",
            "- File upload [200872 bytes], throughput: 2305989.751 bytes/sec\n",
            "\n",
            "2024-12-30T03:59:02.742Z: Upload Master\n",
            "- Workflow [Ingestion] took 0:00:00.226304, used credits [0.00070636]\n",
            "- CONTENT [4fa1f011-eca1-4585-9a4b-d31369c468cb]: Content type [PAGE], file type [DOCUMENT]\n",
            "- URI [https://changelog.graphlit.dev/october-2024/october-7-support-for-anthropic-and-gemini-tool-calling]\n",
            "- File upload [182805 bytes], throughput: 807786.174 bytes/sec\n",
            "\n",
            "2024-12-30T03:59:02.290Z: Upload Master\n",
            "- Workflow [Ingestion] took 0:00:00.162748, used credits [0.00077174]\n",
            "- CONTENT [6a1f0635-0338-4b77-85c2-a476edc6cde9]: Content type [PAGE], file type [DOCUMENT]\n",
            "- URI [https://changelog.graphlit.dev/september-2024/september-3-support-for-web-search-feeds-model-deprecations]\n",
            "- File upload [199725 bytes], throughput: 1227200.251 bytes/sec\n",
            "\n",
            "2024-12-30T03:59:02.232Z: Web capture\n",
            "- Workflow [Preparation] took 0:00:09.183659, used credits [0.03800000]\n",
            "- CONTENT [2dd30528-0956-4c46-9a9c-8ce6ecc9931e]\n",
            "- Processor name [Browserless], units [1]\n",
            "\n",
            "2024-12-30T03:59:02.073Z: Web capture\n",
            "- Workflow [Preparation] took 0:00:09.170880, used credits [0.03800000]\n",
            "- CONTENT [fc169406-76bc-479f-93f2-0c1b1ba4277e]\n",
            "- Processor name [Browserless], units [1]\n",
            "\n",
            "2024-12-30T03:59:02.032Z: Web capture\n",
            "- Workflow [Preparation] took 0:00:06.235260, used credits [0.03800000]\n",
            "- CONTENT [4fa1f011-eca1-4585-9a4b-d31369c468cb]\n",
            "- Processor name [Browserless], units [1]\n",
            "\n",
            "2024-12-30T03:59:02.032Z: Web capture\n",
            "- Workflow [Preparation] took 0:00:06.202891, used credits [0.03800000]\n",
            "- CONTENT [e112772f-cc4a-4323-8c80-8c1d8c123dd2]\n",
            "- Processor name [Browserless], units [1]\n",
            "\n",
            "2024-12-30T03:59:01.691Z: Web capture\n",
            "- Workflow [Preparation] took 0:00:09.253003, used credits [0.03800000]\n",
            "- CONTENT [6a1f0635-0338-4b77-85c2-a476edc6cde9]\n",
            "- Processor name [Browserless], units [1]\n",
            "\n",
            "2024-12-30T03:58:59.852Z: Serverless compute\n",
            "- Workflow [Entity Event] took 0:00:39.247861, used credits [0.07066250]\n",
            "- CONTENT [b682b0ca-255c-4b02-b016-cb56f05edb64]\n",
            "\n",
            "2024-12-30T03:58:59.754Z: Serverless compute\n",
            "- Workflow [Entity Event] took 0:00:42.170606, used credits [0.07592466]\n",
            "- CONTENT [257dc6c9-65d0-416d-9b1c-d412aeb42bd4]\n",
            "\n",
            "2024-12-30T03:58:59.629Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.189515, used credits [0.00034800]\n",
            "- CONTENT [b682b0ca-255c-4b02-b016-cb56f05edb64]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [174 tokens], throughput: 918.132 tokens/sec\n",
            "\n",
            "2024-12-30T03:58:59.627Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.189481, used credits [0.00034800]\n",
            "- CONTENT [b682b0ca-255c-4b02-b016-cb56f05edb64]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [174 tokens], throughput: 918.299 tokens/sec\n",
            "\n",
            "2024-12-30T03:58:59.516Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.246890, used credits [0.00070200]\n",
            "- CONTENT [257dc6c9-65d0-416d-9b1c-d412aeb42bd4]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [351 tokens], throughput: 1421.685 tokens/sec\n",
            "\n",
            "2024-12-30T03:58:59.514Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.240042, used credits [0.00070200]\n",
            "- CONTENT [257dc6c9-65d0-416d-9b1c-d412aeb42bd4]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [351 tokens], throughput: 1462.244 tokens/sec\n",
            "\n",
            "2024-12-30T03:58:59.210Z: Serverless compute\n",
            "- Workflow [Entity Event] took 0:00:39.946413, used credits [0.07192019]\n",
            "- CONTENT [3d78b65e-a42d-44e9-8a9a-07faf938ee0d]\n",
            "\n",
            "2024-12-30T03:58:59.210Z: Serverless compute\n",
            "- Workflow [Entity Event] took 0:00:48.871304, used credits [0.08798871]\n",
            "- CONTENT [7b5b7874-c84b-4607-877c-8bec0e167127]\n",
            "\n",
            "2024-12-30T03:58:59.190Z: Serverless compute\n",
            "- Workflow [Entity Event] took 0:00:38.673216, used credits [0.06962790]\n",
            "- CONTENT [d764f4d3-1282-441c-8e4a-08ce664b0b47]\n",
            "\n",
            "2024-12-30T03:58:58.974Z: Serverless compute\n",
            "- Workflow [Entity Event] took 0:00:39.700962, used credits [0.07147827]\n",
            "- CONTENT [8a9c0eb5-3658-4cca-bf2c-d68cdbea3f15]\n",
            "\n",
            "2024-12-30T03:58:58.970Z: Serverless compute\n",
            "- Workflow [Entity Event] took 0:00:38.434589, used credits [0.06919828]\n",
            "- CONTENT [0341d367-6775-4e57-9a3d-7904d813f243]\n",
            "\n",
            "2024-12-30T03:58:58.895Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.240714, used credits [0.00063600]\n",
            "- CONTENT [3d78b65e-a42d-44e9-8a9a-07faf938ee0d]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [318 tokens], throughput: 1321.071 tokens/sec\n",
            "\n",
            "2024-12-30T03:58:58.888Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.234841, used credits [0.00049200]\n",
            "- CONTENT [d764f4d3-1282-441c-8e4a-08ce664b0b47]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [246 tokens], throughput: 1047.517 tokens/sec\n",
            "\n",
            "2024-12-30T03:58:58.863Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.653366, used credits [0.00166600]\n",
            "- CONTENT [7b5b7874-c84b-4607-877c-8bec0e167127]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [833 tokens], throughput: 1274.935 tokens/sec\n",
            "\n",
            "2024-12-30T03:58:58.857Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.197292, used credits [0.00063600]\n",
            "- CONTENT [3d78b65e-a42d-44e9-8a9a-07faf938ee0d]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [318 tokens], throughput: 1611.823 tokens/sec\n",
            "\n",
            "2024-12-30T03:58:58.856Z: Serverless compute\n",
            "- Workflow [Entity Event] took 0:00:38.333432, used credits [0.06901615]\n",
            "- CONTENT [f0a42b0a-353b-4f08-9a5d-40ce9196a46b]\n",
            "\n",
            "2024-12-30T03:58:58.844Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.176940, used credits [0.00049200]\n",
            "- CONTENT [d764f4d3-1282-441c-8e4a-08ce664b0b47]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [246 tokens], throughput: 1390.301 tokens/sec\n",
            "\n",
            "2024-12-30T03:58:58.823Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.564530, used credits [0.00095600]\n",
            "- CONTENT [0341d367-6775-4e57-9a3d-7904d813f243]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [478 tokens], throughput: 846.723 tokens/sec\n",
            "\n",
            "2024-12-30T03:58:58.781Z: Upload Master\n",
            "- Workflow [Ingestion] took 0:00:00.167394, used credits [0.00086235]\n",
            "- CONTENT [67150a0e-9b17-4261-8f62-1c57686d46e1]: Content type [PAGE], file type [DOCUMENT]\n",
            "- URI [https://changelog.graphlit.dev/february-2024/february-21-support-for-onedrive-and-google-drive-feeds-extract-images-from-pdfs-bug-fixes]\n",
            "- File upload [223175 bytes], throughput: 1333228.591 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:58.777Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.517468, used credits [0.00112600]\n",
            "- CONTENT [0341d367-6775-4e57-9a3d-7904d813f243]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [563 tokens], throughput: 1087.990 tokens/sec\n",
            "\n",
            "2024-12-30T03:58:58.696Z: Upload Master\n",
            "- Workflow [Ingestion] took 0:00:00.181540, used credits [0.00101625]\n",
            "- CONTENT [a937626a-37ee-4eb1-93e5-2206e9a188ec]: Content type [PAGE], file type [DOCUMENT]\n",
            "- URI [https://changelog.graphlit.dev/january-2024/january-18-support-for-content-publishing-llm-tools-clip-image-embeddings-bug-fixes]\n",
            "- File upload [263004 bytes], throughput: 1448738.570 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:58.629Z: Upload Master\n",
            "- Workflow [Ingestion] took 0:00:00.270171, used credits [0.00071423]\n",
            "- CONTENT [efb60fde-e52e-4726-893f-d58347a0deeb]: Content type [PAGE], file type [DOCUMENT]\n",
            "- URI [https://changelog.graphlit.dev/october-2024/october-22-support-for-latest-anthropic-sonnet-3.5-model-cohere-image-embeddings]\n",
            "- File upload [184842 bytes], throughput: 684167.454 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:58.561Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.631244, used credits [0.00125800]\n",
            "- CONTENT [8a9c0eb5-3658-4cca-bf2c-d68cdbea3f15]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [629 tokens], throughput: 996.444 tokens/sec\n",
            "\n",
            "2024-12-30T03:58:58.554Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.620639, used credits [0.00150600]\n",
            "- CONTENT [8a9c0eb5-3658-4cca-bf2c-d68cdbea3f15]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [753 tokens], throughput: 1213.265 tokens/sec\n",
            "\n",
            "2024-12-30T03:58:58.541Z: Serverless compute\n",
            "- Workflow [Entity Event] took 0:00:37.937542, used credits [0.06830338]\n",
            "- CONTENT [1bc9cf17-e156-441d-a307-def6a31d693e]\n",
            "\n",
            "2024-12-30T03:58:58.539Z: Serverless compute\n",
            "- Workflow [Entity Event] took 0:00:46.252268, used credits [0.08327335]\n",
            "- CONTENT [a937626a-37ee-4eb1-93e5-2206e9a188ec]\n",
            "\n",
            "2024-12-30T03:58:58.538Z: Serverless compute\n",
            "- Workflow [Entity Event] took 0:00:46.190435, used credits [0.08316203]\n",
            "- CONTENT [0932e05b-1816-4e99-a4ef-7bc475de60fc]\n",
            "\n",
            "2024-12-30T03:58:58.486Z: Upload Master\n",
            "- Workflow [Ingestion] took 0:00:00.183389, used credits [0.00092961]\n",
            "- CONTENT [d40abe32-e564-4a6c-bd34-cea90b98c172]: Content type [PAGE], file type [DOCUMENT]\n",
            "- URI [https://changelog.graphlit.dev/july-2023/july-15-support-for-sharepoint-feeds-new-conversation-features]\n",
            "- File upload [240582 bytes], throughput: 1311865.693 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:58.365Z: Upload Master\n",
            "- Workflow [Ingestion] took 0:00:00.155783, used credits [0.00095535]\n",
            "- CONTENT [7b5b7874-c84b-4607-877c-8bec0e167127]: Content type [PAGE], file type [DOCUMENT]\n",
            "- URI [https://changelog.graphlit.dev/december-2024/december-22-support-for-dropbox-box-intercom-and-zendesk-feeds-openai-o1-gemini-2.0-bug-fixes]\n",
            "- File upload [247245 bytes], throughput: 1587108.503 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:58.234Z: Serverless compute\n",
            "- Workflow [Entity Event] took 0:00:37.643079, used credits [0.06777323]\n",
            "- CONTENT [41e9b6e8-c479-4416-8ec3-7168709d2861]\n",
            "\n",
            "2024-12-30T03:58:58.232Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.316188, used credits [0.00045200]\n",
            "- CONTENT [f0a42b0a-353b-4f08-9a5d-40ce9196a46b]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [226 tokens], throughput: 714.765 tokens/sec\n",
            "\n",
            "2024-12-30T03:58:58.218Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.297150, used credits [0.00045200]\n",
            "- CONTENT [f0a42b0a-353b-4f08-9a5d-40ce9196a46b]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [226 tokens], throughput: 760.558 tokens/sec\n",
            "\n",
            "2024-12-30T03:58:58.217Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.288231, used credits [0.00063000]\n",
            "- CONTENT [0932e05b-1816-4e99-a4ef-7bc475de60fc]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [315 tokens], throughput: 1092.873 tokens/sec\n",
            "\n",
            "2024-12-30T03:58:58.215Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.631926, used credits [0.00182200]\n",
            "- CONTENT [7b5b7874-c84b-4607-877c-8bec0e167127]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [911 tokens], throughput: 1441.626 tokens/sec\n",
            "\n",
            "2024-12-30T03:58:58.215Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.360816, used credits [0.00111400]\n",
            "- CONTENT [1bc9cf17-e156-441d-a307-def6a31d693e]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [557 tokens], throughput: 1543.722 tokens/sec\n",
            "\n",
            "2024-12-30T03:58:58.211Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.279379, used credits [0.00063000]\n",
            "- CONTENT [0932e05b-1816-4e99-a4ef-7bc475de60fc]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [315 tokens], throughput: 1127.501 tokens/sec\n",
            "\n",
            "2024-12-30T03:58:58.207Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.322261, used credits [0.00138600]\n",
            "- CONTENT [1bc9cf17-e156-441d-a307-def6a31d693e]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [693 tokens], throughput: 2150.430 tokens/sec\n",
            "\n",
            "2024-12-30T03:58:58.197Z: Serverless compute\n",
            "- Workflow [Entity Event] took 0:00:40.622374, used credits [0.07313720]\n",
            "- CONTENT [0ed6b24e-fec6-4008-8bb9-beda6073cbe6]\n",
            "\n",
            "2024-12-30T03:58:58.196Z: Serverless compute\n",
            "- Workflow [Entity Event] took 0:00:41.416111, used credits [0.07456626]\n",
            "- CONTENT [d40abe32-e564-4a6c-bd34-cea90b98c172]\n",
            "\n",
            "2024-12-30T03:58:58.177Z: Upload Master\n",
            "- Workflow [Ingestion] took 0:00:00.148741, used credits [0.00072852]\n",
            "- CONTENT [f0a42b0a-353b-4f08-9a5d-40ce9196a46b]: Content type [PAGE], file type [DOCUMENT]\n",
            "- URI [https://changelog.graphlit.dev/october-2024/october-31-support-for-simulated-tool-calling-bug-fixes]\n",
            "- File upload [188541 bytes], throughput: 1267576.658 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:58.031Z: Upload Master\n",
            "- Workflow [Ingestion] took 0:00:00.150893, used credits [0.00077804]\n",
            "- CONTENT [b96def70-f8ed-4c72-9757-a1648306835a]: Content type [PAGE], file type [DOCUMENT]\n",
            "- URI [https://changelog.graphlit.dev/september-2024/september-1-support-for-fhir-enrichment-latest-cohere-models-bug-fixes]\n",
            "- File upload [201356 bytes], throughput: 1334425.495 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:57.968Z: Upload Master\n",
            "- Workflow [Ingestion] took 0:00:00.639811, used credits [0.00082172]\n",
            "- CONTENT [5345f273-4dcb-4f44-a1a3-4226ff5eaed8]: Content type [PAGE], file type [DOCUMENT]\n",
            "- URI [https://changelog.graphlit.dev/september-2023/september-20-paid-subscription-plans-support-for-custom-observed-entities-and-azure-openai-gpt-4]\n",
            "- File upload [212661 bytes], throughput: 332380.969 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:57.965Z: Upload Master\n",
            "- Workflow [Ingestion] took 0:00:00.567688, used credits [0.00081770]\n",
            "- CONTENT [4adced81-1014-450d-9e42-e81ec370a757]: Content type [PAGE], file type [DOCUMENT]\n",
            "- URI [https://changelog.graphlit.dev/october-2023/october-30-optimized-conversation-responses-added-observable-aliases-bug-fixes]\n",
            "- File upload [211620 bytes], throughput: 372775.055 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:57.961Z: Upload Master\n",
            "- Workflow [Ingestion] took 0:00:00.549308, used credits [0.00077201]\n",
            "- CONTENT [0932e05b-1816-4e99-a4ef-7bc475de60fc]: Content type [PAGE], file type [DOCUMENT]\n",
            "- URI [https://changelog.graphlit.dev/february-2024/february-2-support-for-semantic-alerts-openai-0125-models-performance-enhancements-bug-fixes]\n",
            "- File upload [199796 bytes], throughput: 363723.151 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:57.956Z: Upload Master\n",
            "- Workflow [Ingestion] took 0:00:00.503420, used credits [0.00086914]\n",
            "- CONTENT [1bc9cf17-e156-441d-a307-def6a31d693e]: Content type [PAGE], file type [DOCUMENT]\n",
            "- URI [https://changelog.graphlit.dev/may-2024/may-5-support-for-jina-and-pongo-rerankers-microsoft-teams-feed-new-youtube-downloader-bug-fixes]\n",
            "- File upload [224932 bytes], throughput: 446807.568 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:57.949Z: Upload Master\n",
            "- Workflow [Ingestion] took 0:00:00.442060, used credits [0.00076717]\n",
            "- CONTENT [3d78b65e-a42d-44e9-8a9a-07faf938ee0d]: Content type [PAGE], file type [DOCUMENT]\n",
            "- URI [https://changelog.graphlit.dev/march-2024/march-23-support-for-linear-github-issues-and-jira-issue-feeds-ingest-files-via-web-feed-sitemap]\n",
            "- File upload [198543 bytes], throughput: 449131.136 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:57.949Z: Upload Master\n",
            "- Workflow [Ingestion] took 0:00:00.384904, used credits [0.00072178]\n",
            "- CONTENT [02c635c4-808d-495e-9744-bb501a2066e8]: Content type [PAGE], file type [DOCUMENT]\n",
            "- URI [https://changelog.graphlit.dev/september-2024/september-30-support-for-azure-ai-inference-models-mistral-pixtral-and-latest-google-gemini-models]\n",
            "- File upload [186797 bytes], throughput: 485308.403 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:57.947Z: Upload Master\n",
            "- Workflow [Ingestion] took 0:00:00.578146, used credits [0.00073817]\n",
            "- CONTENT [4eff5e88-2cf6-489f-9bfb-52b30823e07e]: Content type [PAGE], file type [DOCUMENT]\n",
            "- URI [https://changelog.graphlit.dev/december-2024/december-1-support-for-retrieval-only-rag-pipeline-bug-fixes]\n",
            "- File upload [191038 bytes], throughput: 330431.820 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:57.940Z: Upload Master\n",
            "- Workflow [Ingestion] took 0:00:00.426560, used credits [0.00082131]\n",
            "- CONTENT [865f424b-fa74-4640-b593-a9840336a452]: Content type [PAGE], file type [DOCUMENT]\n",
            "- URI [https://changelog.graphlit.dev/september-2024/september-26-support-for-google-ai-and-cerebras-models-and-latest-groq-models]\n",
            "- File upload [212555 bytes], throughput: 498300.240 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:57.919Z: Serverless compute\n",
            "- Workflow [Entity Event] took 0:00:37.369170, used credits [0.06728008]\n",
            "- CONTENT [4adced81-1014-450d-9e42-e81ec370a757]\n",
            "\n",
            "2024-12-30T03:58:57.870Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.482868, used credits [0.00069600]\n",
            "- CONTENT [41e9b6e8-c479-4416-8ec3-7168709d2861]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [348 tokens], throughput: 720.694 tokens/sec\n",
            "\n",
            "2024-12-30T03:58:57.863Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.657260, used credits [0.00239200]\n",
            "- CONTENT [a937626a-37ee-4eb1-93e5-2206e9a188ec]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [1196 tokens], throughput: 1819.675 tokens/sec\n",
            "\n",
            "2024-12-30T03:58:57.818Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.426012, used credits [0.00069600]\n",
            "- CONTENT [41e9b6e8-c479-4416-8ec3-7168709d2861]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [348 tokens], throughput: 816.879 tokens/sec\n",
            "\n",
            "2024-12-30T03:58:57.815Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.461930, used credits [0.00310800]\n",
            "- CONTENT [a937626a-37ee-4eb1-93e5-2206e9a188ec]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [1554 tokens], throughput: 3364.147 tokens/sec\n",
            "\n",
            "2024-12-30T03:58:57.814Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.459453, used credits [0.00139200]\n",
            "- CONTENT [d40abe32-e564-4a6c-bd34-cea90b98c172]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [696 tokens], throughput: 1514.846 tokens/sec\n",
            "\n",
            "2024-12-30T03:58:57.804Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.452113, used credits [0.00063400]\n",
            "- CONTENT [0ed6b24e-fec6-4008-8bb9-beda6073cbe6]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [317 tokens], throughput: 701.153 tokens/sec\n",
            "\n",
            "2024-12-30T03:58:57.610Z: Web capture\n",
            "- Workflow [Preparation] took 0:00:17.879477, used credits [0.03800000]\n",
            "- CONTENT [a937626a-37ee-4eb1-93e5-2206e9a188ec]\n",
            "- Processor name [Browserless], units [1]\n",
            "\n",
            "2024-12-30T03:58:57.586Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.209841, used credits [0.00074800]\n",
            "- CONTENT [4adced81-1014-450d-9e42-e81ec370a757]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [374 tokens], throughput: 1782.304 tokens/sec\n",
            "\n",
            "2024-12-30T03:58:57.582Z: Web capture\n",
            "- Workflow [Preparation] took 0:00:17.847173, used credits [0.03800000]\n",
            "- CONTENT [67150a0e-9b17-4261-8f62-1c57686d46e1]\n",
            "- Processor name [Browserless], units [1]\n",
            "\n",
            "2024-12-30T03:58:57.562Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.183256, used credits [0.00074800]\n",
            "- CONTENT [4adced81-1014-450d-9e42-e81ec370a757]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [374 tokens], throughput: 2040.861 tokens/sec\n",
            "\n",
            "2024-12-30T03:58:57.559Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.217412, used credits [0.00111000]\n",
            "- CONTENT [d40abe32-e564-4a6c-bd34-cea90b98c172]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [555 tokens], throughput: 2552.762 tokens/sec\n",
            "\n",
            "2024-12-30T03:58:57.557Z: Web capture\n",
            "- Workflow [Preparation] took 0:00:17.827715, used credits [0.03800000]\n",
            "- CONTENT [7b5b7874-c84b-4607-877c-8bec0e167127]\n",
            "- Processor name [Browserless], units [1]\n",
            "\n",
            "2024-12-30T03:58:57.484Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.331143, used credits [0.00063400]\n",
            "- CONTENT [0ed6b24e-fec6-4008-8bb9-beda6073cbe6]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [317 tokens], throughput: 957.291 tokens/sec\n",
            "\n",
            "2024-12-30T03:58:57.456Z: Web capture\n",
            "- Workflow [Preparation] took 0:00:17.723177, used credits [0.03800000]\n",
            "- CONTENT [d40abe32-e564-4a6c-bd34-cea90b98c172]\n",
            "- Processor name [Browserless], units [1]\n",
            "\n",
            "2024-12-30T03:58:57.417Z: Web capture\n",
            "- Workflow [Preparation] took 0:00:17.687367, used credits [0.03800000]\n",
            "- CONTENT [f0a42b0a-353b-4f08-9a5d-40ce9196a46b]\n",
            "- Processor name [Browserless], units [1]\n",
            "\n",
            "2024-12-30T03:58:57.365Z: Web capture\n",
            "- Workflow [Preparation] took 0:00:17.345001, used credits [0.03800000]\n",
            "- CONTENT [efb60fde-e52e-4726-893f-d58347a0deeb]\n",
            "- Processor name [Browserless], units [1]\n",
            "\n",
            "2024-12-30T03:58:57.231Z: Web capture\n",
            "- Workflow [Preparation] took 0:00:17.284474, used credits [0.03800000]\n",
            "- CONTENT [b96def70-f8ed-4c72-9757-a1648306835a]\n",
            "- Processor name [Browserless], units [1]\n",
            "\n",
            "2024-12-30T03:58:56.955Z: Serverless compute\n",
            "- Workflow [Entity Event] took 0:00:46.609138, used credits [0.08391587]\n",
            "- CONTENT [4eff5e88-2cf6-489f-9bfb-52b30823e07e]\n",
            "\n",
            "2024-12-30T03:58:56.709Z: Serverless compute\n",
            "- Workflow [Entity Event] took 0:00:43.661890, used credits [0.07860959]\n",
            "- CONTENT [7c8442ac-7d94-4a40-9a3b-fdda07048992]\n",
            "\n",
            "2024-12-30T03:58:56.577Z: Web capture\n",
            "- Workflow [Preparation] took 0:00:16.843948, used credits [0.03800000]\n",
            "- CONTENT [1bc9cf17-e156-441d-a307-def6a31d693e]\n",
            "- Processor name [Browserless], units [1]\n",
            "\n",
            "2024-12-30T03:58:56.508Z: Web capture\n",
            "- Workflow [Preparation] took 0:00:16.769188, used credits [0.03800000]\n",
            "- CONTENT [3d78b65e-a42d-44e9-8a9a-07faf938ee0d]\n",
            "- Processor name [Browserless], units [1]\n",
            "\n",
            "2024-12-30T03:58:56.484Z: Web capture\n",
            "- Workflow [Preparation] took 0:00:16.748094, used credits [0.03800000]\n",
            "- CONTENT [4eff5e88-2cf6-489f-9bfb-52b30823e07e]\n",
            "- Processor name [Browserless], units [1]\n",
            "\n",
            "2024-12-30T03:58:56.483Z: Web capture\n",
            "- Workflow [Preparation] took 0:00:16.752440, used credits [0.03800000]\n",
            "- CONTENT [0932e05b-1816-4e99-a4ef-7bc475de60fc]\n",
            "- Processor name [Browserless], units [1]\n",
            "\n",
            "2024-12-30T03:58:56.482Z: Web capture\n",
            "- Workflow [Preparation] took 0:00:16.440587, used credits [0.03800000]\n",
            "- CONTENT [865f424b-fa74-4640-b593-a9840336a452]\n",
            "- Processor name [Browserless], units [1]\n",
            "\n",
            "2024-12-30T03:58:56.453Z: Web capture\n",
            "- Workflow [Preparation] took 0:00:16.679813, used credits [0.03800000]\n",
            "- CONTENT [4adced81-1014-450d-9e42-e81ec370a757]\n",
            "- Processor name [Browserless], units [1]\n",
            "\n",
            "2024-12-30T03:58:56.398Z: Web capture\n",
            "- Workflow [Preparation] took 0:00:16.462646, used credits [0.03800000]\n",
            "- CONTENT [5345f273-4dcb-4f44-a1a3-4226ff5eaed8]\n",
            "- Processor name [Browserless], units [1]\n",
            "\n",
            "2024-12-30T03:58:56.317Z: Web capture\n",
            "- Workflow [Preparation] took 0:00:16.471767, used credits [0.03800000]\n",
            "- CONTENT [02c635c4-808d-495e-9744-bb501a2066e8]\n",
            "- Processor name [Browserless], units [1]\n",
            "\n",
            "2024-12-30T03:58:55.967Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.485099, used credits [0.00039400]\n",
            "- CONTENT [4eff5e88-2cf6-489f-9bfb-52b30823e07e]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [197 tokens], throughput: 406.103 tokens/sec\n",
            "\n",
            "2024-12-30T03:58:55.811Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.327308, used credits [0.00039400]\n",
            "- CONTENT [4eff5e88-2cf6-489f-9bfb-52b30823e07e]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [197 tokens], throughput: 601.879 tokens/sec\n",
            "\n",
            "2024-12-30T03:58:55.808Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.360596, used credits [0.00059400]\n",
            "- CONTENT [7c8442ac-7d94-4a40-9a3b-fdda07048992]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [297 tokens], throughput: 823.637 tokens/sec\n",
            "\n",
            "2024-12-30T03:58:55.806Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.357334, used credits [0.00059400]\n",
            "- CONTENT [7c8442ac-7d94-4a40-9a3b-fdda07048992]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [297 tokens], throughput: 831.156 tokens/sec\n",
            "\n",
            "2024-12-30T03:58:55.283Z: Serverless compute\n",
            "- Workflow [Entity Event] took 0:00:44.805147, used credits [0.08066793]\n",
            "- CONTENT [253c57c2-3536-4a73-aa76-101372e74b0e]\n",
            "\n",
            "2024-12-30T03:58:54.536Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.341586, used credits [0.00126800]\n",
            "- CONTENT [253c57c2-3536-4a73-aa76-101372e74b0e]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [634 tokens], throughput: 1856.046 tokens/sec\n",
            "\n",
            "2024-12-30T03:58:54.378Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.415395, used credits [0.00107200]\n",
            "- CONTENT [253c57c2-3536-4a73-aa76-101372e74b0e]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [536 tokens], throughput: 1290.337 tokens/sec\n",
            "\n",
            "2024-12-30T03:58:54.259Z: Upload Mezzanine\n",
            "- Workflow [Preparation] took 0:00:00.214762, used credits [0.00001046]\n",
            "- CONTENT [3d78b65e-a42d-44e9-8a9a-07faf938ee0d]: Content type [PAGE], file type [DATA]\n",
            "- File upload [2707 bytes], throughput: 12604.680 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:54.247Z: Upload Mezzanine\n",
            "- Workflow [Preparation] took 0:00:00.539978, used credits [0.00000663]\n",
            "- CONTENT [b682b0ca-255c-4b02-b016-cb56f05edb64]: Content type [PAGE], file type [DATA]\n",
            "- File upload [1717 bytes], throughput: 3179.760 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:53.755Z: Serverless compute\n",
            "- Workflow [Entity Event] took 0:00:41.481051, used credits [0.07468318]\n",
            "- CONTENT [67150a0e-9b17-4261-8f62-1c57686d46e1]\n",
            "\n",
            "2024-12-30T03:58:53.648Z: Upload Mezzanine\n",
            "- Workflow [Preparation] took 0:00:00.096125, used credits [0.00001223]\n",
            "- CONTENT [257dc6c9-65d0-416d-9b1c-d412aeb42bd4]: Content type [PAGE], file type [DATA]\n",
            "- File upload [3165 bytes], throughput: 32925.775 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:53.524Z: Upload Mezzanine\n",
            "- Workflow [Preparation] took 0:00:00.087792, used credits [0.00000764]\n",
            "- CONTENT [d764f4d3-1282-441c-8e4a-08ce664b0b47]: Content type [PAGE], file type [DATA]\n",
            "- File upload [1976 bytes], throughput: 22507.720 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:53.456Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.875605, used credits [0.00146200]\n",
            "- CONTENT [67150a0e-9b17-4261-8f62-1c57686d46e1]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [731 tokens], throughput: 834.851 tokens/sec\n",
            "\n",
            "2024-12-30T03:58:53.117Z: Upload Mezzanine\n",
            "- Workflow [Preparation] took 0:00:00.115325, used credits [0.00001357]\n",
            "- CONTENT [41e9b6e8-c479-4416-8ec3-7168709d2861]: Content type [PAGE], file type [DATA]\n",
            "- File upload [3512 bytes], throughput: 30453.173 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:52.764Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.193958, used credits [0.00130800]\n",
            "- CONTENT [67150a0e-9b17-4261-8f62-1c57686d46e1]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [654 tokens], throughput: 3371.869 tokens/sec\n",
            "\n",
            "2024-12-30T03:58:52.721Z: Upload Mezzanine\n",
            "- Workflow [Preparation] took 0:00:00.078310, used credits [0.00000793]\n",
            "- CONTENT [f0a42b0a-353b-4f08-9a5d-40ce9196a46b]: Content type [PAGE], file type [DATA]\n",
            "- File upload [2053 bytes], throughput: 26216.253 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:52.720Z: Upload Mezzanine\n",
            "- Workflow [Preparation] took 0:00:00.080135, used credits [0.00002560]\n",
            "- CONTENT [7b5b7874-c84b-4607-877c-8bec0e167127]: Content type [PAGE], file type [DATA]\n",
            "- File upload [6624 bytes], throughput: 82660.820 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:52.610Z: Upload Mezzanine\n",
            "- Workflow [Preparation] took 0:00:00.058828, used credits [0.00001167]\n",
            "- CONTENT [0932e05b-1816-4e99-a4ef-7bc475de60fc]: Content type [PAGE], file type [DATA]\n",
            "- File upload [3020 bytes], throughput: 51335.924 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:52.574Z: Serverless compute\n",
            "- Workflow [Entity Event] took 0:00:42.771354, used credits [0.07700626]\n",
            "- CONTENT [52613eca-1a5a-40ae-91b0-3d8243a55439]\n",
            "\n",
            "2024-12-30T03:58:52.551Z: Upload Mezzanine\n",
            "- Workflow [Preparation] took 0:00:00.082168, used credits [0.00001608]\n",
            "- CONTENT [4adced81-1014-450d-9e42-e81ec370a757]: Content type [PAGE], file type [DATA]\n",
            "- File upload [4161 bytes], throughput: 50639.905 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:52.548Z: Serverless compute\n",
            "- Workflow [Entity Event] took 0:00:42.848982, used credits [0.07714602]\n",
            "- CONTENT [8443a72b-f798-4325-b0ac-b821d4e7dea8]\n",
            "\n",
            "2024-12-30T03:58:52.546Z: Serverless compute\n",
            "- Workflow [Entity Event] took 0:00:42.502631, used credits [0.07652245]\n",
            "- CONTENT [fbde99f0-f7ca-4f5d-a318-eb7f4de07912]\n",
            "\n",
            "2024-12-30T03:58:52.443Z: Serverless compute\n",
            "- Workflow [Entity Event] took 0:00:34.850263, used credits [0.06274499]\n",
            "- CONTENT [ebda0578-6209-4833-9bee-36d0050dc5ee]\n",
            "\n",
            "2024-12-30T03:58:52.422Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.526046, used credits [0.00143000]\n",
            "- CONTENT [52613eca-1a5a-40ae-91b0-3d8243a55439]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [715 tokens], throughput: 1359.196 tokens/sec\n",
            "\n",
            "2024-12-30T03:58:52.411Z: Upload Mezzanine\n",
            "- Workflow [Preparation] took 0:00:00.092118, used credits [0.00002022]\n",
            "- CONTENT [8a9c0eb5-3658-4cca-bf2c-d68cdbea3f15]: Content type [PAGE], file type [DATA]\n",
            "- File upload [5234 bytes], throughput: 56818.120 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:52.274Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.710200, used credits [0.00046400]\n",
            "- CONTENT [fbde99f0-f7ca-4f5d-a318-eb7f4de07912]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [232 tokens], throughput: 326.669 tokens/sec\n",
            "\n",
            "2024-12-30T03:58:52.151Z: Upload Mezzanine\n",
            "- Workflow [Preparation] took 0:00:00.096629, used credits [0.00002005]\n",
            "- CONTENT [1bc9cf17-e156-441d-a307-def6a31d693e]: Content type [PAGE], file type [DATA]\n",
            "- File upload [5189 bytes], throughput: 53700.402 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:52.119Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.216706, used credits [0.00155000]\n",
            "- CONTENT [8443a72b-f798-4325-b0ac-b821d4e7dea8]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [775 tokens], throughput: 3576.280 tokens/sec\n",
            "\n",
            "2024-12-30T03:58:52.097Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.207152, used credits [0.00137200]\n",
            "- CONTENT [8443a72b-f798-4325-b0ac-b821d4e7dea8]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [686 tokens], throughput: 3311.581 tokens/sec\n",
            "\n",
            "2024-12-30T03:58:52.046Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.782952, used credits [0.00136800]\n",
            "- CONTENT [ebda0578-6209-4833-9bee-36d0050dc5ee]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [684 tokens], throughput: 873.616 tokens/sec\n",
            "\n",
            "2024-12-30T03:58:52.041Z: Upload Mezzanine\n",
            "- Workflow [Preparation] took 0:00:00.117274, used credits [0.00001352]\n",
            "- CONTENT [0341d367-6775-4e57-9a3d-7904d813f243]: Content type [PAGE], file type [DATA]\n",
            "- File upload [3499 bytes], throughput: 29836.187 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:52.041Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.467664, used credits [0.00046400]\n",
            "- CONTENT [fbde99f0-f7ca-4f5d-a318-eb7f4de07912]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [232 tokens], throughput: 496.082 tokens/sec\n",
            "\n",
            "2024-12-30T03:58:52.040Z: Serverless compute\n",
            "- Workflow [Entity Event] took 0:00:42.529442, used credits [0.07657072]\n",
            "- CONTENT [a0d556d6-0bbc-4df0-9577-bb621d9c6fc2]\n",
            "\n",
            "2024-12-30T03:58:52.034Z: Upload Mezzanine\n",
            "- Workflow [Preparation] took 0:00:00.073539, used credits [0.00003752]\n",
            "- CONTENT [a937626a-37ee-4eb1-93e5-2206e9a188ec]: Content type [PAGE], file type [DATA]\n",
            "- File upload [9709 bytes], throughput: 132024.645 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:51.979Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.369741, used credits [0.00124200]\n",
            "- CONTENT [52613eca-1a5a-40ae-91b0-3d8243a55439]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [621 tokens], throughput: 1679.553 tokens/sec\n",
            "\n",
            "2024-12-30T03:58:51.898Z: Serverless compute\n",
            "- Workflow [Entity Event] took 0:00:41.657203, used credits [0.07500032]\n",
            "- CONTENT [f2817947-a5aa-41d7-a297-b6f16a2d42e1]\n",
            "\n",
            "2024-12-30T03:58:51.733Z: Serverless compute\n",
            "- Workflow [Entity Event] took 0:00:41.497136, used credits [0.07471214]\n",
            "- CONTENT [a263132e-7225-40d3-a75d-39b3ef1edbd1]\n",
            "\n",
            "2024-12-30T03:58:51.676Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.874906, used credits [0.00214200]\n",
            "- CONTENT [f2817947-a5aa-41d7-a297-b6f16a2d42e1]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [1071 tokens], throughput: 1224.132 tokens/sec\n",
            "\n",
            "2024-12-30T03:58:51.591Z: Upload Mezzanine\n",
            "- Workflow [Preparation] took 0:00:00.107545, used credits [0.00002159]\n",
            "- CONTENT [d40abe32-e564-4a6c-bd34-cea90b98c172]: Content type [PAGE], file type [DATA]\n",
            "- File upload [5588 bytes], throughput: 51959.838 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:51.570Z: Serverless compute\n",
            "- Workflow [Entity Event] took 0:00:41.754974, used credits [0.07517635]\n",
            "- CONTENT [3923639b-14f1-484b-86e7-7c6f6e67461d]\n",
            "\n",
            "2024-12-30T03:58:51.552Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.291585, used credits [0.00125000]\n",
            "- CONTENT [ebda0578-6209-4833-9bee-36d0050dc5ee]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [625 tokens], throughput: 2143.460 tokens/sec\n",
            "\n",
            "2024-12-30T03:58:51.548Z: Upload Mezzanine\n",
            "- Workflow [Preparation] took 0:00:00.110960, used credits [0.00001000]\n",
            "- CONTENT [0ed6b24e-fec6-4008-8bb9-beda6073cbe6]: Content type [PAGE], file type [DATA]\n",
            "- File upload [2588 bytes], throughput: 23323.741 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:51.543Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.707062, used credits [0.00087000]\n",
            "- CONTENT [a263132e-7225-40d3-a75d-39b3ef1edbd1]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [435 tokens], throughput: 615.222 tokens/sec\n",
            "\n",
            "2024-12-30T03:58:51.426Z: Serverless compute\n",
            "- Workflow [Entity Event] took 0:00:41.623387, used credits [0.07493944]\n",
            "- CONTENT [1a8c6b11-f325-47e9-bb39-643f7fb92154]\n",
            "\n",
            "2024-12-30T03:58:51.386Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.598118, used credits [0.00114000]\n",
            "- CONTENT [3923639b-14f1-484b-86e7-7c6f6e67461d]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [570 tokens], throughput: 952.988 tokens/sec\n",
            "\n",
            "2024-12-30T03:58:51.380Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.555429, used credits [0.00087000]\n",
            "- CONTENT [a263132e-7225-40d3-a75d-39b3ef1edbd1]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [435 tokens], throughput: 783.179 tokens/sec\n",
            "\n",
            "2024-12-30T03:58:51.301Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.519471, used credits [0.00097200]\n",
            "- CONTENT [3923639b-14f1-484b-86e7-7c6f6e67461d]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [486 tokens], throughput: 935.567 tokens/sec\n",
            "\n",
            "2024-12-30T03:58:51.301Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.495010, used credits [0.00098000]\n",
            "- CONTENT [a0d556d6-0bbc-4df0-9577-bb621d9c6fc2]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [490 tokens], throughput: 989.879 tokens/sec\n",
            "\n",
            "2024-12-30T03:58:51.297Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.463932, used credits [0.00120000]\n",
            "- CONTENT [a0d556d6-0bbc-4df0-9577-bb621d9c6fc2]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [600 tokens], throughput: 1293.293 tokens/sec\n",
            "\n",
            "2024-12-30T03:58:51.286Z: Serverless compute\n",
            "- Workflow [Entity Event] took 0:00:41.478870, used credits [0.07467925]\n",
            "- CONTENT [9ded6f5c-a667-442d-8848-30d7a22e79e0]\n",
            "\n",
            "2024-12-30T03:58:51.132Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.339196, used credits [0.00166800]\n",
            "- CONTENT [f2817947-a5aa-41d7-a297-b6f16a2d42e1]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [834 tokens], throughput: 2458.757 tokens/sec\n",
            "\n",
            "2024-12-30T03:58:51.009Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.380461, used credits [0.00059400]\n",
            "- CONTENT [1a8c6b11-f325-47e9-bb39-643f7fb92154]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [297 tokens], throughput: 780.633 tokens/sec\n",
            "\n",
            "2024-12-30T03:58:50.810Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.249481, used credits [0.00048400]\n",
            "- CONTENT [9ded6f5c-a667-442d-8848-30d7a22e79e0]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [242 tokens], throughput: 970.015 tokens/sec\n",
            "\n",
            "2024-12-30T03:58:50.808Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.592708, used credits [0.00048400]\n",
            "- CONTENT [9ded6f5c-a667-442d-8848-30d7a22e79e0]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [242 tokens], throughput: 408.296 tokens/sec\n",
            "\n",
            "2024-12-30T03:58:50.669Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.344780, used credits [0.00059400]\n",
            "- CONTENT [1a8c6b11-f325-47e9-bb39-643f7fb92154]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [297 tokens], throughput: 861.418 tokens/sec\n",
            "\n",
            "2024-12-30T03:58:50.037Z: Upload Mezzanine\n",
            "- Workflow [Preparation] took 0:00:00.134180, used credits [0.00000795]\n",
            "- CONTENT [4eff5e88-2cf6-489f-9bfb-52b30823e07e]: Content type [PAGE], file type [DATA]\n",
            "- File upload [2058 bytes], throughput: 15337.560 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:50.024Z: Serverless compute\n",
            "- Workflow [Entity Event] took 0:00:40.075969, used credits [0.07215344]\n",
            "- CONTENT [5da3504c-5d1d-4b5c-848e-d3ddb11f3964]\n",
            "\n",
            "2024-12-30T03:58:49.596Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.684493, used credits [0.00052400]\n",
            "- CONTENT [5da3504c-5d1d-4b5c-848e-d3ddb11f3964]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [262 tokens], throughput: 382.765 tokens/sec\n",
            "\n",
            "2024-12-30T03:58:49.577Z: Upload Mezzanine\n",
            "- Workflow [Preparation] took 0:00:00.081121, used credits [0.00001084]\n",
            "- CONTENT [7c8442ac-7d94-4a40-9a3b-fdda07048992]: Content type [PAGE], file type [DATA]\n",
            "- File upload [2805 bytes], throughput: 34578.104 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:49.439Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.521106, used credits [0.00052400]\n",
            "- CONTENT [5da3504c-5d1d-4b5c-848e-d3ddb11f3964]: Content type [PAGE], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [262 tokens], throughput: 502.777 tokens/sec\n",
            "\n",
            "2024-12-30T03:58:47.674Z: Upload Mezzanine\n",
            "- Workflow [Preparation] took 0:00:00.135390, used credits [0.00002153]\n",
            "- CONTENT [67150a0e-9b17-4261-8f62-1c57686d46e1]: Content type [PAGE], file type [DATA]\n",
            "- File upload [5572 bytes], throughput: 41155.121 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:47.500Z: Upload Mezzanine\n",
            "- Workflow [Preparation] took 0:00:00.068486, used credits [0.00001633]\n",
            "- CONTENT [253c57c2-3536-4a73-aa76-101372e74b0e]: Content type [PAGE], file type [DATA]\n",
            "- File upload [4226 bytes], throughput: 61706.042 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:45.869Z: Upload Mezzanine\n",
            "- Workflow [Preparation] took 0:00:00.084028, used credits [0.00001948]\n",
            "- CONTENT [ebda0578-6209-4833-9bee-36d0050dc5ee]: Content type [PAGE], file type [DATA]\n",
            "- File upload [5041 bytes], throughput: 59992.050 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:45.384Z: Upload Mezzanine\n",
            "- Workflow [Preparation] took 0:00:00.094658, used credits [0.00002253]\n",
            "- CONTENT [8443a72b-f798-4325-b0ac-b821d4e7dea8]: Content type [PAGE], file type [DATA]\n",
            "- File upload [5830 bytes], throughput: 61590.471 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:45.126Z: Upload Mezzanine\n",
            "- Workflow [Preparation] took 0:00:00.396186, used credits [0.00001635]\n",
            "- CONTENT [3923639b-14f1-484b-86e7-7c6f6e67461d]: Content type [PAGE], file type [DATA]\n",
            "- File upload [4231 bytes], throughput: 10679.341 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:44.851Z: Upload Mezzanine\n",
            "- Workflow [Preparation] took 0:00:00.132073, used credits [0.00001074]\n",
            "- CONTENT [1a8c6b11-f325-47e9-bb39-643f7fb92154]: Content type [PAGE], file type [DATA]\n",
            "- File upload [2779 bytes], throughput: 21041.346 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:44.738Z: Upload Mezzanine\n",
            "- Workflow [Preparation] took 0:00:00.208131, used credits [0.00000906]\n",
            "- CONTENT [fbde99f0-f7ca-4f5d-a318-eb7f4de07912]: Content type [PAGE], file type [DATA]\n",
            "- File upload [2345 bytes], throughput: 11266.937 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:44.382Z: Upload Mezzanine\n",
            "- Workflow [Preparation] took 0:00:00.081919, used credits [0.00001948]\n",
            "- CONTENT [52613eca-1a5a-40ae-91b0-3d8243a55439]: Content type [PAGE], file type [DATA]\n",
            "- File upload [5041 bytes], throughput: 61536.396 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:44.321Z: Upload Mezzanine\n",
            "- Workflow [Preparation] took 0:00:00.057330, used credits [0.00002728]\n",
            "- CONTENT [f2817947-a5aa-41d7-a297-b6f16a2d42e1]: Content type [PAGE], file type [DATA]\n",
            "- File upload [7060 bytes], throughput: 123147.124 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:44.217Z: Upload Mezzanine\n",
            "- Workflow [Preparation] took 0:00:00.075560, used credits [0.00001454]\n",
            "- CONTENT [a263132e-7225-40d3-a75d-39b3ef1edbd1]: Content type [PAGE], file type [DATA]\n",
            "- File upload [3764 bytes], throughput: 49814.387 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:44.215Z: Upload Mezzanine\n",
            "- Workflow [Preparation] took 0:00:00.075072, used credits [0.00001627]\n",
            "- CONTENT [a0d556d6-0bbc-4df0-9577-bb621d9c6fc2]: Content type [PAGE], file type [DATA]\n",
            "- File upload [4211 bytes], throughput: 56092.668 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:44.214Z: Upload Mezzanine\n",
            "- Workflow [Preparation] took 0:00:00.102079, used credits [0.00000946]\n",
            "- CONTENT [5da3504c-5d1d-4b5c-848e-d3ddb11f3964]: Content type [PAGE], file type [DATA]\n",
            "- File upload [2447 bytes], throughput: 23971.630 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:44.214Z: Upload Mezzanine\n",
            "- Workflow [Preparation] took 0:00:00.093501, used credits [0.00000811]\n",
            "- CONTENT [9ded6f5c-a667-442d-8848-30d7a22e79e0]: Content type [PAGE], file type [DATA]\n",
            "- File upload [2098 bytes], throughput: 22438.143 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:43.810Z: Upload Master\n",
            "- Workflow [Ingestion] took 0:00:00.974056, used credits [0.00076717]\n",
            "- CONTENT [3d78b65e-a42d-44e9-8a9a-07faf938ee0d]: Content type [PAGE], file type [DOCUMENT]\n",
            "- URI [https://changelog.graphlit.dev/march-2024/march-23-support-for-linear-github-issues-and-jira-issue-feeds-ingest-files-via-web-feed-sitemap]\n",
            "- File upload [198543 bytes], throughput: 203831.259 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:43.808Z: Upload Master\n",
            "- Workflow [Ingestion] took 0:00:01.018650, used credits [0.00072098]\n",
            "- CONTENT [d764f4d3-1282-441c-8e4a-08ce664b0b47]: Content type [PAGE], file type [DOCUMENT]\n",
            "- URI [https://changelog.graphlit.dev/november-2024/november-16-support-for-image-description-multi-turn-text-summarization]\n",
            "- File upload [186590 bytes], throughput: 183173.826 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:43.066Z: Upload Master\n",
            "- Workflow [Ingestion] took 0:00:00.734022, used credits [0.00075609]\n",
            "- CONTENT [0341d367-6775-4e57-9a3d-7904d813f243]: Content type [PAGE], file type [DOCUMENT]\n",
            "- URI [https://changelog.graphlit.dev/november-2024/november-10-support-for-web-search-multi-turn-content-summarization-deepgram-language-detection]\n",
            "- File upload [195675 bytes], throughput: 266579.276 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:42.607Z: Upload Master\n",
            "- Workflow [Ingestion] took 0:00:00.930082, used credits [0.00081390]\n",
            "- CONTENT [4adced81-1014-450d-9e42-e81ec370a757]: Content type [PAGE], file type [DOCUMENT]\n",
            "- URI [https://changelog.graphlit.dev/october-2023/october-30-optimized-conversation-responses-added-observable-aliases-bug-fixes]\n",
            "- File upload [210637 bytes], throughput: 226471.381 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:42.278Z: Upload Master\n",
            "- Workflow [Ingestion] took 0:00:00.914560, used credits [0.00080377]\n",
            "- CONTENT [41e9b6e8-c479-4416-8ec3-7168709d2861]: Content type [PAGE], file type [DOCUMENT]\n",
            "- URI [https://changelog.graphlit.dev/july-2024/july-4-support-for-webhook-alerts-keywords-summarization-deepseek-128k-context-window-bug-fixes]\n",
            "- File upload [208016 bytes], throughput: 227449.240 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:42.262Z: Upload Master\n",
            "- Workflow [Ingestion] took 0:00:00.613742, used credits [0.00071865]\n",
            "- CONTENT [b682b0ca-255c-4b02-b016-cb56f05edb64]: Content type [PAGE], file type [DOCUMENT]\n",
            "- URI [https://changelog.graphlit.dev/march-2024/march-13-support-for-claude-3-haiku-model-direct-ingestion-of-base64-encoded-files]\n",
            "- File upload [185986 bytes], throughput: 303035.882 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:42.238Z: Upload Master\n",
            "- Workflow [Ingestion] took 0:00:00.601153, used credits [0.00072809]\n",
            "- CONTENT [f0a42b0a-353b-4f08-9a5d-40ce9196a46b]: Content type [PAGE], file type [DOCUMENT]\n",
            "- URI [https://changelog.graphlit.dev/october-2024/october-31-support-for-simulated-tool-calling-bug-fixes]\n",
            "- File upload [188428 bytes], throughput: 313444.123 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:42.215Z: Upload Master\n",
            "- Workflow [Ingestion] took 0:00:00.614624, used credits [0.00076012]\n",
            "- CONTENT [0ed6b24e-fec6-4008-8bb9-beda6073cbe6]: Content type [PAGE], file type [DOCUMENT]\n",
            "- URI [https://changelog.graphlit.dev/july-2024/july-25-support-for-mistral-large-2-and-nemo-groq-llama-3.1-models-bug-fixes]\n",
            "- File upload [196719 bytes], throughput: 320064.026 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:42.091Z: Upload Master\n",
            "- Workflow [Ingestion] took 0:00:00.909229, used credits [0.00084158]\n",
            "- CONTENT [8a9c0eb5-3658-4cca-bf2c-d68cdbea3f15]: Content type [PAGE], file type [DOCUMENT]\n",
            "- URI [https://changelog.graphlit.dev/may-2024/may-15-support-for-graphrag-openai-gpt-4o-model-performance-improvements-and-bug-fixes]\n",
            "- File upload [217801 bytes], throughput: 239544.608 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:42.089Z: Upload Master\n",
            "- Workflow [Ingestion] took 0:00:00.581347, used credits [0.00076904]\n",
            "- CONTENT [257dc6c9-65d0-416d-9b1c-d412aeb42bd4]: Content type [PAGE], file type [DOCUMENT]\n",
            "- URI [https://changelog.graphlit.dev/june-2024/june-21-support-for-the-claude-3.5-sonnet-model-knowledge-graph-semantic-search-and-bug-fixes]\n",
            "- File upload [199027 bytes], throughput: 342355.028 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:41.956Z: Upload Master\n",
            "- Workflow [Ingestion] took 0:00:01.205028, used credits [0.00086740]\n",
            "- CONTENT [1bc9cf17-e156-441d-a307-def6a31d693e]: Content type [PAGE], file type [DOCUMENT]\n",
            "- URI [https://changelog.graphlit.dev/may-2024/may-5-support-for-jina-and-pongo-rerankers-microsoft-teams-feed-new-youtube-downloader-bug-fixes]\n",
            "- File upload [224482 bytes], throughput: 186287.757 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:41.927Z: Upload Master\n",
            "- Workflow [Ingestion] took 0:00:00.876432, used credits [0.00077673]\n",
            "- CONTENT [0932e05b-1816-4e99-a4ef-7bc475de60fc]: Content type [PAGE], file type [DOCUMENT]\n",
            "- URI [https://changelog.graphlit.dev/february-2024/february-2-support-for-semantic-alerts-openai-0125-models-performance-enhancements-bug-fixes]\n",
            "- File upload [201016 bytes], throughput: 229357.212 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:41.825Z: Upload Master\n",
            "- Workflow [Ingestion] took 0:00:01.268766, used credits [0.00095370]\n",
            "- CONTENT [7b5b7874-c84b-4607-877c-8bec0e167127]: Content type [PAGE], file type [DOCUMENT]\n",
            "- URI [https://changelog.graphlit.dev/december-2024/december-22-support-for-dropbox-box-intercom-and-zendesk-feeds-openai-o1-gemini-2.0-bug-fixes]\n",
            "- File upload [246818 bytes], throughput: 194533.840 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:41.725Z: Upload Master\n",
            "- Workflow [Ingestion] took 0:00:01.002794, used credits [0.00093694]\n",
            "- CONTENT [d40abe32-e564-4a6c-bd34-cea90b98c172]: Content type [PAGE], file type [DOCUMENT]\n",
            "- URI [https://changelog.graphlit.dev/july-2023/july-15-support-for-sharepoint-feeds-new-conversation-features]\n",
            "- File upload [242479 bytes], throughput: 241803.377 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:40.901Z: Upload Master\n",
            "- Workflow [Ingestion] took 0:00:01.590826, used credits [0.00101749]\n",
            "- CONTENT [a937626a-37ee-4eb1-93e5-2206e9a188ec]: Content type [PAGE], file type [DOCUMENT]\n",
            "- URI [https://changelog.graphlit.dev/january-2024/january-18-support-for-content-publishing-llm-tools-clip-image-embeddings-bug-fixes]\n",
            "- File upload [263326 bytes], throughput: 165527.897 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:40.177Z: Upload Master\n",
            "- Workflow [Ingestion] took 0:00:00.885204, used credits [0.00081031]\n",
            "- CONTENT [253c57c2-3536-4a73-aa76-101372e74b0e]: Content type [PAGE], file type [DOCUMENT]\n",
            "- URI [https://changelog.graphlit.dev/december-2024/december-9-support-for-website-mapping-web-page-screenshots-groq-llama-3.3-model-bug-fixes]\n",
            "- File upload [209707 bytes], throughput: 236902.481 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:39.712Z: Upload Master\n",
            "- Workflow [Ingestion] took 0:00:00.713762, used credits [0.00074322]\n",
            "- CONTENT [4eff5e88-2cf6-489f-9bfb-52b30823e07e]: Content type [PAGE], file type [DOCUMENT]\n",
            "- URI [https://changelog.graphlit.dev/december-2024/december-1-support-for-retrieval-only-rag-pipeline-bug-fixes]\n",
            "- File upload [192345 bytes], throughput: 269480.734 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:39.571Z: Upload Master\n",
            "- Workflow [Ingestion] took 0:00:00.125557, used credits [0.00077075]\n",
            "- CONTENT [7c8442ac-7d94-4a40-9a3b-fdda07048992]: Content type [PAGE], file type [DOCUMENT]\n",
            "- URI [https://changelog.graphlit.dev/january-2024/january-22-support-for-google-and-microsoft-email-feeds-reingest-content-in-place-bug-fixes]\n",
            "- File upload [199469 bytes], throughput: 1588675.404 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:39.117Z: Upload Master\n",
            "- Workflow [Ingestion] took 0:00:00.624152, used credits [0.00085771]\n",
            "- CONTENT [67150a0e-9b17-4261-8f62-1c57686d46e1]: Content type [PAGE], file type [DOCUMENT]\n",
            "- URI [https://changelog.graphlit.dev/february-2024/february-21-support-for-onedrive-and-google-drive-feeds-extract-images-from-pdfs-bug-fixes]\n",
            "- File upload [221975 bytes], throughput: 355642.365 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:38.798Z: Upload Master\n",
            "- Workflow [Ingestion] took 0:00:00.634386, used credits [0.00083779]\n",
            "- CONTENT [ebda0578-6209-4833-9bee-36d0050dc5ee]: Content type [PAGE], file type [DOCUMENT]\n",
            "- URI [https://changelog.graphlit.dev/july-2024/july-19-support-for-openai-gpt-4o-mini-byo-key-for-azure-ai-similarity-by-summary-bug-fixes]\n",
            "- File upload [216820 bytes], throughput: 341779.241 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:38.760Z: Web capture\n",
            "- Workflow [Preparation] took 0:00:18.184251, used credits [0.03800000]\n",
            "- CONTENT [0341d367-6775-4e57-9a3d-7904d813f243]\n",
            "- Processor name [Browserless], units [1]\n",
            "\n",
            "2024-12-30T03:58:38.755Z: Web capture\n",
            "- Workflow [Preparation] took 0:00:19.434799, used credits [0.03800000]\n",
            "- CONTENT [8a9c0eb5-3658-4cca-bf2c-d68cdbea3f15]\n",
            "- Processor name [Browserless], units [1]\n",
            "\n",
            "2024-12-30T03:58:38.529Z: Upload Master\n",
            "- Workflow [Ingestion] took 0:00:00.180162, used credits [0.00076342]\n",
            "- CONTENT [1a8c6b11-f325-47e9-bb39-643f7fb92154]: Content type [PAGE], file type [DOCUMENT]\n",
            "- URI [https://changelog.graphlit.dev/august-2023/august-9-support-direct-text-markdown-and-html-ingestion-new-specification-llm-strategy]\n",
            "- File upload [197572 bytes], throughput: 1096633.424 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:38.522Z: Web capture\n",
            "- Workflow [Preparation] took 0:00:17.967028, used credits [0.03800000]\n",
            "- CONTENT [d764f4d3-1282-441c-8e4a-08ce664b0b47]\n",
            "- Processor name [Browserless], units [1]\n",
            "\n",
            "2024-12-30T03:58:38.511Z: Web capture\n",
            "- Workflow [Preparation] took 0:00:18.131989, used credits [0.03800000]\n",
            "- CONTENT [257dc6c9-65d0-416d-9b1c-d412aeb42bd4]\n",
            "- Processor name [Browserless], units [1]\n",
            "\n",
            "2024-12-30T03:58:38.364Z: Web capture\n",
            "- Workflow [Preparation] took 0:00:17.778913, used credits [0.03800000]\n",
            "- CONTENT [f0a42b0a-353b-4f08-9a5d-40ce9196a46b]\n",
            "- Processor name [Browserless], units [1]\n",
            "\n",
            "2024-12-30T03:58:38.353Z: Web capture\n",
            "- Workflow [Preparation] took 0:00:17.688331, used credits [0.03800000]\n",
            "- CONTENT [41e9b6e8-c479-4416-8ec3-7168709d2861]\n",
            "- Processor name [Browserless], units [1]\n",
            "\n",
            "2024-12-30T03:58:38.347Z: Upload Master\n",
            "- Workflow [Ingestion] took 0:00:00.529514, used credits [0.00101284]\n",
            "- CONTENT [f2817947-a5aa-41d7-a297-b6f16a2d42e1]: Content type [PAGE], file type [DOCUMENT]\n",
            "- URI [https://changelog.graphlit.dev/december-2023/december-10-support-for-openai-gpt-4-turbo-llama-2-and-mistral-models-query-by-example-bug-fixes]\n",
            "- File upload [262122 bytes], throughput: 495024.019 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:38.344Z: Web capture\n",
            "- Workflow [Preparation] took 0:00:19.034709, used credits [0.03800000]\n",
            "- CONTENT [3d78b65e-a42d-44e9-8a9a-07faf938ee0d]\n",
            "- Processor name [Browserless], units [1]\n",
            "\n",
            "2024-12-30T03:58:38.295Z: Web capture\n",
            "- Workflow [Preparation] took 0:00:17.611933, used credits [0.03800000]\n",
            "- CONTENT [b682b0ca-255c-4b02-b016-cb56f05edb64]\n",
            "- Processor name [Browserless], units [1]\n",
            "\n",
            "2024-12-30T03:58:38.285Z: Upload Master\n",
            "- Workflow [Ingestion] took 0:00:00.441723, used credits [0.00083719]\n",
            "- CONTENT [52613eca-1a5a-40ae-91b0-3d8243a55439]: Content type [PAGE], file type [DOCUMENT]\n",
            "- URI [https://changelog.graphlit.dev/]\n",
            "- File upload [216663 bytes], throughput: 490494.730 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:38.250Z: Web capture\n",
            "- Workflow [Preparation] took 0:00:19.113424, used credits [0.03800000]\n",
            "- CONTENT [0ed6b24e-fec6-4008-8bb9-beda6073cbe6]\n",
            "- Processor name [Browserless], units [1]\n",
            "\n",
            "2024-12-30T03:58:38.132Z: Web capture\n",
            "- Workflow [Preparation] took 0:00:17.522389, used credits [0.03800000]\n",
            "- CONTENT [4adced81-1014-450d-9e42-e81ec370a757]\n",
            "- Processor name [Browserless], units [1]\n",
            "\n",
            "2024-12-30T03:58:38.112Z: Web capture\n",
            "- Workflow [Preparation] took 0:00:17.427341, used credits [0.03800000]\n",
            "- CONTENT [1bc9cf17-e156-441d-a307-def6a31d693e]\n",
            "- Processor name [Browserless], units [1]\n",
            "\n",
            "2024-12-30T03:58:37.988Z: Upload Master\n",
            "- Workflow [Ingestion] took 0:00:00.404388, used credits [0.00087919]\n",
            "- CONTENT [8443a72b-f798-4325-b0ac-b821d4e7dea8]: Content type [PAGE], file type [DOCUMENT]\n",
            "- URI [https://changelog.graphlit.dev/april-2024/april-7-support-for-discord-feeds-cohere-reranking-section-aware-chunking-and-retrieval]\n",
            "- File upload [227534 bytes], throughput: 562662.731 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:37.985Z: Upload Master\n",
            "- Workflow [Ingestion] took 0:00:00.367528, used credits [0.00083273]\n",
            "- CONTENT [a0d556d6-0bbc-4df0-9577-bb621d9c6fc2]: Content type [PAGE], file type [DOCUMENT]\n",
            "- URI [https://changelog.graphlit.dev/april-2024/april-23-support-for-python-and-typescript-sdks-latest-openai-cohere-and-groq-models-bug-fixes]\n",
            "- File upload [215511 bytes], throughput: 586379.654 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:37.970Z: Upload Master\n",
            "- Workflow [Ingestion] took 0:00:00.374726, used credits [0.00074721]\n",
            "- CONTENT [fbde99f0-f7ca-4f5d-a318-eb7f4de07912]: Content type [PAGE], file type [DOCUMENT]\n",
            "- URI [https://changelog.graphlit.dev/august-2024/august-20-support-for-medical-entities-anthropic-prompt-caching-bug-fixes]\n",
            "- File upload [193377 bytes], throughput: 516049.335 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:37.969Z: Upload Master\n",
            "- Workflow [Ingestion] took 0:00:00.611937, used credits [0.00081138]\n",
            "- CONTENT [3923639b-14f1-484b-86e7-7c6f6e67461d]: Content type [PAGE], file type [DOCUMENT]\n",
            "- URI [https://changelog.graphlit.dev/august-2023/august-3-new-data-model-for-observations-new-category-entity]\n",
            "- File upload [209984 bytes], throughput: 343146.435 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:37.967Z: Upload Master\n",
            "- Workflow [Ingestion] took 0:00:00.359586, used credits [0.00071530]\n",
            "- CONTENT [9ded6f5c-a667-442d-8848-30d7a22e79e0]: Content type [PAGE], file type [DOCUMENT]\n",
            "- URI [https://changelog.graphlit.dev/august-2023/august-17-prepare-for-usage-based-billing-append-sas-tokens-to-uris]\n",
            "- File upload [185118 bytes], throughput: 514809.126 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:37.964Z: Web capture\n",
            "- Workflow [Preparation] took 0:00:27.570285, used credits [0.03800000]\n",
            "- CONTENT [7b5b7874-c84b-4607-877c-8bec0e167127]\n",
            "- Processor name [Browserless], units [1]\n",
            "\n",
            "2024-12-30T03:58:37.951Z: Web capture\n",
            "- Workflow [Preparation] took 0:00:19.132635, used credits [0.03800000]\n",
            "- CONTENT [0932e05b-1816-4e99-a4ef-7bc475de60fc]\n",
            "- Processor name [Browserless], units [1]\n",
            "\n",
            "2024-12-30T03:58:37.925Z: Upload Master\n",
            "- Workflow [Ingestion] took 0:00:00.705975, used credits [0.00081093]\n",
            "- CONTENT [a263132e-7225-40d3-a75d-39b3ef1edbd1]: Content type [PAGE], file type [DOCUMENT]\n",
            "- URI [https://changelog.graphlit.dev/august-2024/august-8-support-for-llm-based-document-extraction-.net-sdk-bug-fixes]\n",
            "- File upload [209867 bytes], throughput: 297272.566 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:37.920Z: Web capture\n",
            "- Workflow [Preparation] took 0:00:18.818364, used credits [0.03800000]\n",
            "- CONTENT [d40abe32-e564-4a6c-bd34-cea90b98c172]\n",
            "- Processor name [Browserless], units [1]\n",
            "\n",
            "2024-12-30T03:58:37.558Z: Web capture\n",
            "- Workflow [Preparation] took 0:00:24.407559, used credits [0.03800000]\n",
            "- CONTENT [a937626a-37ee-4eb1-93e5-2206e9a188ec]\n",
            "- Processor name [Browserless], units [1]\n",
            "\n",
            "2024-12-30T03:58:37.474Z: Upload Master\n",
            "- Workflow [Ingestion] took 0:00:00.392515, used credits [0.00074101]\n",
            "- CONTENT [5da3504c-5d1d-4b5c-848e-d3ddb11f3964]: Content type [PAGE], file type [DOCUMENT]\n",
            "- URI [https://changelog.graphlit.dev/august-2024/august-11-support-for-azure-ai-document-intelligence-by-default-language-aware-summaries]\n",
            "- File upload [191772 bytes], throughput: 488572.411 bytes/sec\n",
            "\n",
            "2024-12-30T03:58:37.236Z: Web capture\n",
            "- Workflow [Preparation] took 0:00:18.095946, used credits [0.03800000]\n",
            "- CONTENT [ebda0578-6209-4833-9bee-36d0050dc5ee]\n",
            "- Processor name [Browserless], units [1]\n",
            "\n",
            "2024-12-30T03:58:37.130Z: Web capture\n",
            "- Workflow [Preparation] took 0:00:24.819724, used credits [0.03800000]\n",
            "- CONTENT [67150a0e-9b17-4261-8f62-1c57686d46e1]\n",
            "- Processor name [Browserless], units [1]\n",
            "\n",
            "2024-12-30T03:58:37.065Z: Web capture\n",
            "- Workflow [Preparation] took 0:00:25.947508, used credits [0.03800000]\n",
            "- CONTENT [253c57c2-3536-4a73-aa76-101372e74b0e]\n",
            "- Processor name [Browserless], units [1]\n",
            "\n",
            "2024-12-30T03:58:36.902Z: Web capture\n",
            "- Workflow [Preparation] took 0:00:27.061634, used credits [0.03800000]\n",
            "- CONTENT [52613eca-1a5a-40ae-91b0-3d8243a55439]\n",
            "- Processor name [Browserless], units [1]\n",
            "\n",
            "2024-12-30T03:58:36.898Z: Web capture\n",
            "- Workflow [Preparation] took 0:00:19.958304, used credits [0.03800000]\n",
            "- CONTENT [7c8442ac-7d94-4a40-9a3b-fdda07048992]\n",
            "- Processor name [Browserless], units [1]\n",
            "\n",
            "2024-12-30T03:58:36.869Z: Web capture\n",
            "- Workflow [Preparation] took 0:00:26.515069, used credits [0.03800000]\n",
            "- CONTENT [f2817947-a5aa-41d7-a297-b6f16a2d42e1]\n",
            "- Processor name [Browserless], units [1]\n",
            "\n",
            "2024-12-30T03:58:36.803Z: Web capture\n",
            "- Workflow [Preparation] took 0:00:26.958128, used credits [0.03800000]\n",
            "- CONTENT [1a8c6b11-f325-47e9-bb39-643f7fb92154]\n",
            "- Processor name [Browserless], units [1]\n",
            "\n",
            "2024-12-30T03:58:36.467Z: Web capture\n",
            "- Workflow [Preparation] took 0:00:26.070257, used credits [0.03800000]\n",
            "- CONTENT [4eff5e88-2cf6-489f-9bfb-52b30823e07e]\n",
            "- Processor name [Browserless], units [1]\n",
            "\n",
            "2024-12-30T03:58:36.049Z: Web capture\n",
            "- Workflow [Preparation] took 0:00:25.961297, used credits [0.03800000]\n",
            "- CONTENT [fbde99f0-f7ca-4f5d-a318-eb7f4de07912]\n",
            "- Processor name [Browserless], units [1]\n",
            "\n",
            "2024-12-30T03:58:35.993Z: Web capture\n",
            "- Workflow [Preparation] took 0:00:26.391996, used credits [0.03800000]\n",
            "- CONTENT [a0d556d6-0bbc-4df0-9577-bb621d9c6fc2]\n",
            "- Processor name [Browserless], units [1]\n",
            "\n",
            "2024-12-30T03:58:34.730Z: Web capture\n",
            "- Workflow [Preparation] took 0:00:24.717783, used credits [0.03800000]\n",
            "- CONTENT [5da3504c-5d1d-4b5c-848e-d3ddb11f3964]\n",
            "- Processor name [Browserless], units [1]\n",
            "\n",
            "2024-12-30T03:58:34.720Z: Web capture\n",
            "- Workflow [Preparation] took 0:00:24.832072, used credits [0.03800000]\n",
            "- CONTENT [9ded6f5c-a667-442d-8848-30d7a22e79e0]\n",
            "- Processor name [Browserless], units [1]\n",
            "\n",
            "2024-12-30T03:58:34.689Z: Web capture\n",
            "- Workflow [Preparation] took 0:00:24.948025, used credits [0.03800000]\n",
            "- CONTENT [8443a72b-f798-4325-b0ac-b821d4e7dea8]\n",
            "- Processor name [Browserless], units [1]\n",
            "\n",
            "2024-12-30T03:58:34.683Z: Web capture\n",
            "- Workflow [Preparation] took 0:00:24.314932, used credits [0.03800000]\n",
            "- CONTENT [a263132e-7225-40d3-a75d-39b3ef1edbd1]\n",
            "- Processor name [Browserless], units [1]\n",
            "\n",
            "2024-12-30T03:58:34.657Z: Web capture\n",
            "- Workflow [Preparation] took 0:00:24.798386, used credits [0.03800000]\n",
            "- CONTENT [3923639b-14f1-484b-86e7-7c6f6e67461d]\n",
            "- Processor name [Browserless], units [1]\n",
            "\n",
            "2024-12-30T03:58:16.358Z: Serverless compute\n",
            "- Workflow [Entity Event] took 0:00:02.710225, used credits [0.00487953]\n",
            "\n",
            "2024-12-30T03:58:12.178Z: Serverless compute\n",
            "- Workflow [Feed] took 0:00:04.809701, used credits [0.00432973]\n",
            "\n",
            "2024-12-30T03:58:05.755Z: GraphQL\n",
            "- Operation took 0:00:00.543093, used credits [0.00000000]\n",
            "- Request:\n",
            "mutation CreateFeed($feed: FeedInput!, $correlationId: String) { createFeed(feed: $feed, correlationId: $correlationId) { id name state type } }\n",
            "- Variables:\n",
            "{\"feed\":\"{ name: \\\"https:\\\\/\\\\/changelog.graphlit.dev\\\", type: WEB, web: { uri: \\\"https:\\\\/\\\\/changelog.graphlit.dev\\\", readLimit: 100 } }\",\"correlationId\":\"\\\"2024-12-30T03:58:05.173095\\\"\"}\n",
            "- Response:\n",
            "{\"data\":{\"createFeed\":{\"id\":\"67102186-088a-46b0-a03d-e94e916ad3ed\",\"name\":\"https://changelog.graphlit.dev\",\"state\":\"ENABLED\",\"type\":\"WEB\"}}}\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "credits = await lookup_credits(publish_correlation_id)\n",
        "\n",
        "if credits is not None:\n",
        "    display(Markdown(f\"### Credits used: {credits.credits:.6f} for publishing\"))\n",
        "    print(f\"- storage [{credits.storage_ratio:.2f}%], compute [{credits.compute_ratio:.2f}%]\")\n",
        "    print(f\"- embedding [{credits.embedding_ratio:.2f}%], completion [{credits.completion_ratio:.2f}%]\")\n",
        "    print(f\"- ingestion [{credits.ingestion_ratio:.2f}%], indexing [{credits.indexing_ratio:.2f}%], preparation [{credits.preparation_ratio:.2f}%], extraction [{credits.extraction_ratio:.2f}%], enrichment [{credits.enrichment_ratio:.2f}%], publishing [{credits.publishing_ratio:.2f}%]\")\n",
        "    print(f\"- search [{credits.search_ratio:.2f}%], conversation [{credits.conversation_ratio:.2f}%]\")\n",
        "    print()\n",
        "\n",
        "usage = await lookup_usage(publish_correlation_id)\n",
        "\n",
        "if usage is not None:\n",
        "    display(Markdown(f\"### Usage records:\"))\n",
        "\n",
        "    for record in usage:\n",
        "        dump_usage_record(record)\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0nqb7p9Rrr1b",
        "outputId": "e1d67200-c70e-45d9-ae69-e0ea424dce7e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Credits used: 30.512571 for publishing"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- storage [0.00%], compute [0.04%]\n",
            "- embedding [0.06%], completion [99.84%]\n",
            "- ingestion [0.00%], indexing [0.00%], preparation [0.00%], extraction [0.00%], enrichment [0.00%], publishing [0.00%]\n",
            "- search [0.06%], conversation [0.00%]\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Usage records:"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "- Bug Fixes:\n",
            "  - Fixed issue where adding content to collections did not sync with the search index (GPLA-2114).\n",
            "  - Resolved rendering issues with conversation sources in section retrieval and text content (GPLA-2511).\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: April 2024.\n",
            "  \n",
            "- Value:\n",
            "  - Offers developers enhanced SDKs for Python and Node.js, improved model support, and better handling of LLM responses, increasing development efficiency and capabilities.\n",
            "\n",
            "2024-12-30T04:07:00.792Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:08.620295, used credits [0.00977400]\n",
            "- CONTENT [a937626a-37ee-4eb1-93e5-2206e9a188ec]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [1586 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/january-2024/january-18-support-for-content-publishing-llm-tools-clip-image-embeddings-bug-fixes</name><title>January 18: Support for content publishing, LLM tools, CLIP image embeddings, bug fixes | Graphlit Changelog</title></metadata> üéÜ\tJanuary 2024\n",
            "January 18: Support for content publishing, LLM tools, CLIP image embeddings, bug fixes\n",
            "New Features\n",
            "üí° Graphlit now supports content publishing, where documents, audio transcripts and even image descriptions, can be summarized, and repurposed into blog posts, emails or AI-generated podcasts.  With the new publishContents mutation, you can configure LLM prompts for summarization and publishing, and assign specifications to use different models and/or system prompts for each step in the process.  The published content will be reingested into Graphlit, and can be searched or used for conversations, like any other form of content.\n",
            "üí° Graphlit now supports publishing conversations as content with the new publishConversation mutation.  You can generate text or audio transcripts of your conversations, to be reused in other tools.\n",
            "üí° Graphlit now supports bulk summarization of contents with the summarizeContents mutation.  You can filter a set of content, by feed, by observable or by similar text, and run a set of summarizations across each content in parallel.\n",
            "üí° Graphlit now supports LLM entity extraction, with the new MODEL_TEXT entity extraction service type.  Similar to using Azure Cognitive Service Text Analytics, you can use any OpenAI or Anthropic model for extracting entities from text.  Internally the LLM returns JSON-LD entities, which we convert into Person, Organization, Place, etc. entities and assign observations to the extracted content.\n",
            "üí° Graphlit now supports LLM tools (aka function calls) with OpenAI models.  You can define the tools to be used with the LLM in the specification object.  With the new extractContents mutation, you can execute a prompt against content using a specification with tools defined.  The mutation will return the JSON arguments assigned by the LLM.\n",
            "üí° Graphlit now supports callback webhooks for LLM tools.  If you assign a URI in the ToolDefinition object, Graphlit will call your webhook the tool name and JSON arguments.  When you respond to the webhook with JSON, we will add that response to the LLM messages, and ask the LLM to complete the original prompt.\n",
            "üí° Graphlit now supports the selection of the Deepgram model (such as Meeting, Phonecall or Finance) with the preparation workflow.  Also, you can assign your own Deepgram API key, which will be used for audio transcription using that workflow.\n",
            "Added support for CLIP image embeddings using Roboflow, which can be used for similar image search.  If you search for contents by similar contents, we will now use the content's text and/or image embeddings to find similar content.\n",
            "Added support for dynamic web page ingestion.  Graphlit now navigates to and automatically scrolls web pages using Browserless.io, so we capture the fully rendered HTML before extracting text.  Also, we now support web page screenshots, if enabled with enableImageAnalysis property in preparation workflow.  These screenshots can be analyzed with multimodal modals, such as GPT-4 Vision, or can be used to create image embeddings for similar image search.\n",
            "Added table parsing when preparing documents.  We now store structured (tab-delimited) text in the JSON text mezzanine which is extracted from documents in the preparation workflow.\n",
            "Added reverse geocoding of lat/long locations found in image or other content metadata.  We now store the real-world address with the content metadata, for use in conversations.\n",
            "Added assistant messages to the conversation message history provided to the LLM.  Originally we had included only user messages, but now we are formatting both user and assistant messages into the LLM prompt for conversations.\n",
            "Added new chunking algorithm for text embeddings.  We support semantic chunking at the page or transcript segment level, and now will create embeddings from smaller sized text chunks per page or segment.\n",
            "Added content metadata to text and image embeddings.  To provide better context for the text embeddings, we now include formatted content metadata, which includes fields like title, subject, author, or description.  For emails, we include to, from, cc, and bcc fields.\n",
            "Added helper mutations isContentDone and isFeedDone which can be used for polling completion of ingested content, or all content ingested by a feed.\n",
            "Added richer image descriptions generated by the GPT-4 Vision model.  Now these provide more useful detail.\n",
            "Added validation of extracted hyperlinks.  Now we test the URIs and remove any inaccessible links during content enrichment.\n",
            "Added deleteContents,  deleteFeeds,  and deleteConversations mutations for multi-deletion of contents, feeds or conversations.\n",
            "Added deleteAllContents,  deleteAllFeeds,  and deleteAllConversations mutations for bulk, filtered deletion of entities.  You can delete all your contents, feeds, or conversations in your project, or a filtered subset of those entities.\n",
            "‚ÑπÔ∏è Starter tier now has a higher content limit of 100K content items.\n",
            "‚ö° In the OpenAIImageExtractionProperties type, the detailMode field was renamed to detailLevel.\n",
            "‚ö° Each SummarizationStrategy object now accepts the specification which is used by the summarization, rather than being assigned at the preparation workflow stage.\n",
            "‚ö° addCollectionContents and removeCollectionContents mutations have been deprecated in favor of addContentsToCollections and removeContentsFromCollection mutations.\n",
            "Bugs Fixed\n",
            "GPLA-1846: Parse Markdown headings into mezzanine JSON\n",
            "GPLA-1779: Not returning SAS token with mezzanine, master URIs\n",
            "GPLA-1348: Summarize text content, not just file content\n",
            "GPLA-1297: Not assigning content error message on preparation workflow failure\n",
            "PreviousJanuary 22: Support for Google and Microsoft email feeds, reingest content in-place, bug fixes\n",
            "NextDecember 10: Support for OpenAI GPT-4 Turbo, Llama 2 and Mistral models; query by example, bug fixes Last updated8 months ago\n",
            "- Completion [418 tokens (includes JSON guardrails tokens)], throughput: 48.490 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for content publishing, allowing documents, audio transcripts, and image descriptions to be summarized and repurposed.\n",
            "  - New mutation for publishing conversations as content, generating text or audio transcripts.\n",
            "  - Bulk summarization of contents with the summarizeContents mutation.\n",
            "  - LLM entity extraction using MODEL_TEXT service type, returning JSON-LD entities.\n",
            "  - Support for LLM tools (function calls) with OpenAI models, including extractContents mutation.\n",
            "  - Callback webhooks for LLM tools, enabling interaction with external services.\n",
            "  - Selection of Deepgram models for audio transcription with custom API key.\n",
            "  - CLIP image embeddings support for similar image search.\n",
            "  - Dynamic web page ingestion with automatic scrolling and screenshot capabilities.\n",
            "  - Table parsing for structured text extraction from documents.\n",
            "  - Reverse geocoding of lat/long locations in content metadata.\n",
            "  - Inclusion of assistant messages in conversation history for LLM prompts.\n",
            "  - New chunking algorithm for semantic text embeddings.\n",
            "  - Enhanced content metadata for text and image embeddings.\n",
            "  - Helper mutations for polling content ingestion completion.\n",
            "  - Richer image descriptions generated by GPT-4 Vision model.\n",
            "  - Validation of extracted hyperlinks to remove inaccessible links.\n",
            "  - Multi-deletion mutations for contents, feeds, and conversations.\n",
            "  - Bulk deletion mutations for filtered subsets of entities.\n",
            "  - Starter tier content limit increased to 100K items.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Renamed detailMode field to detailLevel in OpenAIImageExtractionProperties.\n",
            "  - SummarizationStrategy objects now accept specifications directly.\n",
            "  - Deprecated addCollectionContents and removeCollectionContents mutations in favor of new mutations.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issues with parsing Markdown headings, returning SAS tokens, summarizing text content, and assigning error messages on workflow failures.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: January 18, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced content management capabilities, improved integration with LLM tools, and better data handling for various content types.\n",
            "\n",
            "2024-12-30T04:07:00.030Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:04.348169, used credits [0.00728400]\n",
            "- CONTENT [8443a72b-f798-4325-b0ac-b821d4e7dea8]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [1068 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/april-2024/april-7-support-for-discord-feeds-cohere-reranking-section-aware-chunking-and-retrieval</name><title>April 7: Support for Discord feeds, Cohere reranking, section-aware chunking and retrieval | Graphlit Changelog</title></metadata> üêá\tApril 2024\n",
            "April 7: Support for Discord feeds, Cohere reranking, section-aware chunking and retrieval\n",
            "New Features\n",
            "üí° Graphlit now supports Discord feeds.  By connecting to a Discord channel and providing a bot token, you can ingest all Discord messages and file attachments.\n",
            "üí°  Graphlit now supports Cohere reranking after content retrieval in RAG pipeline.  You can optionally use the Cohere rerank model to semantically rerank the semantic search results, before providing as context to the LLM.\n",
            "Added support for section-aware text chunking and retrieval.  Now, when using section-aware document preparation, such as Azure AI Document Intelligence, Graphlit will store the extracted text according to the semantic chunks (i.e. sections).  The text for each section will be individually chunked and embedded into the vector index.\n",
            "Added support for retrievalStrategy in Specification type. Graphlit now supports CHUNK, SECTION and CONTENT retrieval strategies.  Chunk retrieval will use the search hit chunk, section retrieval will expand the search hit chunk to the containing section (or page, if not using section-aware preparation).  Content retrieval will expand the search hit chunk to the text of the entire document.\n",
            "Added support for rerankingStrategy in Specification type. You can now configure the reranking of content sources, using the Cohere reranking model, by assigning serviceType to COHERE.  More reranking models are planned for the future.\n",
            "Added isSynchronous flag to content ingestion mutations, such as ingestUri, so the mutation will wait for the content to complete the ingestion workflow (or error) before returning.  This is useful for utilizing the API in a Jupyter notebook or Streamlit application, in a synchronous manner without polling.\n",
            "Added includeAttachments flag to SlackFeedProperties.  When enabled, Graphlit will automatically ingest any attachments within Slack messages.\n",
            "‚ö° Added ingestUri mutation to replace the now deprecated ingestPage and ingestFile mutations.  We had seen confusion on when to use one vs the other, and now for any URI, whether it is a web page or hosted PDF, you can pass it to ingestUri, and we will infer the correct content ingestion workflow.\n",
            "‚ö° Removed includeSummaries from the ConversationStrategyInput type.  This will re-added in the future as part of the retrieval strategy.\n",
            "‚ö° Deprecated enableExpandedRetrieval in ConversationStrategyInput type.  This is now handled by setting strategyType to SECTION or CONTENT in the RetrievalStrategyInput type.\n",
            "‚ö° Moved contentLimit from ConversationStrategyInput type to RetrievalStrategyInput type. You can optionally assign the contentLimit to retrievalStrategy which limits the number of content sources leveraged in the LLM prompt context. (Default is 100.)\n",
            "Bugs Fixed\n",
            "GPLA-2469: Failed to ingest PDF hosted on GitHub\n",
            "GPLA-2390: Claude 3 Haiku not adhering to JSON schema\n",
            "GPLA-2474: Prompt rewriting should ignore formatting instructions in prompt\n",
            "GPLA-2462: Missing line break after table rows\n",
            "GPLA-2417: Not extracting images from PPTX correctly\n",
            "PreviousApril 23: Support for Python and TypeScript SDKs, latest OpenAI, Cohere & Groq models, bug fixes\n",
            "NextMarch 23: Support for Linear, GitHub Issues and Jira issue feeds, ingest files via Web feed sitemap\n",
            "Last updated8 months ago\n",
            "- Completion [340 tokens (includes JSON guardrails tokens)], throughput: 78.194 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for Discord feeds: Ingest messages and file attachments from a Discord channel using a bot token.\n",
            "  - Cohere reranking: Optionally rerank semantic search results in the RAG pipeline using the Cohere rerank model.\n",
            "  - Section-aware text chunking and retrieval: Store extracted text according to semantic chunks for improved indexing.\n",
            "  - Retrieval strategies: Support for CHUNK, SECTION, and CONTENT retrieval strategies.\n",
            "  - Reranking strategy: Configure reranking of content sources using the Cohere model.\n",
            "  - Synchronous content ingestion: Added isSynchronous flag for content ingestion mutations to wait for completion.\n",
            "  - Slack attachments: Added includeAttachments flag to automatically ingest attachments in Slack messages.\n",
            "  - IngestUri mutation: Replaces deprecated ingestPage and ingestFile mutations for simplified content ingestion.\n",
            "  \n",
            "- Enhancements/Improvements:\n",
            "  - Removed includeSummaries from ConversationStrategyInput; will be re-added later.\n",
            "  - Deprecated enableExpandedRetrieval; now managed by strategyType in RetrievalStrategyInput.\n",
            "  - Moved contentLimit to RetrievalStrategyInput for better content source management.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issues with PDF ingestion from GitHub.\n",
            "  - Resolved JSON schema adherence for Claude 3 Haiku.\n",
            "  - Prompt rewriting now ignores formatting instructions.\n",
            "  - Corrected missing line breaks after table rows.\n",
            "  - Fixed image extraction from PPTX files.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: April 2024.\n",
            "  - Version updates include new flags and strategies for improved functionality.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced content ingestion capabilities, improved retrieval strategies, and better integration with messaging platforms.\n",
            "\n",
            "2024-12-30T04:06:58.864Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:03.380614, used credits [0.00324000]\n",
            "- CONTENT [9ded6f5c-a667-442d-8848-30d7a22e79e0]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [616 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/august-2023/august-17-prepare-for-usage-based-billing-append-sas-tokens-to-uris</name><title>August 17: Prepare for usage-based billing; append SAS tokens to URIs | Graphlit Changelog</title></metadata> üéÇ\tAugust 2023\n",
            "August 17: Prepare for usage-based billing; append SAS tokens to URIs\n",
            "New Features\n",
            "‚ÑπÔ∏è Behind the scenes, Graphlit is preparing to launch usage-based billing.  This release put in place the infrastructure to track billable events.  Organizations now have a Stripe customer associated with them, and Graphlit projects are auto-subscribed to a Free/Hobby pricing plan.  In a future release, we will provide the ability to upgrade to a paid plan in the Graphlit Developer Portal.  Also, we will provide visualization of usage, on granular basis, in the Portal.\n",
            "üí° Content URIs now have Shared Access Signature (SAS) token appended, so they are accessible after query.  For example, content.transcriptUri will now be able to be downloaded or used directly in an application (until the SAS token expires).\n",
            "üß± Added more robustness for error handling and retries, especially for LLM APIs and audio transcription APIs.\n",
            "PreviousSeptember 4: Workflow configuration; support for Notion feeds; document OCR\n",
            "NextAugust 9: Support direct text, Markdown and HTML ingestion; new Specification LLM strategy\n",
            "Last updated1 year ago\n",
            "- Completion [116 tokens (includes JSON guardrails tokens)], throughput: 34.313 tokens/sec:\n",
            "- New Features:\n",
            "  - Infrastructure for usage-based billing implemented; organizations now have a Stripe customer and auto-subscribed to a Free/Hobby pricing plan.\n",
            "  - Content URIs now include Shared Access Signature (SAS) tokens for direct access after queries.\n",
            "  \n",
            "- Enhancements/Improvements:\n",
            "  - Improved error handling and retries for LLM APIs and audio transcription APIs.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: August 17, 2023.\n",
            "  \n",
            "- Value:\n",
            "  - Prepares developers for future billing options and enhances content accessibility and API reliability.\n",
            "\n",
            "2024-12-30T04:06:55.586Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:04.015786, used credits [0.00607200]\n",
            "- CONTENT [ebda0578-6209-4833-9bee-36d0050dc5ee]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [1016 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/july-2024/july-19-support-for-openai-gpt-4o-mini-byo-key-for-azure-ai-similarity-by-summary-bug-fixes</name><title>July 19: Support for OpenAI GPT-4o Mini, BYO-key for Azure AI, similarity by summary, bug fixes | Graphlit Changelog</title></metadata> ‚òÄÔ∏è\tJuly 2024\n",
            "July 19: Support for OpenAI GPT-4o Mini, BYO-key for Azure AI, similarity by summary, bug fixes\n",
            "New Features\n",
            "üí° Graphlit now supports the OpenAI GPT-4o Mini model, with 16k output tokens.\n",
            "üí° Graphlit now supports 'bring-your-own-key' for Azure AI Document Intelligence models.  We have added a custom endpoint and key property, which can be assigned to use your own Azure AI resource.\n",
            "Updated to use Jina reranker v2 (jina-reranker-v2-base-multilingual) by default.\n",
            "Updated to assign the summary, bullets, etc properties when calling summarizeContents mutation.  Now when summarizing contents, we will store the resulting summary in the content itself, in addition to returning the summarized results.\n",
            "Added relevance property to all entity types, which will be assigned when searching for these entities.  Entity results will be sorted (descending) by this search relevance score.\n",
            "Added the ability to manually update summary, bullets, etc. properties when calling the updateContent mutation.\n",
            "Added offset property to AtlassianJiraFeedProperties, so the timezone offset can be properly assigned for paging of the Jira feed.  (Defaults to zero offset, i.e. UTC.)  Jira does not store dates in UTC format, and the timestamps are based on the server timezone of the hosted Jira instance.  By assigning the timezone offset with the Jira feed, we can reliably page the updated date timestamps from the Jira API.\n",
            "‚ö° We have changed the content similarity search behavior to find similar content by summary, rather than text of the document, when a summary has been previously generated.  For long documents, this will provide a more accurate similarity, rather than comparing on the first few pages of text in a document.\n",
            "‚ö° We have changed the behavior of assigning offset in the entity filter objects for paging through entities.  If using vector or hybrid search, this offset will be ignored (i.e. zero offset).  Paging will not be supported through vector or hybrid search results. For keyword search, the offset will continue to be used, along with the limit property, to provide paging through the search results.  We have made this change because we have found that index-based paging is not reliable with our vector/hybrid search approach.  We are investigating ways to support this reliably with vector/hybrid search in the future.\n",
            "Bugs Fixed\n",
            "GPLA-2915: Add retry on OpenAI API HTTP 524 error (gateway timeout).\n",
            "GPLA-2908: Not paging through Jira feed correctly.\n",
            "GPLA-2917: Search by similar content is not giving expected results on long documents.\n",
            "GPLA-2244: Keyword search not finding text in latter part of long PDF.\n",
            "PreviousJuly 25: Support for Mistral Large 2 & Nemo, Groq Llama 3.1 models, bug fixes\n",
            "NextJuly 4: Support for webhook Alerts, keywords summarization, Deepseek 128k context window, bug fixes\n",
            "Last updated5 months ago\n",
            "- Completion [252 tokens (includes JSON guardrails tokens)], throughput: 62.752 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for OpenAI GPT-4o Mini model with 16k output tokens.\n",
            "  - 'Bring-your-own-key' support for Azure AI Document Intelligence models with custom endpoint and key property.\n",
            "  - Updated to Jina reranker v2 by default.\n",
            "  - Enhanced summarizeContents mutation to store summaries in content.\n",
            "  - Added relevance property for entity types, sorting results by relevance score.\n",
            "  - Ability to manually update summary and bullet properties in updateContent mutation.\n",
            "  - Offset property added to AtlassianJiraFeedProperties for proper timezone assignment.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Content similarity search now finds similar content by summary for better accuracy.\n",
            "  - Changed entity filter object behavior for paging; zero offset for vector/hybrid search.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Added retry on OpenAI API HTTP 524 error.\n",
            "  - Fixed paging issues with Jira feed.\n",
            "  - Improved search results for similar content in long documents.\n",
            "  - Resolved keyword search issues in long PDFs.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: July 19, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers improved model support, enhanced search capabilities, and better handling of content summaries and entity relevance.\n",
            "\n",
            "2024-12-30T04:06:55.435Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:03.364877, used credits [0.00358200]\n",
            "- CONTENT [4eff5e88-2cf6-489f-9bfb-52b30823e07e]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [562 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/december-2024/december-1-support-for-retrieval-only-rag-pipeline-bug-fixes</name><title>December 1: Support for retrieval-only RAG pipeline, bug fixes | Graphlit Changelog</title></metadata> üéÑ\tDecember 2024\n",
            "December 1: Support for retrieval-only RAG pipeline, bug fixes\n",
            "New Features\n",
            "üí° Graphlit now supports formatting of LLM-ready prompts with our RAG pipeline, via the new formatConversation and completeConversation mutations.  This is valuable for supporting LLM streaming by directly calling the LLM from your application, and using Graphlit for RAG retrieval and conversation history. (Colab Notebook Example)\n",
            "We have added support for inline hyperlinks in extracted text from documents and web pages.\n",
            "Bugs Fixed\n",
            "GPLA-3466: Owner ID should accept any non-whitespace string\n",
            "GPLA-3458: Not getting Person-to-Organization edges from entity extraction\n",
            "PreviousDecember 9: Support for website mapping, web page screenshots, Groq Llama 3.3 model, bug fixes\n",
            "NextNovember 24: Support for direct LLM prompt, multi-turn image analysis, bug fixes\n",
            "Last updated28 days ago\n",
            "- Completion [158 tokens (includes JSON guardrails tokens)], throughput: 46.956 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for formatting LLM-ready prompts with RAG pipeline using formatConversation and completeConversation mutations.\n",
            "  - Inline hyperlinks can now be included in extracted text from documents and web pages.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Improved support for LLM streaming by enabling direct calls to the LLM from applications.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issue GPLA-3466: Owner ID now accepts any non-whitespace string.\n",
            "  - Fixed issue GPLA-3458: Resolved problem with missing Person-to-Organization edges from entity extraction.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: December 1, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Enhancements provide developers with better integration for LLM interactions and improved text extraction capabilities.\n",
            "\n",
            "2024-12-30T04:06:54.318Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:03.536914, used credits [0.00599100]\n",
            "- CONTENT [253c57c2-3536-4a73-aa76-101372e74b0e]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [921 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/december-2024/december-9-support-for-website-mapping-web-page-screenshots-groq-llama-3.3-model-bug-fixes</name><title>December 9: Support for website mapping, web page screenshots, Groq Llama 3.3 model, bug fixes | Graphlit Changelog</title></metadata> üéÑ\tDecember 2024\n",
            "December 9: Support for website mapping, web page screenshots, Groq Llama 3.3 model, bug fixes\n",
            "New Features\n",
            "üí° Graphlit now supports mapping a website with the mapWebmutation. You can provide a URL to a website, and the query will return a list of URLs based on the sitemap.xml (or sitemap-index.xml) file, at or underneath the provided URL.\n",
            "üí° Graphlit now supports the generation of web page screenshots with the screenshotPagemutation. By providing the URL of a web page, and optionally, the maximum desired height of the screenshot, we will screenshot the webpage and ingest it automatically as content.  You can provide an optional workflow, which will be applied to the ingested image content, for operations like generating image descriptions with a vision LLM.\n",
            "üí° Graphlit now supports the direct summarization of text with the summarizeTextmutation. By providing the desired summarization strategy, we will summarize the text (i.e. bullet points, social media posts) and return the summarization.\n",
            "üí° Graphlit now supports the direct extraction of text with the extractTextmutation. By providing the LLM tool definitions and an optional LLM specification, we will prompt the desired LLM (or OpenAI GPT-4o, by default) to invoke the provided tools, and return the JSON responses from the LLM tool calling.\n",
            "Graphlit now supports the latest Groq Llama 3.3 model, with the model enum LLAMA_3_3_70B.\n",
            "We have updated Cohere reranking to use the latest Cohere rerank-v3.5model by default.\n",
            "‚ö° We have added a new flattenCitationsfield to the ConversationStrategyInputtype.  By assigning this field to True, when calling promptConversation,we will combine multiple citations from the same content into a single citation.\n",
            "‚ö° For Microsoft email, Microsoft Teams and OneDrive feeds, we have added the clientIdand clientSecretfields as required feed properties. These properties must be assigned, in addition to the refreshTokenfield for proper authentication to the Microsoft Graph API used by these feeds. (Colab Notebook Example)\n",
            "Bugs Fixed\n",
            "GPLA-3492: Not finding sitemap at parent web path\n",
            "GPLA-3500: Failed to handle mismatch of Deepgram model/language\n",
            "PreviousDecember 22: Support for Dropbox, Box, Intercom and Zendesk feeds, OpenAI o1, Gemini 2.0, bug fixes\n",
            "NextDecember 1: Support for retrieval-only RAG pipeline, bug fixes\n",
            "Last updated19 days ago\n",
            "- Completion [269 tokens (includes JSON guardrails tokens)], throughput: 76.055 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for website mapping using mapWebmutation to return URLs from sitemap.xml.\n",
            "  - Generation of web page screenshots with screenshotPagemutation, including optional workflows for image processing.\n",
            "  - Direct summarization of text with summarizeTextmutation, allowing various summarization strategies.\n",
            "  - Direct extraction of text with extractTextmutation, utilizing LLM tools for JSON responses.\n",
            "  - Support for Groq Llama 3.3 model (LLAMA_3_3_70B).\n",
            "  - Updated Cohere reranking to use rerank-v3.5 model by default.\n",
            "  - New flattenCitations field in ConversationStrategyInput to combine multiple citations.\n",
            "  - Required clientId and clientSecret fields added for Microsoft email, Teams, and OneDrive feeds.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Improved handling of citations in conversation prompts.\n",
            "  - Enhanced authentication requirements for Microsoft Graph API feeds.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issue with not finding sitemap at parent web path (GPLA-3492).\n",
            "  - Resolved mismatch handling for Deepgram model/language (GPLA-3500).\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: December 9, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced capabilities for web mapping, content ingestion, and improved API interactions.\n",
            "\n",
            "2024-12-30T04:06:52.080Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:02.105671, used credits [0.00415500]\n",
            "- CONTENT [5da3504c-5d1d-4b5c-848e-d3ddb11f3964]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [629 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/august-2024/august-11-support-for-azure-ai-document-intelligence-by-default-language-aware-summaries</name><title>August 11: Support for Azure AI Document Intelligence by default, language-aware summaries | Graphlit Changelog</title></metadata> üéÇ\tAugust 2024\n",
            "August 11: Support for Azure AI Document Intelligence by default, language-aware summaries\n",
            "New Features\n",
            "Added support for language-aware summaries when using LLM-based document extraction.  Now the summaries for tables and sections generated by the LLM will follow the language of the source text.\n",
            "Added support for language-aware entity descriptions with using LLM-based entity extraction. Now the entity descriptions generated by the LLM will follow the language of the source text.\n",
            "‚ö° We have changed the default document preparation method to use Azure AI Document Intelligence, rather than our built-in document parsers.  We have found that the fidelity of Azure AI is considerably better for complex PDFs, and provides better support for table extraction, so we have made this the default. Note: this does come with increased credit usage per-page, for PDF, DOCX and PPTX documents, but the quality of the extracted documents are noticeably higher for use in RAG pipelines.\n",
            "Bugs Fixed\n",
            "GPLA-3070: Not getting slide count assigned to metadata for PPTX files.\n",
            "PreviousAugust 20: Support for medical entities, Anthropic prompt caching, bug fixes\n",
            "NextAugust 8: Support for LLM-based document extraction, .NET SDK, bug fixes\n",
            "Last updated4 months ago\n",
            "- Completion [189 tokens (includes JSON guardrails tokens)], throughput: 89.758 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for language-aware summaries in LLM-based document extraction, aligning summaries with the source text language.\n",
            "  - Support for language-aware entity descriptions in LLM-based entity extraction, matching descriptions to the source text language.\n",
            "  - Default document preparation method changed to Azure AI Document Intelligence for improved fidelity in complex PDFs and better table extraction.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Increased credit usage per page for PDF, DOCX, and PPTX documents due to the switch to Azure AI Document Intelligence, but with significantly higher quality in extracted documents for RAG pipelines.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issue GPLA-3070 where slide count was not assigned to metadata for PPTX files.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: August 11, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced document extraction capabilities with improved accuracy and language support, facilitating better integration in applications.\n",
            "\n",
            "2024-12-30T04:06:51.975Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:03.007956, used credits [0.00420300]\n",
            "- CONTENT [1a8c6b11-f325-47e9-bb39-643f7fb92154]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [673 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/august-2023/august-9-support-direct-text-markdown-and-html-ingestion-new-specification-llm-strategy</name><title>August 9: Support direct text, Markdown and HTML ingestion; new Specification LLM strategy | Graphlit Changelog</title></metadata> üéÇ\tAugust 2023\n",
            "August 9: Support direct text, Markdown and HTML ingestion; new Specification LLM strategy\n",
            "New Features\n",
            "üí° Added ingestText mutation which supports direct Content ingestion of plain text, Markdown and HTML.  Now, if you have pre-scraped HTML or Markdown text, you can ingest it into Graphlit without reading from a URL.\n",
            "üí° Added Specification strategy property, which allows customization of the LLM context when prompting a conversation.  ConversationStrategy now provides Windowed and Summarized message histories, as well as configuration of the weight between existing conversation messages and Content text pages (or audio transcript segments) in the LLM context.\n",
            "üí° Added auto-summarization of extracted text and audio transcripts.  There is a new Content summary property where a list of summary bullet points can be found.  These summaries can be optionally included in the Conversation prompt context for more accurate LLM responses.\n",
            "‚ÑπÔ∏è Added AzureOpenAIModels and OpenAIModels types to Specification model properties to make it easier to specify the desired LLM.\n",
            "‚ÑπÔ∏è Renamed ConversationMessage date property to timestamp\n",
            "‚ú® Refined the internal LLM prompts for providing content as part of Conversation context.  This provides for much clearer and accurate results from the LLM.\n",
            "PreviousAugust 17: Prepare for usage-based billing; append SAS tokens to URIs\n",
            "NextAugust 3: New data model for Observations, new Category entity\n",
            "Last updated1 year ago\n",
            "- Completion [182 tokens (includes JSON guardrails tokens)], throughput: 60.506 tokens/sec:\n",
            "- New Features:\n",
            "  - Added ingestText mutation for direct ingestion of plain text, Markdown, and HTML without URL reading.\n",
            "  - Introduced Specification strategy property for customizing LLM context with Windowed and Summarized message histories.\n",
            "  - Implemented auto-summarization of extracted text and audio transcripts, with summaries available for Conversation prompt context.\n",
            "  - Added AzureOpenAIModels and OpenAIModels types to Specification model properties for easier LLM specification.\n",
            "  - Renamed ConversationMessage date property to timestamp.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Refined internal LLM prompts for clearer and more accurate results.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - No specific bug fixes mentioned.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: August 2023.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced content ingestion capabilities, improved LLM context customization, and better summarization features for more accurate responses.\n",
            "\n",
            "2024-12-30T04:06:51.460Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:04.959151, used credits [0.00819000]\n",
            "- CONTENT [7b5b7874-c84b-4607-877c-8bec0e167127]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [1230 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/december-2024/december-22-support-for-dropbox-box-intercom-and-zendesk-feeds-openai-o1-gemini-2.0-bug-fixes</name><title>December 22: Support for Dropbox, Box, Intercom and Zendesk feeds, OpenAI o1, Gemini 2.0, bug fixes | Graphlit Changelog</title></metadata> üéÑ\tDecember 2024\n",
            "December 22: Support for Dropbox, Box, Intercom and Zendesk feeds, OpenAI o1, Gemini 2.0, bug fixes\n",
            "New Features\n",
            "üí° Graphlit now supports Dropbox feeds for ingesting files on the Dropbox cloud service. Dropbox feeds require your appKey, appSecret, redirectUriand refreshTokento be assigned. The feed also accepts an optional pathparameter to read files from a specific Dropbox folder.\n",
            "üí° Graphlit now supports Box feeds for ingesting files on the Box cloud service. Box feeds require your clientId, clientSecret, redirectUriand refreshTokento be assigned.\n",
            "üí° Graphlit now supports Intercom feeds for ingesting Intercom Articles and Tickets. We will ingest Intercom Articles as PAGEcontent type, and Tickets as ISSUEcontent type. Intercom feeds require the accessTokenproperty to be assigned.\n",
            "üí° Graphlit now supports Zendesk feeds for ingesting Zendesk Articles and Tickets.  We will ingest Zendesk Articles as PAGEcontent type, and Tickets as ISSUEcontent type. Zendesk feeds require the accessTokenproperty and your Zendesk subdomain to be assigned.\n",
            "Graphlit now supports the latest OpenAI o1 model, with the model enums O1_200kand O1_200k_20241217.\n",
            "Graphlit now supports the latest Gemini Flash 2.0 Experimental model, with the model enum GEMINI_2_0_FLASH_EXPERIMENTAL.\n",
            "Graphlit now supports the latest Cohere R7B model, with the model enum COMMAND_R7B_202412.\n",
            "Graphlit now supports returning the low-level details from prompting RAG conversations, by adding the includeDetailsparameter and setting to True. This includes details on the number of sources, the exact list of messages provided to the LLM, and more.\n",
            "We have added support for filtering of observables, such as Person or Organization, by URI property.\n",
            "We have added the ability to bypass semantic search in content retrieval with conversations. You can assign NONEfor the conversation search type, and it will ignore the user prompt when retrieving content.  It will inject all contents resulting from the content filter into the RAG prompt context.\n",
            "We have added a new createdInLastproperty to all entity filters, which allows easier filtering of entities created within a recent time period. Also, we have added a new inLastproperty to the content filter, which allows easier filtering of content authored within a recent time period. For example, find all images taken in the last 3 days, or find me all emails I received yesterday.\n",
            "We have added support for the latest Azure AI Document Intelligence models, with enums US_PAY_STUB, US_BANK_STATEMENT, and US_BANK_CHECK.\n",
            "We have added support for Google Drive and OneDrive feeds to ingest specific files by providing a list of file identifiers (files), in addition to the folder identifier (folderId).  If files identifiers are provided, they take precedence over the folder identifier.\n",
            "‚ö° For projects upgraded to the Starter Tier after Dec 9, 2024, we have removed the content items limit. Now you can store an unlimited number of content items (i.e. files, web pages, Slack messages) on the Starter or Growth Tiers.  If you have an existing project on the Starter Tier, please reach out and we will manually remove that content item limit on the project.\n",
            "Bugs Fixed\n",
            "GPLA-3529: Can't assign collection to multitenant content\n",
            "GPLA-3579: Should decode HTML characters when parsing HTML email\n",
            "GPLA-3576: Ingesting content in-place doesn't handle isSynchronous properly\n",
            "GPLA-3457: IsFeedDone doesn't return True for finished feed with no contents\n",
            "GPLA-3572: Not handling HTTP 400 error on uploading from URI\n",
            "PreviousDecember 27: Support for LLM fallbacks, native Google Docs formats, website unblocking, bug fixes\n",
            "NextDecember 9: Support for website mapping, web page screenshots, Groq Llama 3.3 model, bug fixes\n",
            "Last updated5 days ago\n",
            "- Completion [375 tokens (includes JSON guardrails tokens)], throughput: 75.618 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for Dropbox feeds for file ingestion, requiring appKey, appSecret, redirectUri, and refreshToken.\n",
            "  - Support for Box feeds for file ingestion, requiring clientId, clientSecret, redirectUri, and refreshToken.\n",
            "  - Support for Intercom feeds for ingesting Articles and Tickets, requiring accessToken.\n",
            "  - Support for Zendesk feeds for ingesting Articles and Tickets, requiring accessToken and Zendesk subdomain.\n",
            "  - Support for OpenAI o1 model with enums O1_200k and O1_200k_20241217.\n",
            "  - Support for Gemini Flash 2.0 Experimental model with enum GEMINI_2_0_FLASH_EXPERIMENTAL.\n",
            "  - Support for Cohere R7B model with enum COMMAND_R7B_202412.\n",
            "  - Ability to return low-level details from RAG conversations with includeDetails parameter.\n",
            "  - Support for filtering observables by URI property.\n",
            "  - Ability to bypass semantic search in content retrieval with conversations.\n",
            "  - New createdInLast property for entity filters and inLast property for content filters.\n",
            "  - Support for Azure AI Document Intelligence models with enums US_PAY_STUB, US_BANK_STATEMENT, and US_BANK_CHECK.\n",
            "  - Support for Google Drive and OneDrive feeds to ingest specific files by file identifiers.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Removal of content items limit for projects upgraded to the Starter Tier after December 9, 2024.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issues with multitenant content assignment, HTML character decoding in emails, synchronous content ingestion, feed completion status, and HTTP error handling during uploads.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: December 22, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced integration capabilities with popular cloud services and improved content management features.\n",
            "\n",
            "2024-12-30T04:06:50.673Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:04.100360, used credits [0.00702600]\n",
            "- CONTENT [67150a0e-9b17-4261-8f62-1c57686d46e1]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [1042 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/february-2024/february-21-support-for-onedrive-and-google-drive-feeds-extract-images-from-pdfs-bug-fixes</name><title>February 21: Support for OneDrive and Google Drive feeds, extract images from PDFs, bug fixes | Graphlit Changelog</title></metadata> üåßÔ∏è\tFebruary 2024\n",
            "February 21: Support for OneDrive and Google Drive feeds, extract images from PDFs, bug fixes\n",
            "New Features\n",
            "üí° Graphlit now supports OneDrive and Google Drive feeds.  Files can be ingested from OneDrive or Google Drive, including shared drives where the authenticated user has access.  Both OneDrive and Google Drive support the reading of existing files, and tracking new files added to storage with recurrent feeds.\n",
            "üí° Graphlit now supports email backup files, such as EML or MSG, which will be assigned the EMAIL file type.  During email file preparation, we will automatically extract and ingest any file attachments.\n",
            "üí° Graphlit now automatically extracts embedded images in PDF files, ingests them as content objects, and links them as children of the parent PDF.\n",
            "üí° Graphlit now supports recursive Notion feeds.  When the isRecursive flag is true in the Notion feed properties, we will crawl child pages and databases, and recursively ingest them in addition to the specified pages and databases.\n",
            "Added support for assigning collections to content ingested with the ingestPage, ingestFile or ingestText mutations.  This saves a step where the content will automatically be added to the collection(s) without requiring another mutation call.\n",
            "Added support for the CODE file type for a wide variety of source code formats, i.e. Python .py, Javascript .js.  Code files use optimized text splitting for enhanced search and retrieval.\n",
            "Added support for customGuidance in Specification object, which can be used for injecting a guidance prompt during the RAG process.  For example, you can instruct the LLM to return a default response string if no content sources are found via semantic search.\n",
            "Added tenants field to Project object, which returns a list of all tenant IDs which have been used to create an entity in Graphlit.\n",
            "Added email metadata, separate from document metadata.  Now emails will contain indexed metadata such as to, from, or subject.\n",
            "‚ö° The contents field for content objects has been replaced with children and parent fields.  For example, when a ZIP file is unpacked, the unpacked files will be added as children of the ZIP file, and the ZIP file will be the parent of each of the unpacked files.\n",
            "‚ö° Removed enableImageAnalysis field from image preparation properties in workflow object.  Now is enabled by default.\n",
            "‚ö° Moved disableSmartCapture field to preparation workflow stage from page preparation properties.  This is used to disable the use of headless Chrome browser to capture HTML from web pages.  It is enabled by default, and if disabled, Graphlit will simply download the HTML from the web page rather than rendering on headless Chrome browser.\n",
            "Bugs Fixed\n",
            "GPLA-2099: Failed to ingest ArXiV PDF.  Fixed PDF parsing error.\n",
            "GPLA-2174: LLM response is incorrect with conversation history, but no content sources.\n",
            "GPLA-2199: ZIP package left in Indexed state after content workflow.\n",
            "PreviousMarch 10: Support for Claude 3, Mistral and Groq models, usage/credits telemetry, bug fixes\n",
            "NextFebruary 2: Support for Semantic Alerts, OpenAI 0125 models, performance enhancements, bug fixes\n",
            "Last updated9 months ago\n",
            "- Completion [325 tokens (includes JSON guardrails tokens)], throughput: 79.261 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for OneDrive and Google Drive feeds, allowing ingestion of files from shared drives.\n",
            "  - Support for email backup files (EML, MSG) with automatic extraction of attachments.\n",
            "  - Automatic extraction of embedded images from PDF files, linking them as children of the parent PDF.\n",
            "  - Support for recursive Notion feeds with the isRecursive flag for crawling child pages and databases.\n",
            "  - Collections can now be assigned to content during ingestion without additional mutation calls.\n",
            "  - Introduction of CODE file type for various source code formats with optimized text splitting.\n",
            "  - Custom guidance can be injected during the RAG process via the Specification object.\n",
            "  - Added tenants field to Project object for listing tenant IDs used in entity creation.\n",
            "  - Email metadata is now indexed separately from document metadata.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Contents field in content objects replaced with children and parent fields for better structure.\n",
            "  - Removed enableImageAnalysis field; it is now enabled by default.\n",
            "  - Moved disableSmartCapture field to preparation workflow stage, enabled by default.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed PDF parsing error for ArXiV PDFs (GPLA-2099).\n",
            "  - Corrected LLM response issues with conversation history and no content sources (GPLA-2174).\n",
            "  - Resolved issue of ZIP package remaining in Indexed state after content workflow (GPLA-2199).\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: February 21, 2024.\n",
            "\n",
            "- Value:\n",
            "  - These updates enhance file ingestion capabilities, improve metadata handling, and streamline workflows for developers.\n",
            "\n",
            "2024-12-30T04:06:49.912Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:03.342199, used credits [0.00559500]\n",
            "- CONTENT [3923639b-14f1-484b-86e7-7c6f6e67461d]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [861 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/august-2023/august-3-new-data-model-for-observations-new-category-entity</name><title>August 3: New data model for Observations, new Category entity | Graphlit Changelog</title></metadata> üéÇ\tAugust 2023\n",
            "August 3: New data model for Observations, new Category entity\n",
            "New Features\n",
            "üí° Revised data model for Observations, Occurrences and observables (i.e. Person, Organization).  Now after entity extraction, content will have one Observation for each observed entity, and a list of occurrences.  Occurrence now supports text, time and image occurrence types.  (Text: page index, time: start/end timestamp, image: bounding box)  Observations now have ObservableType and Observable fields, which specify the observed entity type and entity reference.\n",
            "üí° Added Category entity to GraphQL data model, which supports PII categories such as Phone Number or Credit Card Number.\n",
            "Added probability field to model properties, for the LLM's token probability.  (See OpenAI documentation for more detail.)\n",
            "Added error field to feeds.  If a feed fails to read from the data source, and is marked as ERRORED state, the error field will have the error description.\n",
            "Support reingestion of changed files from feeds.  For feeds, such as SharePoint or Web, where we can recognize that a file or page was updated, we will now reingest the content in-place.  Content will keep the same ID, and will restart the content workflow by re-downloading the updated content from the data source.   Existing observations will be deleted, and new observations will be created from the updated content.\n",
            "‚ÑπÔ∏è Ingestion of content is now idempotent, meaning if you ingest content again from the same URI, we will reingest the content in-place, while keeping the same ID.  (If we can recognize the content has not changed, such as by ETag, we will return the existing content object.)\n",
            "‚ÑπÔ∏è Changed GraphQL data type of SharePoint tenantId, libraryId and siteId to ID rather than String.\n",
            "‚ú® Performance optimization of entity extraction, and the creation of observations.\n",
            "Bugs Fixed\n",
            "GPLA-1130: Only was extracting text from first column of PDF tables.\n",
            "GPLA-1140: Text from DOCX tables was not extracted properly.\n",
            "GPLA-1154: Audio content ingested from RSS feed was not deleted when feed was deleted.\n",
            "PreviousAugust 9: Support direct text, Markdown and HTML ingestion; new Specification LLM strategy\n",
            "NextJuly 15: Support for SharePoint feeds, new Conversation features\n",
            "Last updated1 year ago\n",
            "- Completion [251 tokens (includes JSON guardrails tokens)], throughput: 75.100 tokens/sec:\n",
            "- New Features:\n",
            "  - Revised data model for Observations, Occurrences, and observables (e.g., Person, Organization).\n",
            "  - Each observed entity now has one Observation and a list of occurrences (supports text, time, and image types).\n",
            "  - Added Category entity to GraphQL data model for PII categories (e.g., Phone Number, Credit Card Number).\n",
            "  - Introduced probability field for LLM's token probability.\n",
            "  - Added error field to feeds for error descriptions on failed reads.\n",
            "  - Support for reingestion of changed files from feeds, maintaining the same ID.\n",
            "  - Idempotent content ingestion from the same URI, returning existing content if unchanged.\n",
            "  - Changed GraphQL data type for SharePoint identifiers to ID.\n",
            "  - Performance optimization for entity extraction and observation creation.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Improved handling of content ingestion and updates.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed extraction issues from PDF and DOCX tables.\n",
            "  - Resolved issue where audio content from RSS feeds was not deleted upon feed deletion.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: August 2023.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers improved data handling, enhanced performance, and better error management.\n",
            "\n",
            "2024-12-30T04:06:48.934Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:04.925170, used credits [0.00432000]\n",
            "- CONTENT [fbde99f0-f7ca-4f5d-a318-eb7f4de07912]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [600 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/august-2024/august-20-support-for-medical-entities-anthropic-prompt-caching-bug-fixes</name><title>August 20: Support for medical entities, Anthropic prompt caching, bug fixes | Graphlit Changelog</title></metadata> üéÇ\tAugust 2024\n",
            "August 20: Support for medical entities, Anthropic prompt caching, bug fixes\n",
            "New Features\n",
            "üí° Graphlit now supports the extraction of medical-related entities: MedicalStudy, MedicalCondition, MedicalGuideline, MedicalDrug, MedicalDrugClass, MedicalIndication, MedicalContraindication, MedicalTest, MedicalDevice, MedicalTherapy, and MedicalProcedure.\n",
            "üí° Graphlit now supports medical-related entities in GraphRAG, and via API for queries and mutations.\n",
            "Added support for Anthropic prompt caching. When using Anthropic Sonnet 3.5 or Haiku 3, Anthropic will now cache the entity extraction and LLM document preparation system prompts, which saves on token cost and increases performance.\n",
            "Bugs Fixed\n",
            "GPLA-3104: Should default search type to VECTOR, when performing entity similarity filter.\n",
            "GPLA-3112: Empty PDF fails entity extraction.\n",
            "PreviousSeptember 1: Support for FHIR enrichment, latest Cohere models, bug fixes\n",
            "NextAugust 11: Support for Azure AI Document Intelligence by default, language-aware summaries\n",
            "Last updated4 months ago\n",
            "- Completion [210 tokens (includes JSON guardrails tokens)], throughput: 42.638 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for extraction of medical-related entities: MedicalStudy, MedicalCondition, MedicalGuideline, MedicalDrug, MedicalDrugClass, MedicalIndication, MedicalContraindication, MedicalTest, MedicalDevice, MedicalTherapy, and MedicalProcedure.\n",
            "  - Medical-related entities supported in GraphRAG and via API for queries and mutations.\n",
            "  - Added support for Anthropic prompt caching, improving performance and reducing token costs when using Anthropic Sonnet 3.5 or Haiku 3.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Improved entity extraction and LLM document preparation through caching.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed default search type to VECTOR for entity similarity filter (GPLA-3104).\n",
            "  - Resolved issue where empty PDFs failed entity extraction (GPLA-3112).\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: August 20, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Enhancements provide developers with improved capabilities for handling medical data and increased efficiency in using Anthropic models.\n",
            "\n",
            "2024-12-30T04:06:46.488Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:06.404666, used credits [0.00840000]\n",
            "- CONTENT [f2817947-a5aa-41d7-a297-b6f16a2d42e1]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [1224 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/december-2023/december-10-support-for-openai-gpt-4-turbo-llama-2-and-mistral-models-query-by-example-bug-fixes</name><title>December 10: Support for OpenAI GPT-4 Turbo, Llama 2 and Mistral models; query by example, bug fixes | Graphlit Changelog</title></metadata> üéÑ\tDecember 2023\n",
            "December 10: Support for OpenAI GPT-4 Turbo, Llama 2 and Mistral models; query by example, bug fixes\n",
            "New Features\n",
            "üí° Graphlit now supports the OpenAI GPT-4 Turbo 128k model, both in Azure OpenAI and native OpenAI services.  Added new model enum GPT4_TURBO_VISION_128K.\n",
            "üí° Graphlit now supports Llama 2 7b, 13b, 70b models and Mistral 7b model, via Replicate.  Developers can use their own Replicate API key, or be charged as credits for Graphlit usage.\n",
            "üí° Graphlit now supports the Anthropic Claude 2.1 model. Added new model enum CLAUDE_2_1.\n",
            "üí° Graphlit now supports the OpenAI GPT-4 Vision model for image descriptions and text extraction.  Added new model enum GPT4_TURBO_VISION_128K. See usage example in \"Multimodal RAG\" blog post.\n",
            "Added query by example to contents query.  Developers can specify one or more example contents, and query will use vector embeddings to return similar contents.\n",
            "Added query by example to conversations query.  Developers can specify one or more example conversations, and query will use vector embeddings to return similar conversations.\n",
            "Added vector search support for conversations queries.  Developers can provide search text which will use vector embeddings to return similar conversations.\n",
            "Added promptSpecifications mutation for directly prompting multiple models.  This can be used to evaluate prompts against multiple models or compare different specification parameters in parallel.\n",
            "Added promptStrategy field to Specification, which supports multiple strategy types for preprocessing the prompt before being sent to the LLM model.  For example, REWRITE prompt strategy will ask LLM to rewrite the incoming user prompt based on the previous conversation messages.\n",
            "Added suggestConversation mutation, which returns a list of suggested followup questions based on the specified conversation and related contents.  This can be used to auto-suggest questions for chatbot users.\n",
            "Added new summarization types: CHAPTERS, QUESTIONS and POSTS.   See usage examples in the \"LLMs for Podcasters\" blog post.\n",
            "Added versioned model enums such as GPT4_0613 and GPT35_TURBO_16K_1106.  Without version specified, such as GPT35_TURBO_16K, Graphlit will use the latest production model version, as defined by the LLM vendor.\n",
            "Added lookupContents query to get multiple contents by id in one query.\n",
            "‚ö° In Content type, headline field was renamed to headlines and now returns an array of strings.\n",
            "‚ö° Entity names are now limited to 1024 characters.  Names will be truncated if they exceed the maximum length.\n",
            "‚ö° In SummarizationTypes enum, BULLET_POINTS was renamed to BULLETS.\n",
            "‚ö° In ProjectStorage type, originalTotalSize was renamed to totalSize, and totalRenditionSize field was added.  totalSize is the sum of the ingested source file sizes, and totalRenditionSize is the sum of the source file sizes and any derived rendition sizes.\n",
            "‚ö° In ConversationStrategy type, strategyType was renamed to type for consistency with rest of data model.\n",
            "‚ö° In Specification type, optimizeSearchConversation was removed, and now is handled by OPTIMIZE_SEARCH prompt strategy.\n",
            "Bugs Fixed\n",
            "GPLA-1725: Should ignore RSS.xml from web feed sitemap\n",
            "GPLA-1726: GPT-3.5 Turbo 16k LLM is adding \"Citation #\" to response\n",
            "GPLA-1698: Workflow not applied to link-crawled content\n",
            "GPLA-1692: Mismatched project storage total size, when some content has errored\n",
            "GPLA-1237: Add relevance threshold for semantic search\n",
            "PreviousJanuary 18: Support for content publishing, LLM tools, CLIP image embeddings, bug fixes\n",
            "NextOctober 30: Optimized conversation responses; added observable aliases; bug fixes\n",
            "Last updated11 months ago\n",
            "- Completion [394 tokens (includes JSON guardrails tokens)], throughput: 61.518 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for OpenAI GPT-4 Turbo 128k model in Azure OpenAI and native OpenAI services.\n",
            "  - Support for Llama 2 (7b, 13b, 70b) and Mistral 7b models via Replicate.\n",
            "  - Support for Anthropic Claude 2.1 model.\n",
            "  - Support for OpenAI GPT-4 Vision model for image descriptions and text extraction.\n",
            "  - Query by example added for contents and conversations, utilizing vector embeddings.\n",
            "  - Vector search support for conversations queries.\n",
            "  - New promptSpecifications mutation for prompting multiple models.\n",
            "  - New promptStrategy field for preprocessing prompts.\n",
            "  - SuggestConversation mutation for auto-suggesting follow-up questions.\n",
            "  - New summarization types: CHAPTERS, QUESTIONS, and POSTS.\n",
            "  - Versioned model enums introduced (e.g., GPT4_0613).\n",
            "  - LookupContents query to retrieve multiple contents by ID.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Renamed headline field to headlines, returning an array of strings.\n",
            "  - Entity names limited to 1024 characters.\n",
            "  - BULLET_POINTS renamed to BULLETS in SummarizationTypes enum.\n",
            "  - ProjectStorage type fields renamed for clarity.\n",
            "  - Removed optimizeSearchConversation from Specification type, now handled by OPTIMIZE_SEARCH prompt strategy.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Ignored RSS.xml from web feed sitemap.\n",
            "  - Resolved issue with GPT-3.5 Turbo 16k LLM adding \"Citation #\" to responses.\n",
            "  - Fixed workflow application to link-crawled content.\n",
            "  - Corrected mismatched project storage total size.\n",
            "  - Added relevance threshold for semantic search.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: December 10, 2023.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced model support, improved querying capabilities, and streamlined prompt management, facilitating more efficient and effective application development.\n",
            "\n",
            "2024-12-30T04:06:46.435Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:02.155093, used credits [0.00461400]\n",
            "- CONTENT [0932e05b-1816-4e99-a4ef-7bc475de60fc]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [690 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/february-2024/february-2-support-for-semantic-alerts-openai-0125-models-performance-enhancements-bug-fixes</name><title>February 2: Support for Semantic Alerts, OpenAI 0125 models, performance enhancements, bug fixes | Graphlit Changelog</title></metadata> üåßÔ∏è\tFebruary 2024\n",
            "February 2: Support for Semantic Alerts, OpenAI 0125 models, performance enhancements, bug fixes\n",
            "New Features\n",
            "üí° Graphlit now supports Semantic Alerts, which allows for LLM summarization and publishing of content, on a periodic basis.  This is useful for generating daily reports from email, Slack or other time-based feeds.  Alerts support the same publishing options, i.e. audio and text, as the publishContents mutation.\n",
            "üí° Graphlit now supports the latest OpenAI 0125 model versions, for GPT-4 and GPT-3.5 Turbo.  We will add support for Azure OpenAI when Microsoft releases support for these.\n",
            "Slack feeds now support a listing type field, where you can specify if you want PAST or NEW Slack messages in the feed.\n",
            "üî• This release provides many performance enhancements, which will speed up the content workflows for ingested content.\n",
            "Bugs Fixed\n",
            "GPLA-2114: Collections not being added to text embedding index documents.\n",
            "GPLA-2063: Not handling hallucinated citations.\n",
            "GPLA-1916: Collections not inherited from project-scope into tenant-scope.\n",
            "GPLA-2105: Should error on add/remove of contents to/from collections if content does not exist.\n",
            "PreviousFebruary 21: Support for OneDrive and Google Drive feeds, extract images from PDFs, bug fixes\n",
            "NextJanuary 22: Support for Google and Microsoft email feeds, reingest content in-place, bug fixes\n",
            "Last updated10 months ago\n",
            "- Completion [212 tokens (includes JSON guardrails tokens)], throughput: 98.372 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for Semantic Alerts for LLM summarization and content publishing on a periodic basis, useful for generating daily reports from various feeds.\n",
            "  - Support for OpenAI 0125 model versions for GPT-4 and GPT-3.5 Turbo, with plans to add Azure OpenAI support when available.\n",
            "  - Slack feeds now include a listing type field to specify PAST or NEW messages.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Performance enhancements to speed up content workflows for ingested content.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issues with collections not being added to text embedding index documents.\n",
            "  - Resolved handling of hallucinated citations.\n",
            "  - Addressed inheritance of collections from project-scope to tenant-scope.\n",
            "  - Implemented error handling for adding/removing contents to/from collections if content does not exist.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: February 2, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers improved content management capabilities, enhanced performance, and better error handling in workflows.\n",
            "\n",
            "2024-12-30T04:06:46.355Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:03.669809, used credits [0.00661500]\n",
            "- CONTENT [d40abe32-e564-4a6c-bd34-cea90b98c172]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [913 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/july-2023/july-15-support-for-sharepoint-feeds-new-conversation-features</name><title>July 15: Support for SharePoint feeds, new Conversation features | Graphlit Changelog</title></metadata> üéá\tJuly 2023\n",
            "July 15: Support for SharePoint feeds, new Conversation features\n",
            "New Features\n",
            "üí° Added support for SharePoint feeds: now can create feed to ingest files from SharePoint document library (and optionally, folder within document library)\n",
            "üí° Added support for PII detection during entity extraction from text documents and audio transcripts: now we will create labels such as PII: Social Security Number automatically when PII is detected\n",
            "üí° Added support for developer's own OpenAI API keys and Azure OpenAI deployments in Specifications\n",
            "‚ÑπÔ∏è  Changed semantics of deleteFeed to delete the contents ingested by the feed; since contents are linked to feeds, now feeds can be disabled, while keeping the lineage to the feed, and if feeds are deleted, they will delete the linked contents, so we never lose the feed-to-content lineage\n",
            "Added GraphQL query for SharePoint consent URI, for registered Graphlit Platform Azure AD application\n",
            "Better handling of web sitemap indexes: now if a sitemap.xml contains a sitemapindex element, we will load all linked sitemaps for evaluating web pages to ingest from Web feed\n",
            "Added new GraphQL mutations for openConversation, closeConversation and undoConversation\n",
            "Added timestamps to Conversation messages\n",
            "Added new GraphQL mutations for openCollection and closeCollection\n",
            "Added more configuration for content search: now can specify searchType (KEYWORD, VECTOR, HYBRID) and queryType (SIMPLE, FULL - aka Lucene syntax)\n",
            "Better parsing of iTunes podcast metadata\n",
            "‚ö° Renamed listingLimit field on feeds to readLimit\n",
            "‚ö° Renamed topK to numberSimilar for content vector search type\n",
            "‚ö° Changed GraphQL feed properties: split out azure into azureBlob and azureFile properties\n",
            "‚ö° Changed GraphQL specification properties: split out openAI into openAI and azureOpenAI properties\n",
            "‚ö° Removed count fields on query results, and replaced with explicit count{Entity} queries, which support search and filtering.\n",
            "Bugs Fixed\n",
            "GPLA-1043: Reddit readLimit not taking effect: now the specified limit of Reddit posts will be leveraged for Reddit feeds\n",
            "GPLA-1064: Performance on entity extraction and observation creation for large PDFs was under expectations: now able to build knowledge graph from large PDFs much faster (4x speed improvement)\n",
            "GPLA-1053: If rendition generation errored during content workflow, the content was not properly marked as errored\n",
            "GPLA-1102: Large Web sitemaps were slow to load; rewrote sitemap index handling, and now can process sitemaps with 150K+ entries in seconds.\n",
            "PreviousAugust 3: New data model for Observations, new Category entity\n",
            "Last updated5 months ago\n",
            "- Completion [323 tokens (includes JSON guardrails tokens)], throughput: 88.015 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for SharePoint feeds to ingest files from SharePoint document libraries.\n",
            "  - PII detection during entity extraction from text documents and audio transcripts, automatically labeling detected PII.\n",
            "  - Support for custom OpenAI API keys and Azure OpenAI deployments in Specifications.\n",
            "  - GraphQL query for SharePoint consent URI for registered Azure AD applications.\n",
            "  - Improved handling of web sitemap indexes to load linked sitemaps.\n",
            "  - New GraphQL mutations for managing conversations and collections.\n",
            "  - Timestamps added to Conversation messages.\n",
            "  - Enhanced content search configuration with searchType and queryType options.\n",
            "  - Better parsing of iTunes podcast metadata.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Renamed listingLimit to readLimit and topK to numberSimilar for clarity.\n",
            "  - Split GraphQL feed properties into azureBlob and azureFile.\n",
            "  - Split GraphQL specification properties into openAI and azureOpenAI.\n",
            "  - Removed count fields on query results, replaced with explicit count queries for better search and filtering.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed Reddit readLimit issue to ensure specified limits are applied.\n",
            "  - Improved performance of entity extraction and observation creation for large PDFs (4x speed improvement).\n",
            "  - Corrected error handling for rendition generation in content workflows.\n",
            "  - Enhanced loading speed for large web sitemaps, now processing 150K+ entries quickly.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: July 15, 2023.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced capabilities for data ingestion, improved performance, and better management of content and conversations.\n",
            "\n",
            "2024-12-30T04:06:44.151Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:03.260318, used credits [0.00580500]\n",
            "- CONTENT [a263132e-7225-40d3-a75d-39b3ef1edbd1]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [811 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/august-2024/august-8-support-for-llm-based-document-extraction-.net-sdk-bug-fixes</name><title>August 8: Support for LLM-based document extraction, .NET SDK, bug fixes | Graphlit Changelog</title></metadata> üéÇ\tAugust 2024\n",
            "August 8: Support for LLM-based document extraction, .NET SDK, bug fixes\n",
            "New Features\n",
            "üí° Graphlit now supports LLM-based document preparation, using vision-capable models such as OpenAI GPT-4o and Anthropic Sonnet 3.5.  This is available via the MODEL_DOCUMENT preparation service type, and you can assign a customspecification object and bring your own LLM keys.\n",
            "üí° Graphlit now provides an open source .NET SDK, supporting .NET 6 and .NET 8 (and above).  SDK package can be found on Nuget.org.  Code samples can be found on GitHub.\n",
            "Added identifier property to Content object for mapping content to external database identifiers.  This is supported for content filtering as well.\n",
            "Added support for Claude 3 vision models for image-based entity extraction, using the MODEL_IMAGE entity extraction service.\n",
            "Added context augmentation to conversations, via the augmentedFilter property on the Conversation object.  Any content which matches this augmented filter will be injected into the LLM prompt content, without needing to be related by vector similarity to the user prompt.  This is useful for specifying domain knowledge which should always be referenced by the RAG pipeline.\n",
            "Added support for the latest snapshot of OpenAI GPT-4o, with the model enum GPT4O_128K_20240806.\n",
            "Added reranking of related entities, when preparing the LLM prompt context for GraphRAG.  If reranking is enabled, the metadata from the related entities will be reranked with the same reranker assigned to the conversation specification.\n",
            "‚ö° We have changed the type of the duration field in the AudioMetadata and VideoMetadata types to be TimeSpan rather than string, as to be more consistent with the rest of the API data model.\n",
            "Bugs Fixed\n",
            "GPLA-2884: Support retry on HTTP 529 (Overloaded) error from Anthropic API.\n",
            "PreviousAugust 11: Support for Azure AI Document Intelligence by default, language-aware summaries\n",
            "NextJuly 28: Support for indexing workflow stage, Azure AI language detection, bug fixes\n",
            "Last updated4 months ago\n",
            "- Completion [281 tokens (includes JSON guardrails tokens)], throughput: 86.188 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for LLM-based document preparation using models like OpenAI GPT-4o and Anthropic Sonnet 3.5 via MODEL_DOCUMENT service.\n",
            "  - Introduction of an open source .NET SDK for .NET 6 and .NET 8, available on Nuget.org with code samples on GitHub.\n",
            "  - Added identifier property to Content object for mapping to external database identifiers, aiding in content filtering.\n",
            "  - Support for Claude 3 vision models for image-based entity extraction using MODEL_IMAGE service.\n",
            "  - Context augmentation in conversations through augmentedFilter property, allowing injection of domain knowledge into LLM prompts.\n",
            "  - Support for the latest OpenAI GPT-4o snapshot (GPT4O_128K_20240806).\n",
            "  - Reranking of related entities for LLM prompt context preparation in GraphRAG.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Changed duration field type in AudioMetadata and VideoMetadata from string to TimeSpan for consistency in API data model.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issue GPLA-2884 to support retry on HTTP 529 (Overloaded) error from Anthropic API.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: August 8, 2024.\n",
            "\n",
            "- Value:\n",
            "  - These updates enhance document extraction capabilities, improve SDK accessibility for developers, and streamline content management and entity extraction processes.\n",
            "\n",
            "2024-12-30T04:06:43.851Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:04.879231, used credits [0.00473100]\n",
            "- CONTENT [7c8442ac-7d94-4a40-9a3b-fdda07048992]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [673 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/january-2024/january-22-support-for-google-and-microsoft-email-feeds-reingest-content-in-place-bug-fixes</name><title>January 22: Support for Google and Microsoft email feeds, reingest content in-place, bug fixes | Graphlit Changelog</title></metadata> üéÜ\tJanuary 2024\n",
            "January 22: Support for Google and Microsoft email feeds, reingest content in-place, bug fixes\n",
            "New Features\n",
            "üí° Graphlit now supports Google and Microsoft email feeds.  Email feeds can be created to ingest past emails, or poll for new emails.  Emails create an EMAIL content type. Attachment files can optionally be extracted from emails, and will be linked to their parent email content. If assigning a workflow to the feed, the workflow will be applied both to the email content and the extracted attachment files.\n",
            "üí° Graphlit now supports reingesting content in-place.  The ingestText, ingestPage and ingestFile mutations now take an optional id parameter for an existing content object.  If this id is provided, the existing content will be updated from the provided text or URI source, and will restart the assigned workflow.\n",
            "Added restartAllContents mutation to restart workflow on all partially-ingested contents in project.\n",
            "Added text field to ConversationCitation type, which returns the relevant text from the content source with the citation.\n",
            "Bugs Fixed\n",
            "GPLA-1313: Not extracting links from HTML\n",
            "GPLA-2030: No text extracted from shapes in PPTX files\n",
            "PreviousFebruary 2: Support for Semantic Alerts, OpenAI 0125 models, performance enhancements, bug fixes\n",
            "NextJanuary 18: Support for content publishing, LLM tools, CLIP image embeddings, bug fixes\n",
            "Last updated8 months ago\n",
            "- Completion [226 tokens (includes JSON guardrails tokens)], throughput: 46.319 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for Google and Microsoft email feeds, allowing ingestion of past and new emails, creating an EMAIL content type. Attachments can be extracted and linked to their parent emails.\n",
            "  - Support for reingesting content in-place with optional id parameter for existing content objects, updating them from provided text or URI source, and restarting assigned workflows.\n",
            "  - Added restartAllContents mutation to restart workflows on all partially-ingested contents in a project.\n",
            "  - Added text field to ConversationCitation type to return relevant text from the content source with the citation.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Improved content ingestion capabilities with new features for email and content updates.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issue with not extracting links from HTML (GPLA-1313).\n",
            "  - Resolved problem of no text being extracted from shapes in PPTX files (GPLA-2030).\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: January 22, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced content ingestion options and improved workflow management, increasing efficiency in handling email and existing content updates.\n",
            "\n",
            "2024-12-30T04:06:42.624Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:04.425520, used credits [0.00511500]\n",
            "- CONTENT [257dc6c9-65d0-416d-9b1c-d412aeb42bd4]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [737 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/june-2024/june-21-support-for-the-claude-3.5-sonnet-model-knowledge-graph-semantic-search-and-bug-fixes</name><title>June 21: Support for the Claude 3.5 Sonnet model, knowledge graph semantic search, and bug fixes | Graphlit Changelog</title></metadata> üéì\tJune 2024\n",
            "June 21: Support for the Claude 3.5 Sonnet model, knowledge graph semantic search, and bug fixes\n",
            "New Features\n",
            "üí° Graphlit now supports the Anthropic Claude 3.5 Sonnet model, which can be assigned with the CLAUDE_3_5_SONNET model enum.\n",
            "üí° Graphlit now supports semantic search of observable entities in the knowledge graph, such as Person, Organization and Place.  These entity types will now have vector embeddings created from their enriched metadata, and support searching by similar text, and searching by similar entities.\n",
            "‚ö° We have changed the Google Drive and Google Email feed properties to require the Google OAuth client ID and client secret, along with the existing refresh token, for proper authentication against Google APIs.\n",
            "‚ö° We have added a credits quota on the Free Tier.  Once 1000 credits have been used on the Free Tier, no more content can be ingested, and an upgrade to a paid tier is required.  Customers will receive an email when the credits, storage or contents quota has been reached.\n",
            "Bugs Fixed\n",
            "GPLA-2837: Failed to ingest LinkedIn page as Web feed\n",
            "GPLA-2831: Zero-byte file was left in Indexed state\n",
            "GPLA-2834: Not reading any files from Azure blob feed with space in prefix\n",
            "GPLA-2828: Better handling for files with unknown (or missing) file extensions\n",
            "PreviousJuly 4: Support for webhook Alerts, keywords summarization, Deepseek 128k context window, bug fixes\n",
            "NextJune 9: Support for Deepseek models, JSON-LD webpage parsing, performance improvements and bug fixes\n",
            "Last updated6 months ago\n",
            "- Completion [242 tokens (includes JSON guardrails tokens)], throughput: 54.683 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for the Anthropic Claude 3.5 Sonnet model (model enum: CLAUDE_3_5_SONNET).\n",
            "  - Semantic search for observable entities in the knowledge graph (Person, Organization, Place) with vector embeddings for enriched metadata.\n",
            "  - Google Drive and Google Email feed properties now require Google OAuth client ID, client secret, and refresh token for authentication.\n",
            "  - Introduction of a credits quota on the Free Tier; after 1000 credits, content ingestion stops until an upgrade to a paid tier.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Improved authentication process for Google APIs.\n",
            "  - Notification system for Free Tier users when credits, storage, or content quotas are reached.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issues with ingesting LinkedIn pages, handling zero-byte files, reading files from Azure blob feeds with spaces, and better handling of files with unknown or missing extensions.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: June 21, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Enhancements provide developers with improved model support, better search capabilities, and clearer usage limits on the Free Tier, facilitating more efficient development and integration.\n",
            "\n",
            "2024-12-30T04:06:40.759Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:02.589924, used credits [0.00457800]\n",
            "- CONTENT [0ed6b24e-fec6-4008-8bb9-beda6073cbe6]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [710 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/july-2024/july-25-support-for-mistral-large-2-and-nemo-groq-llama-3.1-models-bug-fixes</name><title>July 25: Support for Mistral Large 2 & Nemo, Groq Llama 3.1 models, bug fixes | Graphlit Changelog</title></metadata> ‚òÄÔ∏è\tJuly 2024\n",
            "July 25: Support for Mistral Large 2 & Nemo, Groq Llama 3.1 models, bug fixes\n",
            "New Features\n",
            "üí° Graphlit now supports the Mistral Large 2 and Mistral Nemo models. The existing MISTRAL_LARGE model enum now will use Mistral Large 2.\n",
            "üí° Graphlit now supports the Llama 3.1 8b, 70b and 405b models on Groq.  (Note, these are rate-limited according to Groq's platform constraints.)\n",
            "Added support for revision strategy on data extraction specifications.  Now you can prompt the LLM to revise its previous data extraction response, similar to the existing completion revision strategy.\n",
            "Added version property for AzureDocumentPreparationProperties type for assigning the API version used by Azure AI Document Intelligence.   By default, Graphlit will continue to use the v4.0 (Preview) API version, but you can override this to assign version to V2023_10_31 to use the v3.1 (GA) API version instead.  For some documents, the General Availability (GA) version of the API can provide better results.\n",
            "Bugs Fixed\n",
            "GPLA-2988: Not extracting hyperlinks from Office documents.\n",
            "PreviousJuly 28: Support for indexing workflow stage, Azure AI language detection, bug fixes\n",
            "NextJuly 19: Support for OpenAI GPT-4o Mini, BYO-key for Azure AI, similarity by summary, bug fixes\n",
            "Last updated5 months ago\n",
            "- Completion [204 tokens (includes JSON guardrails tokens)], throughput: 78.767 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for Mistral Large 2 and Mistral Nemo models; existing MISTRAL_LARGE model enum updated.\n",
            "  - Support for Llama 3.1 models (8b, 70b, 405b) on Groq, with rate limits per Groq's platform.\n",
            "  - Added revision strategy for data extraction specifications, allowing LLM to revise previous responses.\n",
            "  - Version property added for AzureDocumentPreparationProperties to assign API version for Azure AI Document Intelligence; default is v4.0 (Preview), can override to V2023_10_31 for v3.1 (GA) API version.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issue with hyperlinks not being extracted from Office documents (GPLA-2988).\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: July 25, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Enhancements improve model support and data extraction capabilities, offering developers more flexibility and better results with Azure AI.\n",
            "\n",
            "2024-12-30T04:06:39.951Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:02.276765, used credits [0.00423600]\n",
            "- CONTENT [4b9dad6a-8d6f-4daa-b1d9-6c5277939931]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [640 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/july-2024/july-28-support-for-indexing-workflow-stage-azure-ai-language-detection-bug-fixes</name><title>July 28: Support for indexing workflow stage, Azure AI language detection, bug fixes | Graphlit Changelog</title></metadata> ‚òÄÔ∏è\tJuly 2024\n",
            "July 28: Support for indexing workflow stage, Azure AI language detection, bug fixes\n",
            "New Features\n",
            "Added indexing workflow stage. This provides for configuration of indexing services, which may infer metadata from the content.\n",
            "Added AZURE_AI_LANGUAGE content indexing service, which supports inferring the language of extracted text or transcript.\n",
            "Added support for language content metadata.  This returns a list of languages in ISO 639-1 format, which may have been inferred from the extracted text or transcript.\n",
            "Added support for MODEL_IMAGE extraction service.  This provides integration with vision models beyond those provided by OpenAI.  You can assign a custom specification and bring-your-own API key for image extraction models.\n",
            "‚ö° We have deprecated the OPENAI_IMAGE service type, and developers should now use the LLM image service instead.\n",
            "‚ö° We have removed the language field from AudioMetadata type, which has been replaced by the new LanguageMetadata type.\n",
            "Bugs Fixed\n",
            "GPLA-2987: Extracting text with Azure Doc Intelligence does not extract hyperlinks\n",
            "PreviousAugust 8: Support for LLM-based document extraction, .NET SDK, bug fixes\n",
            "NextJuly 25: Support for Mistral Large 2 & Nemo, Groq Llama 3.1 models, bug fixes\n",
            "Last updated5 months ago\n",
            "- Completion [193 tokens (includes JSON guardrails tokens)], throughput: 84.769 tokens/sec:\n",
            "- New Features:\n",
            "  - Added indexing workflow stage for configuring indexing services to infer metadata from content.\n",
            "  - Introduced AZURE_AI_LANGUAGE content indexing service for inferring language from extracted text or transcripts.\n",
            "  - Supported language content metadata returning a list of languages in ISO 639-1 format.\n",
            "  - Added MODEL_IMAGE extraction service for integration with custom vision models using a personal API key.\n",
            "  \n",
            "- Enhancements/Improvements:\n",
            "  - Deprecated OPENAI_IMAGE service type; developers should now use the LLM image service.\n",
            "  - Removed language field from AudioMetadata type, replaced with new LanguageMetadata type.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issue GPLA-2987 where Azure Doc Intelligence did not extract hyperlinks from text.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: July 28, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced capabilities for content indexing, language detection, and image extraction, improving overall functionality and flexibility.\n",
            "\n",
            "2024-12-30T04:06:38.860Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:02.902162, used credits [0.00503400]\n",
            "- CONTENT [41e9b6e8-c479-4416-8ec3-7168709d2861]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [730 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/july-2024/july-4-support-for-webhook-alerts-keywords-summarization-deepseek-128k-context-window-bug-fixes</name><title>July 4: Support for webhook Alerts, keywords summarization, Deepseek 128k context window, bug fixes | Graphlit Changelog</title></metadata> ‚òÄÔ∏è\tJuly 2024\n",
            "July 4: Support for webhook Alerts, keywords summarization, Deepseek 128k context window, bug fixes\n",
            "New Features\n",
            "üí° Graphlit now supports webhook Alerts.  In addition to Slack notifications, you can now receive an HTTP POST webhook with the results of the published text (or text and audio URI) from a prompted alert.\n",
            "Updated the Deepseek chat and coder models to support a 128k token context window.\n",
            "Added customSummary property to Content object, which returns the custom summary generated via preparation workflow.\n",
            "Added keywords summarization type, which is now stored in keywords property in Content object.\n",
            "Added slackChannels query, which returns the list of Slack channels from the workspace authenticated by the Slack bot token.\n",
            "‚ö° We have changed the response from the credits query to return a single ProjectCredits object, rather than the list of correlated objects previously returned.  The credits response now covers all credit usage over the time period specified.\n",
            "Bugs Fixed\n",
            "GPLA-2874: Processing entities is taking longer than 30min for 300+ page PDF\n",
            "GPLA-2875: Messages in queue expiring too early\n",
            "GPLA-2881: Feed read count increasing, after hitting read limit\n",
            "GPLA-2884: Need to handle Anthropic 'overloaded' API response\n",
            "GPLA-2906: JIRA issue identifier not assigned to issue metadata\n",
            "PreviousJuly 19: Support for OpenAI GPT-4o Mini, BYO-key for Azure AI, similarity by summary, bug fixes\n",
            "NextJune 21: Support for the Claude 3.5 Sonnet model, knowledge graph semantic search, and bug fixes\n",
            "Last updated5 months ago\n",
            "- Completion [237 tokens (includes JSON guardrails tokens)], throughput: 81.663 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for webhook Alerts, allowing HTTP POST notifications with published text results.\n",
            "  - Updated Deepseek models to support a 128k token context window.\n",
            "  - Added customSummary property to Content object for custom summaries.\n",
            "  - Introduced keywords summarization type, stored in the keywords property of Content object.\n",
            "  - Added slackChannels query to list Slack channels from the authenticated workspace.\n",
            "  - Changed credits query response to return a single ProjectCredits object covering all credit usage.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Improved response structure for credits query.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Resolved issue of processing entities taking longer than 30 minutes for large PDFs.\n",
            "  - Fixed early expiration of messages in the queue.\n",
            "  - Addressed incorrect feed read count after hitting the read limit.\n",
            "  - Handled Anthropic 'overloaded' API response.\n",
            "  - Assigned JIRA issue identifier to issue metadata.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: July 4, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Enhancements improve notification capabilities, model performance, and data handling, offering developers more efficient tools for managing alerts and processing content.\n",
            "\n",
            "2024-12-30T04:06:38.046Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:02.261353, used credits [0.00458400]\n",
            "- CONTENT [3d78b65e-a42d-44e9-8a9a-07faf938ee0d]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [700 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/march-2024/march-23-support-for-linear-github-issues-and-jira-issue-feeds-ingest-files-via-web-feed-sitemap</name><title>March 23: Support for Linear, GitHub Issues and Jira issue feeds, ingest files via Web feed sitemap | Graphlit Changelog</title></metadata> üçÄ\tMarch 2024\n",
            "March 23: Support for Linear, GitHub Issues and Jira issue feeds, ingest files via Web feed sitemap\n",
            "New Features\n",
            "üí° Graphlit now supports Linear, GitHub Issues and Atlassian Jira feeds.  Graphlit will ingest issues (aka tasks, stories) from these issue-tracking services as individual content items, which will be made searchable and conversational.\n",
            "üí° Added support for ISSUEcontent type, which includes metadata such as title, authors, commenters, status, type, project and team.\n",
            "üí° Added support for default feed read limit.  Now, if you don't specify the readLimit property on feeds, it will default to reading 100 content items.  You can override this default by assigning a custom read limit, which has no upper bounds.  However, one-shot feeds much complete within 15 minutes, or they will be stopped automatically.\n",
            "Added support for ingesting files referenced in a Web sitemap.  Previously any files (i.e. PDF, MP3) referenced in a sitemap.xml would be ignored.  Now you can optionally enable includeFiles in the WebFeedPropertiesInput object to have Graphlit ingest non-HTML pages as part of the Web feed.\n",
            "Bugs Fixed\n",
            "GPLA-2374: Failed to ingest MP4 with large XMP metadata.\n",
            "PreviousApril 7: Support for Discord feeds, Cohere reranking, section-aware chunking and retrieval\n",
            "NextMarch 13: Support for Claude 3 Haiku model, direct ingestion of Base64 encoded files\n",
            "Last updated8 months ago\n",
            "- Completion [207 tokens (includes JSON guardrails tokens)], throughput: 91.538 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for Linear, GitHub Issues, and Atlassian Jira feeds for ingesting issues as searchable content items.\n",
            "  - Introduction of ISSUE content type with metadata including title, authors, commenters, status, type, project, and team.\n",
            "  - Default feed read limit set to 100 content items, customizable with no upper bounds; one-shot feeds must complete within 15 minutes.\n",
            "  - Ingestion of files referenced in a Web sitemap is now supported, allowing non-HTML pages to be included.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Improved handling of files in Web sitemaps, enabling ingestion of various file types.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issue GPLA-2374 related to failing to ingest MP4 files with large XMP metadata.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: March 2024.\n",
            "  \n",
            "- Value:\n",
            "  - Enhances the platform's capability to integrate with popular issue-tracking services, improving content searchability and usability for developers.\n",
            "\n",
            "2024-12-30T04:06:38.036Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:05.146511, used credits [0.00711300]\n",
            "- CONTENT [1bc9cf17-e156-441d-a307-def6a31d693e]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [947 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/may-2024/may-5-support-for-jina-and-pongo-rerankers-microsoft-teams-feed-new-youtube-downloader-bug-fixes</name><title>May 5: Support for Jina and Pongo rerankers, Microsoft Teams feed, new YouTube downloader, bug fixes | Graphlit Changelog</title></metadata> üíê\tMay 2024\n",
            "May 5: Support for Jina and Pongo rerankers, Microsoft Teams feed, new YouTube downloader, bug fixes\n",
            "New Features\n",
            "üí° Graphlit now supports the Jina reranker and Pongo semantic filtering (reranking), in the Specification object.  Now you can choose between COHERE, PONGO and JINA for your reranking serviceType.\n",
            "üí° Graphlit now supports Microsoft Teams feeds for reading messages from Teams channels.\n",
            "Given changes in YouTube video player HTML, we have rewritten the YouTube downloader to support the new page format.\n",
            "Added better handling of HTTP errors when validating URIs.  Previously some websites were returning HTTP 403 (Forbidden) errors when validating their URI, or downloading content.  Now Graphlit is able to scrape these sites, which previously returned errors.\n",
            "Added support for updating content metadata in updateContent mutation.  Now the video, audio, document, etc. metadata can be updated after the content workflow has finished.\n",
            "Added query_contents_graph (and queryContentsGraph) functions to SDKs, which can be used to return nodes and edges from knowledge graph for visualization.\n",
            "‚ö° Citation indices have been changed to be one-based from zero-based.  For example, you will now see \"This is a citation. [1]\" as the first citation in the list.\n",
            "‚ö° Added isSynchronous flag to deleteAll and multiple delete mutations.  By default, bulk delete operations are now asynchronous (and completed after the mutation returns), unless the isSynchronous flag is set to true.\n",
            "‚ö° Added missing count mutations, such as countAlerts, countFeeds, etc.\n",
            "‚ö° Renamed query_content_facets to query_contents_facets in Python SDK\n",
            "‚ö° Renamed queryContentFacets to queryContentsFacets in Node.js SDK\n",
            "Bugs Fixed\n",
            "GPLA-2544: Page relevance not filled-in in all situations\n",
            "GPLA-2546: Not extracting links from PDF with Azure AI Doc Intelligence\n",
            "GPLA-2557: Sporadically returning HTTP 500 from GraphQL API\n",
            "GPLA-2573: Failed to re-ingest content which was deleted immediately after initial ingestion\n",
            "GPLA-2575: Not validating for empty (non-null) parameters in mutations\n",
            "GPLA-2578: Need to handle invalid JSON from LLMs; improper escaping or formatting\n",
            "GPLA-2585: Failed to ingest encoded file with colon (:) in name\n",
            "PreviousMay 15: Support for GraphRAG, OpenAI GPT-4o model, performance improvements and bug fixes\n",
            "NextApril 23: Support for Python and TypeScript SDKs, latest OpenAI, Cohere & Groq models, bug fixes\n",
            "Last updated7 months ago\n",
            "- Completion [356 tokens (includes JSON guardrails tokens)], throughput: 69.173 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for Jina and Pongo rerankers in the Specification object; options for COHERE, PONGO, and JINA as reranking service types.\n",
            "  - Microsoft Teams feeds support for reading messages from Teams channels.\n",
            "  - Rewritten YouTube downloader to accommodate changes in YouTube video player HTML.\n",
            "  - Improved handling of HTTP errors for URI validation and content downloading.\n",
            "  - Support for updating content metadata in updateContent mutation post-workflow.\n",
            "  - Added query_contents_graph functions to SDKs for knowledge graph visualization.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Citation indices changed from zero-based to one-based.\n",
            "  - Added isSynchronous flag for deleteAll and multiple delete mutations; default is asynchronous.\n",
            "  - Added missing count mutations (e.g., countAlerts, countFeeds).\n",
            "  - Renamed query_content_facets to query_contents_facets in Python SDK.\n",
            "  - Renamed queryContentFacets to queryContentsFacets in Node.js SDK.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed page relevance not being filled in all situations.\n",
            "  - Resolved issues with link extraction from PDFs using Azure AI Doc Intelligence.\n",
            "  - Addressed sporadic HTTP 500 errors from GraphQL API.\n",
            "  - Fixed re-ingestion failures for content deleted immediately after initial ingestion.\n",
            "  - Validated non-null parameters in mutations.\n",
            "  - Handled invalid JSON from LLMs with proper escaping or formatting.\n",
            "  - Fixed ingestion of encoded files with colons in names.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: May 5, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced flexibility with reranking options, improved integration with Microsoft Teams, and better error handling, leading to a more robust content management experience.\n",
            "\n",
            "2024-12-30T04:06:37.602Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:03.228775, used credits [0.00667200]\n",
            "- CONTENT [8a9c0eb5-3658-4cca-bf2c-d68cdbea3f15]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [1012 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/may-2024/may-15-support-for-graphrag-openai-gpt-4o-model-performance-improvements-and-bug-fixes</name><title>May 15: Support for GraphRAG, OpenAI GPT-4o model, performance improvements and bug fixes | Graphlit Changelog</title></metadata> üíê\tMay 2024\n",
            "May 15: Support for GraphRAG, OpenAI GPT-4o model, performance improvements and bug fixes\n",
            "New Features\n",
            "üí° Graphlit now supports GraphRAG, where the extracted entities in the knowledge graph can be added as additional context to your RAG con,versation.  Also, with GraphRAG, entities can be extracted from the user prompt, and used as additional content filters - or can be used to query related content sources, which are combined with the vector search results.  This can be configured by specifying your graphStrategy in the Specification object.\n",
            "üí° Graphlit now supports LLM revisions within RAG conversations, where the LLM can be prompted to revise its initial completion response. From our testing, this has been shown to provide 35% more output tokens with higher quality responses.  This can be configured by specifying your revisionStrategy, and you can use our built-in revision prompt, or provide a custom one, and specify how many revisions you want the LLM to make.\n",
            "üí° Graphlit now supports the new OpenAI GPT-4o model for RAG conversations.\n",
            "‚ö° We have changed the default model for Conversations to be OpenAI GPT-4o, from Azure OpenAI GPT-3.5 16k.  This provides faster performance and better quality output.\n",
            "Added graph to promptConversation response, so you can visualize or leverage the nodes and edges of the knowledge graph, resulting from the content retrieval.  For example, if a Person and Organization were observed in the cited content sources used by the RAG pipeline, you will get back those entities and their relationship (such as Person 'works-for' Organization).\n",
            "Expanded the enriched data from WIkipedia to include the long description of an entity.\n",
            "Added getSharePointLibraries, getSharePointFolders, and getOneDriveFolders queries to the API, which can be used to enumerate the storage services.  This makes locating the SharePoint libraryId easier, for example.\n",
            "Added getTeams and getTeamsChannels queries to the API for enumerating Microsoft Teams workspaces.\n",
            "Added extractedCount to the entity extraction connector to limit the number of extracted entities, per entity type.  I.e. if extracted count is 10, it will extract at most ten each of Persons, Organizations, etc.\n",
            "üî•  We have improved performance in several areas: creation of observations after entity extraction, access to cloud storage, rendering the RAG context.\n",
            "üî•  We have optimized the LLM entity extraction process to identify more properties, as well as entity-to-entity relationships.\n",
            "Bugs Fixed\n",
            "GPLA-2652: Not extracting text from HTML in RSS post\n",
            "GPLA-2627: Limit filter only returning half the results\n",
            "GPLA-2613: Not properly extracting structured text from JSON/XML formats\n",
            "PreviousJune 9: Support for Deepseek models, JSON-LD webpage parsing, performance improvements and bug fixes\n",
            "NextMay 5: Support for Jina and Pongo rerankers, Microsoft Teams feed, new YouTube downloader, bug fixes\n",
            "Last updated6 months ago\n",
            "- Completion [303 tokens (includes JSON guardrails tokens)], throughput: 93.844 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for GraphRAG, allowing extracted entities in the knowledge graph to enhance RAG conversations.\n",
            "  - LLM revisions in RAG conversations, improving output by 35% with higher quality responses.\n",
            "  - Integration of the OpenAI GPT-4o model for RAG conversations.\n",
            "  - Default model for Conversations changed to OpenAI GPT-4o for improved performance.\n",
            "  - Added graph visualization in promptConversation responses to show relationships between entities.\n",
            "  - Expanded Wikipedia data to include long descriptions of entities.\n",
            "  - New API queries: getSharePointLibraries, getSharePointFolders, getOneDriveFolders for easier storage service enumeration.\n",
            "  - New API queries: getTeams and getTeamsChannels for Microsoft Teams workspace enumeration.\n",
            "  - Added extractedCount to limit the number of extracted entities per type.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Performance improvements in entity extraction, cloud storage access, and RAG context rendering.\n",
            "  - Optimized LLM entity extraction to identify more properties and relationships.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issues with text extraction from HTML in RSS posts.\n",
            "  - Resolved limit filter returning incomplete results.\n",
            "  - Corrected structured text extraction from JSON/XML formats.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: May 15, 2024.\n",
            "  - Default model updated to OpenAI GPT-4o.\n",
            "\n",
            "- Value:\n",
            "  - Enhancements provide developers with improved performance, better quality responses, and more efficient data extraction capabilities.\n",
            "\n",
            "2024-12-30T04:06:35.898Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:03.921854, used credits [0.00578400]\n",
            "- CONTENT [2dd30528-0956-4c46-9a9c-8ce6ecc9931e]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [812 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/october-2024/october-21-support-openai-cohere-jina-mistral-voyage-and-google-ai-embedding-models</name><title>October 21: Support OpenAI, Cohere, Jina, Mistral, Voyage and Google AI embedding models | Graphlit Changelog</title></metadata> üéÉ\tOctober 2024\n",
            "October 21: Support OpenAI, Cohere, Jina, Mistral, Voyage and Google AI embedding models\n",
            "New Features\n",
            "üí° Graphlit now supports the configuration of image and text embedding models, at the Project level.  You can create an embedding specification for a text or image embedding model, and then assign that to the Project, and all further embedding requests will use that embedding model.  See this Colab notebook for an example of how to configure the project.\n",
            "üí° Graphlit now supports the OpenAI Embedding-3-Small and Embedding-3-Large, Cohere Embed 3.0, Jina Embed 3.0, Mistral Embed, and Voyage 2.0 and 3.0 text embedding models.  Graphlit also now supports Jina CLIP image embeddings, which are used by default for image search.\n",
            "Graphlit now supports the chunkTokenLimit property in Specifications, which specifies the number of tokens for each embedded text chunk.  If this is not configured, Graphlit uses 600 tokens for each embedded text chunk.\n",
            "Graphlit now supports the Voyage reranking model.\n",
            "Graphlit now supports the ingestTextBatch mutation, which accepts an array of text and name pairs, and will asynchronously ingest these into content objects.\n",
            "‚ö° We have moved the chunkTokenLimit property from the Workflow storage embeddings strategy to the Specification object.  The Workflow storage property has now been deprecated.\n",
            "‚ö° We have deprecated the openAIImage property from Workflow entity extraction properties. Use the modelImage property instead.\n",
            "Once a text embedding model has been updated at the project level, any content, conversations or observed entities will no longer be semantically searchable.\n",
            "Text embeddings are not compatible across models, so you will need to delete and reingest any content, or recreate conversations or knowledge graph entities, with the new embedding model to become searchable.\n",
            "PreviousOctober 22: Support for latest Anthropic Sonnet 3.5 model, Cohere image embeddings\n",
            "NextOctober 9: Support for GitHub repository feeds, bug fixes\n",
            "Last updated2 months ago\n",
            "- Completion [279 tokens (includes JSON guardrails tokens)], throughput: 71.140 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for configuration of image and text embedding models at the Project level.\n",
            "  - Support for OpenAI Embedding-3-Small and Embedding-3-Large, Cohere Embed 3.0, Jina Embed 3.0, Mistral Embed, and Voyage 2.0 and 3.0 text embedding models.\n",
            "  - Support for Jina CLIP image embeddings for image search.\n",
            "  - Introduction of chunkTokenLimit property in Specifications for token count per embedded text chunk.\n",
            "  - Support for Voyage reranking model.\n",
            "  - New ingestTextBatch mutation for asynchronous ingestion of text and name pairs.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Moved chunkTokenLimit property from Workflow storage embeddings strategy to Specification object; Workflow storage property deprecated.\n",
            "  - Deprecated openAIImage property from Workflow entity extraction properties; use modelImage property instead.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Updating text embedding models at the project level will affect semantic searchability of content, conversations, or observed entities. Requires deletion and reingestion of content for new model compatibility.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: October 2024.\n",
            "  - Breaking change: Text embeddings are not compatible across models.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced flexibility in embedding model configuration and improved ingestion capabilities, while ensuring compatibility and searchability of content.\n",
            "\n",
            "2024-12-30T04:06:35.717Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:01.596962, used credits [0.00313500]\n",
            "- CONTENT [b682b0ca-255c-4b02-b016-cb56f05edb64]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [549 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/march-2024/march-13-support-for-claude-3-haiku-model-direct-ingestion-of-base64-encoded-files</name><title>March 13: Support for Claude 3 Haiku model, direct ingestion of Base64 encoded files | Graphlit Changelog</title></metadata> üçÄ\tMarch 2024\n",
            "March 13: Support for Claude 3 Haiku model, direct ingestion of Base64 encoded files\n",
            "New Features\n",
            "üí° Graphlit now supports the Claude 3 Haiku model.\n",
            "Added support for direct ingestion of Base64 encoded files with the ingestEncodedFile mutation.  You can pass a Base64 encoded string and MIME type of the file, and it will be ingested into the Graphlit Platform.\n",
            "Added modelService and model properties to ConversationMessage type, which return the model service and model which was used for the LLM completion.\n",
            "PreviousMarch 23: Support for Linear, GitHub Issues and Jira issue feeds, ingest files via Web feed sitemap\n",
            "NextMarch 10: Support for Claude 3, Mistral and Groq models, usage/credits telemetry, bug fixes\n",
            "Last updated8 months ago\n",
            "- Completion [124 tokens (includes JSON guardrails tokens)], throughput: 77.647 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for Claude 3 Haiku model.\n",
            "  - Direct ingestion of Base64 encoded files via the ingestEncodedFile mutation, allowing the input of a Base64 string and MIME type.\n",
            "  - Added modelService and model properties to ConversationMessage type for LLM completion details.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - None specified.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - None specified.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: March 13, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced model support and improved file ingestion capabilities, streamlining the integration process.\n",
            "\n",
            "2024-12-30T04:06:34.259Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:05.172256, used credits [0.00682200]\n",
            "- CONTENT [fc169406-76bc-479f-93f2-0c1b1ba4277e]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [894 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/june-2024/june-9-support-for-deepseek-models-json-ld-webpage-parsing-performance-improvements-and-bug-fixes</name><title>June 9: Support for Deepseek models, JSON-LD webpage parsing, performance improvements and bug fixes | Graphlit Changelog</title></metadata> üéì\tJune 2024\n",
            "June 9: Support for Deepseek models, JSON-LD webpage parsing, performance improvements and bug fixes\n",
            "New Features\n",
            "üí° Graphlit now supports Deepseek LLMs for prompt completion.  We offer the deepseek-chat and deepseek-coder models.\n",
            "üí° Graphlit now supports parsing embedded JSON-LD from web pages.  If a web page contains 'script' tags with JSON-LD, we will automatically parse and inject into the knowledge graph.\n",
            "‚ö° We have changed the default model for entity extraction and image completions to be OpenAI GPT-4o.  This provides faster performance and better quality output.\n",
            "‚ö° We have changed the behavior of knowledge graph generation, from a prompted conversation, to be opt-in.  In order to receive the graph's nodes and edges with the response, you will now need to set generateGraph to True in the specification's graphStrategy object.  This provides improved performance when the graph is not needed for visualization.\n",
            "Added thing property for observable entities, which returns the JSON-LD metadata associated with the entity.\n",
            "Added regex-based filtering for URI paths during feed ingestion, link crawling, and workflow filtering.  You can assign regex patterns in allowedPaths and excludedPaths.\n",
            "Added observableLimit to configure the limit of how many observed entities will be added to the GraphRAG context, defaults to 1000.\n",
            "Added prompt to suggestConversation mutation, which allows customization of the followup question generation.\n",
            "Updated suggestConversation to incorporate the past conversation message history, in addition to the filtered set of content sources.\n",
            "üî•  We have improved performance in knowledge graph retrieval and generation, via better parallelization and batching.\n",
            "Bugs Fixed\n",
            "GPLA-2748: Optimize the retrieval performance of observed entities during GraphRAG\n",
            "GPLA-2732: Invalid user-provided URI causing parsing exception\n",
            "GPLA-2666: Shouldn't require tenant ID for Microsoft email or Teams\n",
            "GPLA-2772: Not returning labels or categories from graph in API\n",
            "GPLA-2762: Failed to extract spreadsheet images\n",
            "GPLA-2687: Email to/from not getting added as observations on emails\n",
            "GPLA-2738: API is returning 'audio' metadata from podcast HTML document\n",
            "PreviousJune 21: Support for the Claude 3.5 Sonnet model, knowledge graph semantic search, and bug fixes\n",
            "NextMay 15: Support for GraphRAG, OpenAI GPT-4o model, performance improvements and bug fixes\n",
            "Last updated6 months ago\n",
            "- Completion [345 tokens (includes JSON guardrails tokens)], throughput: 66.702 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for Deepseek LLMs for prompt completion (deepseek-chat and deepseek-coder models).\n",
            "  - Parsing of embedded JSON-LD from web pages, automatically injecting into the knowledge graph.\n",
            "  - Default model for entity extraction and image completions changed to OpenAI GPT-4o for improved performance and quality.\n",
            "  - Knowledge graph generation behavior changed to opt-in; requires setting generateGraph to True for response inclusion.\n",
            "  - Added thing property for observable entities to return associated JSON-LD metadata.\n",
            "  - Regex-based filtering for URI paths during feed ingestion and workflow filtering.\n",
            "  - Added observableLimit to configure the number of observed entities in GraphRAG context (default 1000).\n",
            "  - Customization of follow-up question generation via prompt in suggestConversation mutation.\n",
            "  - Updated suggestConversation to include past conversation message history.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Improved performance in knowledge graph retrieval and generation through better parallelization and batching.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Optimized retrieval performance of observed entities during GraphRAG.\n",
            "  - Fixed parsing exception caused by invalid user-provided URI.\n",
            "  - Removed requirement for tenant ID for Microsoft email or Teams.\n",
            "  - Resolved issue of not returning labels or categories from graph in API.\n",
            "  - Fixed failure to extract spreadsheet images.\n",
            "  - Addressed issue of email to/from not being added as observations.\n",
            "  - Corrected API returning 'audio' metadata from podcast HTML documents.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: June 9, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced capabilities for model support, improved performance, and better handling of data through new features and bug fixes.\n",
            "\n",
            "2024-12-30T04:06:33.982Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:04.902758, used credits [0.00612000]\n",
            "- CONTENT [d2f41682-fb8b-4599-8c64-91891e13c336]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [836 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/march-2024/march-10-support-for-claude-3-mistral-and-groq-models-usage-credits-telemetry-bug-fixes</name><title>March 10: Support for Claude 3, Mistral and Groq models, usage/credits telemetry, bug fixes | Graphlit Changelog</title></metadata> üçÄ\tMarch 2024\n",
            "March 10: Support for Claude 3, Mistral and Groq models, usage/credits telemetry, bug fixes\n",
            "New Features\n",
            "üí° Graphlit now supports a Command-Line Interface (CLI) for directly accessing the Graphlit Data API without writing code.  See the documentation here.\n",
            "üí° Graphlit now supports the Groq Platform, and models such as Mixtral 8x7b.\n",
            "üí° Graphlit now supports Claude 3 Opus and Sonnet models.\n",
            "üí° Graphlit now supports Mistral La Plateforme, and models such as Mistral Small, Medium, and Large and Mixtral 8x7b.\n",
            "üí° Graphlit now supports the latest v4 of Azure Document Intelligence, including their new models such as Credit Card, Marriage Certificate, and Mortgage documents.\n",
            "Added support for detailed usage and credits telemetry via API, with the usage, credits, lookupUsage and lookupCredits queries.\n",
            "Added support for correlated telemetry, where an optional correlationId can be provided with GraphQL queries and mutations, so credits and usage can be tracked across requests.\n",
            "Added support for project webhook, which will be called when credits have been consumed by the project.\n",
            "Added support for image extraction during DOCX, XLSX, and PPTX document preparation.\n",
            "Added text and markdown properties to Content object, which provide formatted output of extracted text from any content.\n",
            "Added more accurate extraction of tables into mezzanine JSON format, across all content types.\n",
            "Added throughput property to Conversation messages, which returns the tokens/second throughput of LLM.\n",
            "‚ö° Deprecated mezzanineUri property in Content object, which has been replaced by textUri and audioUri.\n",
            "Bugs Fixed\n",
            "GPLA-2281: Not extracting table from PPTX file.\n",
            "GPLA-2282: Not extracting Markdown tables.\n",
            "GPLA-2247: Not extracting relative HTML links properly.\n",
            "GPLA-2241: Failed to post Alert to Slack with Markdown format.\n",
            "PreviousMarch 13: Support for Claude 3 Haiku model, direct ingestion of Base64 encoded files\n",
            "NextFebruary 21: Support for OneDrive and Google Drive feeds, extract images from PDFs, bug fixes\n",
            "Last updated8 months ago\n",
            "- Completion [301 tokens (includes JSON guardrails tokens)], throughput: 61.394 tokens/sec:\n",
            "- New Features:\n",
            "  - Command-Line Interface (CLI) for direct access to the Graphlit Data API.\n",
            "  - Support for Groq Platform and models like Mixtral 8x7b.\n",
            "  - Support for Claude 3 Opus and Sonnet models.\n",
            "  - Support for Mistral La Plateforme and models such as Mistral Small, Medium, and Large.\n",
            "  - Support for Azure Document Intelligence v4, including new models for Credit Card, Marriage Certificate, and Mortgage documents.\n",
            "  - Detailed usage and credits telemetry via API.\n",
            "  - Correlated telemetry with optional correlationId for tracking credits and usage.\n",
            "  - Project webhook for tracking consumed credits.\n",
            "  - Image extraction during DOCX, XLSX, and PPTX document preparation.\n",
            "  - Text and markdown properties added to Content object for formatted output.\n",
            "  - More accurate extraction of tables into mezzanine JSON format.\n",
            "  - Throughput property added to Conversation messages for tokens/second throughput.\n",
            "  - Deprecated mezzanineUri property replaced by textUri and audioUri.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issues with table extraction from PPTX files and Markdown tables.\n",
            "  - Improved extraction of relative HTML links.\n",
            "  - Resolved failure to post Alerts to Slack with Markdown format.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: March 2024.\n",
            "  \n",
            "- Value:\n",
            "  - Enhancements provide developers with improved API access, better document processing capabilities, and more accurate data extraction, facilitating more efficient application development.\n",
            "\n",
            "2024-12-30T04:06:32.826Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:04.361598, used credits [0.00552300]\n",
            "- CONTENT [c693346f-b33a-4931-88f4-5c7142c749b9]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [761 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/october-2024/october-3-support-tool-calling-ingestbatch-mutation-gemini-flash-1.5-8b-bug-fixes</name><title>October 3: Support tool calling, ingestBatch mutation, Gemini Flash 1.5 8b, bug fixes | Graphlit Changelog</title></metadata> üéÉ\tOctober 2024\n",
            "October 3: Support tool calling, ingestBatch mutation, Gemini Flash 1.5 8b, bug fixes\n",
            "New Features\n",
            "üí° Graphlit now supports the ingestBatch mutation, which accepts an array of URIs to files or web pages, and will asynchronously ingest these into content objects.\n",
            "üí° Graphlit now supports the continueConversation mutation, which accepts an array of called tool responses. Also, promptConversation now accepts an array of tool definitions. When tools are called by the LLM, the assistant message returned from promptConversation will have a list of toolCalls which need to responded to from your calling code.  These responses are to be provided back to the LLM via the continueConversation mutation.\n",
            "üí° Graphlit now supports tool calling with OpenAI, Mistral, Deepseek, Groq, and Cerebras model services.  Anthropic, Google Gemini and Cohere support will come later.\n",
            "Added support for prefilled user and assistant messages with createConversation mutation. Now you can send an array of messages when creating a new conversation, which will bootstrap the conversation with the LLM.  These must be provided in user/assistant pairs.\n",
            "Added support for Google Gemini Flash 1.5 8b model.\n",
            "‚ö° We have deprecated the tools property in the Specification object. These will be removed at a later date.  Tools are now to be sent directly to the extractContents and promptConversation mutations.\n",
            "Bugs Fixed\n",
            "GPLA-3207: Models shouldn't be required on update specification call\n",
            "GPLA-3220: Don't send system prompt with OpenAI o1 models\n",
            "PreviousOctober 7: Support for Anthropic and Gemini tool calling\n",
            "NextSeptember 30: Support for Azure AI Inference models, Mistral Pixtral and latest Google Gemini models\n",
            "Last updated2 months ago\n",
            "- Completion [270 tokens (includes JSON guardrails tokens)], throughput: 61.904 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for ingestBatch mutation to asynchronously ingest an array of URIs into content objects.\n",
            "  - Introduction of continueConversation mutation for handling tool responses and promptConversation now accepts an array of tool definitions.\n",
            "  - Tool calling support added for OpenAI, Mistral, Deepseek, Groq, and Cerebras model services; support for Anthropic, Google Gemini, and Cohere coming later.\n",
            "  - Prefilled user and assistant messages supported with createConversation mutation, allowing an array of messages in user/assistant pairs.\n",
            "  - Added support for Google Gemini Flash 1.5 8b model.\n",
            "  - Deprecation of tools property in the Specification object; tools to be sent directly to extractContents and promptConversation mutations.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Improved handling of tool calling and conversation management.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issue where models were incorrectly required on update specification call (GPLA-3207).\n",
            "  - Resolved issue of sending system prompt with OpenAI o1 models (GPLA-3220).\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: October 2024.\n",
            "  - Deprecation notice for tools property in the Specification object.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced capabilities for managing conversations and tool interactions, improving integration with various model services.\n",
            "\n",
            "2024-12-30T04:06:31.866Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:01.705071, used credits [0.00384900]\n",
            "- CONTENT [2489940d-1c11-4cab-82d2-26e5a1bc0dff]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [619 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/november-2024/november-4-support-for-anthropic-claude-3.5-haiku-bug-fixes</name><title>November 4: Support for Anthropic Claude 3.5 Haiku, bug fixes | Graphlit Changelog</title></metadata> ü¶É\tNovember 2024\n",
            "November 4: Support for Anthropic Claude 3.5 Haiku, bug fixes\n",
            "New Features\n",
            "Graphlit now supports the latest Anthropic Haiku 3.5 model, with the model enum CLAUDE_3_5_HAIKU_20241022.\n",
            "‚ö° Once a project has hit the free tier quota, we will now automatically disable all feeds.  Once the project has been upgraded to a paid tier, you can use the enableFeed mutation to re-enable your existing feeds to continue ingestion.\n",
            "‚ö° We have added the disableFallback flag to the RetrievalStrategyInput type, so you can disable the default behavior of falling back to the previous conversation's contents, or worst-case, falling back to the most recently uploaded content.  By setting disableFallback to true, conversations will only attempt to retrieve contents based on the provided filter and/or augmentedFilter properties.\n",
            "Bugs Fixed\n",
            "GPLA-3367: Not extracting text from HTML button element\n",
            "PreviousNovember 10: Support for web search, multi-turn content summarization, Deepgram language detection\n",
            "NextOctober 31: Support for simulated tool calling, bug fixes\n",
            "Last updated1 month ago\n",
            "- Completion [166 tokens (includes JSON guardrails tokens)], throughput: 97.357 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for Anthropic Haiku 3.5 model (model enum: CLAUDE_3_5_HAIKU_20241022).\n",
            "  - Automatic disabling of all feeds upon reaching the free tier quota; re-enable feeds with enableFeed mutation after upgrading to a paid tier.\n",
            "  - Addition of disableFallback flag in RetrievalStrategyInput type to control fallback behavior in conversations.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Improved control over conversation content retrieval with the disableFallback flag.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issue GPLA-3367: Text extraction from HTML button elements.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: November 4, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced model support, better feed management, and improved content retrieval control.\n",
            "\n",
            "2024-12-30T04:06:30.111Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:02.930488, used credits [0.00530100]\n",
            "- CONTENT [0341d367-6775-4e57-9a3d-7904d813f243]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [855 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/november-2024/november-10-support-for-web-search-multi-turn-content-summarization-deepgram-language-detection</name><title>November 10: Support for web search, multi-turn content summarization, Deepgram language detection | Graphlit Changelog</title></metadata> ü¶É\tNovember 2024\n",
            "November 10: Support for web search, multi-turn content summarization, Deepgram language detection\n",
            "New Features\n",
            "üí° Graphlit now supports web search with the searchWeb mutation.  You can select the search service, either Tavily or Exa.AI, and provide the search query and number of search results to be returned.  This is different than the web search feed, in that searchWeb returns the relevant text from the web page and the web page URL from each search hit, but does not ingest each of the web pages. This new mutation is optimized to be used from within an LLM tool.\n",
            "üí° Graphlit now supports multi-turn summarization of content with the reviseContent mutation.  You can provide an LLM prompt and a content reference, along with an optional specification.  This can be used for summarizing any content (documents, web pages, audio transcripts, etc.), and having a multi-turn conversation with the LLM to revise the output from the LLM.  Internally, this creates a conversation locked to a single piece of content.  This works especially well with the OpenAI o1-preview and o1-mini models, because they provide a longer LLM output from each turn.\n",
            "Graphlit now supports the configuration of the Deepgram transcription language, and whether detectLanguage is enabled in DeepgramAudioPreparationPropertiesInput.  Language detection is now enabled by default, and can be disabled by setting detectLanguage to false.\n",
            "‚ö° We have added a requireTool option to promptConversation mutation, so you can control whether the LLM must call one of the provided tool, or if tool calling is optional.\n",
            "‚ö° For accounts created after Nov 8, 2024, we have lowered the credits quota on the Free tier from 1000 credits to 100 credits, and now offer unlimited feeds on the Hobby Tier.\n",
            "‚ö° The Graphlit Data API will now return HTTP 402 (Payment Required) when you have exceeded the credits quota on the free tier.  You must upgrade to the Hobby Tier (or higher) to continue using the API, once the credits quota has been reached.\n",
            "PreviousNovember 16: Support for image description, multi-turn text summarization\n",
            "NextNovember 4: Support for Anthropic Claude 3.5 Haiku, bug fixes\n",
            "Last updated1 month ago\n",
            "- Completion [228 tokens (includes JSON guardrails tokens)], throughput: 77.803 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for web search via the searchWeb mutation, allowing selection of search service (Tavily or Exa.AI) and retrieval of relevant text and URLs.\n",
            "  - Multi-turn content summarization with the reviseContent mutation, enabling conversation with LLM for content revision.\n",
            "  - Configuration of Deepgram transcription language and default language detection enabled in DeepgramAudioPreparationPropertiesInput.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Added requireTool option to promptConversation mutation for controlling tool calling.\n",
            "  - Reduced credits quota on Free tier from 1000 to 100 for accounts created after Nov 8, 2024; unlimited feeds now available on Hobby Tier.\n",
            "  - Graphlit Data API now returns HTTP 402 (Payment Required) when exceeding Free tier credits quota.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - No specific bug fixes mentioned.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: November 10, 2024.\n",
            "\n",
            "- Value:\n",
            "  - These updates enhance the platform's capabilities for developers, providing more flexible search and summarization tools, improved language detection, and clearer usage policies regarding credits.\n",
            "\n",
            "2024-12-30T04:06:28.958Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:04.388600, used credits [0.00590700]\n",
            "- CONTENT [1cd2c534-2f49-4677-ab4a-68a4365f4fdd]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [765 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/october-2023/october-15-support-for-anthropic-claude-models-slack-feeds-and-entity-enrichment</name><title>October 15: Support for Anthropic Claude models, Slack feeds and entity enrichment | Graphlit Changelog</title></metadata> üéÉ\tOctober 2023\n",
            "October 15: Support for Anthropic Claude models, Slack feeds and entity enrichment\n",
            "New Features\n",
            "üî• Graphlit now supports Anthropic Claude and Anthropic Claude Instant large language models.\n",
            "üî• Graphlit now supports Slack feeds, and will ingest Slack messages and linked file attachments from a Slack channel.  Note, this requires the creation of a Slack bot which has been added to the appropriate Slack channel.\n",
            "üí° Added support for entity enrichment to workflow object, which offers Diffbot, Wikipedia and Crunchbase enrichment of observed entities, such as Person, Organization and Place.\n",
            "üí° Added support for text extraction from images.  When using Azure Image Analytics for entity extraction, Graphlit will extract and store any identified text which then becomes searchable.\n",
            "Added embedFacets property to conversation strategy in specification object.\n",
            "Added embedCitations property to conversation strategy in specification object.  This makes content citations optional with the completed conversation message.\n",
            "Added GraphQL mutations for multi-delete of entities, such as deleteCollections, deleteLabels, or deleteConversations.\n",
            "Added GraphQL deleteAllConversations mutation to delete all conversations.\n",
            "Added support for automatically adding ingested content to one or more collections, via ingestion stage of workflow object.\n",
            "Added specification property to preparation workflow stage, which will be used to select the LLM for text summarization.\n",
            "Expanded the properties for observed entities, such as Person, Organization or Product.  Now supports a wider range of properties for entity enrichment.\n",
            "Bugs Fixed\n",
            "GPLA-1520: Unlimited conversation quota not assigned when upgrading project tier\n",
            "GPLA-1285: Entity enrichment not firing event, which can be sent to actions\n",
            "GPLA-1361: Web page left in ingested state, when URL not accessible.\n",
            "PreviousOctober 30: Optimized conversation responses; added observable aliases; bug fixes\n",
            "NextSeptember 24: Support for YouTube feeds; added documentation; bug fixes\n",
            "Last updated1 year ago\n",
            "- Completion [301 tokens (includes JSON guardrails tokens)], throughput: 68.587 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for Anthropic Claude and Anthropic Claude Instant large language models.\n",
            "  - Ingestion of Slack messages and linked file attachments from a Slack channel (requires a Slack bot).\n",
            "  - Entity enrichment for observed entities (Person, Organization, Place) using Diffbot, Wikipedia, and Crunchbase.\n",
            "  - Text extraction from images using Azure Image Analytics, making identified text searchable.\n",
            "  - Added embedFacets and embedCitations properties to conversation strategy in specification object.\n",
            "  - GraphQL mutations for multi-delete of entities (deleteCollections, deleteLabels, deleteConversations).\n",
            "  - GraphQL deleteAllConversations mutation to delete all conversations.\n",
            "  - Automatic addition of ingested content to collections during the ingestion stage of the workflow.\n",
            "  - Specification property added to preparation workflow stage for selecting LLM for text summarization.\n",
            "  - Expanded properties for observed entities for enhanced entity enrichment.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed unlimited conversation quota not assigned when upgrading project tier (GPLA-1520).\n",
            "  - Resolved issue with entity enrichment not firing event (GPLA-1285).\n",
            "  - Fixed web page remaining in ingested state when URL is not accessible (GPLA-1361).\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: October 15, 2023.\n",
            "\n",
            "- Value:\n",
            "  - Enhances capabilities for developers by integrating advanced LLMs, improving data ingestion from Slack, and enriching entity data, thus facilitating better data management and analysis.\n",
            "\n",
            "2024-12-30T04:06:28.946Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:06.379380, used credits [0.00396900]\n",
            "- CONTENT [75f8d5dd-c5e0-4c08-b334-dc5e80ea8025]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [587 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/september-2023/september-24-support-for-youtube-feeds-added-documentation-bug-fixes</name><title>September 24: Support for YouTube feeds; added documentation; bug fixes | Graphlit Changelog</title></metadata> üõ†Ô∏è\tSeptember 2023\n",
            "September 24: Support for YouTube feeds; added documentation; bug fixes\n",
            "New Features\n",
            "üî• Graphlit now supports YouTube feeds, where you can ingest a set of YouTube videos, or an entire YouTube playlist or channel.   Note, we currently support only the ingestion of audio from YouTube videos, which gets transcribed and added to your conversational knowledge graph.\n",
            "New Documentation\n",
            "Added documentation for observable entities mutations and queries (Label, Category, Person, Organization, Place, Event, Product, Repo, Software).\n",
            "Added documentation for using custom Azure OpenAI and OpenAI models with Specifications\n",
            "Bugs Fixed\n",
            "GPLA-1459: LLM prompt formatting was exceeding the token budget with long user prompts.\n",
            "GPLA-1445: Failed to ingest PDF from URL where filename in Content-Disposition header contained a backslash.\n",
            "PreviousOctober 15: Support for Anthropic Claude models, Slack feeds and entity enrichment\n",
            "NextSeptember 20: Paid subscription plans; support for custom observed entities & Azure OpenAI GPT-4\n",
            "Last updated7 months ago\n",
            "- Completion [184 tokens (includes JSON guardrails tokens)], throughput: 28.843 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for YouTube feeds, allowing ingestion of YouTube videos, playlists, or channels (currently supports audio ingestion and transcription).\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Added documentation for observable entities mutations and queries (Label, Category, Person, Organization, Place, Event, Product, Repo, Software).\n",
            "  - Added documentation for using custom Azure OpenAI and OpenAI models with Specifications.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed LLM prompt formatting issue that exceeded token budget with long user prompts (GPLA-1459).\n",
            "  - Resolved issue with ingesting PDF from URL when filename in Content-Disposition header contained a backslash (GPLA-1445).\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: September 2023.\n",
            "\n",
            "- Value:\n",
            "  - Enhances developers' ability to integrate YouTube content and improves documentation for better usage of observable entities and custom models.\n",
            "\n",
            "2024-12-30T04:06:28.374Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:05.293803, used credits [0.00636300]\n",
            "- CONTENT [5345f273-4dcb-4f44-a1a3-4226ff5eaed8]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [845 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/september-2023/september-20-paid-subscription-plans-support-for-custom-observed-entities-and-azure-openai-gpt-4</name><title>September 20: Paid subscription plans; support for custom observed entities & Azure OpenAI GPT-4 | Graphlit Changelog</title></metadata> üõ†Ô∏è\tSeptember 2023\n",
            "September 20: Paid subscription plans; support for custom observed entities & Azure OpenAI GPT-4\n",
            "New Features\n",
            "üî• Graphlit now supports paid Hobby, Starter and Growth tiers for projects, in addition to the existing Free tier.  Starting at $49/mo, plus $0.10/credit for usage, we now support higher quota based on your subscribed tier.   By providing a payment method for your organization in the Developer Portal, you can upgrade each project individually to the tier that fits your application's needs.\n",
            "üí° Added GraphQL mutations for the creation, update and deletion of observed entities (i.e. Person, Organization, Place, Product, Event, Label, Category).\n",
            "üí° Added new observed entity types to knowledge graph: Repo (i.e. Git repo), Software.\n",
            "üí° Added searchType and numberSimilar fields to Specification object for configuring semantic search in conversations.   In situations where the user prompt is limited in length, HYBRID search type can provide better semantic search results for the prompt context.\n",
            "üí° Added support for the Azure OpenAI GPT-4 model.\n",
            "Added support for project quota field.  Project quotas are based on the subscribed pricing tier.   Quota limits are now applied as content is ingested, and as feeds and conversations are created.\n",
            "Added contentLimit to conversation strategy object to limit the number of semantic search content results which are formatted into prompt context.\n",
            "Better relevance ranking on semantic search results when formatting prompt context in conversations.\n",
            "‚ÑπÔ∏è Free tier has updated quota: 1GB storage, 100 contents, 3 feeds and 10 conversations.\n",
            "‚ö° Now using the Deepgram Nova-2 audio transcription model, which is 18% more accurate, and 5-40x faster.\n",
            "Bugs Fixed\n",
            "GPLA-1373: Failed to extract multiple text pages from DOCX without page breaks.  Now we support token-aware page chunking.\n",
            "GPLA-1377: Failed during semantic search with no content results, when prompting conversation.\n",
            "GPLA-1415: Failed when user prompt couldn't generate text embeddings.\n",
            "PreviousSeptember 24: Support for YouTube feeds; added documentation; bug fixes\n",
            "NextSeptember 4: Workflow configuration; support for Notion feeds; document OCR\n",
            "Last updated11 months ago\n",
            "- Completion [319 tokens (includes JSON guardrails tokens)], throughput: 60.259 tokens/sec:\n",
            "- New Features:\n",
            "  - Introduction of paid Hobby, Starter, and Growth subscription tiers, starting at $49/month, with usage fees of $0.10/credit.\n",
            "  - GraphQL mutations for creating, updating, and deleting observed entities (Person, Organization, Place, Product, Event, Label, Category).\n",
            "  - New observed entity types added: Repo (Git repo), Software.\n",
            "  - Added searchType and numberSimilar fields to Specification object for enhanced semantic search.\n",
            "  - Support for Azure OpenAI GPT-4 model.\n",
            "  - Project quota field introduced, with limits based on subscription tier.\n",
            "  - ContentLimit added to conversation strategy object for semantic search results.\n",
            "  - Improved relevance ranking for semantic search results.\n",
            "  - Updated Free tier quota: 1GB storage, 100 contents, 3 feeds, and 10 conversations.\n",
            "  - Implementation of Deepgram Nova-2 audio transcription model, offering 18% more accuracy and 5-40x faster processing.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Better semantic search results with new configuration options.\n",
            "  - Enhanced audio transcription accuracy and speed.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Resolved issue with extracting multiple text pages from DOCX files.\n",
            "  - Fixed semantic search failure when no content results were available.\n",
            "  - Addressed failure in generating text embeddings from user prompts.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: September 20, 2023.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers flexible subscription options, improved search capabilities, and enhanced audio transcription, facilitating better project management and user experience.\n",
            "\n",
            "2024-12-30T04:06:27.034Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:04.857425, used credits [0.00680100]\n",
            "- CONTENT [865f424b-fa74-4640-b593-a9840336a452]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [851 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/september-2024/september-26-support-for-google-ai-and-cerebras-models-and-latest-groq-models</name><title>September 26: Support for Google AI and Cerebras models, and latest Groq models | Graphlit Changelog</title></metadata> üéí\tSeptember 2024\n",
            "September 26: Support for Google AI and Cerebras models, and latest Groq models\n",
            "New Features\n",
            "üí° Graphlit now supports the Cerebras model service which offers the LLAMA_3_1_70B and LLAMA_3_1_8B models.\n",
            "üí° Graphlit now supports the Google AI model service which offers the GEMINI_1_5_PRO and GEMINI_1_5_FLASH models.\n",
            "We have added support for the latest Groq Llama 3.2 preview models, including LLAMA_3_2_1B_PREVIEW, LLAMA_3_2_3B_PREVIEW, LLAMA_3_2_11B_TEXT_PREVIEW, and LLAMA_3_2_90B_TEXT_PREVIEW.  We have also added support for the Llama 3.2 multimodal model LLAMA_3_2_11B_VISION_PREVIEW.\n",
            "We have added a new specification parameter to the promptConversation mutation. Now you can specify your initial specification for a new conversation, or update an existing conversation, without requiring additional API calls.\n",
            "‚ö° We have changed the retrieval behavior of the promptConversation mutation. Now, if no relevant content was found via vector-based semantic search (given the user prompt), we will fallback to any relevant content from the message in the conversation. If there was no content from the conversation to fallback to, we will fallback to the last ingested content in the project. This solves an issue where a first prompt like 'Summarize this' would find no relevant content.  Now it will fallback to retrieve the last ingested content.\n",
            "‚ö° We have renamed the Groq model enum from LLAVA_1_5_7B to LLAVA_1_5_7B_PREVIEW.\n",
            "Bugs Fixed\n",
            "GPLA-3083: Not sending custom instructions/guidance with extraction prompt\n",
            "GPLA-3146: Filtering Persons by email not working\n",
            "GPLA-3171: Not failing on deprecated OpenAI model\n",
            "GPLA-3158: Summarization not using revision strategy\n",
            "PreviousSeptember 30: Support for Azure AI Inference models, Mistral Pixtral and latest Google Gemini models\n",
            "NextSeptember 3: Support for web search feeds, model deprecations\n",
            "Last updated3 months ago\n",
            "- Completion [354 tokens (includes JSON guardrails tokens)], throughput: 72.878 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for Cerebras model service: LLAMA_3_1_70B and LLAMA_3_1_8B models.\n",
            "  - Support for Google AI model service: GEMINI_1_5_PRO and GEMINI_1_5_FLASH models.\n",
            "  - Support for latest Groq Llama 3.2 preview models: LLAMA_3_2_1B_PREVIEW, LLAMA_3_2_3B_PREVIEW, LLAMA_3_2_11B_TEXT_PREVIEW, LLAMA_3_2_90B_TEXT_PREVIEW, and multimodal model LLAMA_3_2_11B_VISION_PREVIEW.\n",
            "  - New specification parameter added to promptConversation mutation for initial or updated conversation specifications.\n",
            "  \n",
            "- Enhancements/Improvements:\n",
            "  - Changed retrieval behavior of promptConversation mutation to fallback to relevant content from the conversation or last ingested content if no relevant content is found.\n",
            "  - Renamed Groq model enum from LLAVA_1_5_7B to LLAVA_1_5_7B_PREVIEW.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issue with not sending custom instructions/guidance with extraction prompt (GPLA-3083).\n",
            "  - Resolved filtering Persons by email not working (GPLA-3146).\n",
            "  - Addressed issue of not failing on deprecated OpenAI model (GPLA-3171).\n",
            "  - Fixed summarization not using revision strategy (GPLA-3158).\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: September 26, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced model support and improved conversation handling, increasing the efficiency and effectiveness of interactions with the platform.\n",
            "\n",
            "2024-12-30T04:06:24.487Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:01.120908, used credits [0.00252000]\n",
            "- CONTENT [e112772f-cc4a-4323-8c80-8c1d8c123dd2]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [484 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/october-2024/october-9-support-for-github-repository-feeds-bug-fixes</name><title>October 9: Support for GitHub repository feeds, bug fixes | Graphlit Changelog</title></metadata> üéÉ\tOctober 2024\n",
            "October 9: Support for GitHub repository feeds, bug fixes\n",
            "New Features\n",
            "üí° Graphlit now supports GitHub feeds, by providing the repository owner and name similar to GitHub Issues feeds, and will ingest code files from any GitHub repository.\n",
            "Bugs Fixed\n",
            "GPLA-3262: Missing row separator in table markdown formatting\n",
            "PreviousOctober 21: Support OpenAI, Cohere, Jina, Mistral, Voyage and Google AI embedding models\n",
            "NextOctober 7: Support for Anthropic and Gemini tool calling\n",
            "Last updated2 months ago\n",
            "- Completion [89 tokens (includes JSON guardrails tokens)], throughput: 79.400 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for GitHub repository feeds, allowing ingestion of code files by providing the repository owner and name.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed missing row separator in table markdown formatting (GPLA-3262).\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: October 9, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Enhances integration with GitHub, improving developers' ability to work with code repositories.\n",
            "\n",
            "2024-12-30T04:06:23.218Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:01.753344, used credits [0.00295800]\n",
            "- CONTENT [4fa1f011-eca1-4585-9a4b-d31369c468cb]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [498 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/october-2024/october-7-support-for-anthropic-and-gemini-tool-calling</name><title>October 7: Support for Anthropic and Gemini tool calling | Graphlit Changelog</title></metadata> üéÉ\tOctober 2024\n",
            "October 7: Support for Anthropic and Gemini tool calling\n",
            "New Features\n",
            "üí° Graphlit now supports tool calling with Anthropic and Google Gemini models.\n",
            "‚ö° We have removed the uri property for tools from ToolDefinitionInput, such that inline webhook tools are no longer supported.  Now you can define any external tools to be called, and those can support sync or async data access to fulfill the tool call.\n",
            "PreviousOctober 9: Support for GitHub repository feeds, bug fixes\n",
            "NextOctober 3: Support tool calling, ingestBatch mutation, Gemini Flash 1.5 8b, bug fixes\n",
            "Last updated2 months ago\n",
            "- Completion [122 tokens (includes JSON guardrails tokens)], throughput: 69.581 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for tool calling with Anthropic and Google Gemini models.\n",
            "  - Removal of the uri property for tools from ToolDefinitionInput, eliminating support for inline webhook tools. External tools can now be defined for sync or async data access.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Improved flexibility in defining external tools for tool calls.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - No specific bug fixes mentioned.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: October 7, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced capabilities for integrating external tools and improved data access options.\n",
            "\n",
            "2024-12-30T04:06:22.942Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:02.957737, used credits [0.00522900]\n",
            "- CONTENT [f3c48cd9-fc5b-4306-9135-aed548177631]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [739 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/september-2023/september-4-workflow-configuration-support-for-notion-feeds-document-ocr</name><title>September 4: Workflow configuration; support for Notion feeds; document OCR | Graphlit Changelog</title></metadata> üõ†Ô∏è\tSeptember 2023\n",
            "September 4: Workflow configuration; support for Notion feeds; document OCR\n",
            "New Features\n",
            "üî• Added Workflow entity to data model for configuring stages of content workflow; can be assigned to Feed or with ingestPage, ingestFile, or ingestText mutations to control how content is ingested, prepared, extracted and enriched into the knowledge graph.\n",
            "üí° Added support for Notion feeds: now can create feed to ingest files from Notion pages or databases (i.e. wikis).\n",
            "üí° Added support for API-created Observation entities, which allow for custom observations of observable entities (i.e. Person, Label) on Content.\n",
            "üí° Added support for Azure AI Document Intelligence as an optional method for preparing PDF files, using OCR and advanced layout analysis.\n",
            "üí° Added summarization strategies, where content can be summarized into paragraphs, bullet points or headline.\n",
            "Added ability to assign default Workflow and Specification to project.\n",
            "Added more well-known link types, during link crawling, such as Discord, Airtable and TypeForm.\n",
            "‚ÑπÔ∏è Free/Hobby plan now has 5GB storage quota; any content ingested past that limit will be auto-deleted.\n",
            "‚ö° Actions have been moved into Workflow entity.\n",
            "‚ö° Link enrichment for Feeds has been moved into the Workflow enrichment stage, now called link crawling.  ExcludeContentDomain property has been reversed and is now called IncludeContentDomain.\n",
            "Bugs Fixed\n",
            "GPLA-1204: Failed to ingest content with backslash in name.\n",
            "GPLA-1276: Failed to ingest RSS posts which contained enclosure URI, but no post URI.\n",
            "PreviousSeptember 20: Paid subscription plans; support for custom observed entities & Azure OpenAI GPT-4\n",
            "NextAugust 17: Prepare for usage-based billing; append SAS tokens to URIs\n",
            "Last updated1 year ago\n",
            "- Completion [251 tokens (includes JSON guardrails tokens)], throughput: 84.862 tokens/sec:\n",
            "- New Features:\n",
            "  - Added Workflow entity for configuring content workflow stages.\n",
            "  - Support for Notion feeds to ingest files from Notion pages or databases.\n",
            "  - API-created Observation entities for custom observations on Content.\n",
            "  - Support for Azure AI Document Intelligence for PDF preparation using OCR.\n",
            "  - Summarization strategies for content into paragraphs, bullet points, or headlines.\n",
            "  - Ability to assign default Workflow and Specification to projects.\n",
            "  - Added support for more link types during link crawling (e.g., Discord, Airtable, TypeForm).\n",
            "  - Free/Hobby plan now includes a 5GB storage quota.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Actions moved into Workflow entity.\n",
            "  - Link enrichment for Feeds moved to Workflow enrichment stage, renamed to link crawling.\n",
            "  - ExcludeContentDomain property renamed to IncludeContentDomain.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issue with content ingestion failure due to backslash in name.\n",
            "  - Resolved failure to ingest RSS posts with enclosure URI but no post URI.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: September 4, 2023.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced workflow configuration, improved content ingestion from Notion, and advanced document processing capabilities.\n",
            "\n",
            "2024-12-30T04:06:22.459Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:01.885515, used credits [0.00360900]\n",
            "- CONTENT [f0a42b0a-353b-4f08-9a5d-40ce9196a46b]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [587 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/october-2024/october-31-support-for-simulated-tool-calling-bug-fixes</name><title>October 31: Support for simulated tool calling, bug fixes | Graphlit Changelog</title></metadata> üéÉ\tOctober 2024\n",
            "October 31: Support for simulated tool calling, bug fixes\n",
            "New Features\n",
            "Graphlit now supports simulated tool calling for LLMs which don't natively support it, such as OpenAI o1-preview and o1-mini.  Tool schema will be formatted into the LLM prompt context, and tool responses are parsed out of the JSON formatted response.\n",
            "‚ö° Given customer feedback, we have lowered the vector and hybrid thresholds used by the semantic search.  Previously, some content at a low relevance was being excluded from the semantic search results.  Now, more low-relevance content will be included in the results, used by the RAG pipeline.  Reranking can be used to sort the search results for relevance.\n",
            "Bugs Fixed\n",
            "GPLA-3357: Not extracting all images from PDF, and should filter out single-color images.\n",
            "PreviousNovember 4: Support for Anthropic Claude 3.5 Haiku, bug fixes\n",
            "NextOctober 22: Support for latest Anthropic Sonnet 3.5 model, Cohere image embeddings\n",
            "Last updated1 month ago\n",
            "- Completion [154 tokens (includes JSON guardrails tokens)], throughput: 81.675 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for simulated tool calling for LLMs like OpenAI o1-preview and o1-mini.\n",
            "  - Tool schema formatted into LLM prompt context; tool responses parsed from JSON.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Lowered vector and hybrid thresholds for semantic search based on customer feedback, allowing more low-relevance content in results.\n",
            "  - Reranking feature for sorting search results by relevance.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issue GPLA-3357: now extracts all images from PDF and filters out single-color images.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: October 2024.\n",
            "\n",
            "- Value:\n",
            "  - Enhancements improve search result relevance and broaden content inclusion, benefiting developers using the platform.\n",
            "\n",
            "2024-12-30T04:06:22.007Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:04.334457, used credits [0.00527100]\n",
            "- CONTENT [3092dd49-a054-4d32-94b2-cb67133a305d]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [761 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/november-2024/november-24-support-for-direct-llm-prompt-multi-turn-image-analysis-bug-fixes</name><title>November 24: Support for direct LLM prompt, multi-turn image analysis, bug fixes | Graphlit Changelog</title></metadata> ü¶É\tNovember 2024\n",
            "November 24: Support for direct LLM prompt, multi-turn image analysis, bug fixes\n",
            "New Features\n",
            "üí° Graphlit now supports multi-turn analysis of images with the reviseImage and reviseEncodedImage mutations.  You can provide an LLM prompt and either a URI or Base-64 encoded image and MIME type, along with an optional LLM specification.  This can be used for analyzing any image and having a multi-turn conversation with the LLM to revise the output from the LLM. (Colab Notebook Example)\n",
            "üí° Graphlit now supports directly prompting an LLM with the prompt mutation, bypassing any RAG content retrieval, while providing an optional list of previous conversation messages.  This also accepts an optional LLM specification. (Colab Notebook Example)\n",
            "We have added support for the new Mistral Pixtral Large model, with PIXTRAL_LARGE model enum, which can be used with LLM completion or entity extraction LLM specifications.\n",
            "We have added support for the OpenAI 2024-11-20 version of GPT-4o, with GPT4O_128K_20241120 model enum.\n",
            "‚ö° We have added Microsoft Entra ID (fka Azure Active Directory) clientId and clientSecret properties to the SharePointFeedPropertiesInput type, which are now required when creating a SharePoint feed using user authentication with refreshToken property. (Colab Notebook Example)\n",
            "Bugs Fixed\n",
            "GPLA-3438: Not filtering on desktop presentation when scraping web pages\n",
            "GPLA-3340: Failed to parse invalid JSON from extracted PDF page\n",
            "GPLA-3427: Not formatting extracted tables properly from Sonnet 3.5\n",
            "PreviousDecember 1: Support for retrieval-only RAG pipeline, bug fixes\n",
            "NextNovember 16: Support for image description, multi-turn text summarization\n",
            "Last updated1 month ago\n",
            "- Completion [249 tokens (includes JSON guardrails tokens)], throughput: 57.447 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for multi-turn analysis of images using reviseImage and reviseEncodedImage mutations, allowing LLM prompts with image URIs or Base-64 encoded images.\n",
            "  - Direct prompting of an LLM with the prompt mutation, bypassing RAG content retrieval, with optional previous conversation messages.\n",
            "  - Support for Mistral Pixtral Large model (PIXTRAL_LARGE).\n",
            "  - Support for OpenAI GPT-4o (GPT4O_128K_20241120).\n",
            "  - Added Microsoft Entra ID clientId and clientSecret properties for SharePoint feed creation with user authentication.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Improved user authentication process for SharePoint feeds.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed filtering issue on desktop presentation when scraping web pages (GPLA-3438).\n",
            "  - Resolved JSON parsing error from extracted PDF pages (GPLA-3340).\n",
            "  - Corrected table formatting from Sonnet 3.5 (GPLA-3427).\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: November 2024.\n",
            "  \n",
            "- Value:\n",
            "  - Enhancements provide developers with advanced image analysis capabilities and improved LLM interactions, streamlining workflows and increasing efficiency.\n",
            "\n",
            "2024-12-30T04:06:21.405Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:03.628667, used credits [0.00443100]\n",
            "- CONTENT [b96def70-f8ed-4c72-9757-a1648306835a]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [661 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/september-2024/september-1-support-for-fhir-enrichment-latest-cohere-models-bug-fixes</name><title>September 1: Support for FHIR enrichment, latest Cohere models, bug fixes | Graphlit Changelog</title></metadata> üéí\tSeptember 2024\n",
            "September 1: Support for FHIR enrichment, latest Cohere models, bug fixes\n",
            "New Features\n",
            "üí° Graphlit now supports entity enrichment from Fast Healthcare Interoperability Resources (FHIR) servers. You can provide the endpoint for a FHIR server, and Graphlit will enrich medical-related entities from the data found in the FHIR server.\n",
            "Added support for latest Cohere models (COMMAND_R_202408, COMMAND_R_PLUS_202408) and added datestamped model enums for the previous versions (COMMAND_R_202403, COMMAND_R_PLUS_202404).  The latest model enums (COMMAND_R and COMMAND_R_PLUS) currently point to the models (COMMAND_R_202403 and COMMAND_R_PLUS_202404) as specified by the Cohere API.\n",
            "Added support for the latest Azure AI Document Intelligence v4.0 preview API (2024-07-31), now used by default.\n",
            "‚ö° We have changed the name of the LinkReferenceType to LinkReference to follow the existing data model standard.\n",
            "Bugs Fixed\n",
            "GPLA-3120: LLM is adding source tags to end of completed messages\n",
            "GPLA-3133: Failed to load sitemap on child page of website.\n",
            "PreviousSeptember 3: Support for web search feeds, model deprecations\n",
            "NextAugust 20: Support for medical entities, Anthropic prompt caching, bug fixes\n",
            "Last updated3 months ago\n",
            "- Completion [204 tokens (includes JSON guardrails tokens)], throughput: 56.219 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for entity enrichment from FHIR servers for medical-related entities.\n",
            "  - Added support for latest Cohere models (COMMAND_R_202408, COMMAND_R_PLUS_202408) with datestamped model enums for previous versions.\n",
            "  - Support for the latest Azure AI Document Intelligence v4.0 preview API (2024-07-31) now used by default.\n",
            "  - Renamed LinkReferenceType to LinkReference to align with data model standards.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Updated naming conventions for consistency with existing standards.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issue where LLM was adding source tags to the end of completed messages (GPLA-3120).\n",
            "  - Resolved failure to load sitemap on child page of website (GPLA-3133).\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: September 1, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Enhances data enrichment capabilities for healthcare applications and improves model support for developers.\n",
            "\n",
            "2024-12-30T04:06:20.502Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:03.229250, used credits [0.00365100]\n",
            "- CONTENT [d764f4d3-1282-441c-8e4a-08ce664b0b47]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [613 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/november-2024/november-16-support-for-image-description-multi-turn-text-summarization</name><title>November 16: Support for image description, multi-turn text summarization | Graphlit Changelog</title></metadata> ü¶É\tNovember 2024\n",
            "November 16: Support for image description, multi-turn text summarization\n",
            "New Features\n",
            "üí° Graphlit now supports multi-turn summarization of text with the reviseText mutation.  You can provide an LLM prompt and text string, along with an optional specification.  This can be used for summarizing any raw text and having a multi-turn conversation with the LLM to revise the output from the LLM.  (Colab Notebook Example)\n",
            "üí° Graphlit now supports image descriptions using vision LLMs, without needing to ingest the image first.  With the new describeImage mutation, which takes a URI, and describeEncodedImage mutation, which takes a Base-64 encoded image and MIME type, you can use any vision LLM to prompt an image description.  These mutations accept an optional specification, where you can select your vision LLM.  If not provided, OpenAI GPT-4o will be used. (Colab Notebook Example)\n",
            "PreviousNovember 24: Support for direct LLM prompt, multi-turn image analysis, bug fixes\n",
            "NextNovember 10: Support for web search, multi-turn content summarization, Deepgram language detection\n",
            "Last updated1 month ago\n",
            "- Completion [151 tokens (includes JSON guardrails tokens)], throughput: 46.760 tokens/sec:\n",
            "- New Features:\n",
            "  - Multi-turn summarization of text with the reviseText mutation, allowing for LLM prompts and text revisions.\n",
            "  - Image descriptions supported via describeImage mutation (URI input) and describeEncodedImage mutation (Base-64 encoded image), utilizing vision LLMs.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Optional specifications for selecting vision LLMs; defaults to OpenAI GPT-4o if not specified.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - No specific bug fixes mentioned in this release.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: November 16, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced capabilities for text summarization and image description without prior image ingestion, improving interaction with LLMs.\n",
            "\n",
            "2024-12-30T04:06:19.782Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:04.949947, used credits [0.00576000]\n",
            "- CONTENT [4adced81-1014-450d-9e42-e81ec370a757]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [740 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/october-2023/october-30-optimized-conversation-responses-added-observable-aliases-bug-fixes</name><title>October 30: Optimized conversation responses; added observable aliases; bug fixes | Graphlit Changelog</title></metadata> üéÉ\tOctober 2023\n",
            "October 30: Optimized conversation responses; added observable aliases; bug fixes\n",
            "New Features\n",
            "üí° Graphlit now supports 'aliases' of observable names, as the alternateNames property.  When an observed entity, such as Organization, is enriched, we store the original name and the enriched name as an alias.  For example, \"OpenAI\" may be enriched to \"OpenAI, Inc.\", and we store \"OpenAI\" as an alias, and update the name to \"OpenAI, Inc.\".\n",
            "üí° Added workflows filter to ContentCriteriaInput type, for filtering content by workflow(s) when creating conversation.\n",
            "Optimized formatting of content sources into prompt context, for more accurate conversation responses.\n",
            "Optimized formatting of extracted text from Slack messages, for better knowledge retrieval.\n",
            "Updated text tokenizer for more accurate token counting.\n",
            "Upgraded Azure Text Analytics to latest preview API version.\n",
            "Authors found in RSS feeds are now stored as observations of Person entities.\n",
            "Added rate limiting for Reddit feeds.\n",
            "Added rate limiting for Wikipedia enrichment.\n",
            "Added support for reading Reddit post comments when reading Reddit feed.\n",
            "‚ö° EmbedFacets has been renamed to EnableFacets in the conversation strategy.\n",
            "‚ö° Removed extra content level in IngestionWorkflowStage type.  Now, the if property is of type IngestionContentFilter.\n",
            "Bugs Fixed\n",
            "GPLA-1556: Better handling of very long user prompts.\n",
            "GPLA-1627: Optimized token budget for more accurate prompt completion.\n",
            "GPLA-1585: More accurate entity matching in Wikipedia entity enrichment.\n",
            "PreviousDecember 10: Support for OpenAI GPT-4 Turbo, Llama 2 and Mistral models; query by example, bug fixes\n",
            "NextOctober 15: Support for Anthropic Claude models, Slack feeds and entity enrichment\n",
            "Last updated1 year ago\n",
            "- Completion [295 tokens (includes JSON guardrails tokens)], throughput: 59.597 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for 'aliases' of observable names via the alternateNames property, allowing original and enriched names to be stored together.\n",
            "  - Workflows filter added to ContentCriteriaInput type for filtering content by workflow(s) in conversations.\n",
            "  - Optimized formatting of content sources and extracted text from Slack messages for improved conversation responses and knowledge retrieval.\n",
            "  - Updated text tokenizer for better token counting.\n",
            "  - Upgraded Azure Text Analytics to the latest preview API version.\n",
            "  - Authors in RSS feeds are now stored as observations of Person entities.\n",
            "  - Rate limiting added for Reddit feeds and Wikipedia enrichment.\n",
            "  - Support for reading Reddit post comments from Reddit feeds.\n",
            "  - EmbedFacets renamed to EnableFacets in conversation strategy.\n",
            "  - Removed extra content level in IngestionWorkflowStage type; if property is now of type IngestionContentFilter.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Better handling of long user prompts.\n",
            "  - Optimized token budget for more accurate prompt completion.\n",
            "  - Improved entity matching in Wikipedia entity enrichment.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Addressed issues with long user prompts for better handling.\n",
            "  - Enhanced token budget optimization for prompt completion accuracy.\n",
            "  - Improved accuracy in entity matching during Wikipedia enrichment.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: October 2023.\n",
            "\n",
            "- Value:\n",
            "  - These updates enhance the platform's capabilities for developers, improving conversation accuracy, content filtering, and data handling efficiency.\n",
            "\n",
            "2024-12-30T04:06:17.716Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:02.883391, used credits [0.00404700]\n",
            "- CONTENT [efb60fde-e52e-4726-893f-d58347a0deeb]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [597 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/october-2024/october-22-support-for-latest-anthropic-sonnet-3.5-model-cohere-image-embeddings</name><title>October 22: Support for latest Anthropic Sonnet 3.5 model, Cohere image embeddings | Graphlit Changelog</title></metadata> üéÉ\tOctober 2024\n",
            "October 22: Support for latest Anthropic Sonnet 3.5 model, Cohere image embeddings\n",
            "New Features\n",
            "Graphlit now supports the latest Anthropic Sonnet 3.5 model (released 10/22/2024).  We have added date-versions model enums for the Anthropic models: CLAUDE_3_5_SONNET_20240620, CLAUDE_3_5_SONNET_20241022, CLAUDE_3_HAIKU_20240307, CLAUDE_3_OPUS_20240229, CLAUDE_3_SONNET_20240229. The existing model enums will target the latest released models, as specified by Anthropic.\n",
            "Graphlit now supports image embeddings using the Cohere Embed 3.0 models.\n",
            "PreviousOctober 31: Support for simulated tool calling, bug fixes\n",
            "NextOctober 21: Support OpenAI, Cohere, Jina, Mistral, Voyage and Google AI embedding models\n",
            "Last updated2 months ago\n",
            "- Completion [188 tokens (includes JSON guardrails tokens)], throughput: 65.201 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for the latest Anthropic Sonnet 3.5 model (released 10/22/2024).\n",
            "  - Added date-version model enums for Anthropic models: CLAUDE_3_5_SONNET_20240620, CLAUDE_3_5_SONNET_20241022, CLAUDE_3_HAIKU_20240307, CLAUDE_3_OPUS_20240229, CLAUDE_3_SONNET_20240229.\n",
            "  - Support for image embeddings using Cohere Embed 3.0 models.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Existing model enums will now target the latest released models as specified by Anthropic.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: October 22, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers access to the latest AI models and enhanced image embedding capabilities.\n",
            "\n",
            "2024-12-30T04:06:17.625Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:02.794656, used credits [0.00432300]\n",
            "- CONTENT [6a1f0635-0338-4b77-85c2-a476edc6cde9]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [689 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/september-2024/september-3-support-for-web-search-feeds-model-deprecations</name><title>September 3: Support for web search feeds, model deprecations | Graphlit Changelog</title></metadata> üéí\tSeptember 2024\n",
            "September 3: Support for web search feeds, model deprecations\n",
            "New Features\n",
            "üí° Graphlit now supports web search feeds, using the Tavily and Exa.AI web search APIs. You can choose the SEARCH feed type, and assign your search text property, and we will ingest the referenced web pages from the search results.  Optionally, you can select the search service via the serviceType property under search feed properties.  By default, Graphlit will use the Tavily API.\n",
            "‚ö° We have deprecated these OpenAI models, according to the future support OpenAI is providing to these legacy models: GPT35_TURBO, GPT35_TURBO_0613, GPT35_TURBO_16K, GPT35_TURBO_16K_0125, GPT35_TURBO_16K_0613, GPT35_TURBO_16K_1106, GPT4, GPT4_0613, GPT4_32K, GPT4_32K_0613, GPT4_TURBO_VISION_128K, and GPT4_TURBO_VISION_128K_1106.  We suggest using GPT-4o or GPT-4o Mini instead.\n",
            "Bugs Fixed\n",
            "GPLA-2523: Can't ingest from same feed URI multiple times and wait on isFeedDone\n",
            "PreviousSeptember 26: Support for Google AI and Cerebras models, and latest Groq models\n",
            "NextSeptember 1: Support for FHIR enrichment, latest Cohere models, bug fixes\n",
            "Last updated3 months ago\n",
            "- Completion [188 tokens (includes JSON guardrails tokens)], throughput: 67.271 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for web search feeds using Tavily and Exa.AI APIs.\n",
            "  - Ability to choose SEARCH feed type and assign search text property for ingesting web pages from search results.\n",
            "  - Option to select search service via serviceType property, defaulting to Tavily API.\n",
            "  \n",
            "- Enhancements/Improvements:\n",
            "  - Deprecation of several OpenAI models due to reduced future support, including various versions of GPT-3.5 and GPT-4. Recommended alternatives are GPT-4o and GPT-4o Mini.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issue GPLA-2523: Ingestion from the same feed URI multiple times and waiting on isFeedDone.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: September 3, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced capabilities for web search integration and guidance on model usage with improved support for newer models.\n",
            "\n",
            "2024-12-30T04:06:17.134Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:02.309199, used credits [0.00421500]\n",
            "- CONTENT [02c635c4-808d-495e-9744-bb501a2066e8]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [641 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/september-2024/september-30-support-for-azure-ai-inference-models-mistral-pixtral-and-latest-google-gemini-models</name><title>September 30: Support for Azure AI Inference models, Mistral Pixtral and latest Google Gemini models | Graphlit Changelog</title></metadata> üéí\tSeptember 2024\n",
            "September 30: Support for Azure AI Inference models, Mistral Pixtral and latest Google Gemini models\n",
            "New Features\n",
            "üí° Graphlit now supports the Azure AI Model Inference API (aka Models as a Service) model service which offers serverless hosting to many models such as Meta Llama 3.2, Cohere Command-R, and many more.  For Azure AI, all models are 'custom', and you will need to provide the serverless endpoint, API key and number of tokens accepted in context window, after provisioning the model of your choice.\n",
            "We have added support for the multimodal Mistral Pixtral model, under the model enum PIXTRAL_12B_2409.\n",
            "We have added versioned model enums for Google Gemini, so you can access GEMINI_1_5_FLASH_001, GEMINI_1_5_FLASH_002, GEMINI_1_5_PRO_001 and GEMINI_1_5_PRO_002.\n",
            "PreviousOctober 3: Support tool calling, ingestBatch mutation, Gemini Flash 1.5 8b, bug fixes\n",
            "NextSeptember 26: Support for Google AI and Cerebras models, and latest Groq models\n",
            "Last updated2 months ago\n",
            "- Completion [191 tokens (includes JSON guardrails tokens)], throughput: 82.713 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for Azure AI Model Inference API, enabling serverless hosting for models like Meta Llama 3.2 and Cohere Command-R.\n",
            "  - Added support for the multimodal Mistral Pixtral model (PIXTRAL_12B_2409).\n",
            "  - Introduced versioned model enums for Google Gemini: GEMINI_1_5_FLASH_001, GEMINI_1_5_FLASH_002, GEMINI_1_5_PRO_001, GEMINI_1_5_PRO_002.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Enhanced model accessibility through versioned enums for Google Gemini.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - No specific bug fixes mentioned in this release.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: September 30, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers expanded model options and improved integration with Azure AI services, enhancing flexibility in model deployment.\n",
            "\n",
            "2024-12-30T04:06:13.244Z: Search entities\n",
            "- Workflow [Semantic search] took 0:00:00.104695, used credits [0.00960000]\n",
            "- Processor name [Azure AI Search], units [48]\n",
            "\n",
            "2024-12-30T04:03:10.603Z: GraphQL\n",
            "- Operation took 0:03:33.293309, used credits [0.00000000]\n",
            "- Request:\n",
            "mutation PublishContents($summaryPrompt: String, $publishPrompt: String!, $connector: ContentPublishingConnectorInput!, $filter: ContentFilter, $includeDetails: Boolean, $isSynchronous: Boolean, $correlationId: String, $name: String, $summarySpecification: EntityReferenceInput, $publishSpecification: EntityReferenceInput, $workflow: EntityReferenceInput) { publishContents(summaryPrompt: $summaryPrompt, publishPrompt: $publishPrompt, connector: $connector, filter: $filter, includeDetails: $includeDetails, isSynchronous: $isSynchronous, correlationId: $correlationId, name: $name, summarySpecification: $summarySpecification, publishSpecification: $publishSpecification, workflow: $workflow) { content { id name state originalDate identifier markdown uri type fileType mimeType format formatName fileExtension fileName fileSize masterUri imageUri textUri audioUri transcriptUri summary customSummary keywords bullets headlines posts chapters questions video { width height duration make model software title description keywords author } audio { keywords author series episode episodeType season publisher copyright genre title description bitrate channels sampleRate bitsPerSample duration } image { width height resolutionX resolutionY bitsPerComponent components projectionType orientation description make model software lens focalLength exposureTime fNumber iso heading pitch } document { title subject summary author publisher description keywords pageCount worksheetCount slideCount wordCount lineCount paragraphCount isEncrypted hasDigitalSignature } } details { contents { id } summaries text textType summarySpecification publishSpecification summaryTime publishTime } } }\n",
            "- Variables:\n",
            "{\"summaryPrompt\":\"\\\"\\\\nYou are an AI assistant that extracts the most important information from product changelog pages.\\\\n\\\\nYou are being provided a changelog web page for one of many releases of the Graphlit Platform in 2024.\\\\n\\\\nYour task is to produce a concise summary that covers:\\\\n\\\\nNew Features ‚Äì Briefly list or describe each new capability.\\\\nEnhancements\\\\/Improvements ‚Äì Any notable improvements or changes.\\\\nBug Fixes ‚Äì Summaries of what was fixed and why it matters.\\\\nOther Key Details ‚Äì Any version numbers, feature flags, or breaking changes.\\\\nDates - When a feature was released, include both the month and year\\\\nValue - What this offers to developers.\\\\nKeep it succinct, accurate, and organized. Use short sentences or bullet points so it‚Äôs easy to incorporate into a map\\\\/reduce pipeline. Omit any superfluous text.\\\\n\\\\nOutput:\\\\nA concise summary in bullet points highlighting the essential updates from the changelog.\\\\n\\\"\",\"publishPrompt\":\"\\\"\\\\nBased on the provided changelog summaries, generate a tree-like timeline visualization for the year 2024 in Graphviz DOT format.  \\\\nInclude all of the major releases, features, and events mentioned. Disregard any unrelated details.  \\\\nOnly include changelogs from 2024.  \\\\n\\\\n---\\\\n\\\\n**Diagram Structure:**  \\\\n- **Year Node:** Represent the year (`2024`) as the root node of the tree.  \\\\n- **Quarter Subgraphs (`cluster_Q1`, `cluster_Q2`, etc.):** Group all months of each quarter together.  \\\\n- **Month Nodes:** Each quarter contains its months (e.g., January, February, and March in Q1).  \\\\n- Draw hierarchical connections:  \\\\n  - Year ‚Üí Quarters (e.g., `2024 ‚Üí Q1, Q2, Q3, Q4`).  \\\\n  - Quarters ‚Üí Months within them (e.g., `Q1 ‚Üí January ‚Üí February ‚Üí March`).  \\\\n  - Link the corresponding months to events\\\\/features, with nodes representing features and edges labeled with the respective dates.  \\\\n\\\\n---\\\\n\\\\n**DOT Style Requirements:**  \\\\n- Use `rankdir=TB` to arrange the timeline from top to bottom (Year ‚Üí Quarters ‚Üí Months).  \\\\n- Use the font ‚ÄúInter‚Äù for all elements.  \\\\n- All nodes should have `shape=rect`, `style=filled`, and consistent dimensions (`width=1.2, height=1.2`).  \\\\n- Subgraph clusters organize quarters and months hierarchically.  \\\\n- Label edges with descriptive phrases such as \\\\\\\"Launched on [Date]\\\\\\\" or \\\\\\\"Introduced on [Date].\\\\\\\"  \\\\n- End every DOT statement with a semicolon. Return only plain Graphviz DOT syntax.  \\\\n\\\\n---\\\\n\\\\n**Example (for styling reference only):**  \\\\n\\\\ndigraph Timeline {  \\\\n    rankdir=TB; \\\\/\\\\/ Top-to-bottom layout  \\\\n\\\\n    \\\\/\\\\/ Global styling  \\\\n    graph [bgcolor=\\\\\\\"#FFFFFF\\\\\\\", fontname=\\\\\\\"Inter\\\\\\\"];  \\\\n    node  [shape=rect, style=filled, fontname=\\\\\\\"Inter\\\\\\\", fontcolor=\\\\\\\"#333333\\\\\\\", width=1.2, height=1.2];  \\\\n    edge  [color=\\\\\\\"#777777\\\\\\\", arrowhead=normal, arrowsize=0.6, fontsize=10];  \\\\n\\\\n    \\\\/\\\\/ Root node for the year  \\\\n    \\\\\\\"2024\\\\\\\" [fillcolor=\\\\\\\"#FFD700\\\\\\\"];  \\\\n\\\\n    \\\\/\\\\/ Q1 Subgraph  \\\\n    subgraph cluster_Q1 {  \\\\n        label=\\\\\\\"Q1\\\\\\\";  \\\\n        style=\\\\\\\"filled\\\\\\\";  \\\\n        color=\\\\\\\"#F0F0F0\\\\\\\";  \\\\n\\\\n        \\\\/\\\\/ Month nodes in Q1  \\\\n        \\\\\\\"January\\\\\\\" [fillcolor=\\\\\\\"#FFECB3\\\\\\\"];  \\\\n        \\\\\\\"February\\\\\\\" [fillcolor=\\\\\\\"#FFECB3\\\\\\\"];  \\\\n        \\\\\\\"March\\\\\\\" [fillcolor=\\\\\\\"#FFECB3\\\\\\\"];  \\\\n\\\\n        \\\\/\\\\/ Connections between months  \\\\n        \\\\\\\"January\\\\\\\" -> \\\\\\\"February\\\\\\\";  \\\\n        \\\\\\\"February\\\\\\\" -> \\\\\\\"March\\\\\\\";  \\\\n    }  \\\\n\\\\n    \\\\/\\\\/ Feature connections  \\\\n    subgraph cluster_January {  \\\\n        style=\\\\\\\"invis\\\\\\\";  \\\\n        \\\\\\\"Feature A (Launched on Jan 15)\\\\\\\" [fillcolor=\\\\\\\"#CCE5FF\\\\\\\"];  \\\\n        \\\\\\\"January\\\\\\\" -> \\\\\\\"Feature A (Launched on Jan 15)\\\\\\\" [label=\\\\\\\"Launched on Jan 15\\\\\\\"];  \\\\n    }  \\\\n\\\\n    subgraph cluster_February {  \\\\n        style=\\\\\\\"invis\\\\\\\";  \\\\n        \\\\\\\"Feature B (Introduced on Feb 10)\\\\\\\" [fillcolor=\\\\\\\"#CCE5FF\\\\\\\"];  \\\\n        \\\\\\\"February\\\\\\\" -> \\\\\\\"Feature B (Introduced on Feb 10)\\\\\\\" [label=\\\\\\\"Introduced on Feb 10\\\\\\\"];  \\\\n    }  \\\\n}\\\\n\\\\nDon't wrap your response on markdown. No ```dot ... ``` blocks.\\\\n\\\"\",\"connector\":\"{ type: TEXT, format: MARKDOWN }\",\"filter\":\"{ feeds: [ { id: \\\"67102186-088a-46b0-a03d-e94e916ad3ed\\\" } ] }\",\"includeDetails\":\"true\",\"isSynchronous\":\"true\",\"correlationId\":\"\\\"2024-12-30T03:58:05.173167\\\"\",\"name\":\"\\\"Published Summary\\\"\",\"summarySpecification\":\"{ id: \\\"14492be0-51f3-4ac6-b9f7-5536c063ad82\\\" }\",\"publishSpecification\":\"{ id: \\\"c7e40759-9760-4f4d-a9dc-4439ec62d6cd\\\" }\"}\n",
            "- Response:\n",
            "{\"data\":{\"publishContents\":{\"content\":{\"id\":\"2c79f064-350a-4c5c-8091-6ffbdb28ddc4\",\"name\":\"Published Summary\",\"state\":\"FINISHED\",\"originalDate\":null,\"identifier\":\"d5df8bdd-320e-4e05-9852-24c125f3d55e\",\"markdown\":\"digraph Timeline {\\n    rankdir=TB;\\n    graph [bgcolor=\\\"#FFFFFF\\\", fontname=\\\"Inter\\\"];\\n    node  [shape=rect, style=filled, fontname=\\\"Inter\\\", fontcolor=\\\"#333333\\\", width=1.2, height=1.2];\\n    edge  [color=\\\"#777777\\\", arrowhead=normal, arrowsize=0.6, fontsize=10];\\n\\n    // Root node for the year\\n    \\\"2024\\\" [fillcolor=\\\"#FFD700\\\"];\\n\\n    // Q1 Subgraph\\n    subgraph cluster_Q1 {\\n        label=\\\"Q1\\\";\\n        style=\\\"filled\\\";\\n        color=\\\"#F0F0F0\\\";\\n\\n        // Month nodes\\n        \\\"January\\\" [fillcolor=\\\"#FFECB3\\\"];\\n        \\\"February\\\" [fillcolor=\\\"#FFECB3\\\"];\\n        \\\"March\\\" [fillcolor=\\\"#FFECB3\\\"];\\n\\n        // Connections between months\\n        \\\"January\\\" -> \\\"February\\\";\\n        \\\"February\\\" -> \\\"March\\\";\\n\\n        // January releases\\n        subgraph cluster_January {\\n            style=\\\"invis\\\";\\n            \\\"Release_Jan_18\\\" [label=\\\"Content publishing, LLM tools, CLIP embeddings\\\", fillcolor=\\\"#CCE5FF\\\"];\\n            \\\"Release_Jan_22\\\" [label=\\\"Google/Microsoft email feeds, reingest content\\\", fillcolor=\\\"#CCE5FF\\\"];\\n\\n            \\\"January\\\" -> \\\"Release_Jan_18\\\" [label=\\\"Jan 18\\\"];\\n            \\\"January\\\" -> \\\"Release_Jan_22\\\" [label=\\\"Jan 22\\\"];\\n        }\\n\\n        // February releases\\n        subgraph cluster_February {\\n            style=\\\"invis\\\";\\n            \\\"Release_Feb_2\\\" [label=\\\"Semantic Alerts, OpenAI 0125 models\\\", fillcolor=\\\"#CCE5FF\\\"];\\n            \\\"Release_Feb_21\\\" [label=\\\"OneDrive/Google Drive feeds, PDF image extraction\\\", fillcolor=\\\"#CCE5FF\\\"];\\n\\n            \\\"February\\\" -> \\\"Release_Feb_2\\\" [label=\\\"Feb 2\\\"];\\n            \\\"February\\\" -> \\\"Release_Feb_21\\\" [label=\\\"Feb 21\\\"];\\n        }\\n\\n        // March releases\\n        subgraph cluster_March {\\n            style=\\\"invis\\\";\\n            \\\"Release_Mar_10\\\" [label=\\\"Claude 3, Mistral, Groq, usage telemetry\\\", fillcolor=\\\"#CCE5FF\\\"];\\n            \\\"Release_Mar_13\\\" [label=\\\"Claude 3 Haiku model, Base64 ingestion\\\", fillcolor=\\\"#CCE5FF\\\"];\\n            \\\"Release_Mar_23\\\" [label=\\\"Linear/GitHub/Jira feeds, ingest via sitemaps\\\", fillcolor=\\\"#CCE5FF\\\"];\\n\\n            \\\"March\\\" -> \\\"Release_Mar_10\\\" [label=\\\"Mar 10\\\"];\\n            \\\"March\\\" -> \\\"Release_Mar_13\\\" [label=\\\"Mar 13\\\"];\\n            \\\"March\\\" -> \\\"Release_Mar_23\\\" [label=\\\"Mar 23\\\"];\\n        }\\n    }\\n\\n    // Q2 Subgraph\\n    subgraph cluster_Q2 {\\n        label=\\\"Q2\\\";\\n        style=\\\"filled\\\";\\n        color=\\\"#F0F0F0\\\";\\n\\n        // Month nodes\\n        \\\"April\\\" [fillcolor=\\\"#FFECB3\\\"];\\n        \\\"May\\\" [fillcolor=\\\"#FFECB3\\\"];\\n        \\\"June\\\" [fillcolor=\\\"#FFECB3\\\"];\\n\\n        // Connections between months\\n        \\\"April\\\" -> \\\"May\\\";\\n        \\\"May\\\" -> \\\"June\\\";\\n\\n        // April releases\\n        subgraph cluster_April {\\n            style=\\\"invis\\\";\\n            \\\"Release_Apr_7\\\"  [label=\\\"Discord feeds, Cohere reranking, chunk retrieval\\\", fillcolor=\\\"#CCE5FF\\\"];\\n            \\\"Release_Apr_23\\\" [label=\\\"Python/TS SDKs, new OpenAI/Cohere/Groq\\\", fillcolor=\\\"#CCE5FF\\\"];\\n\\n            \\\"April\\\" -> \\\"Release_Apr_7\\\"  [label=\\\"Apr 7\\\"];\\n            \\\"April\\\" -> \\\"Release_Apr_23\\\" [label=\\\"Apr 23\\\"];\\n        }\\n\\n        // May releases\\n        subgraph cluster_May {\\n            style=\\\"invis\\\";\\n            \\\"Release_May_5\\\"  [label=\\\"Jina/Pongo rerankers, MS Teams feed, YouTube\\\", fillcolor=\\\"#CCE5FF\\\"];\\n            \\\"Release_May_15\\\" [label=\\\"GraphRAG, GPT-4o model, performance\\\", fillcolor=\\\"#CCE5FF\\\"];\\n\\n            \\\"May\\\" -> \\\"Release_May_5\\\"  [label=\\\"May 5\\\"];\\n            \\\"May\\\" -> \\\"Release_May_15\\\" [label=\\\"May 15\\\"];\\n        }\\n\\n        // June releases\\n        subgraph cluster_June {\\n            style=\\\"invis\\\";\\n            \\\"Release_Jun_9\\\"  [label=\\\"Deepseek models, JSON-LD parsing, KGraph\\\", fillcolor=\\\"#CCE5FF\\\"];\\n            \\\"Release_Jun_21\\\" [label=\\\"Claude 3.5 Sonnet, knowledge graph search\\\", fillcolor=\\\"#CCE5FF\\\"];\\n\\n            \\\"June\\\" -> \\\"Release_Jun_9\\\"  [label=\\\"Jun 9\\\"];\\n            \\\"June\\\" -> \\\"Release_Jun_21\\\" [label=\\\"Jun 21\\\"];\\n        }\\n    }\\n\\n    // Q3 Subgraph\\n    subgraph cluster_Q3 {\\n        label=\\\"Q3\\\";\\n        style=\\\"filled\\\";\\n        color=\\\"#F0F0F0\\\";\\n\\n        // Month nodes\\n        \\\"July\\\" [fillcolor=\\\"#FFECB3\\\"];\\n        \\\"August\\\" [fillcolor=\\\"#FFECB3\\\"];\\n        \\\"September\\\" [fillcolor=\\\"#FFECB3\\\"];\\n\\n        // Connections between months\\n        \\\"July\\\" -> \\\"August\\\";\\n        \\\"August\\\" -> \\\"September\\\";\\n\\n        // July releases\\n        subgraph cluster_July {\\n            style=\\\"invis\\\";\\n            \\\"Release_Jul_4\\\"  [label=\\\"Webhook Alerts, Deepseek 128k context\\\", fillcolor=\\\"#CCE5FF\\\"];\\n            \\\"Release_Jul_19\\\" [label=\\\"GPT-4o Mini, BYO-key Azure AI\\\", fillcolor=\\\"#CCE5FF\\\"];\\n            \\\"Release_Jul_25\\\" [label=\\\"Mistral Large 2/Nemo, Groq Llama 3.1\\\", fillcolor=\\\"#CCE5FF\\\"];\\n            \\\"Release_Jul_28\\\" [label=\\\"Indexing stage, Azure language detection\\\", fillcolor=\\\"#CCE5FF\\\"];\\n\\n            \\\"July\\\" -> \\\"Release_Jul_4\\\"  [label=\\\"Jul 4\\\"];\\n            \\\"July\\\" -> \\\"Release_Jul_19\\\" [label=\\\"Jul 19\\\"];\\n            \\\"July\\\" -> \\\"Release_Jul_25\\\" [label=\\\"Jul 25\\\"];\\n            \\\"July\\\" -> \\\"Release_Jul_28\\\" [label=\\\"Jul 28\\\"];\\n        }\\n\\n        // August releases\\n        subgraph cluster_August {\\n            style=\\\"invis\\\";\\n            \\\"Release_Aug_8\\\"   [label=\\\"LLM doc extraction, .NET SDK\\\", fillcolor=\\\"#CCE5FF\\\"];\\n            \\\"Release_Aug_11\\\"  [label=\\\"Azure AI default, language-aware summaries\\\", fillcolor=\\\"#CCE5FF\\\"];\\n            \\\"Release_Aug_20\\\"  [label=\\\"Medical entities, Anthropic prompt caching\\\", fillcolor=\\\"#CCE5FF\\\"];\\n\\n            \\\"August\\\" -> \\\"Release_Aug_8\\\"  [label=\\\"Aug 8\\\"];\\n            \\\"August\\\" -> \\\"Release_Aug_11\\\" [label=\\\"Aug 11\\\"];\\n            \\\"August\\\" -> \\\"Release_Aug_20\\\" [label=\\\"Aug 20\\\"];\\n        }\\n\\n        // September releases\\n        subgraph cluster_September {\\n            style=\\\"invis\\\";\\n            \\\"Release_Sep_1\\\"   [label=\\\"FHIR enrichment, latest Cohere\\\", fillcolor=\\\"#CCE5FF\\\"];\\n            \\\"Release_Sep_3\\\"   [label=\\\"Web search feeds, model deprecations\\\", fillcolor=\\\"#CCE5FF\\\"];\\n            \\\"Release_Sep_26\\\"  [label=\\\"Google AI, Cerebras, latest Groq\\\", fillcolor=\\\"#CCE5FF\\\"];\\n            \\\"Release_Sep_30\\\"  [label=\\\"Azure AI Inference, Mistral Pixtral, Gemini\\\", fillcolor=\\\"#CCE5FF\\\"];\\n\\n            \\\"September\\\" -> \\\"Release_Sep_1\\\"  [label=\\\"Sep 1\\\"];\\n            \\\"September\\\" -> \\\"Release_Sep_3\\\"  [label=\\\"Sep 3\\\"];\\n            \\\"September\\\" -> \\\"Release_Sep_26\\\" [label=\\\"Sep 26\\\"];\\n            \\\"September\\\" -> \\\"Release_Sep_30\\\" [label=\\\"Sep 30\\\"];\\n        }\\n    }\\n\\n    // Q4 Subgraph\\n    subgraph cluster_Q4 {\\n        label=\\\"Q4\\\";\\n        style=\\\"filled\\\";\\n        color=\\\"#F0F0F0\\\";\\n\\n        // Month nodes\\n        \\\"October\\\" [fillcolor=\\\"#FFECB3\\\"];\\n        \\\"November\\\" [fillcolor=\\\"#FFECB3\\\"];\\n        \\\"December\\\" [fillcolor=\\\"#FFECB3\\\"];\\n\\n        // Connections between months\\n        \\\"October\\\" -> \\\"November\\\";\\n        \\\"November\\\" -> \\\"December\\\";\\n\\n        // October releases\\n        subgraph cluster_October {\\n            style=\\\"invis\\\";\\n            \\\"Release_Oct_3\\\"  [label=\\\"Tool calling, ingestBatch, Gemini Flash 1.5\\\", fillcolor=\\\"#CCE5FF\\\"];\\n            \\\"Release_Oct_7\\\"  [label=\\\"Anthropic & Gemini tool calling\\\", fillcolor=\\\"#CCE5FF\\\"];\\n            \\\"Release_Oct_9\\\"  [label=\\\"GitHub repo feeds\\\", fillcolor=\\\"#CCE5FF\\\"];\\n            \\\"Release_Oct_21\\\" [label=\\\"OpenAI/Cohere/Jina/Mistral/Voyage embeddings\\\", fillcolor=\\\"#CCE5FF\\\"];\\n            \\\"Release_Oct_22\\\" [label=\\\"Anthropic Sonnet 3.5, Cohere image embeddings\\\", fillcolor=\\\"#CCE5FF\\\"];\\n            \\\"Release_Oct_31\\\" [label=\\\"Simulated tool calling\\\", fillcolor=\\\"#CCE5FF\\\"];\\n\\n            \\\"October\\\" -> \\\"Release_Oct_3\\\"  [label=\\\"Oct 3\\\"];\\n            \\\"October\\\" -> \\\"Release_Oct_7\\\"  [label=\\\"Oct 7\\\"];\\n            \\\"October\\\" -> \\\"Release_Oct_9\\\"  [label=\\\"Oct 9\\\"];\\n            \\\"October\\\" -> \\\"Release_Oct_21\\\" [label=\\\"Oct 21\\\"];\\n            \\\"October\\\" -> \\\"Release_Oct_22\\\" [label=\\\"Oct 22\\\"];\\n            \\\"October\\\" -> \\\"Release_Oct_31\\\" [label=\\\"Oct 31\\\"];\\n        }\\n\\n        // November releases\\n        subgraph cluster_November {\\n            style=\\\"invis\\\";\\n            \\\"Release_Nov_4\\\"  [label=\\\"Claude 3.5 Haiku\\\", fillcolor=\\\"#CCE5FF\\\"];\\n            \\\"Release_Nov_10\\\" [label=\\\"Web search, multi-turn summarization\\\", fillcolor=\\\"#CCE5FF\\\"];\\n            \\\"Release_Nov_16\\\" [label=\\\"Image description, multi-turn text summary\\\", fillcolor=\\\"#CCE5FF\\\"];\\n            \\\"Release_Nov_24\\\" [label=\\\"Direct LLM prompt, multi-turn image analysis\\\", fillcolor=\\\"#CCE5FF\\\"];\\n\\n            \\\"November\\\" -> \\\"Release_Nov_4\\\"  [label=\\\"Nov 4\\\"];\\n            \\\"November\\\" -> \\\"Release_Nov_10\\\" [label=\\\"Nov 10\\\"];\\n            \\\"November\\\" -> \\\"Release_Nov_16\\\" [label=\\\"Nov 16\\\"];\\n            \\\"November\\\" -> \\\"Release_Nov_24\\\" [label=\\\"Nov 24\\\"];\\n        }\\n\\n        // December releases\\n        subgraph cluster_December {\\n            style=\\\"invis\\\";\\n            \\\"Release_Dec_1\\\"  [label=\\\"Retrieval-only RAG pipeline\\\", fillcolor=\\\"#CCE5FF\\\"];\\n            \\\"Release_Dec_9\\\"  [label=\\\"Website mapping, screenshots, Groq Llama 3.3\\\", fillcolor=\\\"#CCE5FF\\\"];\\n            \\\"Release_Dec_22\\\" [label=\\\"Dropbox/Box/Intercom/Zendesk feeds, OpenAI o1, Gemini 2.0\\\", fillcolor=\\\"#CCE5FF\\\"];\\n            \\\"Release_Dec_27\\\" [label=\\\"LLM fallbacks, ingest Google Docs\\\", fillcolor=\\\"#CCE5FF\\\"];\\n\\n            \\\"December\\\" -> \\\"Release_Dec_1\\\"  [label=\\\"Dec 1\\\"];\\n            \\\"December\\\" -> \\\"Release_Dec_9\\\"  [label=\\\"Dec 9\\\"];\\n            \\\"December\\\" -> \\\"Release_Dec_22\\\" [label=\\\"Dec 22\\\"];\\n            \\\"December\\\" -> \\\"Release_Dec_27\\\" [label=\\\"Dec 27\\\"];\\n        }\\n    }\\n\\n    // Connections from 2024 to each Quarter\\n    \\\"2024\\\" -> \\\"Q1\\\";\\n    \\\"2024\\\" -> \\\"Q2\\\";\\n    \\\"2024\\\" -> \\\"Q3\\\";\\n    \\\"2024\\\" -> \\\"Q4\\\";\\n}\",\"uri\":null,\"type\":\"TEXT\",\"fileType\":\"DOCUMENT\",\"mimeType\":\"text/markdown\",\"format\":null,\"formatName\":\"Markdown Format\",\"fileExtension\":null,\"fileName\":null,\"fileSize\":null,\"masterUri\":null,\"imageUri\":null,\"textUri\":null,\"audioUri\":null,\"transcriptUri\":null,\"summary\":null,\"customSummary\":null,\"keywords\":null,\"bullets\":null,\"headlines\":null,\"posts\":null,\"chapters\":null,\"questions\":null,\"video\":null,\"audio\":null,\"image\":null,\"document\":null},\"details\":{\"contents\":[{\"id\":\"02c635c4-808d-495e-9744-bb501a2066e8\"},{\"id\":\"6a1f0635-0338-4b77-85c2-a476edc6cde9\"},{\"id\":\"efb60fde-e52e-4726-893f-d58347a0deeb\"},{\"id\":\"4adced81-1014-450d-9e42-e81ec370a757\"},{\"id\":\"d764f4d3-1282-441c-8e4a-08ce664b0b47\"},{\"id\":\"3092dd49-a054-4d32-94b2-cb67133a305d\"},{\"id\":\"b96def70-f8ed-4c72-9757-a1648306835a\"},{\"id\":\"f3c48cd9-fc5b-4306-9135-aed548177631\"},{\"id\":\"f0a42b0a-353b-4f08-9a5d-40ce9196a46b\"},{\"id\":\"4fa1f011-eca1-4585-9a4b-d31369c468cb\"},{\"id\":\"865f424b-fa74-4640-b593-a9840336a452\"},{\"id\":\"75f8d5dd-c5e0-4c08-b334-dc5e80ea8025\"},{\"id\":\"5345f273-4dcb-4f44-a1a3-4226ff5eaed8\"},{\"id\":\"e112772f-cc4a-4323-8c80-8c1d8c123dd2\"},{\"id\":\"1cd2c534-2f49-4677-ab4a-68a4365f4fdd\"},{\"id\":\"0341d367-6775-4e57-9a3d-7904d813f243\"},{\"id\":\"c693346f-b33a-4931-88f4-5c7142c749b9\"},{\"id\":\"d2f41682-fb8b-4599-8c64-91891e13c336\"},{\"id\":\"fc169406-76bc-479f-93f2-0c1b1ba4277e\"},{\"id\":\"2489940d-1c11-4cab-82d2-26e5a1bc0dff\"},{\"id\":\"2dd30528-0956-4c46-9a9c-8ce6ecc9931e\"},{\"id\":\"1bc9cf17-e156-441d-a307-def6a31d693e\"},{\"id\":\"b682b0ca-255c-4b02-b016-cb56f05edb64\"},{\"id\":\"8a9c0eb5-3658-4cca-bf2c-d68cdbea3f15\"},{\"id\":\"3d78b65e-a42d-44e9-8a9a-07faf938ee0d\"},{\"id\":\"41e9b6e8-c479-4416-8ec3-7168709d2861\"},{\"id\":\"4b9dad6a-8d6f-4daa-b1d9-6c5277939931\"},{\"id\":\"0ed6b24e-fec6-4008-8bb9-beda6073cbe6\"},{\"id\":\"257dc6c9-65d0-416d-9b1c-d412aeb42bd4\"},{\"id\":\"7c8442ac-7d94-4a40-9a3b-fdda07048992\"},{\"id\":\"f2817947-a5aa-41d7-a297-b6f16a2d42e1\"},{\"id\":\"a263132e-7225-40d3-a75d-39b3ef1edbd1\"},{\"id\":\"d40abe32-e564-4a6c-bd34-cea90b98c172\"},{\"id\":\"fbde99f0-f7ca-4f5d-a318-eb7f4de07912\"},{\"id\":\"0932e05b-1816-4e99-a4ef-7bc475de60fc\"},{\"id\":\"7b5b7874-c84b-4607-877c-8bec0e167127\"},{\"id\":\"3923639b-14f1-484b-86e7-7c6f6e67461d\"},{\"id\":\"67150a0e-9b17-4261-8f62-1c57686d46e1\"},{\"id\":\"1a8c6b11-f325-47e9-bb39-643f7fb92154\"},{\"id\":\"5da3504c-5d1d-4b5c-848e-d3ddb11f3964\"},{\"id\":\"253c57c2-3536-4a73-aa76-101372e74b0e\"},{\"id\":\"ebda0578-6209-4833-9bee-36d0050dc5ee\"},{\"id\":\"4eff5e88-2cf6-489f-9bfb-52b30823e07e\"},{\"id\":\"a937626a-37ee-4eb1-93e5-2206e9a188ec\"},{\"id\":\"a0d556d6-0bbc-4df0-9577-bb621d9c6fc2\"},{\"id\":\"9ded6f5c-a667-442d-8848-30d7a22e79e0\"},{\"id\":\"8443a72b-f798-4325-b0ac-b821d4e7dea8\"},{\"id\":\"52613eca-1a5a-40ae-91b0-3d8243a55439\"}],\"summaries\":[\"<source>\\n<metadata type='Page'><name>https://changelog.graphlit.dev/october-2024/october-3-support-tool-calling-ingestbatch-mutation-gemini-flash-1.5-8b-bug-fixes</name><title>October 3: Support tool calling, ingestBatch mutation, Gemini Flash 1.5 8b, bug fixes | Graphlit Changelog</title></metadata>\\n<summary>\\n- New Features:\\n  - Support for ingestBatch mutation to asynchronously ingest an array of URIs into content objects.\\n  - Support for continueConversation mutation, allowing responses from called tools to be sent back to the LLM.\\n  - Tool calling support added for OpenAI, Mistral, Deepseek, Groq, and Cerebras model services; support for Anthropic, Google Gemini, and Cohere coming later.\\n  - Prefilled user and assistant messages can now be sent with createConversation mutation.\\n  - Added support for Google Gemini Flash 1.5 8b model.\\n  - Deprecated tools property in the Specification object; tools must now be sent directly to extractContents and promptConversation mutations.\\n\\n- Enhancements/Improvements:\\n  - Improved conversation bootstrapping with prefilled messages.\\n\\n- Bug Fixes:\\n  - Fixed issue where models were incorrectly required on update specification call (GPLA-3207).\\n  - Resolved issue of sending system prompt with OpenAI o1 models (GPLA-3220).\\n\\n- Other Key Details:\\n  - Release Date: October 2024.\\n  - Version: Gemini Flash 1.5 8b.\\n  - Breaking change: tools property in Specification object deprecated.\\n\\n- Value:\\n  - Enhancements provide developers with more flexible and powerful tools for managing conversations and integrating various model services.\\n</summary>\\n</source>\\n\\n\",\"<source>\\n<metadata type='Page'><name>https://changelog.graphlit.dev/october-2023/october-15-support-for-anthropic-claude-models-slack-feeds-and-entity-enrichment</name><title>October 15: Support for Anthropic Claude models, Slack feeds and entity enrichment | Graphlit Changelog</title></metadata>\\n<summary>\\n- New Features:\\n  - Support for Anthropic Claude and Anthropic Claude Instant large language models.\\n  - Ingestion of Slack messages and linked file attachments from Slack channels (requires a Slack bot).\\n  - Entity enrichment for observed entities (Person, Organization, Place) using Diffbot, Wikipedia, and Crunchbase.\\n  - Text extraction from images using Azure Image Analytics, making identified text searchable.\\n  - Added embedFacets and embedCitations properties to conversation strategy in specification object.\\n  - GraphQL mutations for multi-delete of entities (deleteCollections, deleteLabels, deleteConversations).\\n  - GraphQL deleteAllConversations mutation to delete all conversations.\\n  - Automatic addition of ingested content to collections during the ingestion stage of the workflow.\\n  - Specification property added to preparation workflow stage for selecting LLM for text summarization.\\n  - Expanded properties for observed entities for enhanced entity enrichment.\\n\\n- Enhancements/Improvements:\\n  - Improved capabilities for entity enrichment and text extraction.\\n\\n- Bug Fixes:\\n  - Fixed unlimited conversation quota not assigned when upgrading project tier (GPLA-1520).\\n  - Resolved issue with entity enrichment not firing events (GPLA-1285).\\n  - Fixed web page remaining in ingested state when URL is not accessible (GPLA-1361).\\n\\n- Other Key Details:\\n  - Release Date: October 15, 2023.\\n\\n- Value:\\n  - Offers developers enhanced support for LLMs, improved data ingestion from Slack, and advanced entity enrichment capabilities.\\n</summary>\\n</source>\\n\\n\",\"<source>\\n<metadata type='Page'><name>https://changelog.graphlit.dev/november-2024/november-10-support-for-web-search-multi-turn-content-summarization-deepgram-language-detection</name><title>November 10: Support for web search, multi-turn content summarization, Deepgram language detection | Graphlit Changelog</title></metadata>\\n<summary>\\n- New Features:\\n  - Support for web search via the searchWeb mutation, allowing selection of search service (Tavily or Exa.AI) and retrieval of relevant text and URLs.\\n  - Multi-turn content summarization with the reviseContent mutation, enabling conversation with LLM for content revision.\\n  - Configuration of Deepgram transcription language and default language detection enabled in DeepgramAudioPreparationPropertiesInput.\\n\\n- Enhancements/Improvements:\\n  - Added requireTool option to promptConversation mutation for controlling tool calling.\\n  - Reduced credits quota on Free tier from 1000 to 100 for accounts created after Nov 8, 2024; unlimited feeds now available on Hobby Tier.\\n  - Graphlit Data API now returns HTTP 402 (Payment Required) when exceeding free tier credits quota.\\n\\n- Bug Fixes:\\n  - No specific bug fixes mentioned.\\n\\n- Other Key Details:\\n  - Release Date: November 10, 2024.\\n\\n- Value:\\n  - Offers developers enhanced capabilities for web search and content summarization, improved control over tool usage, and clearer API usage guidelines.\\n</summary>\\n</source>\\n\\n\",\"<source>\\n<metadata type='Page'><name>https://changelog.graphlit.dev/september-2023/september-20-paid-subscription-plans-support-for-custom-observed-entities-and-azure-openai-gpt-4</name><title>September 20: Paid subscription plans; support for custom observed entities & Azure OpenAI GPT-4 | Graphlit Changelog</title></metadata>\\n<summary>\\n- New Features:\\n  - Introduction of paid Hobby, Starter, and Growth subscription tiers starting at $49/month, with usage fees of $0.10/credit.\\n  - GraphQL mutations for creating, updating, and deleting observed entities (Person, Organization, Place, Product, Event, Label, Category).\\n  - New observed entity types added: Repo (Git repo), Software.\\n  - Added searchType and numberSimilar fields to Specification object for enhanced semantic search.\\n  - Support for Azure OpenAI GPT-4 model.\\n  - Project quota field introduced, with limits based on subscription tier.\\n  - ContentLimit added to conversation strategy object for semantic search results.\\n  - Improved relevance ranking for semantic search results.\\n  - Updated Free tier quota: 1GB storage, 100 contents, 3 feeds, and 10 conversations.\\n  - Implementation of Deepgram Nova-2 audio transcription model, offering 18% more accuracy and 5-40x faster processing.\\n\\n- Enhancements/Improvements:\\n  - Better semantic search results with new configuration options.\\n  - Enhanced audio transcription accuracy and speed.\\n\\n- Bug Fixes:\\n  - Resolved issue with extracting multiple text pages from DOCX files using token-aware page chunking.\\n  - Fixed semantic search failure when no content results were available.\\n  - Addressed failure in generating text embeddings from user prompts.\\n\\n- Other Key Details:\\n  - Release Date: September 20, 2023.\\n\\n- Value:\\n  - Offers developers flexible subscription options, improved search capabilities, and enhanced audio processing, facilitating better project management and user experience.\\n</summary>\\n</source>\\n\\n\",\"<source>\\n<metadata type='Page'><name>https://changelog.graphlit.dev/january-2024/january-18-support-for-content-publishing-llm-tools-clip-image-embeddings-bug-fixes</name><title>January 18: Support for content publishing, LLM tools, CLIP image embeddings, bug fixes | Graphlit Changelog</title></metadata>\\n<summary>\\n- New Features:\\n  - Support for content publishing, allowing documents, audio transcripts, and image descriptions to be summarized and repurposed.\\n  - New mutation for publishing conversations as content, generating text or audio transcripts.\\n  - Bulk summarization of contents with the summarizeContents mutation.\\n  - LLM entity extraction using MODEL_TEXT service type, returning JSON-LD entities.\\n  - Support for LLM tools (function calls) with OpenAI models, including extractContents mutation.\\n  - Callback webhooks for LLM tools, enabling interaction with external services.\\n  - Selection of Deepgram models for audio transcription with custom API key.\\n  - CLIP image embeddings support for similar image search.\\n  - Dynamic web page ingestion with automatic scrolling and screenshot capabilities.\\n  - Table parsing for structured text extraction from documents.\\n  - Reverse geocoding of lat/long locations in content metadata.\\n  - Inclusion of assistant messages in conversation history for LLM prompts.\\n  - New chunking algorithm for semantic text embeddings.\\n  - Enhanced content metadata for text and image embeddings.\\n  - Helper mutations for polling content ingestion completion.\\n  - Richer image descriptions generated by GPT-4 Vision model.\\n  - Validation of extracted hyperlinks to remove inaccessible links.\\n  - Multi-deletion mutations for contents, feeds, and conversations.\\n  - Bulk deletion mutations for filtered subsets of entities.\\n  - Starter tier content limit increased to 100K items.\\n\\n- Enhancements/Improvements:\\n  - Renamed detailMode field to detailLevel in OpenAIImageExtractionProperties.\\n  - SummarizationStrategy objects now accept specifications directly.\\n  - Deprecated addCollectionContents and removeCollectionContents mutations in favor of new mutations.\\n\\n- Bug Fixes:\\n  - Fixed issues with parsing Markdown headings, returning SAS tokens, summarizing text content, and assigning error messages on workflow failures.\\n\\n- Other Key Details:\\n  - Release Date: January 18, 2024.\\n\\n- Value:\\n  - Offers developers enhanced content management capabilities, improved LLM interactions, and better data extraction and processing features.\\n</summary>\\n</source>\\n\\n\",\"<source>\\n<metadata type='Page'><name>https://changelog.graphlit.dev/july-2024/july-19-support-for-openai-gpt-4o-mini-byo-key-for-azure-ai-similarity-by-summary-bug-fixes</name><title>July 19: Support for OpenAI GPT-4o Mini, BYO-key for Azure AI, similarity by summary, bug fixes | Graphlit Changelog</title></metadata>\\n<summary>\\n- New Features:\\n  - Support for OpenAI GPT-4o Mini model with 16k output tokens.\\n  - 'Bring-your-own-key' support for Azure AI Document Intelligence models with custom endpoint and key property.\\n  - Updated to Jina reranker v2 by default.\\n  - Enhanced summarizeContents mutation to store summaries in content.\\n  - Added relevance property for entity types, sorting results by relevance score.\\n  - Ability to manually update summary and bullet properties in updateContent mutation.\\n  - Offset property added to AtlassianJiraFeedProperties for proper timezone assignment.\\n\\n- Enhancements/Improvements:\\n  - Content similarity search now finds similar content by summary for better accuracy.\\n  - Changed entity filter object behavior for paging; zero offset for vector/hybrid search.\\n\\n- Bug Fixes:\\n  - Added retry on OpenAI API HTTP 524 error.\\n  - Fixed paging issues with Jira feed.\\n  - Improved search results for similar content in long documents.\\n  - Resolved keyword search issues in long PDFs.\\n\\n- Other Key Details:\\n  - Release Date: July 19, 2024.\\n\\n- Value:\\n  - Offers developers improved model support, enhanced search capabilities, and better handling of content summaries and entity relevance.\\n</summary>\\n</source>\\n\\n\",\"<source>\\n<metadata type='Page'><name>https://changelog.graphlit.dev/february-2024/february-21-support-for-onedrive-and-google-drive-feeds-extract-images-from-pdfs-bug-fixes</name><title>February 21: Support for OneDrive and Google Drive feeds, extract images from PDFs, bug fixes | Graphlit Changelog</title></metadata>\\n<summary>\\n- New Features:\\n  - Support for OneDrive and Google Drive feeds, allowing ingestion of files from shared drives.\\n  - Support for email backup files (EML, MSG) with automatic extraction of attachments.\\n  - Automatic extraction of embedded images from PDF files, linking them as children of the parent PDF.\\n  - Support for recursive Notion feeds with the isRecursive flag for crawling child pages and databases.\\n  - Collections can now be assigned to ingested content automatically.\\n  - Introduction of CODE file type for various source code formats with optimized text splitting.\\n  - Custom guidance can be injected during the RAG process via the Specification object.\\n  - Added tenants field to Project object for listing tenant IDs.\\n  - Email metadata is now indexed separately from document metadata.\\n\\n- Enhancements/Improvements:\\n  - Contents field replaced with children and parent fields for content objects.\\n  - Removed enableImageAnalysis field; now enabled by default.\\n  - Moved disableSmartCapture field to preparation workflow stage, enabled by default.\\n\\n- Bug Fixes:\\n  - Fixed PDF parsing error for ArXiV PDFs (GPLA-2099).\\n  - Corrected LLM response issues with conversation history (GPLA-2174).\\n  - Resolved issue of ZIP package remaining in Indexed state after content workflow (GPLA-2199).\\n\\n- Other Key Details:\\n  - Release Date: February 21, 2024.\\n\\n- Value:\\n  - Enhancements improve file ingestion capabilities and metadata handling, streamlining workflows for developers.\\n</summary>\\n</source>\\n\\n\",\"<source>\\n<metadata type='Page'><name>https://changelog.graphlit.dev/december-2023/december-10-support-for-openai-gpt-4-turbo-llama-2-and-mistral-models-query-by-example-bug-fixes</name><title>December 10: Support for OpenAI GPT-4 Turbo, Llama 2 and Mistral models; query by example, bug fixes | Graphlit Changelog</title></metadata>\\n<summary>\\n- New Features:\\n  - Support for OpenAI GPT-4 Turbo 128k model in Azure OpenAI and native OpenAI services.\\n  - Support for Llama 2 (7b, 13b, 70b) and Mistral 7b models via Replicate.\\n  - Support for Anthropic Claude 2.1 model.\\n  - Support for OpenAI GPT-4 Vision model for image descriptions and text extraction.\\n  - Query by example added for contents and conversations, utilizing vector embeddings.\\n  - Vector search support for conversations queries.\\n  - New promptSpecifications mutation for prompting multiple models.\\n  - New promptStrategy field for preprocessing prompts.\\n  - SuggestConversation mutation for auto-suggesting follow-up questions.\\n  - New summarization types: CHAPTERS, QUESTIONS, and POSTS.\\n  - Versioned model enums introduced.\\n  - LookupContents query to retrieve multiple contents by ID.\\n\\n- Enhancements/Improvements:\\n  - Renamed headline field to headlines, returning an array of strings.\\n  - Entity names limited to 1024 characters.\\n  - BULLET_POINTS renamed to BULLETS in SummarizationTypes enum.\\n  - ProjectStorage type fields renamed for clarity.\\n  - Removed optimizeSearchConversation from Specification type, now handled by OPTIMIZE_SEARCH prompt strategy.\\n\\n- Bug Fixes:\\n  - Ignored RSS.xml from web feed sitemap.\\n  - Resolved issue with GPT-3.5 Turbo 16k LLM adding \\\"Citation #\\\" to responses.\\n  - Fixed workflow application to link-crawled content.\\n  - Corrected mismatched project storage total size.\\n  - Added relevance threshold for semantic search.\\n\\n- Other Key Details:\\n  - Release Date: December 10, 2023.\\n\\n- Value:\\n  - Offers developers enhanced model support, improved querying capabilities, and streamlined prompt management, facilitating more efficient and effective application development.\\n</summary>\\n</source>\\n\\n\",\"<source>\\n<metadata type='Page'><name>https://changelog.graphlit.dev/august-2024/august-8-support-for-llm-based-document-extraction-.net-sdk-bug-fixes</name><title>August 8: Support for LLM-based document extraction, .NET SDK, bug fixes | Graphlit Changelog</title></metadata>\\n<summary>\\n- New Features:\\n  - Support for LLM-based document preparation using models like OpenAI GPT-4o and Anthropic Sonnet 3.5 via MODEL_DOCUMENT service.\\n  - Introduction of an open source .NET SDK for .NET 6 and .NET 8, available on Nuget.org with code samples on GitHub.\\n  - Added identifier property to Content object for mapping to external database identifiers, aiding in content filtering.\\n  - Support for Claude 3 vision models for image-based entity extraction using MODEL_IMAGE service.\\n  - Context augmentation in conversations via augmentedFilter property, allowing injection of domain knowledge into LLM prompts.\\n  - Support for the latest snapshot of OpenAI GPT-4o (model enum GPT4O_128K_20240806).\\n  - Reranking of related entities for LLM prompt context preparation in GraphRAG.\\n\\n- Enhancements/Improvements:\\n  - Changed duration field type in AudioMetadata and VideoMetadata from string to TimeSpan for consistency in API data model.\\n\\n- Bug Fixes:\\n  - Fixed issue GPLA-2884 to support retry on HTTP 529 (Overloaded) error from Anthropic API.\\n\\n- Other Key Details:\\n  - Release Date: August 8, 2024.\\n\\n- Value:\\n  - Offers developers enhanced capabilities for document extraction, improved SDK support, and better content management features.\\n</summary>\\n</source>\\n\\n\",\"<source>\\n<metadata type='Page'><name>https://changelog.graphlit.dev/march-2024/march-23-support-for-linear-github-issues-and-jira-issue-feeds-ingest-files-via-web-feed-sitemap</name><title>March 23: Support for Linear, GitHub Issues and Jira issue feeds, ingest files via Web feed sitemap | Graphlit Changelog</title></metadata>\\n<summary>\\n- New Features:\\n  - Support for Linear, GitHub Issues, and Atlassian Jira feeds, allowing ingestion of issues as searchable content items.\\n  - Introduction of ISSUE content type with metadata including title, authors, commenters, status, type, project, and team.\\n  - Default feed read limit set to 100 content items, customizable with no upper bounds; one-shot feeds must complete within 15 minutes.\\n  - Support for ingesting files referenced in a Web sitemap, enabling non-HTML pages to be included.\\n\\n- Enhancements/Improvements:\\n  - Improved handling of files in Web sitemaps, allowing for ingestion of various file types.\\n\\n- Bug Fixes:\\n  - Fixed issue GPLA-2374 related to failing to ingest MP4 files with large XMP metadata.\\n\\n- Other Key Details:\\n  - Release Date: March 2024.\\n  \\n- Value:\\n  - Enhances developers' ability to integrate and manage issue tracking data, improving searchability and content management capabilities.\\n</summary>\\n</source>\\n\\n\",\"<source>\\n<metadata type='Page'><name>https://changelog.graphlit.dev/september-2023/september-24-support-for-youtube-feeds-added-documentation-bug-fixes</name><title>September 24: Support for YouTube feeds; added documentation; bug fixes | Graphlit Changelog</title></metadata>\\n<summary>\\n- New Features:\\n  - Support for YouTube feeds, allowing ingestion of YouTube videos, playlists, or channels (currently supports audio ingestion and transcription).\\n\\n- Enhancements/Improvements:\\n  - Added documentation for observable entities mutations and queries (Label, Category, Person, Organization, Place, Event, Product, Repo, Software).\\n  - Added documentation for using custom Azure OpenAI and OpenAI models with Specifications.\\n\\n- Bug Fixes:\\n  - Fixed LLM prompt formatting issue that exceeded token budget with long user prompts (GPLA-1459).\\n  - Resolved issue with ingesting PDF from URL when filename in Content-Disposition header contained a backslash (GPLA-1445).\\n\\n- Other Key Details:\\n  - Release Date: September 2023.\\n\\n- Value:\\n  - Enhances developers' ability to integrate YouTube content and improves documentation for better usage of observable entities and custom models.\\n</summary>\\n</source>\\n\\n\",\"<source>\\n<metadata type='Page'><name>https://changelog.graphlit.dev/october-2024/october-7-support-for-anthropic-and-gemini-tool-calling</name><title>October 7: Support for Anthropic and Gemini tool calling | Graphlit Changelog</title></metadata>\\n<summary>\\n- New Features:\\n  - Support for tool calling with Anthropic and Google Gemini models.\\n  - Removal of the uri property for tools from ToolDefinitionInput, eliminating support for inline webhook tools. External tools can now be defined for sync or async data access.\\n\\n- Enhancements/Improvements:\\n  - Improved flexibility in defining \n",
            "\n",
            "2024-12-30T04:03:09.006Z: Serverless compute\n",
            "- Workflow [Entity Event] took 0:00:03.501060, used credits [0.00630337]\n",
            "- CONTENT [2c79f064-350a-4c5c-8091-6ffbdb28ddc4]\n",
            "\n",
            "2024-12-30T04:03:08.754Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.573540, used credits [0.00674000]\n",
            "- CONTENT [2c79f064-350a-4c5c-8091-6ffbdb28ddc4]: Content type [TEXT], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [3370 tokens], throughput: 5875.788 tokens/sec\n",
            "\n",
            "2024-12-30T04:03:08.675Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.568606, used credits [0.00492200]\n",
            "- CONTENT [2c79f064-350a-4c5c-8091-6ffbdb28ddc4]: Content type [TEXT], file type [DOCUMENT]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [2461 tokens], throughput: 4328.126 tokens/sec\n",
            "\n",
            "2024-12-30T04:03:04.990Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:02:31.179882, used credits [14.09160000]\n",
            "- Model service [OpenAI], model name [O1_200k]\n",
            "- Prompt [16864 tokens (includes RAG context tokens)]:\n",
            "<source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/october-2024/october-3-support-tool-calling-ingestbatch-mutation-gemini-flash-1.5-8b-bug-fixes</name><title>October 3: Support tool calling, ingestBatch mutation, Gemini Flash 1.5 8b, bug fixes | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Support for ingestBatch mutation to asynchronously ingest an array of URIs into content objects.\n",
            "  - Support for continueConversation mutation, allowing responses from called tools to be sent back to the LLM.\n",
            "  - Tool calling support added for OpenAI, Mistral, Deepseek, Groq, and Cerebras model services; support for Anthropic, Google Gemini, and Cohere coming later.\n",
            "  - Prefilled user and assistant messages can now be sent with createConversation mutation.\n",
            "  - Added support for Google Gemini Flash 1.5 8b model.\n",
            "  - Deprecated tools property in the Specification object; tools must now be sent directly to extractContents and promptConversation mutations.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Improved conversation bootstrapping with prefilled messages.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issue where models were incorrectly required on update specification call (GPLA-3207).\n",
            "  - Resolved issue of sending system prompt with OpenAI o1 models (GPLA-3220).\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: October 2024.\n",
            "  - Version: Gemini Flash 1.5 8b.\n",
            "  - Breaking change: tools property in Specification object deprecated.\n",
            "\n",
            "- Value:\n",
            "  - Enhancements provide developers with more flexible and powerful tools for managing conversations and integrating various model services.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            " <source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/october-2023/october-15-support-for-anthropic-claude-models-slack-feeds-and-entity-enrichment</name><title>October 15: Support for Anthropic Claude models, Slack feeds and entity enrichment | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Support for Anthropic Claude and Anthropic Claude Instant large language models.\n",
            "  - Ingestion of Slack messages and linked file attachments from Slack channels (requires a Slack bot).\n",
            "  - Entity enrichment for observed entities (Person, Organization, Place) using Diffbot, Wikipedia, and Crunchbase.\n",
            "  - Text extraction from images using Azure Image Analytics, making identified text searchable.\n",
            "  - Added embedFacets and embedCitations properties to conversation strategy in specification object.\n",
            "  - GraphQL mutations for multi-delete of entities (deleteCollections, deleteLabels, deleteConversations).\n",
            "  - GraphQL deleteAllConversations mutation to delete all conversations.\n",
            "  - Automatic addition of ingested content to collections during the ingestion stage of the workflow.\n",
            "  - Specification property added to preparation workflow stage for selecting LLM for text summarization.\n",
            "  - Expanded properties for observed entities for enhanced entity enrichment.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Improved capabilities for entity enrichment and text extraction.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed unlimited conversation quota not assigned when upgrading project tier (GPLA-1520).\n",
            "  - Resolved issue with entity enrichment not firing events (GPLA-1285).\n",
            "  - Fixed web page remaining in ingested state when URL is not accessible (GPLA-1361).\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: October 15, 2023.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced support for LLMs, improved data ingestion from Slack, and advanced entity enrichment capabilities.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            " <source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/november-2024/november-10-support-for-web-search-multi-turn-content-summarization-deepgram-language-detection</name><title>November 10: Support for web search, multi-turn content summarization, Deepgram language detection | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Support for web search via the searchWeb mutation, allowing selection of search service (Tavily or Exa.AI) and retrieval of relevant text and URLs.\n",
            "  - Multi-turn content summarization with the reviseContent mutation, enabling conversation with LLM for content revision.\n",
            "  - Configuration of Deepgram transcription language and default language detection enabled in DeepgramAudioPreparationPropertiesInput.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Added requireTool option to promptConversation mutation for controlling tool calling.\n",
            "  - Reduced credits quota on Free tier from 1000 to 100 for accounts created after Nov 8, 2024; unlimited feeds now available on Hobby Tier.\n",
            "  - Graphlit Data API now returns HTTP 402 (Payment Required) when exceeding free tier credits quota.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - No specific bug fixes mentioned.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: November 10, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced capabilities for web search and content summarization, improved control over tool usage, and clearer API usage guidelines.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            " <source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/september-2023/september-20-paid-subscription-plans-support-for-custom-observed-entities-and-azure-openai-gpt-4</name><title>September 20: Paid subscription plans; support for custom observed entities & Azure OpenAI GPT-4 | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Introduction of paid Hobby, Starter, and Growth subscription tiers starting at $49/month, with usage fees of $0.10/credit.\n",
            "  - GraphQL mutations for creating, updating, and deleting observed entities (Person, Organization, Place, Product, Event, Label, Category).\n",
            "  - New observed entity types added: Repo (Git repo), Software.\n",
            "  - Added searchType and numberSimilar fields to Specification object for enhanced semantic search.\n",
            "  - Support for Azure OpenAI GPT-4 model.\n",
            "  - Project quota field introduced, with limits based on subscription tier.\n",
            "  - ContentLimit added to conversation strategy object for semantic search results.\n",
            "  - Improved relevance ranking for semantic search results.\n",
            "  - Updated Free tier quota: 1GB storage, 100 contents, 3 feeds, and 10 conversations.\n",
            "  - Implementation of Deepgram Nova-2 audio transcription model, offering 18% more accuracy and 5-40x faster processing.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Better semantic search results with new configuration options.\n",
            "  - Enhanced audio transcription accuracy and speed.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Resolved issue with extracting multiple text pages from DOCX files using token-aware page chunking.\n",
            "  - Fixed semantic search failure when no content results were available.\n",
            "  - Addressed failure in generating text embeddings from user prompts.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: September 20, 2023.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers flexible subscription options, improved search capabilities, and enhanced audio processing, facilitating better project management and user experience.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            " <source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/january-2024/january-18-support-for-content-publishing-llm-tools-clip-image-embeddings-bug-fixes</name><title>January 18: Support for content publishing, LLM tools, CLIP image embeddings, bug fixes | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Support for content publishing, allowing documents, audio transcripts, and image descriptions to be summarized and repurposed.\n",
            "  - New mutation for publishing conversations as content, generating text or audio transcripts.\n",
            "  - Bulk summarization of contents with the summarizeContents mutation.\n",
            "  - LLM entity extraction using MODEL_TEXT service type, returning JSON-LD entities.\n",
            "  - Support for LLM tools (function calls) with OpenAI models, including extractContents mutation.\n",
            "  - Callback webhooks for LLM tools, enabling interaction with external services.\n",
            "  - Selection of Deepgram models for audio transcription with custom API key.\n",
            "  - CLIP image embeddings support for similar image search.\n",
            "  - Dynamic web page ingestion with automatic scrolling and screenshot capabilities.\n",
            "  - Table parsing for structured text extraction from documents.\n",
            "  - Reverse geocoding of lat/long locations in content metadata.\n",
            "  - Inclusion of assistant messages in conversation history for LLM prompts.\n",
            "  - New chunking algorithm for semantic text embeddings.\n",
            "  - Enhanced content metadata for text and image embeddings.\n",
            "  - Helper mutations for polling content ingestion completion.\n",
            "  - Richer image descriptions generated by GPT-4 Vision model.\n",
            "  - Validation of extracted hyperlinks to remove inaccessible links.\n",
            "  - Multi-deletion mutations for contents, feeds, and conversations.\n",
            "  - Bulk deletion mutations for filtered subsets of entities.\n",
            "  - Starter tier content limit increased to 100K items.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Renamed detailMode field to detailLevel in OpenAIImageExtractionProperties.\n",
            "  - SummarizationStrategy objects now accept specifications directly.\n",
            "  - Deprecated addCollectionContents and removeCollectionContents mutations in favor of new mutations.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issues with parsing Markdown headings, returning SAS tokens, summarizing text content, and assigning error messages on workflow failures.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: January 18, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced content management capabilities, improved LLM interactions, and better data extraction and processing features.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            " <source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/july-2024/july-19-support-for-openai-gpt-4o-mini-byo-key-for-azure-ai-similarity-by-summary-bug-fixes</name><title>July 19: Support for OpenAI GPT-4o Mini, BYO-key for Azure AI, similarity by summary, bug fixes | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Support for OpenAI GPT-4o Mini model with 16k output tokens.\n",
            "  - 'Bring-your-own-key' support for Azure AI Document Intelligence models with custom endpoint and key property.\n",
            "  - Updated to Jina reranker v2 by default.\n",
            "  - Enhanced summarizeContents mutation to store summaries in content.\n",
            "  - Added relevance property for entity types, sorting results by relevance score.\n",
            "  - Ability to manually update summary and bullet properties in updateContent mutation.\n",
            "  - Offset property added to AtlassianJiraFeedProperties for proper timezone assignment.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Content similarity search now finds similar content by summary for better accuracy.\n",
            "  - Changed entity filter object behavior for paging; zero offset for vector/hybrid search.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Added retry on OpenAI API HTTP 524 error.\n",
            "  - Fixed paging issues with Jira feed.\n",
            "  - Improved search results for similar content in long documents.\n",
            "  - Resolved keyword search issues in long PDFs.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: July 19, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers improved model support, enhanced search capabilities, and better handling of content summaries and entity relevance.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            " <source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/february-2024/february-21-support-for-onedrive-and-google-drive-feeds-extract-images-from-pdfs-bug-fixes</name><title>February 21: Support for OneDrive and Google Drive feeds, extract images from PDFs, bug fixes | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Support for OneDrive and Google Drive feeds, allowing ingestion of files from shared drives.\n",
            "  - Support for email backup files (EML, MSG) with automatic extraction of attachments.\n",
            "  - Automatic extraction of embedded images from PDF files, linking them as children of the parent PDF.\n",
            "  - Support for recursive Notion feeds with the isRecursive flag for crawling child pages and databases.\n",
            "  - Collections can now be assigned to ingested content automatically.\n",
            "  - Introduction of CODE file type for various source code formats with optimized text splitting.\n",
            "  - Custom guidance can be injected during the RAG process via the Specification object.\n",
            "  - Added tenants field to Project object for listing tenant IDs.\n",
            "  - Email metadata is now indexed separately from document metadata.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Contents field replaced with children and parent fields for content objects.\n",
            "  - Removed enableImageAnalysis field; now enabled by default.\n",
            "  - Moved disableSmartCapture field to preparation workflow stage, enabled by default.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed PDF parsing error for ArXiV PDFs (GPLA-2099).\n",
            "  - Corrected LLM response issues with conversation history (GPLA-2174).\n",
            "  - Resolved issue of ZIP package remaining in Indexed state after content workflow (GPLA-2199).\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: February 21, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Enhancements improve file ingestion capabilities and metadata handling, streamlining workflows for developers.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            " <source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/december-2023/december-10-support-for-openai-gpt-4-turbo-llama-2-and-mistral-models-query-by-example-bug-fixes</name><title>December 10: Support for OpenAI GPT-4 Turbo, Llama 2 and Mistral models; query by example, bug fixes | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Support for OpenAI GPT-4 Turbo 128k model in Azure OpenAI and native OpenAI services.\n",
            "  - Support for Llama 2 (7b, 13b, 70b) and Mistral 7b models via Replicate.\n",
            "  - Support for Anthropic Claude 2.1 model.\n",
            "  - Support for OpenAI GPT-4 Vision model for image descriptions and text extraction.\n",
            "  - Query by example added for contents and conversations, utilizing vector embeddings.\n",
            "  - Vector search support for conversations queries.\n",
            "  - New promptSpecifications mutation for prompting multiple models.\n",
            "  - New promptStrategy field for preprocessing prompts.\n",
            "  - SuggestConversation mutation for auto-suggesting follow-up questions.\n",
            "  - New summarization types: CHAPTERS, QUESTIONS, and POSTS.\n",
            "  - Versioned model enums introduced.\n",
            "  - LookupContents query to retrieve multiple contents by ID.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Renamed headline field to headlines, returning an array of strings.\n",
            "  - Entity names limited to 1024 characters.\n",
            "  - BULLET_POINTS renamed to BULLETS in SummarizationTypes enum.\n",
            "  - ProjectStorage type fields renamed for clarity.\n",
            "  - Removed optimizeSearchConversation from Specification type, now handled by OPTIMIZE_SEARCH prompt strategy.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Ignored RSS.xml from web feed sitemap.\n",
            "  - Resolved issue with GPT-3.5 Turbo 16k LLM adding \"Citation #\" to responses.\n",
            "  - Fixed workflow application to link-crawled content.\n",
            "  - Corrected mismatched project storage total size.\n",
            "  - Added relevance threshold for semantic search.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: December 10, 2023.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced model support, improved querying capabilities, and streamlined prompt management, facilitating more efficient and effective application development.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            " <source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/august-2024/august-8-support-for-llm-based-document-extraction-.net-sdk-bug-fixes</name><title>August 8: Support for LLM-based document extraction, .NET SDK, bug fixes | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Support for LLM-based document preparation using models like OpenAI GPT-4o and Anthropic Sonnet 3.5 via MODEL_DOCUMENT service.\n",
            "  - Introduction of an open source .NET SDK for .NET 6 and .NET 8, available on Nuget.org with code samples on GitHub.\n",
            "  - Added identifier property to Content object for mapping to external database identifiers, aiding in content filtering.\n",
            "  - Support for Claude 3 vision models for image-based entity extraction using MODEL_IMAGE service.\n",
            "  - Context augmentation in conversations via augmentedFilter property, allowing injection of domain knowledge into LLM prompts.\n",
            "  - Support for the latest snapshot of OpenAI GPT-4o (model enum GPT4O_128K_20240806).\n",
            "  - Reranking of related entities for LLM prompt context preparation in GraphRAG.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Changed duration field type in AudioMetadata and VideoMetadata from string to TimeSpan for consistency in API data model.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issue GPLA-2884 to support retry on HTTP 529 (Overloaded) error from Anthropic API.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: August 8, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced capabilities for document extraction, improved SDK support, and better content management features.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            " <source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/march-2024/march-23-support-for-linear-github-issues-and-jira-issue-feeds-ingest-files-via-web-feed-sitemap</name><title>March 23: Support for Linear, GitHub Issues and Jira issue feeds, ingest files via Web feed sitemap | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Support for Linear, GitHub Issues, and Atlassian Jira feeds, allowing ingestion of issues as searchable content items.\n",
            "  - Introduction of ISSUE content type with metadata including title, authors, commenters, status, type, project, and team.\n",
            "  - Default feed read limit set to 100 content items, customizable with no upper bounds; one-shot feeds must complete within 15 minutes.\n",
            "  - Support for ingesting files referenced in a Web sitemap, enabling non-HTML pages to be included.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Improved handling of files in Web sitemaps, allowing for ingestion of various file types.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issue GPLA-2374 related to failing to ingest MP4 files with large XMP metadata.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: March 2024.\n",
            "  \n",
            "- Value:\n",
            "  - Enhances developers' ability to integrate and manage issue tracking data, improving searchability and content management capabilities.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            " <source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/september-2023/september-24-support-for-youtube-feeds-added-documentation-bug-fixes</name><title>September 24: Support for YouTube feeds; added documentation; bug fixes | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Support for YouTube feeds, allowing ingestion of YouTube videos, playlists, or channels (currently supports audio ingestion and transcription).\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Added documentation for observable entities mutations and queries (Label, Category, Person, Organization, Place, Event, Product, Repo, Software).\n",
            "  - Added documentation for using custom Azure OpenAI and OpenAI models with Specifications.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed LLM prompt formatting issue that exceeded token budget with long user prompts (GPLA-1459).\n",
            "  - Resolved issue with ingesting PDF from URL when filename in Content-Disposition header contained a backslash (GPLA-1445).\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: September 2023.\n",
            "\n",
            "- Value:\n",
            "  - Enhances developers' ability to integrate YouTube content and improves documentation for better usage of observable entities and custom models.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            " <source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/october-2024/october-7-support-for-anthropic-and-gemini-tool-calling</name><title>October 7: Support for Anthropic and Gemini tool calling | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Support for tool calling with Anthropic and Google Gemini models.\n",
            "  - Removal of the uri property for tools from ToolDefinitionInput, eliminating support for inline webhook tools. External tools can now be defined for sync or async data access.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Improved flexibility in defining external tools for tool calls.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - No specific bug fixes mentioned.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: October 7, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced capabilities for integrating external tools and improved data access options.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            " <source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/september-2023/september-4-workflow-configuration-support-for-notion-feeds-document-ocr</name><title>September 4: Workflow configuration; support for Notion feeds; document OCR | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Added Workflow entity for configuring content workflow stages.\n",
            "  - Support for Notion feeds to ingest files from Notion pages or databases.\n",
            "  - API-created Observation entities for custom observations on Content.\n",
            "  - Support for Azure AI Document Intelligence for PDF preparation using OCR.\n",
            "  - Summarization strategies for content (paragraphs, bullet points, headlines).\n",
            "  - Ability to assign default Workflow and Specification to projects.\n",
            "  - Added support for more link types during link crawling (Discord, Airtable, TypeForm).\n",
            "  - Free/Hobby plan now includes a 5GB storage quota.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Actions moved into Workflow entity.\n",
            "  - Link enrichment for Feeds moved to Workflow enrichment stage, renamed to link crawling.\n",
            "  - ExcludeContentDomain property renamed to IncludeContentDomain.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issue with content ingestion failure due to backslash in name.\n",
            "  - Resolved failure to ingest RSS posts with enclosure URI but no post URI.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: September 4, 2023.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced workflow configuration, improved content ingestion from Notion, and advanced document processing capabilities.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            " <source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/september-2024/september-1-support-for-fhir-enrichment-latest-cohere-models-bug-fixes</name><title>September 1: Support for FHIR enrichment, latest Cohere models, bug fixes | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Support for entity enrichment from FHIR servers for medical-related entities.\n",
            "  - Added support for latest Cohere models (COMMAND_R_202408, COMMAND_R_PLUS_202408) with datestamped model enums for previous versions.\n",
            "  - Support for the latest Azure AI Document Intelligence v4.0 preview API (2024-07-31) now used by default.\n",
            "  - Renamed LinkReferenceType to LinkReference to align with data model standards.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Updated naming conventions for consistency with existing standards.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issue where LLM added source tags to the end of completed messages (GPLA-3120).\n",
            "  - Resolved failure to load sitemap on child page of website (GPLA-3133).\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: September 1, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Enhancements improve integration with healthcare data and AI models, providing developers with more robust tools for medical entity enrichment and document intelligence.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            " <source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/november-2024/november-16-support-for-image-description-multi-turn-text-summarization</name><title>November 16: Support for image description, multi-turn text summarization | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Multi-turn summarization of text with the reviseText mutation, allowing for LLM prompts and text revisions.\n",
            "  - Image descriptions supported via describeImage mutation (URI input) and describeEncodedImage mutation (Base-64 encoded image), utilizing vision LLMs.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Optional specifications for selecting vision LLMs; defaults to OpenAI GPT-4o if not provided.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - No specific bug fixes mentioned in this release.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: November 16, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced capabilities for text summarization and image description without prior image ingestion, improving interaction with LLMs.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            " <source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/september-2024/september-30-support-for-azure-ai-inference-models-mistral-pixtral-and-latest-google-gemini-models</name><title>September 30: Support for Azure AI Inference models, Mistral Pixtral and latest Google Gemini models | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Support for Azure AI Model Inference API, enabling serverless hosting for models like Meta Llama 3.2 and Cohere Command-R.\n",
            "  - Added support for the multimodal Mistral Pixtral model (PIXTRAL_12B_2409).\n",
            "  - Introduced versioned model enums for Google Gemini: GEMINI_1_5_FLASH_001, GEMINI_1_5_FLASH_002, GEMINI_1_5_PRO_001, GEMINI_1_5_PRO_002.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Enhanced model accessibility through versioned enums for Google Gemini.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - No specific bug fixes mentioned in this release.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: September 30, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers expanded model support and flexibility with serverless hosting options.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            " <source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/april-2024/april-23-support-for-python-and-typescript-sdks-latest-openai-cohere-and-groq-models-bug-fixes</name><title>April 23: Support for Python and TypeScript SDKs, latest OpenAI, Cohere & Groq models, bug fixes | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Native Python SDK introduced, using Pydantic types; code-generated from GraphQL schema, no GraphQL knowledge required.\n",
            "  - Native Node.js SDK introduced, using TypeScript types; code-generated from GraphQL schema, no GraphQL knowledge required.\n",
            "  - Support for OpenAI's 2024-04-09 models, including GPT4_TURBO-128K.\n",
            "  - Support for Groq models: LLaMA3 70b, LLaMA3 8b, and Gemma 7b.\n",
            "  - Support for Command R and Command-R+ models in Cohere model service.\n",
            "  - Added support for Jina reranking with the JINA reranking model service type.\n",
            "  - Updated Cohere reranking model to v3.0.\n",
            "  - Improved reliability of parsing LLM responses that don't follow JSON schema.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Cleaned up nullability of GraphQL parameters for better clarity on required, optional, or nullable parameters.\n",
            "  - Added missing deleteWorkflows and deleteAllCollections mutations.\n",
            "  - Split reranking model service type into RetrievalModelServiceTypes enum.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issue with content not syncing to search index (GPLA-2114).\n",
            "  - Resolved rendering issues with conversation sources and section retrieval (GPLA-2511).\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: April 2024.\n",
            "  \n",
            "- Value:\n",
            "  - Offers developers enhanced SDK support, improved model integration, and better error handling, facilitating easier development and deployment of applications.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            " <source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/april-2024/april-7-support-for-discord-feeds-cohere-reranking-section-aware-chunking-and-retrieval</name><title>April 7: Support for Discord feeds, Cohere reranking, section-aware chunking and retrieval | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Support for Discord feeds: Ingest messages and file attachments from a Discord channel using a bot token.\n",
            "  - Cohere reranking: Optionally rerank semantic search results in the RAG pipeline using the Cohere model.\n",
            "  - Section-aware text chunking and retrieval: Store extracted text according to semantic chunks for improved indexing.\n",
            "  - Retrieval strategies: Support for CHUNK, SECTION, and CONTENT retrieval strategies.\n",
            "  - Reranking strategy: Configure reranking of content sources using the Cohere model.\n",
            "  - Synchronous content ingestion: Added isSynchronous flag for content ingestion mutations.\n",
            "  - Slack attachments: Enable automatic ingestion of attachments in Slack messages.\n",
            "  - IngestUri mutation: Replaces deprecated ingestPage and ingestFile mutations for simplified content ingestion.\n",
            "  \n",
            "- Enhancements/Improvements:\n",
            "  - Removed includeSummaries from ConversationStrategyInput; will be re-added later.\n",
            "  - Deprecated enableExpandedRetrieval; now managed by strategyType in RetrievalStrategyInput.\n",
            "  - Moved contentLimit to RetrievalStrategyInput for better content source management.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issues with PDF ingestion from GitHub.\n",
            "  - Resolved JSON schema adherence for Claude 3 Haiku.\n",
            "  - Prompt rewriting now ignores formatting instructions.\n",
            "  - Corrected line breaks after table rows.\n",
            "  - Fixed image extraction from PPTX files.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: April 2024.\n",
            "  - Version updates include new flags and strategies for improved functionality.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced capabilities for content ingestion, retrieval, and processing, improving integration with various platforms and models.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            " <source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/december-2024/december-1-support-for-retrieval-only-rag-pipeline-bug-fixes</name><title>December 1: Support for retrieval-only RAG pipeline, bug fixes | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Support for formatting LLM-ready prompts with RAG pipeline using formatConversation and completeConversation mutations.\n",
            "  - Inline hyperlinks support in extracted text from documents and web pages.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Improved LLM streaming capabilities by allowing direct calls from applications.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issue where Owner ID should accept any non-whitespace string (GPLA-3466).\n",
            "  - Resolved problem with missing Person-to-Organization edges from entity extraction (GPLA-3458).\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: December 1, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Enhances developer experience by improving prompt formatting and text extraction capabilities, facilitating better integration with LLMs.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            " <source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/december-2024/december-9-support-for-website-mapping-web-page-screenshots-groq-llama-3.3-model-bug-fixes</name><title>December 9: Support for website mapping, web page screenshots, Groq Llama 3.3 model, bug fixes | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Support for website mapping using mapWebmutation to return URLs from sitemap.xml.\n",
            "  - Generation of web page screenshots with screenshotPagemutation, including optional workflows for image processing.\n",
            "  - Direct summarization of text with summarizeTextmutation, allowing various summarization strategies.\n",
            "  - Direct extraction of text with extractTextmutation, utilizing LLM tools for JSON responses.\n",
            "  - Support for Groq Llama 3.3 model (LLAMA_3_3_70B).\n",
            "  - Updated Cohere reranking to use rerank-v3.5 model by default.\n",
            "  - New flattenCitations field in ConversationStrategyInput to combine multiple citations.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Required clientId and clientSecret fields added for Microsoft email, Teams, and OneDrive feeds for proper authentication.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issue with not finding sitemap at parent web path (GPLA-3492).\n",
            "  - Resolved mismatch handling of Deepgram model/language (GPLA-3500).\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: December 9, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced capabilities for web mapping, content ingestion, and improved integration with Microsoft services.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            " <source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/august-2024/august-11-support-for-azure-ai-document-intelligence-by-default-language-aware-summaries</name><title>August 11: Support for Azure AI Document Intelligence by default, language-aware summaries | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Support for language-aware summaries in LLM-based document extraction, aligning summaries with the source text language.\n",
            "  - Support for language-aware entity descriptions in LLM-based entity extraction, matching descriptions to the source text language.\n",
            "  - Default document preparation method changed to Azure AI Document Intelligence for improved fidelity in complex PDFs and better table extraction.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Increased credit usage per page for PDF, DOCX, and PPTX documents due to the switch to Azure AI Document Intelligence, but with significantly higher quality in extracted documents for RAG pipelines.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issue GPLA-3070 where slide count was not assigned to metadata for PPTX files.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: August 11, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced document extraction capabilities with improved accuracy and language support, facilitating better integration in applications.\n",
            "</summary>\n",
            "</source>\n",
            "\n",
            " <source>\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/august-2023/august-9-support-direct-text-markdown-and-html-ingestion-new-specification-llm-strategy</name><title>August 9: Support direct text, Markdown and HTML ingestion; new Specification LLM strategy | Graphlit Changelog</title></metadata>\n",
            "<summary>\n",
            "- New Features:\n",
            "  - Added ingestText mutation for direct ingestion of plain text, Markdown, and HTML without URL reading.\n",
            "  - Introduced Specification strategy property for cust\n",
            "- Completion [7527 tokens (includes JSON guardrails tokens)], throughput: 49.788 tokens/sec:\n",
            "digraph Timeline {\n",
            "    rankdir=TB;\n",
            "    graph [bgcolor=\"#FFFFFF\", fontname=\"Inter\"];\n",
            "    node  [shape=rect, style=filled, fontname=\"Inter\", fontcolor=\"#333333\", width=1.2, height=1.2];\n",
            "    edge  [color=\"#777777\", arrowhead=normal, arrowsize=0.6, fontsize=10];\n",
            "\n",
            "    // Root node for the year\n",
            "    \"2024\" [fillcolor=\"#FFD700\"];\n",
            "\n",
            "    // Q1 Subgraph\n",
            "    subgraph cluster_Q1 {\n",
            "        label=\"Q1\";\n",
            "        style=\"filled\";\n",
            "        color=\"#F0F0F0\";\n",
            "\n",
            "        // Month nodes\n",
            "        \"January\" [fillcolor=\"#FFECB3\"];\n",
            "        \"February\" [fillcolor=\"#FFECB3\"];\n",
            "        \"March\" [fillcolor=\"#FFECB3\"];\n",
            "\n",
            "        // Connections between months\n",
            "        \"January\" -> \"February\";\n",
            "        \"February\" -> \"March\";\n",
            "\n",
            "        // January releases\n",
            "        subgraph cluster_January {\n",
            "            style=\"invis\";\n",
            "            \"Release_Jan_18\" [label=\"Content publishing, LLM tools, CLIP embeddings\", fillcolor=\"#CCE5FF\"];\n",
            "            \"Release_Jan_22\" [label=\"Google/Microsoft email feeds, reingest content\", fillcolor=\"#CCE5FF\"];\n",
            "\n",
            "            \"January\" -> \"Release_Jan_18\" [label=\"Jan 18\"];\n",
            "            \"January\" -> \"Release_Jan_22\" [label=\"Jan 22\"];\n",
            "        }\n",
            "\n",
            "        // February releases\n",
            "        subgraph cluster_February {\n",
            "            style=\"invis\";\n",
            "            \"Release_Feb_2\" [label=\"Semantic Alerts, OpenAI 0125 models\", fillcolor=\"#CCE5FF\"];\n",
            "            \"Release_Feb_21\" [label=\"OneDrive/Google Drive feeds, PDF image extraction\", fillcolor=\"#CCE5FF\"];\n",
            "\n",
            "            \"February\" -> \"Release_Feb_2\" [label=\"Feb 2\"];\n",
            "            \"February\" -> \"Release_Feb_21\" [label=\"Feb 21\"];\n",
            "        }\n",
            "\n",
            "        // March releases\n",
            "        subgraph cluster_March {\n",
            "            style=\"invis\";\n",
            "            \"Release_Mar_10\" [label=\"Claude 3, Mistral, Groq, usage telemetry\", fillcolor=\"#CCE5FF\"];\n",
            "            \"Release_Mar_13\" [label=\"Claude 3 Haiku model, Base64 ingestion\", fillcolor=\"#CCE5FF\"];\n",
            "            \"Release_Mar_23\" [label=\"Linear/GitHub/Jira feeds, ingest via sitemaps\", fillcolor=\"#CCE5FF\"];\n",
            "\n",
            "            \"March\" -> \"Release_Mar_10\" [label=\"Mar 10\"];\n",
            "            \"March\" -> \"Release_Mar_13\" [label=\"Mar 13\"];\n",
            "            \"March\" -> \"Release_Mar_23\" [label=\"Mar 23\"];\n",
            "        }\n",
            "    }\n",
            "\n",
            "    // Q2 Subgraph\n",
            "    subgraph cluster_Q2 {\n",
            "        label=\"Q2\";\n",
            "        style=\"filled\";\n",
            "        color=\"#F0F0F0\";\n",
            "\n",
            "        // Month nodes\n",
            "        \"April\" [fillcolor=\"#FFECB3\"];\n",
            "        \"May\" [fillcolor=\"#FFECB3\"];\n",
            "        \"June\" [fillcolor=\"#FFECB3\"];\n",
            "\n",
            "        // Connections between months\n",
            "        \"April\" -> \"May\";\n",
            "        \"May\" -> \"June\";\n",
            "\n",
            "        // April releases\n",
            "        subgraph cluster_April {\n",
            "            style=\"invis\";\n",
            "            \"Release_Apr_7\"  [label=\"Discord feeds, Cohere reranking, chunk retrieval\", fillcolor=\"#CCE5FF\"];\n",
            "            \"Release_Apr_23\" [label=\"Python/TS SDKs, new OpenAI/Cohere/Groq\", fillcolor=\"#CCE5FF\"];\n",
            "\n",
            "            \"April\" -> \"Release_Apr_7\"  [label=\"Apr 7\"];\n",
            "            \"April\" -> \"Release_Apr_23\" [label=\"Apr 23\"];\n",
            "        }\n",
            "\n",
            "        // May releases\n",
            "        subgraph cluster_May {\n",
            "            style=\"invis\";\n",
            "            \"Release_May_5\"  [label=\"Jina/Pongo rerankers, MS Teams feed, YouTube\", fillcolor=\"#CCE5FF\"];\n",
            "            \"Release_May_15\" [label=\"GraphRAG, GPT-4o model, performance\", fillcolor=\"#CCE5FF\"];\n",
            "\n",
            "            \"May\" -> \"Release_May_5\"  [label=\"May 5\"];\n",
            "            \"May\" -> \"Release_May_15\" [label=\"May 15\"];\n",
            "        }\n",
            "\n",
            "        // June releases\n",
            "        subgraph cluster_June {\n",
            "            style=\"invis\";\n",
            "            \"Release_Jun_9\"  [label=\"Deepseek models, JSON-LD parsing, KGraph\", fillcolor=\"#CCE5FF\"];\n",
            "            \"Release_Jun_21\" [label=\"Claude 3.5 Sonnet, knowledge graph search\", fillcolor=\"#CCE5FF\"];\n",
            "\n",
            "            \"June\" -> \"Release_Jun_9\"  [label=\"Jun 9\"];\n",
            "            \"June\" -> \"Release_Jun_21\" [label=\"Jun 21\"];\n",
            "        }\n",
            "    }\n",
            "\n",
            "    // Q3 Subgraph\n",
            "    subgraph cluster_Q3 {\n",
            "        label=\"Q3\";\n",
            "        style=\"filled\";\n",
            "        color=\"#F0F0F0\";\n",
            "\n",
            "        // Month nodes\n",
            "        \"July\" [fillcolor=\"#FFECB3\"];\n",
            "        \"August\" [fillcolor=\"#FFECB3\"];\n",
            "        \"September\" [fillcolor=\"#FFECB3\"];\n",
            "\n",
            "        // Connections between months\n",
            "        \"July\" -> \"August\";\n",
            "        \"August\" -> \"September\";\n",
            "\n",
            "        // July releases\n",
            "        subgraph cluster_July {\n",
            "            style=\"invis\";\n",
            "            \"Release_Jul_4\"  [label=\"Webhook Alerts, Deepseek 128k context\", fillcolor=\"#CCE5FF\"];\n",
            "            \"Release_Jul_19\" [label=\"GPT-4o Mini, BYO-key Azure AI\", fillcolor=\"#CCE5FF\"];\n",
            "            \"Release_Jul_25\" [label=\"Mistral Large 2/Nemo, Groq Llama 3.1\", fillcolor=\"#CCE5FF\"];\n",
            "            \"Release_Jul_28\" [label=\"Indexing stage, Azure language detection\", fillcolor=\"#CCE5FF\"];\n",
            "\n",
            "            \"July\" -> \"Release_Jul_4\"  [label=\"Jul 4\"];\n",
            "            \"July\" -> \"Release_Jul_19\" [label=\"Jul 19\"];\n",
            "            \"July\" -> \"Release_Jul_25\" [label=\"Jul 25\"];\n",
            "            \"July\" -> \"Release_Jul_28\" [label=\"Jul 28\"];\n",
            "        }\n",
            "\n",
            "        // August releases\n",
            "        subgraph cluster_August {\n",
            "            style=\"invis\";\n",
            "            \"Release_Aug_8\"   [label=\"LLM doc extraction, .NET SDK\", fillcolor=\"#CCE5FF\"];\n",
            "            \"Release_Aug_11\"  [label=\"Azure AI default, language-aware summaries\", fillcolor=\"#CCE5FF\"];\n",
            "            \"Release_Aug_20\"  [label=\"Medical entities, Anthropic prompt caching\", fillcolor=\"#CCE5FF\"];\n",
            "\n",
            "            \"August\" -> \"Release_Aug_8\"  [label=\"Aug 8\"];\n",
            "            \"August\" -> \"Release_Aug_11\" [label=\"Aug 11\"];\n",
            "            \"August\" -> \"Release_Aug_20\" [label=\"Aug 20\"];\n",
            "        }\n",
            "\n",
            "        // September releases\n",
            "        subgraph cluster_September {\n",
            "            style=\"invis\";\n",
            "            \"Release_Sep_1\"   [label=\"FHIR enrichment, latest Cohere\", fillcolor=\"#CCE5FF\"];\n",
            "            \"Release_Sep_3\"   [label=\"Web search feeds, model deprecations\", fillcolor=\"#CCE5FF\"];\n",
            "            \"Release_Sep_26\"  [label=\"Google AI, Cerebras, latest Groq\", fillcolor=\"#CCE5FF\"];\n",
            "            \"Release_Sep_30\"  [label=\"Azure AI Inference, Mistral Pixtral, Gemini\", fillcolor=\"#CCE5FF\"];\n",
            "\n",
            "            \"September\" -> \"Release_Sep_1\"  [label=\"Sep 1\"];\n",
            "            \"September\" -> \"Release_Sep_3\"  [label=\"Sep 3\"];\n",
            "            \"September\" -> \"Release_Sep_26\" [label=\"Sep 26\"];\n",
            "            \"September\" -> \"Release_Sep_30\" [label=\"Sep 30\"];\n",
            "        }\n",
            "    }\n",
            "\n",
            "    // Q4 Subgraph\n",
            "    subgraph cluster_Q4 {\n",
            "        label=\"Q4\";\n",
            "        style=\"filled\";\n",
            "        color=\"#F0F0F0\";\n",
            "\n",
            "        // Month nodes\n",
            "        \"October\" [fillcolor=\"#FFECB3\"];\n",
            "        \"November\" [fillcolor=\"#FFECB3\"];\n",
            "        \"December\" [fillcolor=\"#FFECB3\"];\n",
            "\n",
            "        // Connections between months\n",
            "        \"October\" -> \"November\";\n",
            "        \"November\" -> \"December\";\n",
            "\n",
            "        // October releases\n",
            "        subgraph cluster_October {\n",
            "            style=\"invis\";\n",
            "            \"Release_Oct_3\"  [label=\"Tool calling, ingestBatch, Gemini Flash 1.5\", fillcolor=\"#CCE5FF\"];\n",
            "            \"Release_Oct_7\"  [label=\"Anthropic & Gemini tool calling\", fillcolor=\"#CCE5FF\"];\n",
            "            \"Release_Oct_9\"  [label=\"GitHub repo feeds\", fillcolor=\"#CCE5FF\"];\n",
            "            \"Release_Oct_21\" [label=\"OpenAI/Cohere/Jina/Mistral/Voyage embeddings\", fillcolor=\"#CCE5FF\"];\n",
            "            \"Release_Oct_22\" [label=\"Anthropic Sonnet 3.5, Cohere image embeddings\", fillcolor=\"#CCE5FF\"];\n",
            "            \"Release_Oct_31\" [label=\"Simulated tool calling\", fillcolor=\"#CCE5FF\"];\n",
            "\n",
            "            \"October\" -> \"Release_Oct_3\"  [label=\"Oct 3\"];\n",
            "            \"October\" -> \"Release_Oct_7\"  [label=\"Oct 7\"];\n",
            "            \"October\" -> \"Release_Oct_9\"  [label=\"Oct 9\"];\n",
            "            \"October\" -> \"Release_Oct_21\" [label=\"Oct 21\"];\n",
            "            \"October\" -> \"Release_Oct_22\" [label=\"Oct 22\"];\n",
            "            \"October\" -> \"Release_Oct_31\" [label=\"Oct 31\"];\n",
            "        }\n",
            "\n",
            "        // November releases\n",
            "        subgraph cluster_November {\n",
            "            style=\"invis\";\n",
            "            \"Release_Nov_4\"  [label=\"Claude 3.5 Haiku\", fillcolor=\"#CCE5FF\"];\n",
            "            \"Release_Nov_10\" [label=\"Web search, multi-turn summarization\", fillcolor=\"#CCE5FF\"];\n",
            "            \"Release_Nov_16\" [label=\"Image description, multi-turn text summary\", fillcolor=\"#CCE5FF\"];\n",
            "            \"Release_Nov_24\" [label=\"Direct LLM prompt, multi-turn image analysis\", fillcolor=\"#CCE5FF\"];\n",
            "\n",
            "            \"November\" -> \"Release_Nov_4\"  [label=\"Nov 4\"];\n",
            "            \"November\" -> \"Release_Nov_10\" [label=\"Nov 10\"];\n",
            "            \"November\" -> \"Release_Nov_16\" [label=\"Nov 16\"];\n",
            "            \"November\" -> \"Release_Nov_24\" [label=\"Nov 24\"];\n",
            "        }\n",
            "\n",
            "        // December releases\n",
            "        subgraph cluster_December {\n",
            "            style=\"invis\";\n",
            "            \"Release_Dec_1\"  [label=\"Retrieval-only RAG pipeline\", fillcolor=\"#CCE5FF\"];\n",
            "            \"Release_Dec_9\"  [label=\"Website mapping, screenshots, Groq Llama 3.3\", fillcolor=\"#CCE5FF\"];\n",
            "            \"Release_Dec_22\" [label=\"Dropbox/Box/Intercom/Zendesk feeds, OpenAI o1, Gemini 2.0\", fillcolor=\"#CCE5FF\"];\n",
            "            \"Release_Dec_27\" [label=\"LLM fallbacks, ingest Google Docs\", fillcolor=\"#CCE5FF\"];\n",
            "\n",
            "            \"December\" -> \"Release_Dec_1\"  [label=\"Dec 1\"];\n",
            "            \"December\" -> \"Release_Dec_9\"  [label=\"Dec 9\"];\n",
            "            \"December\" -> \"Release_Dec_22\" [label=\"Dec 22\"];\n",
            "            \"December\" -> \"Release_Dec_27\" [label=\"Dec 27\"];\n",
            "        }\n",
            "    }\n",
            "\n",
            "    // Connections from 2024 to each Quarter\n",
            "    \"2024\" -> \"Q1\";\n",
            "    \"2024\" -> \"Q2\";\n",
            "    \"2024\" -> \"Q3\";\n",
            "    \"2024\" -> \"Q4\";\n",
            "}\n",
            "\n",
            "2024-12-30T04:00:33.691Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:10.619283, used credits [0.00973800]\n",
            "- CONTENT [a937626a-37ee-4eb1-93e5-2206e9a188ec]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [1586 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/january-2024/january-18-support-for-content-publishing-llm-tools-clip-image-embeddings-bug-fixes</name><title>January 18: Support for content publishing, LLM tools, CLIP image embeddings, bug fixes | Graphlit Changelog</title></metadata> üéÜ\tJanuary 2024\n",
            "January 18: Support for content publishing, LLM tools, CLIP image embeddings, bug fixes\n",
            "New Features\n",
            "üí° Graphlit now supports content publishing, where documents, audio transcripts and even image descriptions, can be summarized, and repurposed into blog posts, emails or AI-generated podcasts.  With the new publishContents mutation, you can configure LLM prompts for summarization and publishing, and assign specifications to use different models and/or system prompts for each step in the process.  The published content will be reingested into Graphlit, and can be searched or used for conversations, like any other form of content.\n",
            "üí° Graphlit now supports publishing conversations as content with the new publishConversation mutation.  You can generate text or audio transcripts of your conversations, to be reused in other tools.\n",
            "üí° Graphlit now supports bulk summarization of contents with the summarizeContents mutation.  You can filter a set of content, by feed, by observable or by similar text, and run a set of summarizations across each content in parallel.\n",
            "üí° Graphlit now supports LLM entity extraction, with the new MODEL_TEXT entity extraction service type.  Similar to using Azure Cognitive Service Text Analytics, you can use any OpenAI or Anthropic model for extracting entities from text.  Internally the LLM returns JSON-LD entities, which we convert into Person, Organization, Place, etc. entities and assign observations to the extracted content.\n",
            "üí° Graphlit now supports LLM tools (aka function calls) with OpenAI models.  You can define the tools to be used with the LLM in the specification object.  With the new extractContents mutation, you can execute a prompt against content using a specification with tools defined.  The mutation will return the JSON arguments assigned by the LLM.\n",
            "üí° Graphlit now supports callback webhooks for LLM tools.  If you assign a URI in the ToolDefinition object, Graphlit will call your webhook the tool name and JSON arguments.  When you respond to the webhook with JSON, we will add that response to the LLM messages, and ask the LLM to complete the original prompt.\n",
            "üí° Graphlit now supports the selection of the Deepgram model (such as Meeting, Phonecall or Finance) with the preparation workflow.  Also, you can assign your own Deepgram API key, which will be used for audio transcription using that workflow.\n",
            "Added support for CLIP image embeddings using Roboflow, which can be used for similar image search.  If you search for contents by similar contents, we will now use the content's text and/or image embeddings to find similar content.\n",
            "Added support for dynamic web page ingestion.  Graphlit now navigates to and automatically scrolls web pages using Browserless.io, so we capture the fully rendered HTML before extracting text.  Also, we now support web page screenshots, if enabled with enableImageAnalysis property in preparation workflow.  These screenshots can be analyzed with multimodal modals, such as GPT-4 Vision, or can be used to create image embeddings for similar image search.\n",
            "Added table parsing when preparing documents.  We now store structured (tab-delimited) text in the JSON text mezzanine which is extracted from documents in the preparation workflow.\n",
            "Added reverse geocoding of lat/long locations found in image or other content metadata.  We now store the real-world address with the content metadata, for use in conversations.\n",
            "Added assistant messages to the conversation message history provided to the LLM.  Originally we had included only user messages, but now we are formatting both user and assistant messages into the LLM prompt for conversations.\n",
            "Added new chunking algorithm for text embeddings.  We support semantic chunking at the page or transcript segment level, and now will create embeddings from smaller sized text chunks per page or segment.\n",
            "Added content metadata to text and image embeddings.  To provide better context for the text embeddings, we now include formatted content metadata, which includes fields like title, subject, author, or description.  For emails, we include to, from, cc, and bcc fields.\n",
            "Added helper mutations isContentDone and isFeedDone which can be used for polling completion of ingested content, or all content ingested by a feed.\n",
            "Added richer image descriptions generated by the GPT-4 Vision model.  Now these provide more useful detail.\n",
            "Added validation of extracted hyperlinks.  Now we test the URIs and remove any inaccessible links during content enrichment.\n",
            "Added deleteContents,  deleteFeeds,  and deleteConversations mutations for multi-deletion of contents, feeds or conversations.\n",
            "Added deleteAllContents,  deleteAllFeeds,  and deleteAllConversations mutations for bulk, filtered deletion of entities.  You can delete all your contents, feeds, or conversations in your project, or a filtered subset of those entities.\n",
            "‚ÑπÔ∏è Starter tier now has a higher content limit of 100K content items.\n",
            "‚ö° In the OpenAIImageExtractionProperties type, the detailMode field was renamed to detailLevel.\n",
            "‚ö° Each SummarizationStrategy object now accepts the specification which is used by the summarization, rather than being assigned at the preparation workflow stage.\n",
            "‚ö° addCollectionContents and removeCollectionContents mutations have been deprecated in favor of addContentsToCollections and removeContentsFromCollection mutations.\n",
            "Bugs Fixed\n",
            "GPLA-1846: Parse Markdown headings into mezzanine JSON\n",
            "GPLA-1779: Not returning SAS token with mezzanine, master URIs\n",
            "GPLA-1348: Summarize text content, not just file content\n",
            "GPLA-1297: Not assigning content error message on preparation workflow failure\n",
            "PreviousJanuary 22: Support for Google and Microsoft email feeds, reingest content in-place, bug fixes\n",
            "NextDecember 10: Support for OpenAI GPT-4 Turbo, Llama 2 and Mistral models; query by example, bug fixes Last updated8 months ago\n",
            "- Completion [415 tokens (includes JSON guardrails tokens)], throughput: 39.080 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for content publishing, allowing documents, audio transcripts, and image descriptions to be summarized and repurposed.\n",
            "  - New mutation for publishing conversations as content, generating text or audio transcripts.\n",
            "  - Bulk summarization of contents with the summarizeContents mutation.\n",
            "  - LLM entity extraction using MODEL_TEXT service type, returning JSON-LD entities.\n",
            "  - Support for LLM tools (function calls) with OpenAI models, including extractContents mutation.\n",
            "  - Callback webhooks for LLM tools, enabling interaction with external services.\n",
            "  - Selection of Deepgram models for audio transcription with custom API key.\n",
            "  - CLIP image embeddings support for similar image search.\n",
            "  - Dynamic web page ingestion with automatic scrolling and screenshot capabilities.\n",
            "  - Table parsing for structured text extraction from documents.\n",
            "  - Reverse geocoding of lat/long locations in content metadata.\n",
            "  - Inclusion of assistant messages in conversation history for LLM prompts.\n",
            "  - New chunking algorithm for semantic text embeddings.\n",
            "  - Enhanced content metadata for text and image embeddings.\n",
            "  - Helper mutations for polling content ingestion completion.\n",
            "  - Richer image descriptions generated by GPT-4 Vision model.\n",
            "  - Validation of extracted hyperlinks to remove inaccessible links.\n",
            "  - Multi-deletion mutations for contents, feeds, and conversations.\n",
            "  - Bulk deletion mutations for filtered subsets of entities.\n",
            "  - Starter tier content limit increased to 100K items.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Renamed detailMode field to detailLevel in OpenAIImageExtractionProperties.\n",
            "  - SummarizationStrategy objects now accept specifications directly.\n",
            "  - Deprecated addCollectionContents and removeCollectionContents mutations in favor of new mutations.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issues with parsing Markdown headings, returning SAS tokens, summarizing text content, and assigning error messages on workflow failures.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: January 18, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced content management capabilities, improved LLM interactions, and better data extraction and processing features.\n",
            "\n",
            "2024-12-30T04:00:30.815Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:03.254500, used credits [0.00564600]\n",
            "- CONTENT [52613eca-1a5a-40ae-91b0-3d8243a55439]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [974 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/</name><title>December 27: Support for LLM fallbacks, native Google Docs formats, website unblocking, bug fixes | Graphlit Changelog</title></metadata> üéÑ\tDecember 2024\n",
            "December 27: Support for LLM fallbacks, native Google Docs formats, website unblocking, bug fixes\n",
            "New Features\n",
            "üí° Graphlit now supports LLM fallbacks which can help protect your application from model provider downtime.  By assigning the fallbacksproperty when creating your conversation, you can provide an optional list of LLM specifications to be used (in order).  These fallback specifications will only be used when we failed to prompt the conversation via the main specification.  Caveat, the RAG pipeline will only use the strategies provided in the main specification for prompt rewriting, content retrieval, etc.  Content is not re-retrieved upon fallback - the formatted LLM prompt will be tried against each fallback specification in succession until one succeeds. (Colab Notebook Example)\n",
            "üí° Graphlit now supports querying of all available models, through the new modelsquery in the API.  This returns the model enum, model service type enum, description, and several other useful details about the models.\n",
            "Graphlit now supports the ingestion of native Google Docs, Google Sheets and Google Slides documents from Google Drive feeds.  These formats will be auto-exported to the corresponding Microsoft Office format (DOCX, XLSX, PPTX) prior to ingesting as content.\n",
            "Graphlit now supports unblocking of websites, such as those using Cloudflare.  You can set enableUnblockedCaptureto true on the PreparationWorkflowStageto enable unblocking - through our integration with Browserless.io headless browser service.  This does incur an additional cost per page, compared to normal web page ingestion.\n",
            "We have added support for assigning observations to contents ingested via feeds.  By assigning observationsto the IngestionWorkflowStagein workflow object, you can assign Labels, Organizations, etc. without needing to use entity extraction.\n",
            "We have added support for assigning observations when ingesting content via ingestUri, ingestText, etc. mutations. By passing observationsas a parameter, similar to `collections`, you can assign Labels, Organizations, etc. without needing to use entity extraction.\n",
            "‚ö° We have changed the response type of the publishContentsmutation to return PublishContentstype.  This new PublishContentstype wraps the published Contentobject, and includes the new Detailsproperty of PublishingDetailstype. We have added an includeDetailsparameter to publishContentsmutation, which will fill in the Details property with a list of intermediate content summaries and the published text, among other publishing metrics.\n",
            "‚ö° We have changed the behavior of publishContentssuch that, if no content was retrieved for publishing, the mutation returns a null content object rather than returning an error.\n",
            "Bugs Fixed\n",
            "GPLA-3645: Table headers merged together on web scrape\n",
            "GPLA-3634: Failed to extract pages from PDF with empty hyperlink text\n",
            "GPLA-3633: Not handling empty observables properly for reranking\n",
            "NextDecember 22: Support for Dropbox, Box, Intercom and Zendesk feeds, OpenAI o1, Gemini 2.0, bug fixes\n",
            "Last updated23 hours ago\n",
            "- Completion [227 tokens (includes JSON guardrails tokens)], throughput: 69.750 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for LLM fallbacks to protect applications from model provider downtime.\n",
            "  - New API query for all available models, providing model details.\n",
            "  - Ingestion of native Google Docs, Sheets, and Slides from Google Drive, auto-exported to Microsoft Office formats.\n",
            "  - Website unblocking support for sites using Cloudflare, enabled via Browserless.io integration.\n",
            "  - Ability to assign observations to ingested content without entity extraction.\n",
            "  - Enhanced content publishing response type with new details property.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Changed response type of publishContents mutation to include publishing details.\n",
            "  - Updated behavior of publishContents to return null for no content instead of an error.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed table headers merging issue on web scrape.\n",
            "  - Resolved failure to extract pages from PDFs with empty hyperlink text.\n",
            "  - Improved handling of empty observables for reranking.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: December 2024.\n",
            "  \n",
            "- Value:\n",
            "  - These updates enhance application reliability, improve content ingestion capabilities, and streamline the publishing process for developers.\n",
            "\n",
            "2024-12-30T04:00:30.370Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:05.611226, used credits [0.00651300]\n",
            "- CONTENT [a0d556d6-0bbc-4df0-9577-bb621d9c6fc2]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [879 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/april-2024/april-23-support-for-python-and-typescript-sdks-latest-openai-cohere-and-groq-models-bug-fixes</name><title>April 23: Support for Python and TypeScript SDKs, latest OpenAI, Cohere & Groq models, bug fixes | Graphlit Changelog</title></metadata> üêá\tApril 2024\n",
            "April 23: Support for Python and TypeScript SDKs, latest OpenAI, Cohere & Groq models, bug fixes\n",
            "New Features\n",
            "üí° Graphlit now supports a native Python SDK, using Pydantic types. The Python SDK is code-generated from the current GraphQL schema, but does not require GraphQL knowledge. You can find the latest PyPi package here.  The Streamlit sample applications have been updated to use the new Python SDK.\n",
            "üí° Graphlit now supports a native Node.js SDK, using TypeScript types. The Node.js SDK is code-generated from the current GraphQL schema, but does not require GraphQL knowledge. You can find the latest NPM package here.\n",
            "üí° Graphlit now supports the 2024-04-09 models in the OpenAI model service. GPT4_TURBO-128K will give the latest OpenAI GPT-4 model, following this model list.  We have added the GPT4_TURBO_128K_2024_04_09 enum to specify the new model.\n",
            "üí° Graphlit now supports LLaMA3 70b, LLaMA3 8b and Gemma 7b models in the Groq model service.\n",
            "üí° Graphlit now supports the Command R and Command-R+ models in the Cohere model service.\n",
            "Added support for Jina reranking, using the JINA reranking model service type in the reranking retrieval strategy.\n",
            "Updated the Cohere reranking model to use the latest v3.0 model.\n",
            "Increased the reliability of parsing LLM responses, in cases where they don't follow the JSON schema.\n",
            "‚ö° Cleaned up nullability of GraphQL parameters, so parameters better reflect if they are required or optional, or allow nulls.\n",
            "‚ö° Added missing deleteWorkflows and deleteAllCollections mutations.\n",
            "‚ö° Split out reranking model service type as RetrievalModelServiceTypes enum.\n",
            "Bugs Fixed\n",
            "GPLA-2114: Adding content to collections not syncing search index\n",
            "GPLA-2511: Failing to render any conversation sources with section retrieval and text content\n",
            "PreviousMay 5: Support for Jina and Pongo rerankers, Microsoft Teams feed, new YouTube downloader, bug fixes\n",
            "NextApril 7: Support for Discord feeds, Cohere reranking, section-aware chunking and retrieval\n",
            "Last updated8 months ago\n",
            "- Completion [323 tokens (includes JSON guardrails tokens)], throughput: 57.563 tokens/sec:\n",
            "- New Features:\n",
            "  - Native Python SDK introduced, using Pydantic types; code-generated from GraphQL schema, no GraphQL knowledge required.\n",
            "  - Native Node.js SDK introduced, using TypeScript types; code-generated from GraphQL schema, no GraphQL knowledge required.\n",
            "  - Support for OpenAI's 2024-04-09 models, including GPT4_TURBO-128K.\n",
            "  - Support for Groq models: LLaMA3 70b, LLaMA3 8b, and Gemma 7b.\n",
            "  - Support for Command R and Command-R+ models in Cohere model service.\n",
            "  - Added support for Jina reranking with the JINA reranking model service type.\n",
            "  - Updated Cohere reranking model to v3.0.\n",
            "  - Improved reliability of parsing LLM responses that don't follow JSON schema.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Cleaned up nullability of GraphQL parameters for better clarity on required, optional, or nullable parameters.\n",
            "  - Added missing deleteWorkflows and deleteAllCollections mutations.\n",
            "  - Split reranking model service type into RetrievalModelServiceTypes enum.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issue with content not syncing to search index (GPLA-2114).\n",
            "  - Resolved rendering issues with conversation sources and section retrieval (GPLA-2511).\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: April 2024.\n",
            "  \n",
            "- Value:\n",
            "  - Offers developers enhanced SDK support, improved model integration, and better error handling, facilitating easier development and deployment of applications.\n",
            "\n",
            "2024-12-30T04:00:30.108Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:05.146283, used credits [0.00720000]\n",
            "- CONTENT [8443a72b-f798-4325-b0ac-b821d4e7dea8]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [1068 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/april-2024/april-7-support-for-discord-feeds-cohere-reranking-section-aware-chunking-and-retrieval</name><title>April 7: Support for Discord feeds, Cohere reranking, section-aware chunking and retrieval | Graphlit Changelog</title></metadata> üêá\tApril 2024\n",
            "April 7: Support for Discord feeds, Cohere reranking, section-aware chunking and retrieval\n",
            "New Features\n",
            "üí° Graphlit now supports Discord feeds.  By connecting to a Discord channel and providing a bot token, you can ingest all Discord messages and file attachments.\n",
            "üí°  Graphlit now supports Cohere reranking after content retrieval in RAG pipeline.  You can optionally use the Cohere rerank model to semantically rerank the semantic search results, before providing as context to the LLM.\n",
            "Added support for section-aware text chunking and retrieval.  Now, when using section-aware document preparation, such as Azure AI Document Intelligence, Graphlit will store the extracted text according to the semantic chunks (i.e. sections).  The text for each section will be individually chunked and embedded into the vector index.\n",
            "Added support for retrievalStrategy in Specification type. Graphlit now supports CHUNK, SECTION and CONTENT retrieval strategies.  Chunk retrieval will use the search hit chunk, section retrieval will expand the search hit chunk to the containing section (or page, if not using section-aware preparation).  Content retrieval will expand the search hit chunk to the text of the entire document.\n",
            "Added support for rerankingStrategy in Specification type. You can now configure the reranking of content sources, using the Cohere reranking model, by assigning serviceType to COHERE.  More reranking models are planned for the future.\n",
            "Added isSynchronous flag to content ingestion mutations, such as ingestUri, so the mutation will wait for the content to complete the ingestion workflow (or error) before returning.  This is useful for utilizing the API in a Jupyter notebook or Streamlit application, in a synchronous manner without polling.\n",
            "Added includeAttachments flag to SlackFeedProperties.  When enabled, Graphlit will automatically ingest any attachments within Slack messages.\n",
            "‚ö° Added ingestUri mutation to replace the now deprecated ingestPage and ingestFile mutations.  We had seen confusion on when to use one vs the other, and now for any URI, whether it is a web page or hosted PDF, you can pass it to ingestUri, and we will infer the correct content ingestion workflow.\n",
            "‚ö° Removed includeSummaries from the ConversationStrategyInput type.  This will re-added in the future as part of the retrieval strategy.\n",
            "‚ö° Deprecated enableExpandedRetrieval in ConversationStrategyInput type.  This is now handled by setting strategyType to SECTION or CONTENT in the RetrievalStrategyInput type.\n",
            "‚ö° Moved contentLimit from ConversationStrategyInput type to RetrievalStrategyInput type. You can optionally assign the contentLimit to retrievalStrategy which limits the number of content sources leveraged in the LLM prompt context. (Default is 100.)\n",
            "Bugs Fixed\n",
            "GPLA-2469: Failed to ingest PDF hosted on GitHub\n",
            "GPLA-2390: Claude 3 Haiku not adhering to JSON schema\n",
            "GPLA-2474: Prompt rewriting should ignore formatting instructions in prompt\n",
            "GPLA-2462: Missing line break after table rows\n",
            "GPLA-2417: Not extracting images from PPTX correctly\n",
            "PreviousApril 23: Support for Python and TypeScript SDKs, latest OpenAI, Cohere & Groq models, bug fixes\n",
            "NextMarch 23: Support for Linear, GitHub Issues and Jira issue feeds, ingest files via Web feed sitemap\n",
            "Last updated8 months ago\n",
            "- Completion [333 tokens (includes JSON guardrails tokens)], throughput: 64.707 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for Discord feeds: Ingest messages and file attachments from a Discord channel using a bot token.\n",
            "  - Cohere reranking: Optionally rerank semantic search results in the RAG pipeline using the Cohere model.\n",
            "  - Section-aware text chunking and retrieval: Store extracted text according to semantic chunks for improved indexing.\n",
            "  - Retrieval strategies: Support for CHUNK, SECTION, and CONTENT retrieval strategies.\n",
            "  - Reranking strategy: Configure reranking of content sources using the Cohere model.\n",
            "  - Synchronous content ingestion: Added isSynchronous flag for content ingestion mutations.\n",
            "  - Slack attachments: Enable automatic ingestion of attachments in Slack messages.\n",
            "  - IngestUri mutation: Replaces deprecated ingestPage and ingestFile mutations for simplified content ingestion.\n",
            "  \n",
            "- Enhancements/Improvements:\n",
            "  - Removed includeSummaries from ConversationStrategyInput; will be re-added later.\n",
            "  - Deprecated enableExpandedRetrieval; now managed by strategyType in RetrievalStrategyInput.\n",
            "  - Moved contentLimit to RetrievalStrategyInput for better content source management.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issues with PDF ingestion from GitHub.\n",
            "  - Resolved JSON schema adherence for Claude 3 Haiku.\n",
            "  - Prompt rewriting now ignores formatting instructions.\n",
            "  - Corrected line breaks after table rows.\n",
            "  - Fixed image extraction from PPTX files.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: April 2024.\n",
            "  - Version updates include new flags and strategies for improved functionality.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced capabilities for content ingestion, retrieval, and processing, improving integration with various platforms and models.\n",
            "\n",
            "2024-12-30T04:00:27.437Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:02.596185, used credits [0.00385200]\n",
            "- CONTENT [9ded6f5c-a667-442d-8848-30d7a22e79e0]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [616 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/august-2023/august-17-prepare-for-usage-based-billing-append-sas-tokens-to-uris</name><title>August 17: Prepare for usage-based billing; append SAS tokens to URIs | Graphlit Changelog</title></metadata> üéÇ\tAugust 2023\n",
            "August 17: Prepare for usage-based billing; append SAS tokens to URIs\n",
            "New Features\n",
            "‚ÑπÔ∏è Behind the scenes, Graphlit is preparing to launch usage-based billing.  This release put in place the infrastructure to track billable events.  Organizations now have a Stripe customer associated with them, and Graphlit projects are auto-subscribed to a Free/Hobby pricing plan.  In a future release, we will provide the ability to upgrade to a paid plan in the Graphlit Developer Portal.  Also, we will provide visualization of usage, on granular basis, in the Portal.\n",
            "üí° Content URIs now have Shared Access Signature (SAS) token appended, so they are accessible after query.  For example, content.transcriptUri will now be able to be downloaded or used directly in an application (until the SAS token expires).\n",
            "üß± Added more robustness for error handling and retries, especially for LLM APIs and audio transcription APIs.\n",
            "PreviousSeptember 4: Workflow configuration; support for Notion feeds; document OCR\n",
            "NextAugust 9: Support direct text, Markdown and HTML ingestion; new Specification LLM strategy\n",
            "Last updated1 year ago\n",
            "- Completion [167 tokens (includes JSON guardrails tokens)], throughput: 64.325 tokens/sec:\n",
            "- New Features:\n",
            "  - Infrastructure for usage-based billing implemented; organizations now have a Stripe customer.\n",
            "  - Graphlit projects auto-subscribed to a Free/Hobby pricing plan; future upgrade options to be available in the Developer Portal.\n",
            "  - Visualization of usage to be provided in the Portal.\n",
            "  - Content URIs now include Shared Access Signature (SAS) tokens for direct access post-query.\n",
            "  \n",
            "- Enhancements/Improvements:\n",
            "  - Improved error handling and retries for LLM APIs and audio transcription APIs.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - No specific bug fixes mentioned.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: August 17, 2023.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers a framework for billing based on usage and enhanced access to content through SAS tokens, improving application integration and error management.\n",
            "\n",
            "2024-12-30T04:00:24.883Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:02.079941, used credits [0.00352200]\n",
            "- CONTENT [4eff5e88-2cf6-489f-9bfb-52b30823e07e]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [562 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/december-2024/december-1-support-for-retrieval-only-rag-pipeline-bug-fixes</name><title>December 1: Support for retrieval-only RAG pipeline, bug fixes | Graphlit Changelog</title></metadata> üéÑ\tDecember 2024\n",
            "December 1: Support for retrieval-only RAG pipeline, bug fixes\n",
            "New Features\n",
            "üí° Graphlit now supports formatting of LLM-ready prompts with our RAG pipeline, via the new formatConversation and completeConversation mutations.  This is valuable for supporting LLM streaming by directly calling the LLM from your application, and using Graphlit for RAG retrieval and conversation history. (Colab Notebook Example)\n",
            "We have added support for inline hyperlinks in extracted text from documents and web pages.\n",
            "Bugs Fixed\n",
            "GPLA-3466: Owner ID should accept any non-whitespace string\n",
            "GPLA-3458: Not getting Person-to-Organization edges from entity extraction\n",
            "PreviousDecember 9: Support for website mapping, web page screenshots, Groq Llama 3.3 model, bug fixes\n",
            "NextNovember 24: Support for direct LLM prompt, multi-turn image analysis, bug fixes\n",
            "Last updated28 days ago\n",
            "- Completion [153 tokens (includes JSON guardrails tokens)], throughput: 73.560 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for formatting LLM-ready prompts with RAG pipeline using formatConversation and completeConversation mutations.\n",
            "  - Inline hyperlinks support in extracted text from documents and web pages.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Improved LLM streaming capabilities by allowing direct calls from applications.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issue where Owner ID should accept any non-whitespace string (GPLA-3466).\n",
            "  - Resolved problem with missing Person-to-Organization edges from entity extraction (GPLA-3458).\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: December 1, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Enhances developer experience by improving prompt formatting and text extraction capabilities, facilitating better integration with LLMs.\n",
            "\n",
            "2024-12-30T04:00:24.785Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:03.381432, used credits [0.00607200]\n",
            "- CONTENT [ebda0578-6209-4833-9bee-36d0050dc5ee]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [1016 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/july-2024/july-19-support-for-openai-gpt-4o-mini-byo-key-for-azure-ai-similarity-by-summary-bug-fixes</name><title>July 19: Support for OpenAI GPT-4o Mini, BYO-key for Azure AI, similarity by summary, bug fixes | Graphlit Changelog</title></metadata> ‚òÄÔ∏è\tJuly 2024\n",
            "July 19: Support for OpenAI GPT-4o Mini, BYO-key for Azure AI, similarity by summary, bug fixes\n",
            "New Features\n",
            "üí° Graphlit now supports the OpenAI GPT-4o Mini model, with 16k output tokens.\n",
            "üí° Graphlit now supports 'bring-your-own-key' for Azure AI Document Intelligence models.  We have added a custom endpoint and key property, which can be assigned to use your own Azure AI resource.\n",
            "Updated to use Jina reranker v2 (jina-reranker-v2-base-multilingual) by default.\n",
            "Updated to assign the summary, bullets, etc properties when calling summarizeContents mutation.  Now when summarizing contents, we will store the resulting summary in the content itself, in addition to returning the summarized results.\n",
            "Added relevance property to all entity types, which will be assigned when searching for these entities.  Entity results will be sorted (descending) by this search relevance score.\n",
            "Added the ability to manually update summary, bullets, etc. properties when calling the updateContent mutation.\n",
            "Added offset property to AtlassianJiraFeedProperties, so the timezone offset can be properly assigned for paging of the Jira feed.  (Defaults to zero offset, i.e. UTC.)  Jira does not store dates in UTC format, and the timestamps are based on the server timezone of the hosted Jira instance.  By assigning the timezone offset with the Jira feed, we can reliably page the updated date timestamps from the Jira API.\n",
            "‚ö° We have changed the content similarity search behavior to find similar content by summary, rather than text of the document, when a summary has been previously generated.  For long documents, this will provide a more accurate similarity, rather than comparing on the first few pages of text in a document.\n",
            "‚ö° We have changed the behavior of assigning offset in the entity filter objects for paging through entities.  If using vector or hybrid search, this offset will be ignored (i.e. zero offset).  Paging will not be supported through vector or hybrid search results. For keyword search, the offset will continue to be used, along with the limit property, to provide paging through the search results.  We have made this change because we have found that index-based paging is not reliable with our vector/hybrid search approach.  We are investigating ways to support this reliably with vector/hybrid search in the future.\n",
            "Bugs Fixed\n",
            "GPLA-2915: Add retry on OpenAI API HTTP 524 error (gateway timeout).\n",
            "GPLA-2908: Not paging through Jira feed correctly.\n",
            "GPLA-2917: Search by similar content is not giving expected results on long documents.\n",
            "GPLA-2244: Keyword search not finding text in latter part of long PDF.\n",
            "PreviousJuly 25: Support for Mistral Large 2 & Nemo, Groq Llama 3.1 models, bug fixes\n",
            "NextJuly 4: Support for webhook Alerts, keywords summarization, Deepseek 128k context window, bug fixes\n",
            "Last updated5 months ago\n",
            "- Completion [252 tokens (includes JSON guardrails tokens)], throughput: 74.525 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for OpenAI GPT-4o Mini model with 16k output tokens.\n",
            "  - 'Bring-your-own-key' support for Azure AI Document Intelligence models with custom endpoint and key property.\n",
            "  - Updated to Jina reranker v2 by default.\n",
            "  - Enhanced summarizeContents mutation to store summaries in content.\n",
            "  - Added relevance property for entity types, sorting results by relevance score.\n",
            "  - Ability to manually update summary and bullet properties in updateContent mutation.\n",
            "  - Offset property added to AtlassianJiraFeedProperties for proper timezone assignment.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Content similarity search now finds similar content by summary for better accuracy.\n",
            "  - Changed entity filter object behavior for paging; zero offset for vector/hybrid search.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Added retry on OpenAI API HTTP 524 error.\n",
            "  - Fixed paging issues with Jira feed.\n",
            "  - Improved search results for similar content in long documents.\n",
            "  - Resolved keyword search issues in long PDFs.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: July 19, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers improved model support, enhanced search capabilities, and better handling of content summaries and entity relevance.\n",
            "\n",
            "2024-12-30T04:00:24.716Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:03.338981, used credits [0.00579900]\n",
            "- CONTENT [253c57c2-3536-4a73-aa76-101372e74b0e]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [921 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/december-2024/december-9-support-for-website-mapping-web-page-screenshots-groq-llama-3.3-model-bug-fixes</name><title>December 9: Support for website mapping, web page screenshots, Groq Llama 3.3 model, bug fixes | Graphlit Changelog</title></metadata> üéÑ\tDecember 2024\n",
            "December 9: Support for website mapping, web page screenshots, Groq Llama 3.3 model, bug fixes\n",
            "New Features\n",
            "üí° Graphlit now supports mapping a website with the mapWebmutation. You can provide a URL to a website, and the query will return a list of URLs based on the sitemap.xml (or sitemap-index.xml) file, at or underneath the provided URL.\n",
            "üí° Graphlit now supports the generation of web page screenshots with the screenshotPagemutation. By providing the URL of a web page, and optionally, the maximum desired height of the screenshot, we will screenshot the webpage and ingest it automatically as content.  You can provide an optional workflow, which will be applied to the ingested image content, for operations like generating image descriptions with a vision LLM.\n",
            "üí° Graphlit now supports the direct summarization of text with the summarizeTextmutation. By providing the desired summarization strategy, we will summarize the text (i.e. bullet points, social media posts) and return the summarization.\n",
            "üí° Graphlit now supports the direct extraction of text with the extractTextmutation. By providing the LLM tool definitions and an optional LLM specification, we will prompt the desired LLM (or OpenAI GPT-4o, by default) to invoke the provided tools, and return the JSON responses from the LLM tool calling.\n",
            "Graphlit now supports the latest Groq Llama 3.3 model, with the model enum LLAMA_3_3_70B.\n",
            "We have updated Cohere reranking to use the latest Cohere rerank-v3.5model by default.\n",
            "‚ö° We have added a new flattenCitationsfield to the ConversationStrategyInputtype.  By assigning this field to True, when calling promptConversation,we will combine multiple citations from the same content into a single citation.\n",
            "‚ö° For Microsoft email, Microsoft Teams and OneDrive feeds, we have added the clientIdand clientSecretfields as required feed properties. These properties must be assigned, in addition to the refreshTokenfield for proper authentication to the Microsoft Graph API used by these feeds. (Colab Notebook Example)\n",
            "Bugs Fixed\n",
            "GPLA-3492: Not finding sitemap at parent web path\n",
            "GPLA-3500: Failed to handle mismatch of Deepgram model/language\n",
            "PreviousDecember 22: Support for Dropbox, Box, Intercom and Zendesk feeds, OpenAI o1, Gemini 2.0, bug fixes\n",
            "NextDecember 1: Support for retrieval-only RAG pipeline, bug fixes\n",
            "Last updated19 days ago\n",
            "- Completion [253 tokens (includes JSON guardrails tokens)], throughput: 75.772 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for website mapping using mapWebmutation to return URLs from sitemap.xml.\n",
            "  - Generation of web page screenshots with screenshotPagemutation, including optional workflows for image processing.\n",
            "  - Direct summarization of text with summarizeTextmutation, allowing various summarization strategies.\n",
            "  - Direct extraction of text with extractTextmutation, utilizing LLM tools for JSON responses.\n",
            "  - Support for Groq Llama 3.3 model (LLAMA_3_3_70B).\n",
            "  - Updated Cohere reranking to use rerank-v3.5 model by default.\n",
            "  - New flattenCitations field in ConversationStrategyInput to combine multiple citations.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Required clientId and clientSecret fields added for Microsoft email, Teams, and OneDrive feeds for proper authentication.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issue with not finding sitemap at parent web path (GPLA-3492).\n",
            "  - Resolved mismatch handling of Deepgram model/language (GPLA-3500).\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: December 9, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced capabilities for web mapping, content ingestion, and improved integration with Microsoft services.\n",
            "\n",
            "2024-12-30T04:00:23.025Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:02.636187, used credits [0.00415500]\n",
            "- CONTENT [5da3504c-5d1d-4b5c-848e-d3ddb11f3964]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [629 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/august-2024/august-11-support-for-azure-ai-document-intelligence-by-default-language-aware-summaries</name><title>August 11: Support for Azure AI Document Intelligence by default, language-aware summaries | Graphlit Changelog</title></metadata> üéÇ\tAugust 2024\n",
            "August 11: Support for Azure AI Document Intelligence by default, language-aware summaries\n",
            "New Features\n",
            "Added support for language-aware summaries when using LLM-based document extraction.  Now the summaries for tables and sections generated by the LLM will follow the language of the source text.\n",
            "Added support for language-aware entity descriptions with using LLM-based entity extraction. Now the entity descriptions generated by the LLM will follow the language of the source text.\n",
            "‚ö° We have changed the default document preparation method to use Azure AI Document Intelligence, rather than our built-in document parsers.  We have found that the fidelity of Azure AI is considerably better for complex PDFs, and provides better support for table extraction, so we have made this the default. Note: this does come with increased credit usage per-page, for PDF, DOCX and PPTX documents, but the quality of the extracted documents are noticeably higher for use in RAG pipelines.\n",
            "Bugs Fixed\n",
            "GPLA-3070: Not getting slide count assigned to metadata for PPTX files.\n",
            "PreviousAugust 20: Support for medical entities, Anthropic prompt caching, bug fixes\n",
            "NextAugust 8: Support for LLM-based document extraction, .NET SDK, bug fixes\n",
            "Last updated4 months ago\n",
            "- Completion [189 tokens (includes JSON guardrails tokens)], throughput: 71.694 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for language-aware summaries in LLM-based document extraction, aligning summaries with the source text language.\n",
            "  - Support for language-aware entity descriptions in LLM-based entity extraction, matching descriptions to the source text language.\n",
            "  - Default document preparation method changed to Azure AI Document Intelligence for improved fidelity in complex PDFs and better table extraction.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Increased credit usage per page for PDF, DOCX, and PPTX documents due to the switch to Azure AI Document Intelligence, but with significantly higher quality in extracted documents for RAG pipelines.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issue GPLA-3070 where slide count was not assigned to metadata for PPTX files.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: August 11, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced document extraction capabilities with improved accuracy and language support, facilitating better integration in applications.\n",
            "\n",
            "2024-12-30T04:00:22.656Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:02.784261, used credits [0.00420300]\n",
            "- CONTENT [1a8c6b11-f325-47e9-bb39-643f7fb92154]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [673 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/august-2023/august-9-support-direct-text-markdown-and-html-ingestion-new-specification-llm-strategy</name><title>August 9: Support direct text, Markdown and HTML ingestion; new Specification LLM strategy | Graphlit Changelog</title></metadata> üéÇ\tAugust 2023\n",
            "August 9: Support direct text, Markdown and HTML ingestion; new Specification LLM strategy\n",
            "New Features\n",
            "üí° Added ingestText mutation which supports direct Content ingestion of plain text, Markdown and HTML.  Now, if you have pre-scraped HTML or Markdown text, you can ingest it into Graphlit without reading from a URL.\n",
            "üí° Added Specification strategy property, which allows customization of the LLM context when prompting a conversation.  ConversationStrategy now provides Windowed and Summarized message histories, as well as configuration of the weight between existing conversation messages and Content text pages (or audio transcript segments) in the LLM context.\n",
            "üí° Added auto-summarization of extracted text and audio transcripts.  There is a new Content summary property where a list of summary bullet points can be found.  These summaries can be optionally included in the Conversation prompt context for more accurate LLM responses.\n",
            "‚ÑπÔ∏è Added AzureOpenAIModels and OpenAIModels types to Specification model properties to make it easier to specify the desired LLM.\n",
            "‚ÑπÔ∏è Renamed ConversationMessage date property to timestamp\n",
            "‚ú® Refined the internal LLM prompts for providing content as part of Conversation context.  This provides for much clearer and accurate results from the LLM.\n",
            "PreviousAugust 17: Prepare for usage-based billing; append SAS tokens to URIs\n",
            "NextAugust 3: New data model for Observations, new Category entity\n",
            "Last updated1 year ago\n",
            "- Completion [182 tokens (includes JSON guardrails tokens)], throughput: 65.367 tokens/sec:\n",
            "- New Features:\n",
            "  - Added ingestText mutation for direct ingestion of plain text, Markdown, and HTML without URL reading.\n",
            "  - Introduced Specification strategy property for customizing LLM context with Windowed and Summarized message histories.\n",
            "  - Implemented auto-summarization of extracted text and audio transcripts, with summaries available for Conversation prompt context.\n",
            "  - Added AzureOpenAIModels and OpenAIModels types to Specification model properties for easier LLM specification.\n",
            "  - Renamed ConversationMessage date property to timestamp.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Refined internal LLM prompts for clearer and more accurate results.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - No specific bug fixes mentioned.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: August 2023.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced content ingestion capabilities, improved LLM context customization, and better summarization features for more accurate responses.\n",
            "\n",
            "2024-12-30T04:00:21.284Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:05.382503, used credits [0.00819000]\n",
            "- CONTENT [7b5b7874-c84b-4607-877c-8bec0e167127]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [1230 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/december-2024/december-22-support-for-dropbox-box-intercom-and-zendesk-feeds-openai-o1-gemini-2.0-bug-fixes</name><title>December 22: Support for Dropbox, Box, Intercom and Zendesk feeds, OpenAI o1, Gemini 2.0, bug fixes | Graphlit Changelog</title></metadata> üéÑ\tDecember 2024\n",
            "December 22: Support for Dropbox, Box, Intercom and Zendesk feeds, OpenAI o1, Gemini 2.0, bug fixes\n",
            "New Features\n",
            "üí° Graphlit now supports Dropbox feeds for ingesting files on the Dropbox cloud service. Dropbox feeds require your appKey, appSecret, redirectUriand refreshTokento be assigned. The feed also accepts an optional pathparameter to read files from a specific Dropbox folder.\n",
            "üí° Graphlit now supports Box feeds for ingesting files on the Box cloud service. Box feeds require your clientId, clientSecret, redirectUriand refreshTokento be assigned.\n",
            "üí° Graphlit now supports Intercom feeds for ingesting Intercom Articles and Tickets. We will ingest Intercom Articles as PAGEcontent type, and Tickets as ISSUEcontent type. Intercom feeds require the accessTokenproperty to be assigned.\n",
            "üí° Graphlit now supports Zendesk feeds for ingesting Zendesk Articles and Tickets.  We will ingest Zendesk Articles as PAGEcontent type, and Tickets as ISSUEcontent type. Zendesk feeds require the accessTokenproperty and your Zendesk subdomain to be assigned.\n",
            "Graphlit now supports the latest OpenAI o1 model, with the model enums O1_200kand O1_200k_20241217.\n",
            "Graphlit now supports the latest Gemini Flash 2.0 Experimental model, with the model enum GEMINI_2_0_FLASH_EXPERIMENTAL.\n",
            "Graphlit now supports the latest Cohere R7B model, with the model enum COMMAND_R7B_202412.\n",
            "Graphlit now supports returning the low-level details from prompting RAG conversations, by adding the includeDetailsparameter and setting to True. This includes details on the number of sources, the exact list of messages provided to the LLM, and more.\n",
            "We have added support for filtering of observables, such as Person or Organization, by URI property.\n",
            "We have added the ability to bypass semantic search in content retrieval with conversations. You can assign NONEfor the conversation search type, and it will ignore the user prompt when retrieving content.  It will inject all contents resulting from the content filter into the RAG prompt context.\n",
            "We have added a new createdInLastproperty to all entity filters, which allows easier filtering of entities created within a recent time period. Also, we have added a new inLastproperty to the content filter, which allows easier filtering of content authored within a recent time period. For example, find all images taken in the last 3 days, or find me all emails I received yesterday.\n",
            "We have added support for the latest Azure AI Document Intelligence models, with enums US_PAY_STUB, US_BANK_STATEMENT, and US_BANK_CHECK.\n",
            "We have added support for Google Drive and OneDrive feeds to ingest specific files by providing a list of file identifiers (files), in addition to the folder identifier (folderId).  If files identifiers are provided, they take precedence over the folder identifier.\n",
            "‚ö° For projects upgraded to the Starter Tier after Dec 9, 2024, we have removed the content items limit. Now you can store an unlimited number of content items (i.e. files, web pages, Slack messages) on the Starter or Growth Tiers.  If you have an existing project on the Starter Tier, please reach out and we will manually remove that content item limit on the project.\n",
            "Bugs Fixed\n",
            "GPLA-3529: Can't assign collection to multitenant content\n",
            "GPLA-3579: Should decode HTML characters when parsing HTML email\n",
            "GPLA-3576: Ingesting content in-place doesn't handle isSynchronous properly\n",
            "GPLA-3457: IsFeedDone doesn't return True for finished feed with no contents\n",
            "GPLA-3572: Not handling HTTP 400 error on uploading from URI\n",
            "PreviousDecember 27: Support for LLM fallbacks, native Google Docs formats, website unblocking, bug fixes\n",
            "NextDecember 9: Support for website mapping, web page screenshots, Groq Llama 3.3 model, bug fixes\n",
            "Last updated5 days ago\n",
            "- Completion [375 tokens (includes JSON guardrails tokens)], throughput: 69.670 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for Dropbox feeds for file ingestion, requiring appKey, appSecret, redirectUri, and refreshToken.\n",
            "  - Support for Box feeds for file ingestion, requiring clientId, clientSecret, redirectUri, and refreshToken.\n",
            "  - Support for Intercom feeds for ingesting Articles and Tickets, requiring accessToken.\n",
            "  - Support for Zendesk feeds for ingesting Articles and Tickets, requiring accessToken and Zendesk subdomain.\n",
            "  - Support for OpenAI o1 model with enums O1_200k and O1_200k_20241217.\n",
            "  - Support for Gemini Flash 2.0 Experimental model with enum GEMINI_2_0_FLASH_EXPERIMENTAL.\n",
            "  - Support for Cohere R7B model with enum COMMAND_R7B_202412.\n",
            "  - Ability to return low-level details from RAG conversations with includeDetails parameter.\n",
            "  - Support for filtering observables by URI property.\n",
            "  - Ability to bypass semantic search in content retrieval with conversations.\n",
            "  - New createdInLast property for entity filters and inLast property for content filters.\n",
            "  - Support for Azure AI Document Intelligence models with enums US_PAY_STUB, US_BANK_STATEMENT, and US_BANK_CHECK.\n",
            "  - Support for Google Drive and OneDrive feeds to ingest specific files by file identifiers.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Removal of content items limit for projects upgraded to the Starter Tier after December 9, 2024.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issues with multitenant content assignment, HTML character decoding in emails, synchronous content ingestion, feed completion status, and HTTP error handling during uploads.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: December 22, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced integration capabilities with popular cloud services and improved content management features.\n",
            "\n",
            "2024-12-30T04:00:21.275Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:05.324868, used credits [0.00577500]\n",
            "- CONTENT [3923639b-14f1-484b-86e7-7c6f6e67461d]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [861 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/august-2023/august-3-new-data-model-for-observations-new-category-entity</name><title>August 3: New data model for Observations, new Category entity | Graphlit Changelog</title></metadata> üéÇ\tAugust 2023\n",
            "August 3: New data model for Observations, new Category entity\n",
            "New Features\n",
            "üí° Revised data model for Observations, Occurrences and observables (i.e. Person, Organization).  Now after entity extraction, content will have one Observation for each observed entity, and a list of occurrences.  Occurrence now supports text, time and image occurrence types.  (Text: page index, time: start/end timestamp, image: bounding box)  Observations now have ObservableType and Observable fields, which specify the observed entity type and entity reference.\n",
            "üí° Added Category entity to GraphQL data model, which supports PII categories such as Phone Number or Credit Card Number.\n",
            "Added probability field to model properties, for the LLM's token probability.  (See OpenAI documentation for more detail.)\n",
            "Added error field to feeds.  If a feed fails to read from the data source, and is marked as ERRORED state, the error field will have the error description.\n",
            "Support reingestion of changed files from feeds.  For feeds, such as SharePoint or Web, where we can recognize that a file or page was updated, we will now reingest the content in-place.  Content will keep the same ID, and will restart the content workflow by re-downloading the updated content from the data source.   Existing observations will be deleted, and new observations will be created from the updated content.\n",
            "‚ÑπÔ∏è Ingestion of content is now idempotent, meaning if you ingest content again from the same URI, we will reingest the content in-place, while keeping the same ID.  (If we can recognize the content has not changed, such as by ETag, we will return the existing content object.)\n",
            "‚ÑπÔ∏è Changed GraphQL data type of SharePoint tenantId, libraryId and siteId to ID rather than String.\n",
            "‚ú® Performance optimization of entity extraction, and the creation of observations.\n",
            "Bugs Fixed\n",
            "GPLA-1130: Only was extracting text from first column of PDF tables.\n",
            "GPLA-1140: Text from DOCX tables was not extracted properly.\n",
            "GPLA-1154: Audio content ingested from RSS feed was not deleted when feed was deleted.\n",
            "PreviousAugust 9: Support direct text, Markdown and HTML ingestion; new Specification LLM strategy\n",
            "NextJuly 15: Support for SharePoint feeds, new Conversation features\n",
            "Last updated1 year ago\n",
            "- Completion [266 tokens (includes JSON guardrails tokens)], throughput: 49.954 tokens/sec:\n",
            "- New Features:\n",
            "  - Revised data model for Observations, Occurrences, and observables (e.g., Person, Organization).\n",
            "  - Each observed entity now has one Observation and a list of occurrences, supporting text, time, and image types.\n",
            "  - Added Category entity to GraphQL data model for PII categories (e.g., Phone Number, Credit Card Number).\n",
            "  - Introduced probability field for LLM's token probability.\n",
            "  - Added error field to feeds for error descriptions on failed reads.\n",
            "  - Support for reingestion of changed files from feeds, maintaining the same ID and restarting the content workflow.\n",
            "  - Idempotent content ingestion allows reingestion from the same URI without ID changes.\n",
            "  - Changed GraphQL data type for SharePoint tenantId, libraryId, and siteId to ID.\n",
            "  - Performance optimization for entity extraction and observation creation.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Improved handling of content ingestion and updates.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed extraction issues from PDF and DOCX tables.\n",
            "  - Resolved issue where audio content from RSS feeds was not deleted upon feed deletion.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: August 2023.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers improved data handling, enhanced entity extraction, and better error management.\n",
            "\n",
            "2024-12-30T04:00:20.297Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:03.924570, used credits [0.00682200]\n",
            "- CONTENT [67150a0e-9b17-4261-8f62-1c57686d46e1]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [1042 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/february-2024/february-21-support-for-onedrive-and-google-drive-feeds-extract-images-from-pdfs-bug-fixes</name><title>February 21: Support for OneDrive and Google Drive feeds, extract images from PDFs, bug fixes | Graphlit Changelog</title></metadata> üåßÔ∏è\tFebruary 2024\n",
            "February 21: Support for OneDrive and Google Drive feeds, extract images from PDFs, bug fixes\n",
            "New Features\n",
            "üí° Graphlit now supports OneDrive and Google Drive feeds.  Files can be ingested from OneDrive or Google Drive, including shared drives where the authenticated user has access.  Both OneDrive and Google Drive support the reading of existing files, and tracking new files added to storage with recurrent feeds.\n",
            "üí° Graphlit now supports email backup files, such as EML or MSG, which will be assigned the EMAIL file type.  During email file preparation, we will automatically extract and ingest any file attachments.\n",
            "üí° Graphlit now automatically extracts embedded images in PDF files, ingests them as content objects, and links them as children of the parent PDF.\n",
            "üí° Graphlit now supports recursive Notion feeds.  When the isRecursive flag is true in the Notion feed properties, we will crawl child pages and databases, and recursively ingest them in addition to the specified pages and databases.\n",
            "Added support for assigning collections to content ingested with the ingestPage, ingestFile or ingestText mutations.  This saves a step where the content will automatically be added to the collection(s) without requiring another mutation call.\n",
            "Added support for the CODE file type for a wide variety of source code formats, i.e. Python .py, Javascript .js.  Code files use optimized text splitting for enhanced search and retrieval.\n",
            "Added support for customGuidance in Specification object, which can be used for injecting a guidance prompt during the RAG process.  For example, you can instruct the LLM to return a default response string if no content sources are found via semantic search.\n",
            "Added tenants field to Project object, which returns a list of all tenant IDs which have been used to create an entity in Graphlit.\n",
            "Added email metadata, separate from document metadata.  Now emails will contain indexed metadata such as to, from, or subject.\n",
            "‚ö° The contents field for content objects has been replaced with children and parent fields.  For example, when a ZIP file is unpacked, the unpacked files will be added as children of the ZIP file, and the ZIP file will be the parent of each of the unpacked files.\n",
            "‚ö° Removed enableImageAnalysis field from image preparation properties in workflow object.  Now is enabled by default.\n",
            "‚ö° Moved disableSmartCapture field to preparation workflow stage from page preparation properties.  This is used to disable the use of headless Chrome browser to capture HTML from web pages.  It is enabled by default, and if disabled, Graphlit will simply download the HTML from the web page rather than rendering on headless Chrome browser.\n",
            "Bugs Fixed\n",
            "GPLA-2099: Failed to ingest ArXiV PDF.  Fixed PDF parsing error.\n",
            "GPLA-2174: LLM response is incorrect with conversation history, but no content sources.\n",
            "GPLA-2199: ZIP package left in Indexed state after content workflow.\n",
            "PreviousMarch 10: Support for Claude 3, Mistral and Groq models, usage/credits telemetry, bug fixes\n",
            "NextFebruary 2: Support for Semantic Alerts, OpenAI 0125 models, performance enhancements, bug fixes\n",
            "Last updated9 months ago\n",
            "- Completion [308 tokens (includes JSON guardrails tokens)], throughput: 78.480 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for OneDrive and Google Drive feeds, allowing ingestion of files from shared drives.\n",
            "  - Support for email backup files (EML, MSG) with automatic extraction of attachments.\n",
            "  - Automatic extraction of embedded images from PDF files, linking them as children of the parent PDF.\n",
            "  - Support for recursive Notion feeds with the isRecursive flag for crawling child pages and databases.\n",
            "  - Collections can now be assigned to ingested content automatically.\n",
            "  - Introduction of CODE file type for various source code formats with optimized text splitting.\n",
            "  - Custom guidance can be injected during the RAG process via the Specification object.\n",
            "  - Added tenants field to Project object for listing tenant IDs.\n",
            "  - Email metadata is now indexed separately from document metadata.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Contents field replaced with children and parent fields for content objects.\n",
            "  - Removed enableImageAnalysis field; now enabled by default.\n",
            "  - Moved disableSmartCapture field to preparation workflow stage, enabled by default.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed PDF parsing error for ArXiV PDFs (GPLA-2099).\n",
            "  - Corrected LLM response issues with conversation history (GPLA-2174).\n",
            "  - Resolved issue of ZIP package remaining in Indexed state after content workflow (GPLA-2199).\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: February 21, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Enhancements improve file ingestion capabilities and metadata handling, streamlining workflows for developers.\n",
            "\n",
            "2024-12-30T04:00:19.807Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:12.360238, used credits [0.00829200]\n",
            "- CONTENT [f2817947-a5aa-41d7-a297-b6f16a2d42e1]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [1224 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/december-2023/december-10-support-for-openai-gpt-4-turbo-llama-2-and-mistral-models-query-by-example-bug-fixes</name><title>December 10: Support for OpenAI GPT-4 Turbo, Llama 2 and Mistral models; query by example, bug fixes | Graphlit Changelog</title></metadata> üéÑ\tDecember 2023\n",
            "December 10: Support for OpenAI GPT-4 Turbo, Llama 2 and Mistral models; query by example, bug fixes\n",
            "New Features\n",
            "üí° Graphlit now supports the OpenAI GPT-4 Turbo 128k model, both in Azure OpenAI and native OpenAI services.  Added new model enum GPT4_TURBO_VISION_128K.\n",
            "üí° Graphlit now supports Llama 2 7b, 13b, 70b models and Mistral 7b model, via Replicate.  Developers can use their own Replicate API key, or be charged as credits for Graphlit usage.\n",
            "üí° Graphlit now supports the Anthropic Claude 2.1 model. Added new model enum CLAUDE_2_1.\n",
            "üí° Graphlit now supports the OpenAI GPT-4 Vision model for image descriptions and text extraction.  Added new model enum GPT4_TURBO_VISION_128K. See usage example in \"Multimodal RAG\" blog post.\n",
            "Added query by example to contents query.  Developers can specify one or more example contents, and query will use vector embeddings to return similar contents.\n",
            "Added query by example to conversations query.  Developers can specify one or more example conversations, and query will use vector embeddings to return similar conversations.\n",
            "Added vector search support for conversations queries.  Developers can provide search text which will use vector embeddings to return similar conversations.\n",
            "Added promptSpecifications mutation for directly prompting multiple models.  This can be used to evaluate prompts against multiple models or compare different specification parameters in parallel.\n",
            "Added promptStrategy field to Specification, which supports multiple strategy types for preprocessing the prompt before being sent to the LLM model.  For example, REWRITE prompt strategy will ask LLM to rewrite the incoming user prompt based on the previous conversation messages.\n",
            "Added suggestConversation mutation, which returns a list of suggested followup questions based on the specified conversation and related contents.  This can be used to auto-suggest questions for chatbot users.\n",
            "Added new summarization types: CHAPTERS, QUESTIONS and POSTS.   See usage examples in the \"LLMs for Podcasters\" blog post.\n",
            "Added versioned model enums such as GPT4_0613 and GPT35_TURBO_16K_1106.  Without version specified, such as GPT35_TURBO_16K, Graphlit will use the latest production model version, as defined by the LLM vendor.\n",
            "Added lookupContents query to get multiple contents by id in one query.\n",
            "‚ö° In Content type, headline field was renamed to headlines and now returns an array of strings.\n",
            "‚ö° Entity names are now limited to 1024 characters.  Names will be truncated if they exceed the maximum length.\n",
            "‚ö° In SummarizationTypes enum, BULLET_POINTS was renamed to BULLETS.\n",
            "‚ö° In ProjectStorage type, originalTotalSize was renamed to totalSize, and totalRenditionSize field was added.  totalSize is the sum of the ingested source file sizes, and totalRenditionSize is the sum of the source file sizes and any derived rendition sizes.\n",
            "‚ö° In ConversationStrategy type, strategyType was renamed to type for consistency with rest of data model.\n",
            "‚ö° In Specification type, optimizeSearchConversation was removed, and now is handled by OPTIMIZE_SEARCH prompt strategy.\n",
            "Bugs Fixed\n",
            "GPLA-1725: Should ignore RSS.xml from web feed sitemap\n",
            "GPLA-1726: GPT-3.5 Turbo 16k LLM is adding \"Citation #\" to response\n",
            "GPLA-1698: Workflow not applied to link-crawled content\n",
            "GPLA-1692: Mismatched project storage total size, when some content has errored\n",
            "GPLA-1237: Add relevance threshold for semantic search\n",
            "PreviousJanuary 18: Support for content publishing, LLM tools, CLIP image embeddings, bug fixes\n",
            "NextOctober 30: Optimized conversation responses; added observable aliases; bug fixes\n",
            "Last updated11 months ago\n",
            "- Completion [385 tokens (includes JSON guardrails tokens)], throughput: 31.148 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for OpenAI GPT-4 Turbo 128k model in Azure OpenAI and native OpenAI services.\n",
            "  - Support for Llama 2 (7b, 13b, 70b) and Mistral 7b models via Replicate.\n",
            "  - Support for Anthropic Claude 2.1 model.\n",
            "  - Support for OpenAI GPT-4 Vision model for image descriptions and text extraction.\n",
            "  - Query by example added for contents and conversations, utilizing vector embeddings.\n",
            "  - Vector search support for conversations queries.\n",
            "  - New promptSpecifications mutation for prompting multiple models.\n",
            "  - New promptStrategy field for preprocessing prompts.\n",
            "  - SuggestConversation mutation for auto-suggesting follow-up questions.\n",
            "  - New summarization types: CHAPTERS, QUESTIONS, and POSTS.\n",
            "  - Versioned model enums introduced.\n",
            "  - LookupContents query to retrieve multiple contents by ID.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Renamed headline field to headlines, returning an array of strings.\n",
            "  - Entity names limited to 1024 characters.\n",
            "  - BULLET_POINTS renamed to BULLETS in SummarizationTypes enum.\n",
            "  - ProjectStorage type fields renamed for clarity.\n",
            "  - Removed optimizeSearchConversation from Specification type, now handled by OPTIMIZE_SEARCH prompt strategy.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Ignored RSS.xml from web feed sitemap.\n",
            "  - Resolved issue with GPT-3.5 Turbo 16k LLM adding \"Citation #\" to responses.\n",
            "  - Fixed workflow application to link-crawled content.\n",
            "  - Corrected mismatched project storage total size.\n",
            "  - Added relevance threshold for semantic search.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: December 10, 2023.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced model support, improved querying capabilities, and streamlined prompt management, facilitating more efficient and effective application development.\n",
            "\n",
            "2024-12-30T04:00:16.278Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:04.582561, used credits [0.00430800]\n",
            "- CONTENT [fbde99f0-f7ca-4f5d-a318-eb7f4de07912]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [600 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/august-2024/august-20-support-for-medical-entities-anthropic-prompt-caching-bug-fixes</name><title>August 20: Support for medical entities, Anthropic prompt caching, bug fixes | Graphlit Changelog</title></metadata> üéÇ\tAugust 2024\n",
            "August 20: Support for medical entities, Anthropic prompt caching, bug fixes\n",
            "New Features\n",
            "üí° Graphlit now supports the extraction of medical-related entities: MedicalStudy, MedicalCondition, MedicalGuideline, MedicalDrug, MedicalDrugClass, MedicalIndication, MedicalContraindication, MedicalTest, MedicalDevice, MedicalTherapy, and MedicalProcedure.\n",
            "üí° Graphlit now supports medical-related entities in GraphRAG, and via API for queries and mutations.\n",
            "Added support for Anthropic prompt caching. When using Anthropic Sonnet 3.5 or Haiku 3, Anthropic will now cache the entity extraction and LLM document preparation system prompts, which saves on token cost and increases performance.\n",
            "Bugs Fixed\n",
            "GPLA-3104: Should default search type to VECTOR, when performing entity similarity filter.\n",
            "GPLA-3112: Empty PDF fails entity extraction.\n",
            "PreviousSeptember 1: Support for FHIR enrichment, latest Cohere models, bug fixes\n",
            "NextAugust 11: Support for Azure AI Document Intelligence by default, language-aware summaries\n",
            "Last updated4 months ago\n",
            "- Completion [209 tokens (includes JSON guardrails tokens)], throughput: 45.608 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for extraction of medical-related entities: MedicalStudy, MedicalCondition, MedicalGuideline, MedicalDrug, MedicalDrugClass, MedicalIndication, MedicalContraindication, MedicalTest, MedicalDevice, MedicalTherapy, and MedicalProcedure.\n",
            "  - Medical-related entities supported in GraphRAG and via API for queries and mutations.\n",
            "  - Added support for Anthropic prompt caching, improving performance and reducing token costs when using Anthropic Sonnet 3.5 or Haiku 3.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Improved entity extraction and LLM document preparation through caching.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed default search type to VECTOR for entity similarity filter (GPLA-3104).\n",
            "  - Resolved issue where empty PDFs failed entity extraction (GPLA-3112).\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: August 20, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Enhancements provide developers with improved capabilities for handling medical data and better performance in entity extraction tasks.\n",
            "\n",
            "2024-12-30T04:00:15.859Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:02.681112, used credits [0.00459000]\n",
            "- CONTENT [0932e05b-1816-4e99-a4ef-7bc475de60fc]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [690 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/february-2024/february-2-support-for-semantic-alerts-openai-0125-models-performance-enhancements-bug-fixes</name><title>February 2: Support for Semantic Alerts, OpenAI 0125 models, performance enhancements, bug fixes | Graphlit Changelog</title></metadata> üåßÔ∏è\tFebruary 2024\n",
            "February 2: Support for Semantic Alerts, OpenAI 0125 models, performance enhancements, bug fixes\n",
            "New Features\n",
            "üí° Graphlit now supports Semantic Alerts, which allows for LLM summarization and publishing of content, on a periodic basis.  This is useful for generating daily reports from email, Slack or other time-based feeds.  Alerts support the same publishing options, i.e. audio and text, as the publishContents mutation.\n",
            "üí° Graphlit now supports the latest OpenAI 0125 model versions, for GPT-4 and GPT-3.5 Turbo.  We will add support for Azure OpenAI when Microsoft releases support for these.\n",
            "Slack feeds now support a listing type field, where you can specify if you want PAST or NEW Slack messages in the feed.\n",
            "üî• This release provides many performance enhancements, which will speed up the content workflows for ingested content.\n",
            "Bugs Fixed\n",
            "GPLA-2114: Collections not being added to text embedding index documents.\n",
            "GPLA-2063: Not handling hallucinated citations.\n",
            "GPLA-1916: Collections not inherited from project-scope into tenant-scope.\n",
            "GPLA-2105: Should error on add/remove of contents to/from collections if content does not exist.\n",
            "PreviousFebruary 21: Support for OneDrive and Google Drive feeds, extract images from PDFs, bug fixes\n",
            "NextJanuary 22: Support for Google and Microsoft email feeds, reingest content in-place, bug fixes\n",
            "Last updated10 months ago\n",
            "- Completion [210 tokens (includes JSON guardrails tokens)], throughput: 78.326 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for Semantic Alerts for LLM summarization and content publishing on a periodic basis, useful for generating daily reports from various feeds.\n",
            "  - Support for OpenAI 0125 model versions for GPT-4 and GPT-3.5 Turbo, with plans to add Azure OpenAI support when available.\n",
            "  - Slack feeds now include a listing type field to specify PAST or NEW messages.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Performance enhancements to speed up content workflows for ingested content.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issues with collections not being added to text embedding index documents.\n",
            "  - Resolved handling of hallucinated citations.\n",
            "  - Addressed inheritance of collections from project-scope to tenant-scope.\n",
            "  - Implemented error handling for adding/removing contents to/from collections if content does not exist.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: February 2, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers improved content management capabilities, enhanced performance, and better error handling.\n",
            "\n",
            "2024-12-30T04:00:15.805Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:04.109440, used credits [0.00635100]\n",
            "- CONTENT [d40abe32-e564-4a6c-bd34-cea90b98c172]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [913 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/july-2023/july-15-support-for-sharepoint-feeds-new-conversation-features</name><title>July 15: Support for SharePoint feeds, new Conversation features | Graphlit Changelog</title></metadata> üéá\tJuly 2023\n",
            "July 15: Support for SharePoint feeds, new Conversation features\n",
            "New Features\n",
            "üí° Added support for SharePoint feeds: now can create feed to ingest files from SharePoint document library (and optionally, folder within document library)\n",
            "üí° Added support for PII detection during entity extraction from text documents and audio transcripts: now we will create labels such as PII: Social Security Number automatically when PII is detected\n",
            "üí° Added support for developer's own OpenAI API keys and Azure OpenAI deployments in Specifications\n",
            "‚ÑπÔ∏è  Changed semantics of deleteFeed to delete the contents ingested by the feed; since contents are linked to feeds, now feeds can be disabled, while keeping the lineage to the feed, and if feeds are deleted, they will delete the linked contents, so we never lose the feed-to-content lineage\n",
            "Added GraphQL query for SharePoint consent URI, for registered Graphlit Platform Azure AD application\n",
            "Better handling of web sitemap indexes: now if a sitemap.xml contains a sitemapindex element, we will load all linked sitemaps for evaluating web pages to ingest from Web feed\n",
            "Added new GraphQL mutations for openConversation, closeConversation and undoConversation\n",
            "Added timestamps to Conversation messages\n",
            "Added new GraphQL mutations for openCollection and closeCollection\n",
            "Added more configuration for content search: now can specify searchType (KEYWORD, VECTOR, HYBRID) and queryType (SIMPLE, FULL - aka Lucene syntax)\n",
            "Better parsing of iTunes podcast metadata\n",
            "‚ö° Renamed listingLimit field on feeds to readLimit\n",
            "‚ö° Renamed topK to numberSimilar for content vector search type\n",
            "‚ö° Changed GraphQL feed properties: split out azure into azureBlob and azureFile properties\n",
            "‚ö° Changed GraphQL specification properties: split out openAI into openAI and azureOpenAI properties\n",
            "‚ö° Removed count fields on query results, and replaced with explicit count{Entity} queries, which support search and filtering.\n",
            "Bugs Fixed\n",
            "GPLA-1043: Reddit readLimit not taking effect: now the specified limit of Reddit posts will be leveraged for Reddit feeds\n",
            "GPLA-1064: Performance on entity extraction and observation creation for large PDFs was under expectations: now able to build knowledge graph from large PDFs much faster (4x speed improvement)\n",
            "GPLA-1053: If rendition generation errored during content workflow, the content was not properly marked as errored\n",
            "GPLA-1102: Large Web sitemaps were slow to load; rewrote sitemap index handling, and now can process sitemaps with 150K+ entries in seconds.\n",
            "PreviousAugust 3: New data model for Observations, new Category entity\n",
            "Last updated5 months ago\n",
            "- Completion [301 tokens (includes JSON guardrails tokens)], throughput: 73.246 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for SharePoint feeds to ingest files from SharePoint document libraries.\n",
            "  - PII detection during entity extraction from text documents and audio transcripts, automatically labeling detected PII.\n",
            "  - Support for custom OpenAI API keys and Azure OpenAI deployments in Specifications.\n",
            "  - GraphQL query for SharePoint consent URI for registered Azure AD applications.\n",
            "  - Improved handling of web sitemap indexes to load linked sitemaps.\n",
            "  - New GraphQL mutations for managing conversations and collections.\n",
            "  - Timestamps added to Conversation messages.\n",
            "  - Enhanced content search configuration with new search and query types.\n",
            "  - Better parsing of iTunes podcast metadata.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Renamed fields for clarity: listingLimit to readLimit, topK to numberSimilar.\n",
            "  - Split GraphQL properties for Azure and OpenAI for better organization.\n",
            "  - Removed count fields on query results, replaced with explicit count queries.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed Reddit readLimit issue to ensure specified limits are applied.\n",
            "  - Improved performance for entity extraction from large PDFs (4x speed increase).\n",
            "  - Corrected error handling for rendition generation in content workflows.\n",
            "  - Enhanced loading speed for large web sitemaps, now processing 150K+ entries quickly.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: July 15, 2023.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced data ingestion capabilities, improved performance, and better management of content and conversations.\n",
            "\n",
            "2024-12-30T04:00:13.106Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:03.943238, used credits [0.00579300]\n",
            "- CONTENT [a263132e-7225-40d3-a75d-39b3ef1edbd1]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [811 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/august-2024/august-8-support-for-llm-based-document-extraction-.net-sdk-bug-fixes</name><title>August 8: Support for LLM-based document extraction, .NET SDK, bug fixes | Graphlit Changelog</title></metadata> üéÇ\tAugust 2024\n",
            "August 8: Support for LLM-based document extraction, .NET SDK, bug fixes\n",
            "New Features\n",
            "üí° Graphlit now supports LLM-based document preparation, using vision-capable models such as OpenAI GPT-4o and Anthropic Sonnet 3.5.  This is available via the MODEL_DOCUMENT preparation service type, and you can assign a customspecification object and bring your own LLM keys.\n",
            "üí° Graphlit now provides an open source .NET SDK, supporting .NET 6 and .NET 8 (and above).  SDK package can be found on Nuget.org.  Code samples can be found on GitHub.\n",
            "Added identifier property to Content object for mapping content to external database identifiers.  This is supported for content filtering as well.\n",
            "Added support for Claude 3 vision models for image-based entity extraction, using the MODEL_IMAGE entity extraction service.\n",
            "Added context augmentation to conversations, via the augmentedFilter property on the Conversation object.  Any content which matches this augmented filter will be injected into the LLM prompt content, without needing to be related by vector similarity to the user prompt.  This is useful for specifying domain knowledge which should always be referenced by the RAG pipeline.\n",
            "Added support for the latest snapshot of OpenAI GPT-4o, with the model enum GPT4O_128K_20240806.\n",
            "Added reranking of related entities, when preparing the LLM prompt context for GraphRAG.  If reranking is enabled, the metadata from the related entities will be reranked with the same reranker assigned to the conversation specification.\n",
            "‚ö° We have changed the type of the duration field in the AudioMetadata and VideoMetadata types to be TimeSpan rather than string, as to be more consistent with the rest of the API data model.\n",
            "Bugs Fixed\n",
            "GPLA-2884: Support retry on HTTP 529 (Overloaded) error from Anthropic API.\n",
            "PreviousAugust 11: Support for Azure AI Document Intelligence by default, language-aware summaries\n",
            "NextJuly 28: Support for indexing workflow stage, Azure AI language detection, bug fixes\n",
            "Last updated4 months ago\n",
            "- Completion [280 tokens (includes JSON guardrails tokens)], throughput: 71.008 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for LLM-based document preparation using models like OpenAI GPT-4o and Anthropic Sonnet 3.5 via MODEL_DOCUMENT service.\n",
            "  - Introduction of an open source .NET SDK for .NET 6 and .NET 8, available on Nuget.org with code samples on GitHub.\n",
            "  - Added identifier property to Content object for mapping to external database identifiers, aiding in content filtering.\n",
            "  - Support for Claude 3 vision models for image-based entity extraction using MODEL_IMAGE service.\n",
            "  - Context augmentation in conversations via augmentedFilter property, allowing injection of domain knowledge into LLM prompts.\n",
            "  - Support for the latest snapshot of OpenAI GPT-4o (model enum GPT4O_128K_20240806).\n",
            "  - Reranking of related entities for LLM prompt context preparation in GraphRAG.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Changed duration field type in AudioMetadata and VideoMetadata from string to TimeSpan for consistency in API data model.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issue GPLA-2884 to support retry on HTTP 529 (Overloaded) error from Anthropic API.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: August 8, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced capabilities for document extraction, improved SDK support, and better content management features.\n",
            "\n",
            "2024-12-30T04:00:11.622Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:04.534649, used credits [0.00505500]\n",
            "- CONTENT [257dc6c9-65d0-416d-9b1c-d412aeb42bd4]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [737 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/june-2024/june-21-support-for-the-claude-3.5-sonnet-model-knowledge-graph-semantic-search-and-bug-fixes</name><title>June 21: Support for the Claude 3.5 Sonnet model, knowledge graph semantic search, and bug fixes | Graphlit Changelog</title></metadata> üéì\tJune 2024\n",
            "June 21: Support for the Claude 3.5 Sonnet model, knowledge graph semantic search, and bug fixes\n",
            "New Features\n",
            "üí° Graphlit now supports the Anthropic Claude 3.5 Sonnet model, which can be assigned with the CLAUDE_3_5_SONNET model enum.\n",
            "üí° Graphlit now supports semantic search of observable entities in the knowledge graph, such as Person, Organization and Place.  These entity types will now have vector embeddings created from their enriched metadata, and support searching by similar text, and searching by similar entities.\n",
            "‚ö° We have changed the Google Drive and Google Email feed properties to require the Google OAuth client ID and client secret, along with the existing refresh token, for proper authentication against Google APIs.\n",
            "‚ö° We have added a credits quota on the Free Tier.  Once 1000 credits have been used on the Free Tier, no more content can be ingested, and an upgrade to a paid tier is required.  Customers will receive an email when the credits, storage or contents quota has been reached.\n",
            "Bugs Fixed\n",
            "GPLA-2837: Failed to ingest LinkedIn page as Web feed\n",
            "GPLA-2831: Zero-byte file was left in Indexed state\n",
            "GPLA-2834: Not reading any files from Azure blob feed with space in prefix\n",
            "GPLA-2828: Better handling for files with unknown (or missing) file extensions\n",
            "PreviousJuly 4: Support for webhook Alerts, keywords summarization, Deepseek 128k context window, bug fixes\n",
            "NextJune 9: Support for Deepseek models, JSON-LD webpage parsing, performance improvements and bug fixes\n",
            "Last updated6 months ago\n",
            "- Completion [237 tokens (includes JSON guardrails tokens)], throughput: 52.264 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for the Anthropic Claude 3.5 Sonnet model (model enum: CLAUDE_3_5_SONNET).\n",
            "  - Semantic search for observable entities in the knowledge graph (Person, Organization, Place) with vector embeddings for enriched metadata.\n",
            "  - Google Drive and Google Email feed properties now require Google OAuth client ID, client secret, and refresh token for authentication.\n",
            "  - Introduction of a credits quota on the Free Tier; ingestion stops after 1000 credits, requiring an upgrade to a paid tier.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Improved authentication process for Google APIs.\n",
            "  - Notification system for Free Tier users when credits, storage, or content quotas are reached.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Resolved issues with ingesting LinkedIn pages, handling zero-byte files, reading files from Azure blob feeds with spaces, and better handling of files with unknown or missing extensions.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: June 21, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Enhancements provide developers with improved model support, better search capabilities, and clearer usage limits, facilitating more efficient application development.\n",
            "\n",
            "2024-12-30T04:00:11.612Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:04.447924, used credits [0.00474300]\n",
            "- CONTENT [7c8442ac-7d94-4a40-9a3b-fdda07048992]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [673 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/january-2024/january-22-support-for-google-and-microsoft-email-feeds-reingest-content-in-place-bug-fixes</name><title>January 22: Support for Google and Microsoft email feeds, reingest content in-place, bug fixes | Graphlit Changelog</title></metadata> üéÜ\tJanuary 2024\n",
            "January 22: Support for Google and Microsoft email feeds, reingest content in-place, bug fixes\n",
            "New Features\n",
            "üí° Graphlit now supports Google and Microsoft email feeds.  Email feeds can be created to ingest past emails, or poll for new emails.  Emails create an EMAIL content type. Attachment files can optionally be extracted from emails, and will be linked to their parent email content. If assigning a workflow to the feed, the workflow will be applied both to the email content and the extracted attachment files.\n",
            "üí° Graphlit now supports reingesting content in-place.  The ingestText, ingestPage and ingestFile mutations now take an optional id parameter for an existing content object.  If this id is provided, the existing content will be updated from the provided text or URI source, and will restart the assigned workflow.\n",
            "Added restartAllContents mutation to restart workflow on all partially-ingested contents in project.\n",
            "Added text field to ConversationCitation type, which returns the relevant text from the content source with the citation.\n",
            "Bugs Fixed\n",
            "GPLA-1313: Not extracting links from HTML\n",
            "GPLA-2030: No text extracted from shapes in PPTX files\n",
            "PreviousFebruary 2: Support for Semantic Alerts, OpenAI 0125 models, performance enhancements, bug fixes\n",
            "NextJanuary 18: Support for content publishing, LLM tools, CLIP image embeddings, bug fixes\n",
            "Last updated8 months ago\n",
            "- Completion [227 tokens (includes JSON guardrails tokens)], throughput: 51.035 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for Google and Microsoft email feeds, allowing ingestion of past and new emails, creating an EMAIL content type. Attachments can be extracted and linked to their parent emails.\n",
            "  - Support for reingesting content in-place with optional id parameter for existing content objects, updating them from provided text or URI source, and restarting the assigned workflow.\n",
            "  - Added restartAllContents mutation to restart workflows on all partially-ingested contents in a project.\n",
            "  - Added text field to ConversationCitation type to return relevant text from the content source with the citation.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Improved content ingestion capabilities with new features for email and content updates.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issue with links not being extracted from HTML (GPLA-1313).\n",
            "  - Resolved problem of no text being extracted from shapes in PPTX files (GPLA-2030).\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: January 22, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced content ingestion options and improved workflow management, increasing efficiency in handling email and content updates.\n",
            "\n",
            "2024-12-30T04:00:09.072Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:03.335979, used credits [0.00457800]\n",
            "- CONTENT [0ed6b24e-fec6-4008-8bb9-beda6073cbe6]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [710 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/july-2024/july-25-support-for-mistral-large-2-and-nemo-groq-llama-3.1-models-bug-fixes</name><title>July 25: Support for Mistral Large 2 & Nemo, Groq Llama 3.1 models, bug fixes | Graphlit Changelog</title></metadata> ‚òÄÔ∏è\tJuly 2024\n",
            "July 25: Support for Mistral Large 2 & Nemo, Groq Llama 3.1 models, bug fixes\n",
            "New Features\n",
            "üí° Graphlit now supports the Mistral Large 2 and Mistral Nemo models. The existing MISTRAL_LARGE model enum now will use Mistral Large 2.\n",
            "üí° Graphlit now supports the Llama 3.1 8b, 70b and 405b models on Groq.  (Note, these are rate-limited according to Groq's platform constraints.)\n",
            "Added support for revision strategy on data extraction specifications.  Now you can prompt the LLM to revise its previous data extraction response, similar to the existing completion revision strategy.\n",
            "Added version property for AzureDocumentPreparationProperties type for assigning the API version used by Azure AI Document Intelligence.   By default, Graphlit will continue to use the v4.0 (Preview) API version, but you can override this to assign version to V2023_10_31 to use the v3.1 (GA) API version instead.  For some documents, the General Availability (GA) version of the API can provide better results.\n",
            "Bugs Fixed\n",
            "GPLA-2988: Not extracting hyperlinks from Office documents.\n",
            "PreviousJuly 28: Support for indexing workflow stage, Azure AI language detection, bug fixes\n",
            "NextJuly 19: Support for OpenAI GPT-4o Mini, BYO-key for Azure AI, similarity by summary, bug fixes\n",
            "Last updated5 months ago\n",
            "- Completion [204 tokens (includes JSON guardrails tokens)], throughput: 61.151 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for Mistral Large 2 and Mistral Nemo models; existing MISTRAL_LARGE model enum updated.\n",
            "  - Support for Llama 3.1 models (8b, 70b, 405b) on Groq, with rate limits per Groq's platform.\n",
            "  - Added revision strategy for data extraction specifications, allowing LLM to revise previous responses.\n",
            "  - Version property added for AzureDocumentPreparationProperties to assign API version for Azure AI Document Intelligence; default is v4.0 (Preview), can override to V2023_10_31 for v3.1 (GA) API version.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issue with hyperlinks not being extracted from Office documents (GPLA-2988).\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: July 25, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Enhancements improve model support and data extraction capabilities, offering developers more flexibility and better results with Azure AI.\n",
            "\n",
            "2024-12-30T04:00:07.411Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:05.235411, used credits [0.00686400]\n",
            "- CONTENT [8a9c0eb5-3658-4cca-bf2c-d68cdbea3f15]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [1012 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/may-2024/may-15-support-for-graphrag-openai-gpt-4o-model-performance-improvements-and-bug-fixes</name><title>May 15: Support for GraphRAG, OpenAI GPT-4o model, performance improvements and bug fixes | Graphlit Changelog</title></metadata> üíê\tMay 2024\n",
            "May 15: Support for GraphRAG, OpenAI GPT-4o model, performance improvements and bug fixes\n",
            "New Features\n",
            "üí° Graphlit now supports GraphRAG, where the extracted entities in the knowledge graph can be added as additional context to your RAG con,versation.  Also, with GraphRAG, entities can be extracted from the user prompt, and used as additional content filters - or can be used to query related content sources, which are combined with the vector search results.  This can be configured by specifying your graphStrategy in the Specification object.\n",
            "üí° Graphlit now supports LLM revisions within RAG conversations, where the LLM can be prompted to revise its initial completion response. From our testing, this has been shown to provide 35% more output tokens with higher quality responses.  This can be configured by specifying your revisionStrategy, and you can use our built-in revision prompt, or provide a custom one, and specify how many revisions you want the LLM to make.\n",
            "üí° Graphlit now supports the new OpenAI GPT-4o model for RAG conversations.\n",
            "‚ö° We have changed the default model for Conversations to be OpenAI GPT-4o, from Azure OpenAI GPT-3.5 16k.  This provides faster performance and better quality output.\n",
            "Added graph to promptConversation response, so you can visualize or leverage the nodes and edges of the knowledge graph, resulting from the content retrieval.  For example, if a Person and Organization were observed in the cited content sources used by the RAG pipeline, you will get back those entities and their relationship (such as Person 'works-for' Organization).\n",
            "Expanded the enriched data from WIkipedia to include the long description of an entity.\n",
            "Added getSharePointLibraries, getSharePointFolders, and getOneDriveFolders queries to the API, which can be used to enumerate the storage services.  This makes locating the SharePoint libraryId easier, for example.\n",
            "Added getTeams and getTeamsChannels queries to the API for enumerating Microsoft Teams workspaces.\n",
            "Added extractedCount to the entity extraction connector to limit the number of extracted entities, per entity type.  I.e. if extracted count is 10, it will extract at most ten each of Persons, Organizations, etc.\n",
            "üî•  We have improved performance in several areas: creation of observations after entity extraction, access to cloud storage, rendering the RAG context.\n",
            "üî•  We have optimized the LLM entity extraction process to identify more properties, as well as entity-to-entity relationships.\n",
            "Bugs Fixed\n",
            "GPLA-2652: Not extracting text from HTML in RSS post\n",
            "GPLA-2627: Limit filter only returning half the results\n",
            "GPLA-2613: Not properly extracting structured text from JSON/XML formats\n",
            "PreviousJune 9: Support for Deepseek models, JSON-LD webpage parsing, performance improvements and bug fixes\n",
            "NextMay 5: Support for Jina and Pongo rerankers, Microsoft Teams feed, new YouTube downloader, bug fixes\n",
            "Last updated6 months ago\n",
            "- Completion [319 tokens (includes JSON guardrails tokens)], throughput: 60.931 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for GraphRAG, allowing extracted entities to be added as context in RAG conversations and used as content filters.\n",
            "  - LLM revisions in RAG conversations, enabling the LLM to revise initial responses, resulting in 35% more output tokens and higher quality.\n",
            "  - Support for OpenAI GPT-4o model in RAG conversations.\n",
            "  - Default model for Conversations changed to OpenAI GPT-4o for improved performance and output quality.\n",
            "  - Added graph visualization in promptConversation responses to show relationships between entities.\n",
            "  - Expanded enriched data from Wikipedia to include long descriptions of entities.\n",
            "  - New API queries: getSharePointLibraries, getSharePointFolders, getOneDriveFolders for easier storage service enumeration.\n",
            "  - New API queries: getTeams and getTeamsChannels for enumerating Microsoft Teams workspaces.\n",
            "  - Added extractedCount to limit the number of extracted entities per type.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Performance improvements in entity extraction, cloud storage access, and RAG context rendering.\n",
            "  - Optimized LLM entity extraction to identify more properties and relationships.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issues with text extraction from HTML in RSS posts, limit filter returning incomplete results, and structured text extraction from JSON/XML formats.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: May 15, 2024.\n",
            "  - Default model updated to OpenAI GPT-4o.\n",
            "\n",
            "- Value:\n",
            "  - Enhancements provide developers with improved performance, better quality responses, and more efficient entity extraction and management capabilities.\n",
            "\n",
            "2024-12-30T04:00:07.037Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:02.397342, used credits [0.00438000]\n",
            "- CONTENT [4b9dad6a-8d6f-4daa-b1d9-6c5277939931]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [640 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/july-2024/july-28-support-for-indexing-workflow-stage-azure-ai-language-detection-bug-fixes</name><title>July 28: Support for indexing workflow stage, Azure AI language detection, bug fixes | Graphlit Changelog</title></metadata> ‚òÄÔ∏è\tJuly 2024\n",
            "July 28: Support for indexing workflow stage, Azure AI language detection, bug fixes\n",
            "New Features\n",
            "Added indexing workflow stage. This provides for configuration of indexing services, which may infer metadata from the content.\n",
            "Added AZURE_AI_LANGUAGE content indexing service, which supports inferring the language of extracted text or transcript.\n",
            "Added support for language content metadata.  This returns a list of languages in ISO 639-1 format, which may have been inferred from the extracted text or transcript.\n",
            "Added support for MODEL_IMAGE extraction service.  This provides integration with vision models beyond those provided by OpenAI.  You can assign a custom specification and bring-your-own API key for image extraction models.\n",
            "‚ö° We have deprecated the OPENAI_IMAGE service type, and developers should now use the LLM image service instead.\n",
            "‚ö° We have removed the language field from AudioMetadata type, which has been replaced by the new LanguageMetadata type.\n",
            "Bugs Fixed\n",
            "GPLA-2987: Extracting text with Azure Doc Intelligence does not extract hyperlinks\n",
            "PreviousAugust 8: Support for LLM-based document extraction, .NET SDK, bug fixes\n",
            "NextJuly 25: Support for Mistral Large 2 & Nemo, Groq Llama 3.1 models, bug fixes\n",
            "Last updated5 months ago\n",
            "- Completion [205 tokens (includes JSON guardrails tokens)], throughput: 85.511 tokens/sec:\n",
            "- New Features:\n",
            "  - Added indexing workflow stage for configuring indexing services to infer metadata from content.\n",
            "  - Introduced AZURE_AI_LANGUAGE content indexing service for inferring language from extracted text or transcripts.\n",
            "  - Supported language content metadata returning a list of languages in ISO 639-1 format.\n",
            "  - Added MODEL_IMAGE extraction service for integration with various vision models, allowing custom specifications and API keys.\n",
            "  - Deprecated OPENAI_IMAGE service type; developers should use LLM image service instead.\n",
            "  - Removed language field from AudioMetadata type, replaced with new LanguageMetadata type.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Improved configuration options for indexing services and language detection.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issue GPLA-2987 where Azure Doc Intelligence did not extract hyperlinks from text.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: July 28, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced capabilities for content indexing, language detection, and image extraction, improving overall functionality and flexibility.\n",
            "\n",
            "2024-12-30T04:00:06.995Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:02.510388, used credits [0.00504600]\n",
            "- CONTENT [41e9b6e8-c479-4416-8ec3-7168709d2861]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [730 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/july-2024/july-4-support-for-webhook-alerts-keywords-summarization-deepseek-128k-context-window-bug-fixes</name><title>July 4: Support for webhook Alerts, keywords summarization, Deepseek 128k context window, bug fixes | Graphlit Changelog</title></metadata> ‚òÄÔ∏è\tJuly 2024\n",
            "July 4: Support for webhook Alerts, keywords summarization, Deepseek 128k context window, bug fixes\n",
            "New Features\n",
            "üí° Graphlit now supports webhook Alerts.  In addition to Slack notifications, you can now receive an HTTP POST webhook with the results of the published text (or text and audio URI) from a prompted alert.\n",
            "Updated the Deepseek chat and coder models to support a 128k token context window.\n",
            "Added customSummary property to Content object, which returns the custom summary generated via preparation workflow.\n",
            "Added keywords summarization type, which is now stored in keywords property in Content object.\n",
            "Added slackChannels query, which returns the list of Slack channels from the workspace authenticated by the Slack bot token.\n",
            "‚ö° We have changed the response from the credits query to return a single ProjectCredits object, rather than the list of correlated objects previously returned.  The credits response now covers all credit usage over the time period specified.\n",
            "Bugs Fixed\n",
            "GPLA-2874: Processing entities is taking longer than 30min for 300+ page PDF\n",
            "GPLA-2875: Messages in queue expiring too early\n",
            "GPLA-2881: Feed read count increasing, after hitting read limit\n",
            "GPLA-2884: Need to handle Anthropic 'overloaded' API response\n",
            "GPLA-2906: JIRA issue identifier not assigned to issue metadata\n",
            "PreviousJuly 19: Support for OpenAI GPT-4o Mini, BYO-key for Azure AI, similarity by summary, bug fixes\n",
            "NextJune 21: Support for the Claude 3.5 Sonnet model, knowledge graph semantic search, and bug fixes\n",
            "Last updated5 months ago\n",
            "- Completion [238 tokens (includes JSON guardrails tokens)], throughput: 94.806 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for webhook Alerts, allowing HTTP POST notifications with published text results.\n",
            "  - Updated Deepseek models to support a 128k token context window.\n",
            "  - Added customSummary property to Content object for custom summaries.\n",
            "  - Introduced keywords summarization type, stored in the keywords property of Content object.\n",
            "  - Added slackChannels query to list Slack channels from the authenticated workspace.\n",
            "  - Changed credits query response to return a single ProjectCredits object covering all credit usage.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Improved response structure for credits query.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Resolved issue with processing entities taking longer than 30 minutes for large PDFs.\n",
            "  - Fixed early expiration of messages in the queue.\n",
            "  - Addressed incorrect feed read count after hitting the read limit.\n",
            "  - Handled Anthropic 'overloaded' API response.\n",
            "  - Assigned JIRA issue identifier to issue metadata.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: July 4, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Enhancements improve notification capabilities, context handling, and data summarization, offering developers more efficient tools for managing alerts and content processing.\n",
            "\n",
            "2024-12-30T04:00:05.632Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:03.440579, used credits [0.00454800]\n",
            "- CONTENT [3d78b65e-a42d-44e9-8a9a-07faf938ee0d]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [700 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/march-2024/march-23-support-for-linear-github-issues-and-jira-issue-feeds-ingest-files-via-web-feed-sitemap</name><title>March 23: Support for Linear, GitHub Issues and Jira issue feeds, ingest files via Web feed sitemap | Graphlit Changelog</title></metadata> üçÄ\tMarch 2024\n",
            "March 23: Support for Linear, GitHub Issues and Jira issue feeds, ingest files via Web feed sitemap\n",
            "New Features\n",
            "üí° Graphlit now supports Linear, GitHub Issues and Atlassian Jira feeds.  Graphlit will ingest issues (aka tasks, stories) from these issue-tracking services as individual content items, which will be made searchable and conversational.\n",
            "üí° Added support for ISSUEcontent type, which includes metadata such as title, authors, commenters, status, type, project and team.\n",
            "üí° Added support for default feed read limit.  Now, if you don't specify the readLimit property on feeds, it will default to reading 100 content items.  You can override this default by assigning a custom read limit, which has no upper bounds.  However, one-shot feeds much complete within 15 minutes, or they will be stopped automatically.\n",
            "Added support for ingesting files referenced in a Web sitemap.  Previously any files (i.e. PDF, MP3) referenced in a sitemap.xml would be ignored.  Now you can optionally enable includeFiles in the WebFeedPropertiesInput object to have Graphlit ingest non-HTML pages as part of the Web feed.\n",
            "Bugs Fixed\n",
            "GPLA-2374: Failed to ingest MP4 with large XMP metadata.\n",
            "PreviousApril 7: Support for Discord feeds, Cohere reranking, section-aware chunking and retrieval\n",
            "NextMarch 13: Support for Claude 3 Haiku model, direct ingestion of Base64 encoded files\n",
            "Last updated8 months ago\n",
            "- Completion [204 tokens (includes JSON guardrails tokens)], throughput: 59.292 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for Linear, GitHub Issues, and Atlassian Jira feeds, allowing ingestion of issues as searchable content items.\n",
            "  - Introduction of ISSUE content type with metadata including title, authors, commenters, status, type, project, and team.\n",
            "  - Default feed read limit set to 100 content items, customizable with no upper bounds; one-shot feeds must complete within 15 minutes.\n",
            "  - Support for ingesting files referenced in a Web sitemap, enabling non-HTML pages to be included.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Improved handling of files in Web sitemaps, allowing for ingestion of various file types.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issue GPLA-2374 related to failing to ingest MP4 files with large XMP metadata.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: March 2024.\n",
            "  \n",
            "- Value:\n",
            "  - Enhances developers' ability to integrate and manage issue tracking data, improving searchability and content management capabilities.\n",
            "\n",
            "2024-12-30T04:00:04.510Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:09.356961, used credits [0.00682200]\n",
            "- CONTENT [fc169406-76bc-479f-93f2-0c1b1ba4277e]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [894 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/june-2024/june-9-support-for-deepseek-models-json-ld-webpage-parsing-performance-improvements-and-bug-fixes</name><title>June 9: Support for Deepseek models, JSON-LD webpage parsing, performance improvements and bug fixes | Graphlit Changelog</title></metadata> üéì\tJune 2024\n",
            "June 9: Support for Deepseek models, JSON-LD webpage parsing, performance improvements and bug fixes\n",
            "New Features\n",
            "üí° Graphlit now supports Deepseek LLMs for prompt completion.  We offer the deepseek-chat and deepseek-coder models.\n",
            "üí° Graphlit now supports parsing embedded JSON-LD from web pages.  If a web page contains 'script' tags with JSON-LD, we will automatically parse and inject into the knowledge graph.\n",
            "‚ö° We have changed the default model for entity extraction and image completions to be OpenAI GPT-4o.  This provides faster performance and better quality output.\n",
            "‚ö° We have changed the behavior of knowledge graph generation, from a prompted conversation, to be opt-in.  In order to receive the graph's nodes and edges with the response, you will now need to set generateGraph to True in the specification's graphStrategy object.  This provides improved performance when the graph is not needed for visualization.\n",
            "Added thing property for observable entities, which returns the JSON-LD metadata associated with the entity.\n",
            "Added regex-based filtering for URI paths during feed ingestion, link crawling, and workflow filtering.  You can assign regex patterns in allowedPaths and excludedPaths.\n",
            "Added observableLimit to configure the limit of how many observed entities will be added to the GraphRAG context, defaults to 1000.\n",
            "Added prompt to suggestConversation mutation, which allows customization of the followup question generation.\n",
            "Updated suggestConversation to incorporate the past conversation message history, in addition to the filtered set of content sources.\n",
            "üî•  We have improved performance in knowledge graph retrieval and generation, via better parallelization and batching.\n",
            "Bugs Fixed\n",
            "GPLA-2748: Optimize the retrieval performance of observed entities during GraphRAG\n",
            "GPLA-2732: Invalid user-provided URI causing parsing exception\n",
            "GPLA-2666: Shouldn't require tenant ID for Microsoft email or Teams\n",
            "GPLA-2772: Not returning labels or categories from graph in API\n",
            "GPLA-2762: Failed to extract spreadsheet images\n",
            "GPLA-2687: Email to/from not getting added as observations on emails\n",
            "GPLA-2738: API is returning 'audio' metadata from podcast HTML document\n",
            "PreviousJune 21: Support for the Claude 3.5 Sonnet model, knowledge graph semantic search, and bug fixes\n",
            "NextMay 15: Support for GraphRAG, OpenAI GPT-4o model, performance improvements and bug fixes\n",
            "Last updated6 months ago\n",
            "- Completion [345 tokens (includes JSON guardrails tokens)], throughput: 36.871 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for Deepseek LLMs for prompt completion (deepseek-chat and deepseek-coder models).\n",
            "  - Parsing of embedded JSON-LD from web pages, automatically injecting into the knowledge graph.\n",
            "  - Default model for entity extraction and image completions changed to OpenAI GPT-4o for improved performance and quality.\n",
            "  - Knowledge graph generation behavior changed to opt-in; requires setting generateGraph to True for response inclusion.\n",
            "  - Added thing property for observable entities to return associated JSON-LD metadata.\n",
            "  - Regex-based filtering for URI paths during feed ingestion and workflow filtering.\n",
            "  - Added observableLimit to configure the number of observed entities in GraphRAG context (default 1000).\n",
            "  - Customization of follow-up question generation via prompt in suggestConversation mutation.\n",
            "  - Updated suggestConversation to include past conversation message history.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Improved performance in knowledge graph retrieval and generation through better parallelization and batching.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Optimized retrieval performance of observed entities during GraphRAG.\n",
            "  - Fixed parsing exception caused by invalid user-provided URI.\n",
            "  - Removed requirement for tenant ID for Microsoft email or Teams.\n",
            "  - Resolved issue of not returning labels or categories from graph in API.\n",
            "  - Fixed failure to extract spreadsheet images.\n",
            "  - Addressed issue of email to/from not being added as observations.\n",
            "  - Corrected API returning 'audio' metadata from podcast HTML documents.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: June 9, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced capabilities for model support, improved performance, and better handling of data through new features and bug fixes.\n",
            "\n",
            "2024-12-30T04:00:04.400Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:06.033964, used credits [0.00700500]\n",
            "- CONTENT [1bc9cf17-e156-441d-a307-def6a31d693e]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [947 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/may-2024/may-5-support-for-jina-and-pongo-rerankers-microsoft-teams-feed-new-youtube-downloader-bug-fixes</name><title>May 5: Support for Jina and Pongo rerankers, Microsoft Teams feed, new YouTube downloader, bug fixes | Graphlit Changelog</title></metadata> üíê\tMay 2024\n",
            "May 5: Support for Jina and Pongo rerankers, Microsoft Teams feed, new YouTube downloader, bug fixes\n",
            "New Features\n",
            "üí° Graphlit now supports the Jina reranker and Pongo semantic filtering (reranking), in the Specification object.  Now you can choose between COHERE, PONGO and JINA for your reranking serviceType.\n",
            "üí° Graphlit now supports Microsoft Teams feeds for reading messages from Teams channels.\n",
            "Given changes in YouTube video player HTML, we have rewritten the YouTube downloader to support the new page format.\n",
            "Added better handling of HTTP errors when validating URIs.  Previously some websites were returning HTTP 403 (Forbidden) errors when validating their URI, or downloading content.  Now Graphlit is able to scrape these sites, which previously returned errors.\n",
            "Added support for updating content metadata in updateContent mutation.  Now the video, audio, document, etc. metadata can be updated after the content workflow has finished.\n",
            "Added query_contents_graph (and queryContentsGraph) functions to SDKs, which can be used to return nodes and edges from knowledge graph for visualization.\n",
            "‚ö° Citation indices have been changed to be one-based from zero-based.  For example, you will now see \"This is a citation. [1]\" as the first citation in the list.\n",
            "‚ö° Added isSynchronous flag to deleteAll and multiple delete mutations.  By default, bulk delete operations are now asynchronous (and completed after the mutation returns), unless the isSynchronous flag is set to true.\n",
            "‚ö° Added missing count mutations, such as countAlerts, countFeeds, etc.\n",
            "‚ö° Renamed query_content_facets to query_contents_facets in Python SDK\n",
            "‚ö° Renamed queryContentFacets to queryContentsFacets in Node.js SDK\n",
            "Bugs Fixed\n",
            "GPLA-2544: Page relevance not filled-in in all situations\n",
            "GPLA-2546: Not extracting links from PDF with Azure AI Doc Intelligence\n",
            "GPLA-2557: Sporadically returning HTTP 500 from GraphQL API\n",
            "GPLA-2573: Failed to re-ingest content which was deleted immediately after initial ingestion\n",
            "GPLA-2575: Not validating for empty (non-null) parameters in mutations\n",
            "GPLA-2578: Need to handle invalid JSON from LLMs; improper escaping or formatting\n",
            "GPLA-2585: Failed to ingest encoded file with colon (:) in name\n",
            "PreviousMay 15: Support for GraphRAG, OpenAI GPT-4o model, performance improvements and bug fixes\n",
            "NextApril 23: Support for Python and TypeScript SDKs, latest OpenAI, Cohere & Groq models, bug fixes\n",
            "Last updated7 months ago\n",
            "- Completion [347 tokens (includes JSON guardrails tokens)], throughput: 57.508 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for Jina and Pongo rerankers in the Specification object; options for COHERE, PONGO, and JINA as reranking service types.\n",
            "  - Microsoft Teams feeds integration for reading messages from Teams channels.\n",
            "  - Rewritten YouTube downloader to accommodate changes in YouTube video player HTML.\n",
            "  - Improved handling of HTTP errors for URI validation and content downloading.\n",
            "  - Support for updating content metadata in updateContent mutation post-workflow.\n",
            "  - Introduction of query_contents_graph functions for knowledge graph visualization.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Citation indices changed from zero-based to one-based.\n",
            "  - Added isSynchronous flag for deleteAll and multiple delete mutations; default is asynchronous.\n",
            "  - Added missing count mutations (e.g., countAlerts, countFeeds).\n",
            "  - Renamed query_content_facets to query_contents_facets in Python SDK.\n",
            "  - Renamed queryContentFacets to queryContentsFacets in Node.js SDK.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Resolved issues with page relevance not being filled in.\n",
            "  - Fixed link extraction from PDFs using Azure AI Doc Intelligence.\n",
            "  - Addressed sporadic HTTP 500 errors from GraphQL API.\n",
            "  - Fixed re-ingestion failures for content deleted immediately after initial ingestion.\n",
            "  - Implemented validation for non-null parameters in mutations.\n",
            "  - Handled invalid JSON from LLMs with proper escaping/formatting.\n",
            "  - Fixed ingestion of encoded files with colons in names.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: May 5, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Enhancements provide developers with more flexible content management and improved error handling, facilitating better integration and user experience.\n",
            "\n",
            "2024-12-30T04:00:02.135Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:04.762068, used credits [0.00560400]\n",
            "- CONTENT [2dd30528-0956-4c46-9a9c-8ce6ecc9931e]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [812 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/october-2024/october-21-support-openai-cohere-jina-mistral-voyage-and-google-ai-embedding-models</name><title>October 21: Support OpenAI, Cohere, Jina, Mistral, Voyage and Google AI embedding models | Graphlit Changelog</title></metadata> üéÉ\tOctober 2024\n",
            "October 21: Support OpenAI, Cohere, Jina, Mistral, Voyage and Google AI embedding models\n",
            "New Features\n",
            "üí° Graphlit now supports the configuration of image and text embedding models, at the Project level.  You can create an embedding specification for a text or image embedding model, and then assign that to the Project, and all further embedding requests will use that embedding model.  See this Colab notebook for an example of how to configure the project.\n",
            "üí° Graphlit now supports the OpenAI Embedding-3-Small and Embedding-3-Large, Cohere Embed 3.0, Jina Embed 3.0, Mistral Embed, and Voyage 2.0 and 3.0 text embedding models.  Graphlit also now supports Jina CLIP image embeddings, which are used by default for image search.\n",
            "Graphlit now supports the chunkTokenLimit property in Specifications, which specifies the number of tokens for each embedded text chunk.  If this is not configured, Graphlit uses 600 tokens for each embedded text chunk.\n",
            "Graphlit now supports the Voyage reranking model.\n",
            "Graphlit now supports the ingestTextBatch mutation, which accepts an array of text and name pairs, and will asynchronously ingest these into content objects.\n",
            "‚ö° We have moved the chunkTokenLimit property from the Workflow storage embeddings strategy to the Specification object.  The Workflow storage property has now been deprecated.\n",
            "‚ö° We have deprecated the openAIImage property from Workflow entity extraction properties. Use the modelImage property instead.\n",
            "Once a text embedding model has been updated at the project level, any content, conversations or observed entities will no longer be semantically searchable.\n",
            "Text embeddings are not compatible across models, so you will need to delete and reingest any content, or recreate conversations or knowledge graph entities, with the new embedding model to become searchable.\n",
            "PreviousOctober 22: Support for latest Anthropic Sonnet 3.5 model, Cohere image embeddings\n",
            "NextOctober 9: Support for GitHub repository feeds, bug fixes\n",
            "Last updated2 months ago\n",
            "- Completion [264 tokens (includes JSON guardrails tokens)], throughput: 55.438 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for configuring image and text embedding models at the Project level.\n",
            "  - Support for OpenAI Embedding-3-Small, Embedding-3-Large, Cohere Embed 3.0, Jina Embed 3.0, Mistral Embed, and Voyage 2.0 and 3.0 text embedding models.\n",
            "  - Support for Jina CLIP image embeddings for image search.\n",
            "  - Introduction of chunkTokenLimit property in Specifications for embedded text chunk token count.\n",
            "  - Support for Voyage reranking model.\n",
            "  - New ingestTextBatch mutation for asynchronous ingestion of text and name pairs.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Moved chunkTokenLimit property from Workflow storage to Specification object; Workflow storage property deprecated.\n",
            "  - Deprecated openAIImage property; use modelImage property instead.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Text embedding models must be updated at the project level for content, conversations, or observed entities to be semantically searchable. Incompatibility across models requires deletion and reingestion of content.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: October 2024.\n",
            "  - Breaking changes related to text embeddings and project-level updates.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced flexibility in embedding model configuration and improved ingestion capabilities.\n",
            "\n",
            "2024-12-30T04:00:02.046Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:01.879623, used credits [0.00313500]\n",
            "- CONTENT [b682b0ca-255c-4b02-b016-cb56f05edb64]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [549 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/march-2024/march-13-support-for-claude-3-haiku-model-direct-ingestion-of-base64-encoded-files</name><title>March 13: Support for Claude 3 Haiku model, direct ingestion of Base64 encoded files | Graphlit Changelog</title></metadata> üçÄ\tMarch 2024\n",
            "March 13: Support for Claude 3 Haiku model, direct ingestion of Base64 encoded files\n",
            "New Features\n",
            "üí° Graphlit now supports the Claude 3 Haiku model.\n",
            "Added support for direct ingestion of Base64 encoded files with the ingestEncodedFile mutation.  You can pass a Base64 encoded string and MIME type of the file, and it will be ingested into the Graphlit Platform.\n",
            "Added modelService and model properties to ConversationMessage type, which return the model service and model which was used for the LLM completion.\n",
            "PreviousMarch 23: Support for Linear, GitHub Issues and Jira issue feeds, ingest files via Web feed sitemap\n",
            "NextMarch 10: Support for Claude 3, Mistral and Groq models, usage/credits telemetry, bug fixes\n",
            "Last updated8 months ago\n",
            "- Completion [124 tokens (includes JSON guardrails tokens)], throughput: 65.971 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for Claude 3 Haiku model.\n",
            "  - Direct ingestion of Base64 encoded files via the ingestEncodedFile mutation, allowing the input of a Base64 string and MIME type.\n",
            "  - Added modelService and model properties to ConversationMessage type for LLM completion details.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - None specified.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - None specified.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: March 13, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced model support and improved file ingestion capabilities, streamlining the integration process.\n",
            "\n",
            "2024-12-30T04:00:00.045Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:05.580902, used credits [0.00616800]\n",
            "- CONTENT [d2f41682-fb8b-4599-8c64-91891e13c336]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [836 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/march-2024/march-10-support-for-claude-3-mistral-and-groq-models-usage-credits-telemetry-bug-fixes</name><title>March 10: Support for Claude 3, Mistral and Groq models, usage/credits telemetry, bug fixes | Graphlit Changelog</title></metadata> üçÄ\tMarch 2024\n",
            "March 10: Support for Claude 3, Mistral and Groq models, usage/credits telemetry, bug fixes\n",
            "New Features\n",
            "üí° Graphlit now supports a Command-Line Interface (CLI) for directly accessing the Graphlit Data API without writing code.  See the documentation here.\n",
            "üí° Graphlit now supports the Groq Platform, and models such as Mixtral 8x7b.\n",
            "üí° Graphlit now supports Claude 3 Opus and Sonnet models.\n",
            "üí° Graphlit now supports Mistral La Plateforme, and models such as Mistral Small, Medium, and Large and Mixtral 8x7b.\n",
            "üí° Graphlit now supports the latest v4 of Azure Document Intelligence, including their new models such as Credit Card, Marriage Certificate, and Mortgage documents.\n",
            "Added support for detailed usage and credits telemetry via API, with the usage, credits, lookupUsage and lookupCredits queries.\n",
            "Added support for correlated telemetry, where an optional correlationId can be provided with GraphQL queries and mutations, so credits and usage can be tracked across requests.\n",
            "Added support for project webhook, which will be called when credits have been consumed by the project.\n",
            "Added support for image extraction during DOCX, XLSX, and PPTX document preparation.\n",
            "Added text and markdown properties to Content object, which provide formatted output of extracted text from any content.\n",
            "Added more accurate extraction of tables into mezzanine JSON format, across all content types.\n",
            "Added throughput property to Conversation messages, which returns the tokens/second throughput of LLM.\n",
            "‚ö° Deprecated mezzanineUri property in Content object, which has been replaced by textUri and audioUri.\n",
            "Bugs Fixed\n",
            "GPLA-2281: Not extracting table from PPTX file.\n",
            "GPLA-2282: Not extracting Markdown tables.\n",
            "GPLA-2247: Not extracting relative HTML links properly.\n",
            "GPLA-2241: Failed to post Alert to Slack with Markdown format.\n",
            "PreviousMarch 13: Support for Claude 3 Haiku model, direct ingestion of Base64 encoded files\n",
            "NextFebruary 21: Support for OneDrive and Google Drive feeds, extract images from PDFs, bug fixes\n",
            "Last updated8 months ago\n",
            "- Completion [305 tokens (includes JSON guardrails tokens)], throughput: 54.651 tokens/sec:\n",
            "- New Features:\n",
            "  - Command-Line Interface (CLI) for direct access to the Graphlit Data API.\n",
            "  - Support for Groq Platform and models like Mixtral 8x7b.\n",
            "  - Support for Claude 3 Opus and Sonnet models.\n",
            "  - Support for Mistral La Plateforme and models such as Mistral Small, Medium, and Large.\n",
            "  - Support for Azure Document Intelligence v4, including new models for Credit Card, Marriage Certificate, and Mortgage documents.\n",
            "  - Detailed usage and credits telemetry via API.\n",
            "  - Correlated telemetry with optional correlationId for tracking credits and usage.\n",
            "  - Project webhook for notifications when credits are consumed.\n",
            "  - Image extraction during DOCX, XLSX, and PPTX document preparation.\n",
            "  - Text and markdown properties added to Content object for formatted output.\n",
            "  - More accurate extraction of tables into mezzanine JSON format.\n",
            "  - Throughput property added to Conversation messages for tokens/second throughput.\n",
            "  - Deprecated mezzanineUri property replaced by textUri and audioUri.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issues with table extraction from PPTX files and Markdown tables.\n",
            "  - Improved extraction of relative HTML links.\n",
            "  - Resolved failure to post alerts to Slack with Markdown format.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: March 10, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Enhancements provide developers with improved API access, better document processing capabilities, and more accurate data extraction, facilitating more efficient application development.\n",
            "\n",
            "2024-12-30T03:59:58.258Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:02.903401, used credits [0.00386100]\n",
            "- CONTENT [2489940d-1c11-4cab-82d2-26e5a1bc0dff]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [619 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/november-2024/november-4-support-for-anthropic-claude-3.5-haiku-bug-fixes</name><title>November 4: Support for Anthropic Claude 3.5 Haiku, bug fixes | Graphlit Changelog</title></metadata> ü¶É\tNovember 2024\n",
            "November 4: Support for Anthropic Claude 3.5 Haiku, bug fixes\n",
            "New Features\n",
            "Graphlit now supports the latest Anthropic Haiku 3.5 model, with the model enum CLAUDE_3_5_HAIKU_20241022.\n",
            "‚ö° Once a project has hit the free tier quota, we will now automatically disable all feeds.  Once the project has been upgraded to a paid tier, you can use the enableFeed mutation to re-enable your existing feeds to continue ingestion.\n",
            "‚ö° We have added the disableFallback flag to the RetrievalStrategyInput type, so you can disable the default behavior of falling back to the previous conversation's contents, or worst-case, falling back to the most recently uploaded content.  By setting disableFallback to true, conversations will only attempt to retrieve contents based on the provided filter and/or augmentedFilter properties.\n",
            "Bugs Fixed\n",
            "GPLA-3367: Not extracting text from HTML button element\n",
            "PreviousNovember 10: Support for web search, multi-turn content summarization, Deepgram language detection\n",
            "NextOctober 31: Support for simulated tool calling, bug fixes\n",
            "Last updated1 month ago\n",
            "- Completion [167 tokens (includes JSON guardrails tokens)], throughput: 57.519 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for Anthropic Haiku 3.5 model (model enum: CLAUDE_3_5_HAIKU_20241022).\n",
            "  - Automatic disabling of all feeds upon reaching the free tier quota; re-enable feeds with enableFeed mutation after upgrading to a paid tier.\n",
            "  - Added disableFallback flag to RetrievalStrategyInput type to control fallback behavior in conversations.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Improved control over conversation content retrieval with the disableFallback flag.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issue with not extracting text from HTML button elements (GPLA-3367).\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: November 4, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced model support, better feed management, and improved content retrieval control.\n",
            "\n",
            "2024-12-30T03:59:57.287Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:04.325778, used credits [0.00558300]\n",
            "- CONTENT [c693346f-b33a-4931-88f4-5c7142c749b9]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [761 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/october-2024/october-3-support-tool-calling-ingestbatch-mutation-gemini-flash-1.5-8b-bug-fixes</name><title>October 3: Support tool calling, ingestBatch mutation, Gemini Flash 1.5 8b, bug fixes | Graphlit Changelog</title></metadata> üéÉ\tOctober 2024\n",
            "October 3: Support tool calling, ingestBatch mutation, Gemini Flash 1.5 8b, bug fixes\n",
            "New Features\n",
            "üí° Graphlit now supports the ingestBatch mutation, which accepts an array of URIs to files or web pages, and will asynchronously ingest these into content objects.\n",
            "üí° Graphlit now supports the continueConversation mutation, which accepts an array of called tool responses. Also, promptConversation now accepts an array of tool definitions. When tools are called by the LLM, the assistant message returned from promptConversation will have a list of toolCalls which need to responded to from your calling code.  These responses are to be provided back to the LLM via the continueConversation mutation.\n",
            "üí° Graphlit now supports tool calling with OpenAI, Mistral, Deepseek, Groq, and Cerebras model services.  Anthropic, Google Gemini and Cohere support will come later.\n",
            "Added support for prefilled user and assistant messages with createConversation mutation. Now you can send an array of messages when creating a new conversation, which will bootstrap the conversation with the LLM.  These must be provided in user/assistant pairs.\n",
            "Added support for Google Gemini Flash 1.5 8b model.\n",
            "‚ö° We have deprecated the tools property in the Specification object. These will be removed at a later date.  Tools are now to be sent directly to the extractContents and promptConversation mutations.\n",
            "Bugs Fixed\n",
            "GPLA-3207: Models shouldn't be required on update specification call\n",
            "GPLA-3220: Don't send system prompt with OpenAI o1 models\n",
            "PreviousOctober 7: Support for Anthropic and Gemini tool calling\n",
            "NextSeptember 30: Support for Azure AI Inference models, Mistral Pixtral and latest Google Gemini models\n",
            "Last updated2 months ago\n",
            "- Completion [275 tokens (includes JSON guardrails tokens)], throughput: 63.572 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for ingestBatch mutation to asynchronously ingest an array of URIs into content objects.\n",
            "  - Support for continueConversation mutation, allowing responses from called tools to be sent back to the LLM.\n",
            "  - Tool calling support added for OpenAI, Mistral, Deepseek, Groq, and Cerebras model services; support for Anthropic, Google Gemini, and Cohere coming later.\n",
            "  - Prefilled user and assistant messages can now be sent with createConversation mutation.\n",
            "  - Added support for Google Gemini Flash 1.5 8b model.\n",
            "  - Deprecated tools property in the Specification object; tools must now be sent directly to extractContents and promptConversation mutations.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Improved conversation bootstrapping with prefilled messages.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issue where models were incorrectly required on update specification call (GPLA-3207).\n",
            "  - Resolved issue of sending system prompt with OpenAI o1 models (GPLA-3220).\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: October 2024.\n",
            "  - Version: Gemini Flash 1.5 8b.\n",
            "  - Breaking change: tools property in Specification object deprecated.\n",
            "\n",
            "- Value:\n",
            "  - Enhancements provide developers with more flexible and powerful tools for managing conversations and integrating various model services.\n",
            "\n",
            "2024-12-30T03:59:55.236Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:05.263004, used credits [0.00599100]\n",
            "- CONTENT [1cd2c534-2f49-4677-ab4a-68a4365f4fdd]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [765 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/october-2023/october-15-support-for-anthropic-claude-models-slack-feeds-and-entity-enrichment</name><title>October 15: Support for Anthropic Claude models, Slack feeds and entity enrichment | Graphlit Changelog</title></metadata> üéÉ\tOctober 2023\n",
            "October 15: Support for Anthropic Claude models, Slack feeds and entity enrichment\n",
            "New Features\n",
            "üî• Graphlit now supports Anthropic Claude and Anthropic Claude Instant large language models.\n",
            "üî• Graphlit now supports Slack feeds, and will ingest Slack messages and linked file attachments from a Slack channel.  Note, this requires the creation of a Slack bot which has been added to the appropriate Slack channel.\n",
            "üí° Added support for entity enrichment to workflow object, which offers Diffbot, Wikipedia and Crunchbase enrichment of observed entities, such as Person, Organization and Place.\n",
            "üí° Added support for text extraction from images.  When using Azure Image Analytics for entity extraction, Graphlit will extract and store any identified text which then becomes searchable.\n",
            "Added embedFacets property to conversation strategy in specification object.\n",
            "Added embedCitations property to conversation strategy in specification object.  This makes content citations optional with the completed conversation message.\n",
            "Added GraphQL mutations for multi-delete of entities, such as deleteCollections, deleteLabels, or deleteConversations.\n",
            "Added GraphQL deleteAllConversations mutation to delete all conversations.\n",
            "Added support for automatically adding ingested content to one or more collections, via ingestion stage of workflow object.\n",
            "Added specification property to preparation workflow stage, which will be used to select the LLM for text summarization.\n",
            "Expanded the properties for observed entities, such as Person, Organization or Product.  Now supports a wider range of properties for entity enrichment.\n",
            "Bugs Fixed\n",
            "GPLA-1520: Unlimited conversation quota not assigned when upgrading project tier\n",
            "GPLA-1285: Entity enrichment not firing event, which can be sent to actions\n",
            "GPLA-1361: Web page left in ingested state, when URL not accessible.\n",
            "PreviousOctober 30: Optimized conversation responses; added observable aliases; bug fixes\n",
            "NextSeptember 24: Support for YouTube feeds; added documentation; bug fixes\n",
            "Last updated1 year ago\n",
            "- Completion [308 tokens (includes JSON guardrails tokens)], throughput: 58.522 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for Anthropic Claude and Anthropic Claude Instant large language models.\n",
            "  - Ingestion of Slack messages and linked file attachments from Slack channels (requires a Slack bot).\n",
            "  - Entity enrichment for observed entities (Person, Organization, Place) using Diffbot, Wikipedia, and Crunchbase.\n",
            "  - Text extraction from images using Azure Image Analytics, making identified text searchable.\n",
            "  - Added embedFacets and embedCitations properties to conversation strategy in specification object.\n",
            "  - GraphQL mutations for multi-delete of entities (deleteCollections, deleteLabels, deleteConversations).\n",
            "  - GraphQL deleteAllConversations mutation to delete all conversations.\n",
            "  - Automatic addition of ingested content to collections during the ingestion stage of the workflow.\n",
            "  - Specification property added to preparation workflow stage for selecting LLM for text summarization.\n",
            "  - Expanded properties for observed entities for enhanced entity enrichment.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Improved capabilities for entity enrichment and text extraction.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed unlimited conversation quota not assigned when upgrading project tier (GPLA-1520).\n",
            "  - Resolved issue with entity enrichment not firing events (GPLA-1285).\n",
            "  - Fixed web page remaining in ingested state when URL is not accessible (GPLA-1361).\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: October 15, 2023.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced support for LLMs, improved data ingestion from Slack, and advanced entity enrichment capabilities.\n",
            "\n",
            "2024-12-30T03:59:54.971Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:03.883253, used credits [0.00521700]\n",
            "- CONTENT [0341d367-6775-4e57-9a3d-7904d813f243]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [855 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/november-2024/november-10-support-for-web-search-multi-turn-content-summarization-deepgram-language-detection</name><title>November 10: Support for web search, multi-turn content summarization, Deepgram language detection | Graphlit Changelog</title></metadata> ü¶É\tNovember 2024\n",
            "November 10: Support for web search, multi-turn content summarization, Deepgram language detection\n",
            "New Features\n",
            "üí° Graphlit now supports web search with the searchWeb mutation.  You can select the search service, either Tavily or Exa.AI, and provide the search query and number of search results to be returned.  This is different than the web search feed, in that searchWeb returns the relevant text from the web page and the web page URL from each search hit, but does not ingest each of the web pages. This new mutation is optimized to be used from within an LLM tool.\n",
            "üí° Graphlit now supports multi-turn summarization of content with the reviseContent mutation.  You can provide an LLM prompt and a content reference, along with an optional specification.  This can be used for summarizing any content (documents, web pages, audio transcripts, etc.), and having a multi-turn conversation with the LLM to revise the output from the LLM.  Internally, this creates a conversation locked to a single piece of content.  This works especially well with the OpenAI o1-preview and o1-mini models, because they provide a longer LLM output from each turn.\n",
            "Graphlit now supports the configuration of the Deepgram transcription language, and whether detectLanguage is enabled in DeepgramAudioPreparationPropertiesInput.  Language detection is now enabled by default, and can be disabled by setting detectLanguage to false.\n",
            "‚ö° We have added a requireTool option to promptConversation mutation, so you can control whether the LLM must call one of the provided tool, or if tool calling is optional.\n",
            "‚ö° For accounts created after Nov 8, 2024, we have lowered the credits quota on the Free tier from 1000 credits to 100 credits, and now offer unlimited feeds on the Hobby Tier.\n",
            "‚ö° The Graphlit Data API will now return HTTP 402 (Payment Required) when you have exceeded the credits quota on the free tier.  You must upgrade to the Hobby Tier (or higher) to continue using the API, once the credits quota has been reached.\n",
            "PreviousNovember 16: Support for image description, multi-turn text summarization\n",
            "NextNovember 4: Support for Anthropic Claude 3.5 Haiku, bug fixes\n",
            "Last updated1 month ago\n",
            "- Completion [221 tokens (includes JSON guardrails tokens)], throughput: 56.911 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for web search via the searchWeb mutation, allowing selection of search service (Tavily or Exa.AI) and retrieval of relevant text and URLs.\n",
            "  - Multi-turn content summarization with the reviseContent mutation, enabling conversation with LLM for content revision.\n",
            "  - Configuration of Deepgram transcription language and default language detection enabled in DeepgramAudioPreparationPropertiesInput.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Added requireTool option to promptConversation mutation for controlling tool calling.\n",
            "  - Reduced credits quota on Free tier from 1000 to 100 for accounts created after Nov 8, 2024; unlimited feeds now available on Hobby Tier.\n",
            "  - Graphlit Data API now returns HTTP 402 (Payment Required) when exceeding free tier credits quota.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - No specific bug fixes mentioned.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: November 10, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced capabilities for web search and content summarization, improved control over tool usage, and clearer API usage guidelines.\n",
            "\n",
            "2024-12-30T03:59:54.308Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:05.847348, used credits [0.00642300]\n",
            "- CONTENT [5345f273-4dcb-4f44-a1a3-4226ff5eaed8]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [845 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/september-2023/september-20-paid-subscription-plans-support-for-custom-observed-entities-and-azure-openai-gpt-4</name><title>September 20: Paid subscription plans; support for custom observed entities & Azure OpenAI GPT-4 | Graphlit Changelog</title></metadata> üõ†Ô∏è\tSeptember 2023\n",
            "September 20: Paid subscription plans; support for custom observed entities & Azure OpenAI GPT-4\n",
            "New Features\n",
            "üî• Graphlit now supports paid Hobby, Starter and Growth tiers for projects, in addition to the existing Free tier.  Starting at $49/mo, plus $0.10/credit for usage, we now support higher quota based on your subscribed tier.   By providing a payment method for your organization in the Developer Portal, you can upgrade each project individually to the tier that fits your application's needs.\n",
            "üí° Added GraphQL mutations for the creation, update and deletion of observed entities (i.e. Person, Organization, Place, Product, Event, Label, Category).\n",
            "üí° Added new observed entity types to knowledge graph: Repo (i.e. Git repo), Software.\n",
            "üí° Added searchType and numberSimilar fields to Specification object for configuring semantic search in conversations.   In situations where the user prompt is limited in length, HYBRID search type can provide better semantic search results for the prompt context.\n",
            "üí° Added support for the Azure OpenAI GPT-4 model.\n",
            "Added support for project quota field.  Project quotas are based on the subscribed pricing tier.   Quota limits are now applied as content is ingested, and as feeds and conversations are created.\n",
            "Added contentLimit to conversation strategy object to limit the number of semantic search content results which are formatted into prompt context.\n",
            "Better relevance ranking on semantic search results when formatting prompt context in conversations.\n",
            "‚ÑπÔ∏è Free tier has updated quota: 1GB storage, 100 contents, 3 feeds and 10 conversations.\n",
            "‚ö° Now using the Deepgram Nova-2 audio transcription model, which is 18% more accurate, and 5-40x faster.\n",
            "Bugs Fixed\n",
            "GPLA-1373: Failed to extract multiple text pages from DOCX without page breaks.  Now we support token-aware page chunking.\n",
            "GPLA-1377: Failed during semantic search with no content results, when prompting conversation.\n",
            "GPLA-1415: Failed when user prompt couldn't generate text embeddings.\n",
            "PreviousSeptember 24: Support for YouTube feeds; added documentation; bug fixes\n",
            "NextSeptember 4: Workflow configuration; support for Notion feeds; document OCR\n",
            "Last updated11 months ago\n",
            "- Completion [324 tokens (includes JSON guardrails tokens)], throughput: 55.410 tokens/sec:\n",
            "- New Features:\n",
            "  - Introduction of paid Hobby, Starter, and Growth subscription tiers starting at $49/month, with usage fees of $0.10/credit.\n",
            "  - GraphQL mutations for creating, updating, and deleting observed entities (Person, Organization, Place, Product, Event, Label, Category).\n",
            "  - New observed entity types added: Repo (Git repo), Software.\n",
            "  - Added searchType and numberSimilar fields to Specification object for enhanced semantic search.\n",
            "  - Support for Azure OpenAI GPT-4 model.\n",
            "  - Project quota field introduced, with limits based on subscription tier.\n",
            "  - ContentLimit added to conversation strategy object for semantic search results.\n",
            "  - Improved relevance ranking for semantic search results.\n",
            "  - Updated Free tier quota: 1GB storage, 100 contents, 3 feeds, and 10 conversations.\n",
            "  - Implementation of Deepgram Nova-2 audio transcription model, offering 18% more accuracy and 5-40x faster processing.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Better semantic search results with new configuration options.\n",
            "  - Enhanced audio transcription accuracy and speed.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Resolved issue with extracting multiple text pages from DOCX files using token-aware page chunking.\n",
            "  - Fixed semantic search failure when no content results were available.\n",
            "  - Addressed failure in generating text embeddings from user prompts.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: September 20, 2023.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers flexible subscription options, improved search capabilities, and enhanced audio processing, facilitating better project management and user experience.\n",
            "\n",
            "2024-12-30T03:59:52.891Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:05.623634, used credits [0.00680100]\n",
            "- CONTENT [865f424b-fa74-4640-b593-a9840336a452]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [851 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/september-2024/september-26-support-for-google-ai-and-cerebras-models-and-latest-groq-models</name><title>September 26: Support for Google AI and Cerebras models, and latest Groq models | Graphlit Changelog</title></metadata> üéí\tSeptember 2024\n",
            "September 26: Support for Google AI and Cerebras models, and latest Groq models\n",
            "New Features\n",
            "üí° Graphlit now supports the Cerebras model service which offers the LLAMA_3_1_70B and LLAMA_3_1_8B models.\n",
            "üí° Graphlit now supports the Google AI model service which offers the GEMINI_1_5_PRO and GEMINI_1_5_FLASH models.\n",
            "We have added support for the latest Groq Llama 3.2 preview models, including LLAMA_3_2_1B_PREVIEW, LLAMA_3_2_3B_PREVIEW, LLAMA_3_2_11B_TEXT_PREVIEW, and LLAMA_3_2_90B_TEXT_PREVIEW.  We have also added support for the Llama 3.2 multimodal model LLAMA_3_2_11B_VISION_PREVIEW.\n",
            "We have added a new specification parameter to the promptConversation mutation. Now you can specify your initial specification for a new conversation, or update an existing conversation, without requiring additional API calls.\n",
            "‚ö° We have changed the retrieval behavior of the promptConversation mutation. Now, if no relevant content was found via vector-based semantic search (given the user prompt), we will fallback to any relevant content from the message in the conversation. If there was no content from the conversation to fallback to, we will fallback to the last ingested content in the project. This solves an issue where a first prompt like 'Summarize this' would find no relevant content.  Now it will fallback to retrieve the last ingested content.\n",
            "‚ö° We have renamed the Groq model enum from LLAVA_1_5_7B to LLAVA_1_5_7B_PREVIEW.\n",
            "Bugs Fixed\n",
            "GPLA-3083: Not sending custom instructions/guidance with extraction prompt\n",
            "GPLA-3146: Filtering Persons by email not working\n",
            "GPLA-3171: Not failing on deprecated OpenAI model\n",
            "GPLA-3158: Summarization not using revision strategy\n",
            "PreviousSeptember 30: Support for Azure AI Inference models, Mistral Pixtral and latest Google Gemini models\n",
            "NextSeptember 3: Support for web search feeds, model deprecations\n",
            "Last updated3 months ago\n",
            "- Completion [354 tokens (includes JSON guardrails tokens)], throughput: 62.949 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for Cerebras model service: LLAMA_3_1_70B and LLAMA_3_1_8B models.\n",
            "  - Support for Google AI model service: GEMINI_1_5_PRO and GEMINI_1_5_FLASH models.\n",
            "  - Support for latest Groq Llama 3.2 preview models: LLAMA_3_2_1B_PREVIEW, LLAMA_3_2_3B_PREVIEW, LLAMA_3_2_11B_TEXT_PREVIEW, LLAMA_3_2_90B_TEXT_PREVIEW, and multimodal model LLAMA_3_2_11B_VISION_PREVIEW.\n",
            "  - New specification parameter added to promptConversation mutation for initial or updated conversation specifications.\n",
            "  \n",
            "- Enhancements/Improvements:\n",
            "  - Changed retrieval behavior of promptConversation mutation to fallback to relevant content from the conversation or last ingested content if no relevant content is found.\n",
            "  - Renamed Groq model enum from LLAVA_1_5_7B to LLAVA_1_5_7B_PREVIEW.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issue with not sending custom instructions/guidance with extraction prompt (GPLA-3083).\n",
            "  - Resolved filtering persons by email not working (GPLA-3146).\n",
            "  - Addressed issue of not failing on deprecated OpenAI model (GPLA-3171).\n",
            "  - Fixed summarization not using revision strategy (GPLA-3158).\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: September 26, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced model support and improved conversation handling, increasing the efficiency and effectiveness of interactions with the platform.\n",
            "\n",
            "2024-12-30T03:59:51.017Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:02.926868, used credits [0.00396900]\n",
            "- CONTENT [75f8d5dd-c5e0-4c08-b334-dc5e80ea8025]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [587 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/september-2023/september-24-support-for-youtube-feeds-added-documentation-bug-fixes</name><title>September 24: Support for YouTube feeds; added documentation; bug fixes | Graphlit Changelog</title></metadata> üõ†Ô∏è\tSeptember 2023\n",
            "September 24: Support for YouTube feeds; added documentation; bug fixes\n",
            "New Features\n",
            "üî• Graphlit now supports YouTube feeds, where you can ingest a set of YouTube videos, or an entire YouTube playlist or channel.   Note, we currently support only the ingestion of audio from YouTube videos, which gets transcribed and added to your conversational knowledge graph.\n",
            "New Documentation\n",
            "Added documentation for observable entities mutations and queries (Label, Category, Person, Organization, Place, Event, Product, Repo, Software).\n",
            "Added documentation for using custom Azure OpenAI and OpenAI models with Specifications\n",
            "Bugs Fixed\n",
            "GPLA-1459: LLM prompt formatting was exceeding the token budget with long user prompts.\n",
            "GPLA-1445: Failed to ingest PDF from URL where filename in Content-Disposition header contained a backslash.\n",
            "PreviousOctober 15: Support for Anthropic Claude models, Slack feeds and entity enrichment\n",
            "NextSeptember 20: Paid subscription plans; support for custom observed entities & Azure OpenAI GPT-4\n",
            "Last updated7 months ago\n",
            "- Completion [184 tokens (includes JSON guardrails tokens)], throughput: 62.866 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for YouTube feeds, allowing ingestion of YouTube videos, playlists, or channels (currently supports audio ingestion and transcription).\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Added documentation for observable entities mutations and queries (Label, Category, Person, Organization, Place, Event, Product, Repo, Software).\n",
            "  - Added documentation for using custom Azure OpenAI and OpenAI models with Specifications.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed LLM prompt formatting issue that exceeded token budget with long user prompts (GPLA-1459).\n",
            "  - Resolved issue with ingesting PDF from URL when filename in Content-Disposition header contained a backslash (GPLA-1445).\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: September 2023.\n",
            "\n",
            "- Value:\n",
            "  - Enhances developers' ability to integrate YouTube content and improves documentation for better usage of observable entities and custom models.\n",
            "\n",
            "2024-12-30T03:59:49.732Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:01.174692, used credits [0.00252000]\n",
            "- CONTENT [e112772f-cc4a-4323-8c80-8c1d8c123dd2]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [484 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/october-2024/october-9-support-for-github-repository-feeds-bug-fixes</name><title>October 9: Support for GitHub repository feeds, bug fixes | Graphlit Changelog</title></metadata> üéÉ\tOctober 2024\n",
            "October 9: Support for GitHub repository feeds, bug fixes\n",
            "New Features\n",
            "üí° Graphlit now supports GitHub feeds, by providing the repository owner and name similar to GitHub Issues feeds, and will ingest code files from any GitHub repository.\n",
            "Bugs Fixed\n",
            "GPLA-3262: Missing row separator in table markdown formatting\n",
            "PreviousOctober 21: Support OpenAI, Cohere, Jina, Mistral, Voyage and Google AI embedding models\n",
            "NextOctober 7: Support for Anthropic and Gemini tool calling\n",
            "Last updated2 months ago\n",
            "- Completion [89 tokens (includes JSON guardrails tokens)], throughput: 75.765 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for GitHub repository feeds, allowing ingestion of code files by providing the repository owner and name.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed missing row separator in table markdown formatting (GPLA-3262).\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: October 9, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Enhances integration with GitHub, improving developers' ability to work with code repositories.\n",
            "\n",
            "2024-12-30T03:59:48.473Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:01.717386, used credits [0.00295800]\n",
            "- CONTENT [4fa1f011-eca1-4585-9a4b-d31369c468cb]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [498 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/october-2024/october-7-support-for-anthropic-and-gemini-tool-calling</name><title>October 7: Support for Anthropic and Gemini tool calling | Graphlit Changelog</title></metadata> üéÉ\tOctober 2024\n",
            "October 7: Support for Anthropic and Gemini tool calling\n",
            "New Features\n",
            "üí° Graphlit now supports tool calling with Anthropic and Google Gemini models.\n",
            "‚ö° We have removed the uri property for tools from ToolDefinitionInput, such that inline webhook tools are no longer supported.  Now you can define any external tools to be called, and those can support sync or async data access to fulfill the tool call.\n",
            "PreviousOctober 9: Support for GitHub repository feeds, bug fixes\n",
            "NextOctober 3: Support tool calling, ingestBatch mutation, Gemini Flash 1.5 8b, bug fixes\n",
            "Last updated2 months ago\n",
            "- Completion [122 tokens (includes JSON guardrails tokens)], throughput: 71.038 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for tool calling with Anthropic and Google Gemini models.\n",
            "  - Removal of the uri property for tools from ToolDefinitionInput, eliminating support for inline webhook tools. External tools can now be defined for sync or async data access.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Improved flexibility in defining external tools for tool calls.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - No specific bug fixes mentioned.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: October 7, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced capabilities for integrating external tools and improved data access options.\n",
            "\n",
            "2024-12-30T03:59:48.415Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:04.156673, used credits [0.00519300]\n",
            "- CONTENT [f3c48cd9-fc5b-4306-9135-aed548177631]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [739 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/september-2023/september-4-workflow-configuration-support-for-notion-feeds-document-ocr</name><title>September 4: Workflow configuration; support for Notion feeds; document OCR | Graphlit Changelog</title></metadata> üõ†Ô∏è\tSeptember 2023\n",
            "September 4: Workflow configuration; support for Notion feeds; document OCR\n",
            "New Features\n",
            "üî• Added Workflow entity to data model for configuring stages of content workflow; can be assigned to Feed or with ingestPage, ingestFile, or ingestText mutations to control how content is ingested, prepared, extracted and enriched into the knowledge graph.\n",
            "üí° Added support for Notion feeds: now can create feed to ingest files from Notion pages or databases (i.e. wikis).\n",
            "üí° Added support for API-created Observation entities, which allow for custom observations of observable entities (i.e. Person, Label) on Content.\n",
            "üí° Added support for Azure AI Document Intelligence as an optional method for preparing PDF files, using OCR and advanced layout analysis.\n",
            "üí° Added summarization strategies, where content can be summarized into paragraphs, bullet points or headline.\n",
            "Added ability to assign default Workflow and Specification to project.\n",
            "Added more well-known link types, during link crawling, such as Discord, Airtable and TypeForm.\n",
            "‚ÑπÔ∏è Free/Hobby plan now has 5GB storage quota; any content ingested past that limit will be auto-deleted.\n",
            "‚ö° Actions have been moved into Workflow entity.\n",
            "‚ö° Link enrichment for Feeds has been moved into the Workflow enrichment stage, now called link crawling.  ExcludeContentDomain property has been reversed and is now called IncludeContentDomain.\n",
            "Bugs Fixed\n",
            "GPLA-1204: Failed to ingest content with backslash in name.\n",
            "GPLA-1276: Failed to ingest RSS posts which contained enclosure URI, but no post URI.\n",
            "PreviousSeptember 20: Paid subscription plans; support for custom observed entities & Azure OpenAI GPT-4\n",
            "NextAugust 17: Prepare for usage-based billing; append SAS tokens to URIs\n",
            "Last updated1 year ago\n",
            "- Completion [248 tokens (includes JSON guardrails tokens)], throughput: 59.663 tokens/sec:\n",
            "- New Features:\n",
            "  - Added Workflow entity for configuring content workflow stages.\n",
            "  - Support for Notion feeds to ingest files from Notion pages or databases.\n",
            "  - API-created Observation entities for custom observations on Content.\n",
            "  - Support for Azure AI Document Intelligence for PDF preparation using OCR.\n",
            "  - Summarization strategies for content (paragraphs, bullet points, headlines).\n",
            "  - Ability to assign default Workflow and Specification to projects.\n",
            "  - Added support for more link types during link crawling (Discord, Airtable, TypeForm).\n",
            "  - Free/Hobby plan now includes a 5GB storage quota.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Actions moved into Workflow entity.\n",
            "  - Link enrichment for Feeds moved to Workflow enrichment stage, renamed to link crawling.\n",
            "  - ExcludeContentDomain property renamed to IncludeContentDomain.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issue with content ingestion failure due to backslash in name.\n",
            "  - Resolved failure to ingest RSS posts with enclosure URI but no post URI.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: September 4, 2023.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced workflow configuration, improved content ingestion from Notion, and advanced document processing capabilities.\n",
            "\n",
            "2024-12-30T03:59:47.873Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:02.777128, used credits [0.00360900]\n",
            "- CONTENT [f0a42b0a-353b-4f08-9a5d-40ce9196a46b]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [587 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/october-2024/october-31-support-for-simulated-tool-calling-bug-fixes</name><title>October 31: Support for simulated tool calling, bug fixes | Graphlit Changelog</title></metadata> üéÉ\tOctober 2024\n",
            "October 31: Support for simulated tool calling, bug fixes\n",
            "New Features\n",
            "Graphlit now supports simulated tool calling for LLMs which don't natively support it, such as OpenAI o1-preview and o1-mini.  Tool schema will be formatted into the LLM prompt context, and tool responses are parsed out of the JSON formatted response.\n",
            "‚ö° Given customer feedback, we have lowered the vector and hybrid thresholds used by the semantic search.  Previously, some content at a low relevance was being excluded from the semantic search results.  Now, more low-relevance content will be included in the results, used by the RAG pipeline.  Reranking can be used to sort the search results for relevance.\n",
            "Bugs Fixed\n",
            "GPLA-3357: Not extracting all images from PDF, and should filter out single-color images.\n",
            "PreviousNovember 4: Support for Anthropic Claude 3.5 Haiku, bug fixes\n",
            "NextOctober 22: Support for latest Anthropic Sonnet 3.5 model, Cohere image embeddings\n",
            "Last updated1 month ago\n",
            "- Completion [154 tokens (includes JSON guardrails tokens)], throughput: 55.453 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for simulated tool calling for LLMs like OpenAI o1-preview and o1-mini.\n",
            "  - Tool schema formatted into LLM prompt context; tool responses parsed from JSON.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Lowered vector and hybrid thresholds for semantic search based on customer feedback, allowing more low-relevance content in results.\n",
            "  - Reranking feature for sorting search results by relevance.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issue GPLA-3357: now extracts all images from PDF and filters out single-color images.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: October 2024.\n",
            "\n",
            "- Value:\n",
            "  - Enhancements improve search result relevance and broaden content inclusion, benefiting developers using the platform.\n",
            "\n",
            "2024-12-30T03:59:47.197Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:04.106386, used credits [0.00529500]\n",
            "- CONTENT [3092dd49-a054-4d32-94b2-cb67133a305d]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [761 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/november-2024/november-24-support-for-direct-llm-prompt-multi-turn-image-analysis-bug-fixes</name><title>November 24: Support for direct LLM prompt, multi-turn image analysis, bug fixes | Graphlit Changelog</title></metadata> ü¶É\tNovember 2024\n",
            "November 24: Support for direct LLM prompt, multi-turn image analysis, bug fixes\n",
            "New Features\n",
            "üí° Graphlit now supports multi-turn analysis of images with the reviseImage and reviseEncodedImage mutations.  You can provide an LLM prompt and either a URI or Base-64 encoded image and MIME type, along with an optional LLM specification.  This can be used for analyzing any image and having a multi-turn conversation with the LLM to revise the output from the LLM. (Colab Notebook Example)\n",
            "üí° Graphlit now supports directly prompting an LLM with the prompt mutation, bypassing any RAG content retrieval, while providing an optional list of previous conversation messages.  This also accepts an optional LLM specification. (Colab Notebook Example)\n",
            "We have added support for the new Mistral Pixtral Large model, with PIXTRAL_LARGE model enum, which can be used with LLM completion or entity extraction LLM specifications.\n",
            "We have added support for the OpenAI 2024-11-20 version of GPT-4o, with GPT4O_128K_20241120 model enum.\n",
            "‚ö° We have added Microsoft Entra ID (fka Azure Active Directory) clientId and clientSecret properties to the SharePointFeedPropertiesInput type, which are now required when creating a SharePoint feed using user authentication with refreshToken property. (Colab Notebook Example)\n",
            "Bugs Fixed\n",
            "GPLA-3438: Not filtering on desktop presentation when scraping web pages\n",
            "GPLA-3340: Failed to parse invalid JSON from extracted PDF page\n",
            "GPLA-3427: Not formatting extracted tables properly from Sonnet 3.5\n",
            "PreviousDecember 1: Support for retrieval-only RAG pipeline, bug fixes\n",
            "NextNovember 16: Support for image description, multi-turn text summarization\n",
            "Last updated1 month ago\n",
            "- Completion [251 tokens (includes JSON guardrails tokens)], throughput: 61.124 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for multi-turn analysis of images using reviseImage and reviseEncodedImage mutations, allowing LLM prompts with image URIs or Base-64 encoded images.\n",
            "  - Direct prompting of an LLM with the prompt mutation, bypassing RAG content retrieval, with optional previous conversation messages.\n",
            "  - Support for Mistral Pixtral Large model (PIXTRAL_LARGE).\n",
            "  - Support for OpenAI GPT-4o (GPT4O_128K_20241120).\n",
            "  - Added Microsoft Entra ID clientId and clientSecret properties for SharePoint feed creation with user authentication.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Improved user authentication process for SharePoint feeds.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed filtering issue on desktop presentation when scraping web pages (GPLA-3438).\n",
            "  - Resolved JSON parsing error from extracted PDF pages (GPLA-3340).\n",
            "  - Corrected table formatting from Sonnet 3.5 (GPLA-3427).\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: November 24, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Enhancements provide developers with advanced image analysis capabilities and improved LLM interactions, streamlining workflows and increasing efficiency.\n",
            "\n",
            "2024-12-30T03:59:46.650Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:03.489650, used credits [0.00453900]\n",
            "- CONTENT [b96def70-f8ed-4c72-9757-a1648306835a]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [661 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/september-2024/september-1-support-for-fhir-enrichment-latest-cohere-models-bug-fixes</name><title>September 1: Support for FHIR enrichment, latest Cohere models, bug fixes | Graphlit Changelog</title></metadata> üéí\tSeptember 2024\n",
            "September 1: Support for FHIR enrichment, latest Cohere models, bug fixes\n",
            "New Features\n",
            "üí° Graphlit now supports entity enrichment from Fast Healthcare Interoperability Resources (FHIR) servers. You can provide the endpoint for a FHIR server, and Graphlit will enrich medical-related entities from the data found in the FHIR server.\n",
            "Added support for latest Cohere models (COMMAND_R_202408, COMMAND_R_PLUS_202408) and added datestamped model enums for the previous versions (COMMAND_R_202403, COMMAND_R_PLUS_202404).  The latest model enums (COMMAND_R and COMMAND_R_PLUS) currently point to the models (COMMAND_R_202403 and COMMAND_R_PLUS_202404) as specified by the Cohere API.\n",
            "Added support for the latest Azure AI Document Intelligence v4.0 preview API (2024-07-31), now used by default.\n",
            "‚ö° We have changed the name of the LinkReferenceType to LinkReference to follow the existing data model standard.\n",
            "Bugs Fixed\n",
            "GPLA-3120: LLM is adding source tags to end of completed messages\n",
            "GPLA-3133: Failed to load sitemap on child page of website.\n",
            "PreviousSeptember 3: Support for web search feeds, model deprecations\n",
            "NextAugust 20: Support for medical entities, Anthropic prompt caching, bug fixes\n",
            "Last updated3 months ago\n",
            "- Completion [213 tokens (includes JSON guardrails tokens)], throughput: 61.038 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for entity enrichment from FHIR servers for medical-related entities.\n",
            "  - Added support for latest Cohere models (COMMAND_R_202408, COMMAND_R_PLUS_202408) with datestamped model enums for previous versions.\n",
            "  - Support for the latest Azure AI Document Intelligence v4.0 preview API (2024-07-31) now used by default.\n",
            "  - Renamed LinkReferenceType to LinkReference to align with data model standards.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Updated naming conventions for consistency with existing standards.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issue where LLM added source tags to the end of completed messages (GPLA-3120).\n",
            "  - Resolved failure to load sitemap on child page of website (GPLA-3133).\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: September 1, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Enhancements improve integration with healthcare data and AI models, providing developers with more robust tools for medical entity enrichment and document intelligence.\n",
            "\n",
            "2024-12-30T03:59:45.015Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:02.201915, used credits [0.00365100]\n",
            "- CONTENT [d764f4d3-1282-441c-8e4a-08ce664b0b47]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [613 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/november-2024/november-16-support-for-image-description-multi-turn-text-summarization</name><title>November 16: Support for image description, multi-turn text summarization | Graphlit Changelog</title></metadata> ü¶É\tNovember 2024\n",
            "November 16: Support for image description, multi-turn text summarization\n",
            "New Features\n",
            "üí° Graphlit now supports multi-turn summarization of text with the reviseText mutation.  You can provide an LLM prompt and text string, along with an optional specification.  This can be used for summarizing any raw text and having a multi-turn conversation with the LLM to revise the output from the LLM.  (Colab Notebook Example)\n",
            "üí° Graphlit now supports image descriptions using vision LLMs, without needing to ingest the image first.  With the new describeImage mutation, which takes a URI, and describeEncodedImage mutation, which takes a Base-64 encoded image and MIME type, you can use any vision LLM to prompt an image description.  These mutations accept an optional specification, where you can select your vision LLM.  If not provided, OpenAI GPT-4o will be used. (Colab Notebook Example)\n",
            "PreviousNovember 24: Support for direct LLM prompt, multi-turn image analysis, bug fixes\n",
            "NextNovember 10: Support for web search, multi-turn content summarization, Deepgram language detection\n",
            "Last updated1 month ago\n",
            "- Completion [151 tokens (includes JSON guardrails tokens)], throughput: 68.577 tokens/sec:\n",
            "- New Features:\n",
            "  - Multi-turn summarization of text with the reviseText mutation, allowing for LLM prompts and text revisions.\n",
            "  - Image descriptions supported via describeImage mutation (URI input) and describeEncodedImage mutation (Base-64 encoded image), utilizing vision LLMs.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Optional specifications for selecting vision LLMs; defaults to OpenAI GPT-4o if not provided.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - No specific bug fixes mentioned in this release.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: November 16, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced capabilities for text summarization and image description without prior image ingestion, improving interaction with LLMs.\n",
            "\n",
            "2024-12-30T03:59:44.172Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:05.248386, used credits [0.00414300]\n",
            "- CONTENT [02c635c4-808d-495e-9744-bb501a2066e8]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [641 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/september-2024/september-30-support-for-azure-ai-inference-models-mistral-pixtral-and-latest-google-gemini-models</name><title>September 30: Support for Azure AI Inference models, Mistral Pixtral and latest Google Gemini models | Graphlit Changelog</title></metadata> üéí\tSeptember 2024\n",
            "September 30: Support for Azure AI Inference models, Mistral Pixtral and latest Google Gemini models\n",
            "New Features\n",
            "üí° Graphlit now supports the Azure AI Model Inference API (aka Models as a Service) model service which offers serverless hosting to many models such as Meta Llama 3.2, Cohere Command-R, and many more.  For Azure AI, all models are 'custom', and you will need to provide the serverless endpoint, API key and number of tokens accepted in context window, after provisioning the model of your choice.\n",
            "We have added support for the multimodal Mistral Pixtral model, under the model enum PIXTRAL_12B_2409.\n",
            "We have added versioned model enums for Google Gemini, so you can access GEMINI_1_5_FLASH_001, GEMINI_1_5_FLASH_002, GEMINI_1_5_PRO_001 and GEMINI_1_5_PRO_002.\n",
            "PreviousOctober 3: Support tool calling, ingestBatch mutation, Gemini Flash 1.5 8b, bug fixes\n",
            "NextSeptember 26: Support for Google AI and Cerebras models, and latest Groq models\n",
            "Last updated2 months ago\n",
            "- Completion [185 tokens (includes JSON guardrails tokens)], throughput: 35.249 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for Azure AI Model Inference API, enabling serverless hosting for models like Meta Llama 3.2 and Cohere Command-R.\n",
            "  - Added support for the multimodal Mistral Pixtral model (PIXTRAL_12B_2409).\n",
            "  - Introduced versioned model enums for Google Gemini: GEMINI_1_5_FLASH_001, GEMINI_1_5_FLASH_002, GEMINI_1_5_PRO_001, GEMINI_1_5_PRO_002.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Enhanced model accessibility through versioned enums for Google Gemini.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - No specific bug fixes mentioned in this release.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: September 30, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers expanded model support and flexibility with serverless hosting options.\n",
            "\n",
            "2024-12-30T03:59:42.971Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:04.047020, used credits [0.00570000]\n",
            "- CONTENT [4adced81-1014-450d-9e42-e81ec370a757]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [740 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/october-2023/october-30-optimized-conversation-responses-added-observable-aliases-bug-fixes</name><title>October 30: Optimized conversation responses; added observable aliases; bug fixes | Graphlit Changelog</title></metadata> üéÉ\tOctober 2023\n",
            "October 30: Optimized conversation responses; added observable aliases; bug fixes\n",
            "New Features\n",
            "üí° Graphlit now supports 'aliases' of observable names, as the alternateNames property.  When an observed entity, such as Organization, is enriched, we store the original name and the enriched name as an alias.  For example, \"OpenAI\" may be enriched to \"OpenAI, Inc.\", and we store \"OpenAI\" as an alias, and update the name to \"OpenAI, Inc.\".\n",
            "üí° Added workflows filter to ContentCriteriaInput type, for filtering content by workflow(s) when creating conversation.\n",
            "Optimized formatting of content sources into prompt context, for more accurate conversation responses.\n",
            "Optimized formatting of extracted text from Slack messages, for better knowledge retrieval.\n",
            "Updated text tokenizer for more accurate token counting.\n",
            "Upgraded Azure Text Analytics to latest preview API version.\n",
            "Authors found in RSS feeds are now stored as observations of Person entities.\n",
            "Added rate limiting for Reddit feeds.\n",
            "Added rate limiting for Wikipedia enrichment.\n",
            "Added support for reading Reddit post comments when reading Reddit feed.\n",
            "‚ö° EmbedFacets has been renamed to EnableFacets in the conversation strategy.\n",
            "‚ö° Removed extra content level in IngestionWorkflowStage type.  Now, the if property is of type IngestionContentFilter.\n",
            "Bugs Fixed\n",
            "GPLA-1556: Better handling of very long user prompts.\n",
            "GPLA-1627: Optimized token budget for more accurate prompt completion.\n",
            "GPLA-1585: More accurate entity matching in Wikipedia entity enrichment.\n",
            "PreviousDecember 10: Support for OpenAI GPT-4 Turbo, Llama 2 and Mistral models; query by example, bug fixes\n",
            "NextOctober 15: Support for Anthropic Claude models, Slack feeds and entity enrichment\n",
            "Last updated1 year ago\n",
            "- Completion [290 tokens (includes JSON guardrails tokens)], throughput: 71.658 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for 'aliases' of observable names via the alternateNames property, allowing original and enriched names to be stored together.\n",
            "  - Workflows filter added to ContentCriteriaInput type for filtering content by workflow(s) in conversations.\n",
            "  - Optimized formatting of content sources and extracted text from Slack messages for improved conversation responses and knowledge retrieval.\n",
            "  - Updated text tokenizer for better token counting.\n",
            "  - Upgraded Azure Text Analytics to the latest preview API version.\n",
            "  - Authors in RSS feeds are now stored as observations of Person entities.\n",
            "  - Rate limiting added for Reddit feeds and Wikipedia enrichment.\n",
            "  - Support for reading Reddit post comments from Reddit feeds.\n",
            "  - EmbedFacets renamed to EnableFacets in conversation strategy.\n",
            "  - Removed extra content level in IngestionWorkflowStage type; if property is now of type IngestionContentFilter.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Better handling of long user prompts.\n",
            "  - Optimized token budget for more accurate prompt completion.\n",
            "  - Improved entity matching in Wikipedia entity enrichment.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Addressed issues with long user prompts for better handling.\n",
            "  - Enhanced token budget optimization for improved prompt completion accuracy.\n",
            "  - Fixed entity matching for more accurate Wikipedia enrichment.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: October 2023.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers improved conversation accuracy, better content filtering, and enhanced entity recognition capabilities.\n",
            "\n",
            "2024-12-30T03:59:42.902Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:03.978112, used credits [0.00416700]\n",
            "- CONTENT [efb60fde-e52e-4726-893f-d58347a0deeb]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [597 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/october-2024/october-22-support-for-latest-anthropic-sonnet-3.5-model-cohere-image-embeddings</name><title>October 22: Support for latest Anthropic Sonnet 3.5 model, Cohere image embeddings | Graphlit Changelog</title></metadata> üéÉ\tOctober 2024\n",
            "October 22: Support for latest Anthropic Sonnet 3.5 model, Cohere image embeddings\n",
            "New Features\n",
            "Graphlit now supports the latest Anthropic Sonnet 3.5 model (released 10/22/2024).  We have added date-versions model enums for the Anthropic models: CLAUDE_3_5_SONNET_20240620, CLAUDE_3_5_SONNET_20241022, CLAUDE_3_HAIKU_20240307, CLAUDE_3_OPUS_20240229, CLAUDE_3_SONNET_20240229. The existing model enums will target the latest released models, as specified by Anthropic.\n",
            "Graphlit now supports image embeddings using the Cohere Embed 3.0 models.\n",
            "PreviousOctober 31: Support for simulated tool calling, bug fixes\n",
            "NextOctober 21: Support OpenAI, Cohere, Jina, Mistral, Voyage and Google AI embedding models\n",
            "Last updated2 months ago\n",
            "- Completion [198 tokens (includes JSON guardrails tokens)], throughput: 49.772 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for the latest Anthropic Sonnet 3.5 model (released 10/22/2024).\n",
            "  - Added date-version model enums for Anthropic models: \n",
            "    - CLAUDE_3_5_SONNET_20240620\n",
            "    - CLAUDE_3_5_SONNET_20241022\n",
            "    - CLAUDE_3_HAIKU_20240307\n",
            "    - CLAUDE_3_OPUS_20240229\n",
            "    - CLAUDE_3_SONNET_20240229\n",
            "  - Support for image embeddings using Cohere Embed 3.0 models.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - Existing model enums now target the latest released models as specified by Anthropic.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: October 22, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers access to the latest AI models and enhanced image embedding capabilities.\n",
            "\n",
            "2024-12-30T03:59:42.676Z: Prompt completion\n",
            "- Workflow [Enrichment] took 0:00:03.748715, used credits [0.00427500]\n",
            "- CONTENT [6a1f0635-0338-4b77-85c2-a476edc6cde9]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [689 tokens (includes RAG context tokens)]:\n",
            "<metadata type='Page'><name>https://changelog.graphlit.dev/september-2024/september-3-support-for-web-search-feeds-model-deprecations</name><title>September 3: Support for web search feeds, model deprecations | Graphlit Changelog</title></metadata> üéí\tSeptember 2024\n",
            "September 3: Support for web search feeds, model deprecations\n",
            "New Features\n",
            "üí° Graphlit now supports web search feeds, using the Tavily and Exa.AI web search APIs. You can choose the SEARCH feed type, and assign your search text property, and we will ingest the referenced web pages from the search results.  Optionally, you can select the search service via the serviceType property under search feed properties.  By default, Graphlit will use the Tavily API.\n",
            "‚ö° We have deprecated these OpenAI models, according to the future support OpenAI is providing to these legacy models: GPT35_TURBO, GPT35_TURBO_0613, GPT35_TURBO_16K, GPT35_TURBO_16K_0125, GPT35_TURBO_16K_0613, GPT35_TURBO_16K_1106, GPT4, GPT4_0613, GPT4_32K, GPT4_32K_0613, GPT4_TURBO_VISION_128K, and GPT4_TURBO_VISION_128K_1106.  We suggest using GPT-4o or GPT-4o Mini instead.\n",
            "Bugs Fixed\n",
            "GPLA-2523: Can't ingest from same feed URI multiple times and wait on isFeedDone\n",
            "PreviousSeptember 26: Support for Google AI and Cerebras models, and latest Groq models\n",
            "NextSeptember 1: Support for FHIR enrichment, latest Cohere models, bug fixes\n",
            "Last updated3 months ago\n",
            "- Completion [184 tokens (includes JSON guardrails tokens)], throughput: 49.083 tokens/sec:\n",
            "- New Features:\n",
            "  - Support for web search feeds using Tavily and Exa.AI APIs.\n",
            "  - Ability to choose SEARCH feed type and assign search text property for ingesting web pages from search results.\n",
            "  - Option to select search service via serviceType property, defaulting to Tavily API.\n",
            "  - Deprecation of several OpenAI models (e.g., GPT35_TURBO, GPT4) with a recommendation to use GPT-4o or GPT-4o Mini.\n",
            "\n",
            "- Enhancements/Improvements:\n",
            "  - None specified.\n",
            "\n",
            "- Bug Fixes:\n",
            "  - Fixed issue GPLA-2523: Ingestion from the same feed URI multiple times and waiting on isFeedDone.\n",
            "\n",
            "- Other Key Details:\n",
            "  - Release Date: September 3, 2024.\n",
            "\n",
            "- Value:\n",
            "  - Offers developers enhanced capabilities for web search integration and guidance on model usage moving forward.\n",
            "\n",
            "2024-12-30T03:59:37.433Z: Search entities\n",
            "- Workflow [Semantic search] took 0:00:00.107828, used credits [0.00960000]\n",
            "- Processor name [Azure AI Search], units [48]\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}