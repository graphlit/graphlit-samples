{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1cSnEIDnT7SYyUpfap5KiK6Y_LWLQdk6s",
      "authorship_tag": "ABX9TyMMOeSNzKzQSUTSPCcCifzk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/graphlit/graphlit-samples/blob/main/python/Notebook%20Examples/Graphlit_2024_09_26_Analyze_Costs_%26_Usage.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Description**\n",
        "\n",
        "This example shows how to analyze the credit usage and individual usage logs from a Graphlit preparation workflow and RAG conversation."
      ],
      "metadata": {
        "id": "pDz1gRPjOtn5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Requirements**\n",
        "\n",
        "Prior to running this notebook, you will need to [signup](https://docs.graphlit.dev/getting-started/signup) for Graphlit, and [create a project](https://docs.graphlit.dev/getting-started/create-project).\n",
        "\n",
        "You will need the Graphlit organization ID, preview environment ID and JWT secret from your created project.\n",
        "\n",
        "Assign these properties as Colab secrets: GRAPHLIT_ORGANIZATION_ID, GRAPHLIT_ENVIRONMENT_ID and GRAPHLIT_JWT_SECRET.\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "laG2MXUIhNnx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install Graphlit Python client SDK"
      ],
      "metadata": {
        "id": "NwRzDHWWienC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "fefizrrh4xGD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a6a6724-5eed-4d76-8e12-65c578f70614"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: graphlit-client in /usr/local/lib/python3.10/dist-packages (1.0.20240914001)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from graphlit-client) (0.27.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from graphlit-client) (2.9.2)\n",
            "Requirement already satisfied: PyJWT in /usr/local/lib/python3.10/dist-packages (from graphlit-client) (2.9.0)\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.10/dist-packages (from graphlit-client) (13.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->graphlit-client) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->graphlit-client) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->graphlit-client) (4.12.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->graphlit-client) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->graphlit-client) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->graphlit-client) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->graphlit-client) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->graphlit-client) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->graphlit-client) (0.14.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->graphlit-client) (1.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade graphlit-client"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade isodate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfT9rOE8B5aA",
        "outputId": "b8d2c438-f4aa-4dd1-d920-494446f39f45"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: isodate in /usr/local/lib/python3.10/dist-packages (0.6.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from isodate) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize Graphlit"
      ],
      "metadata": {
        "id": "abV1114jL-bR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from graphlit import Graphlit\n",
        "from graphlit_api import input_types, enums, exceptions\n",
        "\n",
        "os.environ['GRAPHLIT_ORGANIZATION_ID'] = userdata.get('GRAPHLIT_ORGANIZATION_ID')\n",
        "os.environ['GRAPHLIT_ENVIRONMENT_ID'] = userdata.get('GRAPHLIT_ENVIRONMENT_ID')\n",
        "os.environ['GRAPHLIT_JWT_SECRET'] = userdata.get('GRAPHLIT_JWT_SECRET')\n",
        "\n",
        "graphlit = Graphlit()"
      ],
      "metadata": {
        "id": "WoMAWD4LLP_q"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Graphlit helper functions"
      ],
      "metadata": {
        "id": "pgRX57EHMVfl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Optional\n",
        "from datetime import datetime, timedelta\n",
        "import isodate\n",
        "\n",
        "async def ingest_uri(uri: str, correlation_id: str):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    try:\n",
        "        # Using synchronous mode, so the notebook waits for the content to be ingested\n",
        "        response = await graphlit.client.ingest_uri(uri=uri, is_synchronous=True, correlation_id=correlation_id)\n",
        "\n",
        "        return response.ingest_uri.id if response.ingest_uri is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "async def create_anthropic_specification(model: enums.AnthropicModels):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    input = input_types.SpecificationInput(\n",
        "        name=f\"Anthropic [{str(model)}]\",\n",
        "        type=enums.SpecificationTypes.COMPLETION,\n",
        "        serviceType=enums.ModelServiceTypes.ANTHROPIC,\n",
        "        anthropic=input_types.AnthropicModelPropertiesInput(\n",
        "            model=model,\n",
        "        ),\n",
        "        promptStrategy=input_types.PromptStrategyInput(\n",
        "            type=enums.PromptStrategyTypes.OPTIMIZE_SEARCH\n",
        "        ),\n",
        "        retrievalStrategy=input_types.RetrievalStrategyInput(\n",
        "            type=enums.RetrievalStrategyTypes.SECTION\n",
        "        ),\n",
        "        rerankingStrategy=input_types.RerankingStrategyInput(\n",
        "            serviceType=enums.RerankingModelServiceTypes.COHERE\n",
        "        )\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.create_specification(input)\n",
        "\n",
        "        return response.create_specification.id if response.create_specification is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "    return None\n",
        "\n",
        "async def create_conversation(specification_id: str):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    input = input_types.ConversationInput(\n",
        "        name=\"Conversation\",\n",
        "        specification=input_types.EntityReferenceInput(\n",
        "            id=specification_id\n",
        "        )\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.create_conversation(input)\n",
        "\n",
        "        return response.create_conversation.id if response.create_conversation is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "async def delete_conversation(conversation_id: str):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    if conversation_id is not None:\n",
        "        _ = await graphlit.client.delete_conversation(conversation_id)\n",
        "\n",
        "async def prompt_conversation(conversation_id: str, prompt: str, correlation_id: str):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.prompt_conversation(prompt, conversation_id, correlation_id)\n",
        "\n",
        "        return response.prompt_conversation.message.message if response.prompt_conversation is not None and response.prompt_conversation.message is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "async def lookup_usage(correlation_id: str):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.lookup_usage(correlation_id)\n",
        "\n",
        "        return response.lookup_usage if response.lookup_usage is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "async def lookup_credits(correlation_id: str):\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    try:\n",
        "        response = await graphlit.client.lookup_credits(correlation_id)\n",
        "\n",
        "        return response.lookup_credits if response.lookup_credits is not None else None\n",
        "    except exceptions.GraphQLClientError as e:\n",
        "        print(str(e))\n",
        "        return None\n",
        "\n",
        "async def delete_all_specifications():\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    _ = await graphlit.client.delete_all_specifications(is_synchronous=True)\n",
        "\n",
        "async def delete_all_conversations():\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    _ = await graphlit.client.delete_all_conversations(is_synchronous=True)\n",
        "\n",
        "async def delete_all_contents():\n",
        "    if graphlit.client is None:\n",
        "        return;\n",
        "\n",
        "    _ = await graphlit.client.delete_all_contents(is_synchronous=True)\n",
        "\n",
        "def dump_usage_record(record):\n",
        "    print(f\"{record.date}: {record.name}\")\n",
        "\n",
        "    duration = isodate.parse_duration(record.duration)\n",
        "\n",
        "    if record.workflow:\n",
        "        print(f\"- Workflow [{record.workflow}] took {duration}, used credits [{record.credits:.8f}]\")\n",
        "    else:\n",
        "        print(f\"- Operation took {duration}, used credits [{record.credits:.8f}]\")\n",
        "\n",
        "    if record.entity_id:\n",
        "        if record.entity_type:\n",
        "            if record.entity_type == enums.EntityTypes.CONTENT and record.content_type:\n",
        "                print(f\"- {record.entity_type} [{record.entity_id}]: Content type [{record.content_type}], file type [{record.file_type}]\")\n",
        "            else:\n",
        "                print(f\"- {record.entity_type} [{record.entity_id}]\")\n",
        "        else:\n",
        "            print(f\"- Entity [{record.entity_id}]\")\n",
        "\n",
        "    if record.model_service:\n",
        "        print(f\"- Model service [{record.model_service}], model name [{record.model_name}]\")\n",
        "\n",
        "    if record.processor_name:\n",
        "        if record.processor_name in [\"Deepgram Audio Transcription\", \"Assembly.AI Audio Transcription\"]:\n",
        "            length = timedelta(milliseconds=record.count or 0)\n",
        "\n",
        "            if record.model_name:\n",
        "                print(f\"- Processor name [{record.processor_name}], model name [{record.model_name}], length [{length}]\")\n",
        "            else:\n",
        "                print(f\"- Processor name [{record.processor_name}], length [{length}]\")\n",
        "        else:\n",
        "            if record.count:\n",
        "                if record.model_name:\n",
        "                    print(f\"- Processor name [{record.processor_name}], model name [{record.model_name}], units [{record.count}]\")\n",
        "                else:\n",
        "                    print(f\"- Processor name [{record.processor_name}], units [{record.count}]\")\n",
        "            else:\n",
        "                if record.model_name:\n",
        "                    print(f\"- Processor name [{record.processor_name}], model name [{record.model_name}]\")\n",
        "                else:\n",
        "                    print(f\"- Processor name [{record.processor_name}]\")\n",
        "\n",
        "    if record.uri:\n",
        "        print(f\"- URI [{record.uri}]\")\n",
        "\n",
        "    if record.name == \"Prompt completion\":\n",
        "        if record.prompt:\n",
        "            print(f\"- Prompt [{record.prompt_tokens} tokens (includes RAG context tokens)]:\")\n",
        "            print(record.prompt)\n",
        "\n",
        "        if record.completion:\n",
        "            print(f\"- Completion [{record.completion_tokens} tokens (includes JSON guardrails tokens)], throughput: {record.throughput:.3f} tokens/sec:\")\n",
        "            print(record.completion)\n",
        "\n",
        "    elif record.name == \"Text embedding\":\n",
        "        if record.prompt_tokens is not None:\n",
        "            print(f\"- Text embedding [{record.prompt_tokens} tokens], throughput: {record.throughput:.3f} tokens/sec\")\n",
        "\n",
        "    elif record.name == \"Document preparation\":\n",
        "        if record.prompt_tokens is not None and record.completion_tokens is not None:\n",
        "            print(f\"- Document preparation [{record.prompt_tokens} input tokens, {record.completion_tokens} output tokens], throughput: {record.throughput:.3f} tokens/sec\")\n",
        "\n",
        "    elif record.name == \"Data extraction\":\n",
        "        if record.prompt_tokens is not None and record.completion_tokens is not None:\n",
        "            print(f\"- Data extraction [{record.prompt_tokens} input tokens, {record.completion_tokens} output tokens], throughput: {record.throughput:.3f} tokens/sec\")\n",
        "\n",
        "    elif record.name == \"GraphQL\":\n",
        "        if record.request:\n",
        "            print(f\"- Request:\")\n",
        "            print(record.request)\n",
        "\n",
        "        if record.variables:\n",
        "            print(f\"- Variables:\")\n",
        "            print(record.variables)\n",
        "\n",
        "        if record.response:\n",
        "            print(f\"- Response:\")\n",
        "            print(record.response)\n",
        "\n",
        "    if record.name.startswith(\"Upload\"):\n",
        "        print(f\"- File upload [{record.count} bytes], throughput: {record.throughput:.3f} bytes/sec\")\n",
        "\n",
        "    print()\n"
      ],
      "metadata": {
        "id": "mtwjJsvVOVCh"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Execute Graphlit example"
      ],
      "metadata": {
        "id": "srzhQt4COLVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown, HTML\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "# Remove any existing contents, conversations and specifications; only needed for notebook example\n",
        "await delete_all_conversations()\n",
        "await delete_all_specifications()\n",
        "await delete_all_contents()\n",
        "\n",
        "print('Deleted all contents, conversations and specifications.')\n",
        "\n",
        "# NOTE: create a unique cost correlation ID\n",
        "correlation_id = datetime.now().isoformat()\n",
        "\n",
        "content_id = await ingest_uri(uri=\"https://graphlitplatform.blob.core.windows.net/samples/Unstructured%20Data%20is%20Dark%20Data%20Podcast.mp3\", correlation_id=correlation_id)\n",
        "\n",
        "if content_id is not None:\n",
        "    print(f'Ingested content [{content_id}]:')"
      ],
      "metadata": {
        "id": "fOb6COcONZIJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09afccc6-9ba3-4ea2-caba-2417bbd1ffda"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleted all contents, conversations and specifications.\n",
            "Ingested content [bd8c5c18-a06d-40b6-a59b-b6c9901eb484]:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    # Specify the RAG prompt\n",
        "    prompt = \"In 3-5 detailed paragraphs, explain unstructured data and its usefulness for knowledge capture and retrieval.\""
      ],
      "metadata": {
        "id": "-9kBDUIdbhIy"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prompt conversation with Anthropic Sonnet 3.5."
      ],
      "metadata": {
        "id": "kqG9WHXhbld-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    specification_id = await create_anthropic_specification(enums.AnthropicModels.CLAUDE_3_5_SONNET)\n",
        "\n",
        "    if specification_id is not None:\n",
        "        print(f'Created specification [{specification_id}].')\n",
        "\n",
        "        conversation_id = await create_conversation(specification_id)\n",
        "\n",
        "        if conversation_id is not None:\n",
        "            print(f'Created conversation [{conversation_id}].')\n",
        "\n",
        "            message = await prompt_conversation(conversation_id, prompt, correlation_id)\n",
        "\n",
        "            if message is not None:\n",
        "                display(Markdown('### Conversation:'))\n",
        "                display(Markdown(f'**User:**\\n{prompt}'))\n",
        "                display(Markdown(f'**Assistant:**\\n{message}'))\n",
        "                print()\n",
        "\n",
        "            await delete_conversation(conversation_id)\n",
        "\n",
        "time.sleep(5) # NOTE: give it a little time for all usage records to be processed, so we report on all the credits\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "id": "uSwSy3gXq7AN",
        "outputId": "ed45750a-ffad-4d33-fb1e-20dfcff7118e"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created specification [ceb3f551-cfd5-408f-8a16-664a45ea438c].\n",
            "Created conversation [0c7dec61-53be-46f0-94fe-caf3d06ddcac].\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Conversation:"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**User:**\nIn 3-5 detailed paragraphs, explain unstructured data and its usefulness for knowledge capture and retrieval."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Assistant:**\nUnstructured data encompasses a wide range of file-based information, including images, audio, 3D geometry, point clouds, documents, and emails. While the term 'unstructured' may be somewhat of a misnomer, as these files do have defined structures and formats, it refers to data that is not organized in a traditional database format. This type of data is increasingly valuable for businesses and organizations, as it often contains rich, contextual information about real-world assets and events that can be difficult to capture in structured formats.\n\nThe value of unstructured data lies in its ability to provide deep insights when properly analyzed and contextualized. By applying advanced techniques such as machine learning and natural language processing, organizations can extract meaningful information from diverse sources like images, audio recordings, and text documents. This process allows for the creation of knowledge graphs that connect disparate pieces of information, revealing patterns, trends, and relationships that might otherwise remain hidden. The ability to search across years of data and identify commonalities or changes over time is particularly powerful for decision-making and strategic planning.\n\nOne of the key challenges in working with unstructured data is effective management and retrieval. Many organizations struggle with 'dark data' - information that has been collected but is not being utilized effectively. By implementing systems that can parse, index, and contextualize unstructured data, businesses can unlock the value of their historical archives and current data streams. This approach enables more comprehensive analytics, improved search capabilities, and the ability to derive actionable insights from a broader range of information sources, ultimately leading to more informed decision-making and innovative problem-solving."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, HTML, JSON\n",
        "\n",
        "credits = await lookup_credits(correlation_id)\n",
        "\n",
        "if credits is not None:\n",
        "    display(Markdown(f\"### Credits used: {credits.credits:.6f}\"))\n",
        "    print(f\"- storage [{credits.storage_ratio:.2f}%], compute [{credits.compute_ratio:.2f}%]\")\n",
        "    print(f\"- embedding [{credits.embedding_ratio:.2f}%], completion [{credits.completion_ratio:.2f}%]\")\n",
        "    print(f\"- ingestion [{credits.ingestion_ratio:.2f}%], indexing [{credits.indexing_ratio:.2f}%], preparation [{credits.preparation_ratio:.2f}%], extraction [{credits.extraction_ratio:.2f}%], enrichment [{credits.enrichment_ratio:.2f}%], publishing [{credits.publishing_ratio:.2f}%]\")\n",
        "    print(f\"- search [{credits.search_ratio:.2f}%], conversation [{credits.conversation_ratio:.2f}%]\")\n",
        "    print()\n",
        "\n",
        "usage = await lookup_usage(correlation_id)\n",
        "\n",
        "if usage is not None:\n",
        "    display(Markdown(f\"### Usage records:\"))\n",
        "\n",
        "    for record in usage:\n",
        "        dump_usage_record(record)\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Wnmfn5hMBCKK",
        "outputId": "b7d2c7d3-5cfb-4f49-be53-e6172ca0d34f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Credits used: 5.194996"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- storage [5.13%], compute [7.81%]\n",
            "- embedding [0.83%], completion [0.00%]\n",
            "- ingestion [0.00%], indexing [0.00%], preparation [76.81%], extraction [0.00%], enrichment [0.00%], publishing [0.00%]\n",
            "- search [0.38%], conversation [9.04%]\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### Usage records:"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-09-27T05:00:53.738Z: Serverless compute\n",
            "- Workflow [Entity Event] took 0:00:00.312238, used credits [0.00572784]\n",
            "\n",
            "2024-09-27T05:00:53.573Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.090259, used credits [0.00069000]\n",
            "- CONVERSATION [0c7dec61-53be-46f0-94fe-caf3d06ddcac]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [345 tokens], throughput: 3822.342 tokens/sec\n",
            "\n",
            "2024-09-27T05:00:53.572Z: GraphQL\n",
            "- Operation took 0:00:10.635036, used credits [0.19509383]\n",
            "- Request:\n",
            "mutation PromptConversation($prompt: String!, $id: ID, $correlationId: String) { promptConversation(prompt: $prompt, id: $id, correlationId: $correlationId) { conversation { id } message { role author message citations { content { id name state originalDate identifier uri type fileType mimeType format formatName fileExtension fileName fileSize masterUri imageUri textUri audioUri transcriptUri summary customSummary keywords bullets headlines posts chapters questions video { width height duration make model software title description keywords author } audio { keywords author series episode episodeType season publisher copyright genre title description bitrate channels sampleRate bitsPerSample duration } image { width height resolutionX resolutionY bitsPerComponent components projectionType orientation description make model software lens focalLength exposureTime fNumber iso heading pitch } document { title subject summary author publisher description keywords pageCount worksheetCount slideCount wordCount lineCount paragraphCount isEncrypted hasDigitalSignature } } index text startTime endTime pageNumber frameNumber } tokens throughput completionTime timestamp modelService model } messageCount facets { type value range { from to } count facet observable { type observable { id name } } } graph { nodes { id name type metadata } edges { from to relation } } } }\n",
            "- Variables:\n",
            "{\"prompt\":\"\\\"In 3-5 detailed paragraphs, explain unstructured data and its usefulness for knowledge capture and retrieval.\\\"\",\"id\":\"\\\"0c7dec61-53be-46f0-94fe-caf3d06ddcac\\\"\",\"correlationId\":\"\\\"2024-09-27T05:00:20.799363\\\"\"}\n",
            "- Response:\n",
            "{\"data\":{\"promptConversation\":{\"conversation\":{\"id\":\"0c7dec61-53be-46f0-94fe-caf3d06ddcac\"},\"message\":{\"role\":\"ASSISTANT\",\"author\":null,\"message\":\"Unstructured data encompasses a wide range of file-based information, including images, audio, 3D geometry, point clouds, documents, and emails. While the term 'unstructured' may be somewhat of a misnomer, as these files do have defined structures and formats, it refers to data that is not organized in a traditional database format. This type of data is increasingly valuable for businesses and organizations, as it often contains rich, contextual information about real-world assets and events that can be difficult to capture in structured formats.\\n\\nThe value of unstructured data lies in its ability to provide deep insights when properly analyzed and contextualized. By applying advanced techniques such as machine learning and natural language processing, organizations can extract meaningful information from diverse sources like images, audio recordings, and text documents. This process allows for the creation of knowledge graphs that connect disparate pieces of information, revealing patterns, trends, and relationships that might otherwise remain hidden. The ability to search across years of data and identify commonalities or changes over time is particularly powerful for decision-making and strategic planning.\\n\\nOne of the key challenges in working with unstructured data is effective management and retrieval. Many organizations struggle with 'dark data' - information that has been collected but is not being utilized effectively. By implementing systems that can parse, index, and contextualize unstructured data, businesses can unlock the value of their historical archives and current data streams. This approach enables more comprehensive analytics, improved search capabilities, and the ability to derive actionable insights from a broader range of information sources, ultimately leading to more informed decision-making and innovative problem-solving.\",\"citations\":null,\"tokens\":389,\"throughput\":57.95856897998685,\"completionTime\":\"PT6.7116909S\",\"timestamp\":\"2024-09-27T05:00:53.278Z\",\"modelService\":\"ANTHROPIC\",\"model\":\"Claude 3.5 Sonnet (Latest)\"},\"messageCount\":2,\"facets\":null,\"graph\":null}}}\n",
            "\n",
            "2024-09-27T05:00:53.274Z: Prompt completion\n",
            "- Workflow [Conversation] took 0:00:06.711691, used credits [0.29907000]\n",
            "- CONVERSATION [0c7dec61-53be-46f0-94fe-caf3d06ddcac]\n",
            "- Model service [Anthropic], model name [Claude_3_5_Sonnet]\n",
            "- Prompt [4701 tokens (includes RAG context tokens)]:\n",
            "In 3-5 detailed paragraphs, explain unstructured data and its usefulness for knowledge capture and retrieval.\n",
            "- Completion [389 tokens (includes JSON guardrails tokens)], throughput: 57.959 tokens/sec:\n",
            "Unstructured data encompasses a wide range of file-based information, including images, audio, 3D geometry, point clouds, documents, and emails. While the term 'unstructured' may be somewhat of a misnomer, as these files do have defined structures and formats, it refers to data that is not organized in a traditional database format. This type of data is increasingly valuable for businesses and organizations, as it often contains rich, contextual information about real-world assets and events that can be difficult to capture in structured formats.\n",
            "\n",
            "The value of unstructured data lies in its ability to provide deep insights when properly analyzed and contextualized. By applying advanced techniques such as machine learning and natural language processing, organizations can extract meaningful information from diverse sources like images, audio recordings, and text documents. This process allows for the creation of knowledge graphs that connect disparate pieces of information, revealing patterns, trends, and relationships that might otherwise remain hidden. The ability to search across years of data and identify commonalities or changes over time is particularly powerful for decision-making and strategic planning.\n",
            "\n",
            "One of the key challenges in working with unstructured data is effective management and retrieval. Many organizations struggle with 'dark data' - information that has been collected but is not being utilized effectively. By implementing systems that can parse, index, and contextualize unstructured data, businesses can unlock the value of their historical archives and current data streams. This approach enables more comprehensive analytics, improved search capabilities, and the ability to derive actionable insights from a broader range of information sources, ultimately leading to more informed decision-making and innovative problem-solving.\n",
            "\n",
            "2024-09-27T05:00:46.530Z: Content reranking\n",
            "- Workflow [Conversation] took 0:00:00.297880, used credits [0.01500000]\n",
            "- CONVERSATION [0c7dec61-53be-46f0-94fe-caf3d06ddcac]\n",
            "- Model service [Cohere], model name [Rerank_3_0]\n",
            "\n",
            "2024-09-27T05:00:45.394Z: Search entities\n",
            "- Workflow [Semantic search] took 0:00:00.323014, used credits [0.01522500]\n",
            "- Processor name [Azure AI Search], units [87]\n",
            "\n",
            "2024-09-27T05:00:45.261Z: Text embedding\n",
            "- Workflow [Semantic search] took 0:00:00.164143, used credits [0.00002450]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [14 tokens], throughput: 85.291 tokens/sec\n",
            "\n",
            "2024-09-27T05:00:45.068Z: Prompt completion\n",
            "- Workflow [Conversation] took 0:00:00.534759, used credits [0.00042525]\n",
            "- CONVERSATION [0c7dec61-53be-46f0-94fe-caf3d06ddcac]\n",
            "- Model service [OpenAI], model name [GPT4o_Mini_128k]\n",
            "- Prompt [133 tokens (includes RAG context tokens)]:\n",
            "Rewrite the following user prompt into comma-delimited key words or phrases, which will be used as a search query for relevant content.\n",
            "Ignore any formatting instructions, which appear unrelated to the question. For example, ignore 'Return the accomplishments as a bulleted list.'\n",
            "You are not to answer the prompt, just rewrite it.\n",
            "Don't preface your response with anything similar to 'Here is the rewritten user prompt'. Only return the rewritten user prompt as your response, as plain text.\n",
            "\n",
            "<user-prompt>\n",
            "In 3-5 detailed paragraphs, explain unstructured data and its usefulness for knowledge capture and retrieval.\n",
            "</user-prompt>\n",
            "\n",
            "- Completion [14 tokens (includes JSON guardrails tokens)], throughput: 26.180 tokens/sec:\n",
            "unstructured data, usefulness, knowledge capture, knowledge retrieval, detailed explanation\n",
            "\n",
            "2024-09-27T05:00:41.931Z: GraphQL\n",
            "- Operation took 0:00:21.087931, used credits [0.38684638]\n",
            "- Request:\n",
            "mutation IngestUri($name: String, $uri: URL!, $id: ID, $isSynchronous: Boolean, $workflow: EntityReferenceInput, $collections: [EntityReferenceInput!], $correlationId: String) { ingestUri(name: $name, uri: $uri, id: $id, workflow: $workflow, collections: $collections, isSynchronous: $isSynchronous, correlationId: $correlationId) { id name state type fileType mimeType uri collections { id name } } }\n",
            "- Variables:\n",
            "{\"uri\":\"\\\"https:\\\\/\\\\/graphlitplatform.blob.core.windows.net\\\\/samples\\\\/Unstructured%20Data%20is%20Dark%20Data%20Podcast.mp3\\\"\",\"isSynchronous\":\"true\",\"correlationId\":\"\\\"2024-09-27T05:00:20.799363\\\"\"}\n",
            "- Response:\n",
            "{\"data\":{\"ingestUri\":{\"id\":\"bd8c5c18-a06d-40b6-a59b-b6c9901eb484\",\"name\":\"Unstructured Data is Dark Data Podcast.mp3\",\"state\":\"FINISHED\",\"type\":\"FILE\",\"fileType\":\"AUDIO\",\"mimeType\":\"audio/mp3\",\"uri\":\"https://graphlitplatform.blob.core.windows.net/samples/Unstructured%20Data%20is%20Dark%20Data%20Podcast.mp3\",\"collections\":null}}}\n",
            "\n",
            "2024-09-27T05:00:39.032Z: Serverless compute\n",
            "- Workflow [Entity Event] took 0:00:17.370131, used credits [0.31864541]\n",
            "- CONTENT [bd8c5c18-a06d-40b6-a59b-b6c9901eb484]\n",
            "\n",
            "2024-09-27T05:00:38.611Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.866816, used credits [0.01648000]\n",
            "- CONTENT [bd8c5c18-a06d-40b6-a59b-b6c9901eb484]: Content type [FILE], file type [AUDIO]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [8240 tokens], throughput: 9506.055 tokens/sec\n",
            "\n",
            "2024-09-27T05:00:38.338Z: Text embedding\n",
            "- Workflow [Preparation] took 0:00:00.576409, used credits [0.02149200]\n",
            "- CONTENT [bd8c5c18-a06d-40b6-a59b-b6c9901eb484]: Content type [FILE], file type [AUDIO]\n",
            "- Model service [OpenAI], model name [Ada_002]\n",
            "- Text embedding [10746 tokens], throughput: 18642.999 tokens/sec\n",
            "\n",
            "2024-09-27T05:00:36.590Z: Upload Transcript\n",
            "- Workflow [Preparation] took 0:00:00.045167, used credits [0.00049124]\n",
            "- CONTENT [bd8c5c18-a06d-40b6-a59b-b6c9901eb484]: Content type [FILE], file type [DATA]\n",
            "- File upload [90970 bytes], throughput: 2014094.455 bytes/sec\n",
            "\n",
            "2024-09-27T05:00:36.347Z: Processed Transcript\n",
            "- Workflow [Preparation] took 0:00:05.823431, used credits [3.56329533]\n",
            "- CONTENT [bd8c5c18-a06d-40b6-a59b-b6c9901eb484]: Content type [FILE], file type [DATA]\n",
            "- Processor name [Deepgram Audio Transcription], model name [nova-2-general], length [0:41:26.020000]\n",
            "\n",
            "2024-09-27T05:00:29.890Z: Upload Mezzanine\n",
            "- Workflow [Preparation] took 0:00:00.661249, used credits [0.17824452]\n",
            "- CONTENT [bd8c5c18-a06d-40b6-a59b-b6c9901eb484]: Content type [FILE], file type [AUDIO]\n",
            "- File upload [33008244 bytes], throughput: 49918032.378 bytes/sec\n",
            "\n",
            "2024-09-27T05:00:23.212Z: Upload Master\n",
            "- Workflow [Ingestion] took 0:00:01.372877, used credits [0.17824452]\n",
            "- CONTENT [bd8c5c18-a06d-40b6-a59b-b6c9901eb484]: Content type [FILE], file type [AUDIO]\n",
            "- URI [https://graphlitplatform.blob.core.windows.net/samples/Unstructured%20Data%20is%20Dark%20Data%20Podcast.mp3]\n",
            "- File upload [33008244 bytes], throughput: 24043125.216 bytes/sec\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}